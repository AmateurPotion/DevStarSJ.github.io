{"meta":{"title":"Dev Star SJ","subtitle":"DevStarSJ","description":"Sharing the common developer's try-on","author":"Yun Seok-joon","url":"http://DevStarSJ.github.io"},"pages":[{"title":"all-archives","date":"2017-04-24T05:03:20.000Z","updated":"2017-03-05T14:32:17.000Z","comments":false,"path":"all-archives/index.html","permalink":"http://DevStarSJ.github.io/all-archives/index.html","excerpt":"","text":""},{"title":"all-tags","date":"2017-04-24T05:03:20.000Z","updated":"2017-03-05T14:25:15.000Z","comments":false,"path":"all-tags/index.html","permalink":"http://DevStarSJ.github.io/all-tags/index.html","excerpt":"","text":""},{"title":"all-categories","date":"2017-04-24T05:03:20.000Z","updated":"2017-03-05T14:23:47.000Z","comments":false,"path":"all-categories/index.html","permalink":"http://DevStarSJ.github.io/all-categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Using Partial View as a Component","slug":"ASPNET.UsingPartialViewAsaComponent","date":"2017-05-24T06:20:00.000Z","updated":"2017-05-24T06:46:36.000Z","comments":true,"path":"2017/05/24/ASPNET.UsingPartialViewAsaComponent/","link":"","permalink":"http://DevStarSJ.github.io/2017/05/24/ASPNET.UsingPartialViewAsaComponent/","excerpt":"","text":"Using Partial View as a ComponentPartial View를 이용해서 View의 특정부분을 분리하여 관리가 가능하다.Partial View안에 관련 코드들(script, html…) 들을 모아놓고 그 중 특정 부분만 사용하는 것도 가능하다.이걸 이용하면 관련된 기능들을 하나의 Partial View에 넣어두고 관리하는게 가능해진다. 예를 들어서 여러 개의 버튼들을 모아놓은 html 해당 버튼을 눌렀을때 동작하는 script 버튼을 눌렀을때 pop-up 처럼보이게 visible처리되는 div 들… 위 3개의 코드들을 각각 별게의 위치에서 불러와야 하는 경우에도 1개의 Parial View 파일에 넣어둘 수 있는 방법이 있다. _ButtonComponents.cshtml123456789101112131415161718192021222324252627282930313233343536373839@&#123; var section = ViewData[\"section\"] as string; ...&#125;@if (section == \"button\") &#123; @Model.status &lt;button id=\"btn_ok\"&gt; ... &lt;/button&gt; &lt;button id=\"btn_select\"&gt; ... &lt;/button&gt;&#125;@if (section == \"script\") &#123; &lt;script type=\"text/javascript\"&gt; ... &lt;/script&gt;&#125;@if (section == \"popup\") &#123; &lt;div id=\"statusModal\" class=\"modal\" style=\"width:300px; top: 400px;\"&gt; &lt;div class=\"modal-content\"&gt; &lt;div class=\"modal-header\"&gt; &lt;h3&gt;선택&lt;/h3&gt; &lt;/div&gt; &lt;select id=\"select\" style=\"display: inline-block; width: 280px;\"&gt; &lt;option value=\"\" selected&gt;선택&lt;/option&gt; &lt;option value=\"1\"&gt;1&lt;/option&gt; &lt;option value=\"2\"&gt;확2&lt;/option&gt; &lt;/select&gt; &lt;div class=\"btn-group align-right\"&gt; &lt;button id=\"select_ok\"&gt;확인&lt;/button&gt; &lt;button id=\"select_cancel\"&gt;취소&lt;/button&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&#125; 위와 같이 선언된 Partial View 를 보면 section값이 script , button, popup인 3개의 영역으로 이루어져 있다. 이제 사용하는 곳에서 section값을 함께 전달하여 원하는 부분의 코드만 불러오면 된다. 123456789101112131415161718192021222324@model Models.SampleViewModel@&#123; ...&#125;@section scripts&#123;&lt;script type=\"text/javascript\"&gt; ...&lt;/script&gt;@Html.Partial(\"_ButtonComponents\", Model, new ViewDataDictionary &#123; &#123; \"section\", \"script\" &#125; &#125; )&#125;...&lt;table&gt; &lt;tr&gt; &lt;td&gt; @Html.Partial(\"_ButtonComponents\", Model, new ViewDataDictionary &#123; &#123; \"section\", \"button\" &#125; &#125; ) &lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;...@Html.Partial(\"_ButtonComponents\", Model, new ViewDataDictionary &#123; &#123; \"section\", \"popup\" &#125; &#125;)","categories":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/categories/C/"},{"name":"ASP.NET","slug":"C/ASP-NET","permalink":"http://DevStarSJ.github.io/categories/C/ASP-NET/"}],"tags":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/tags/C/"}]},{"title":"C# LINQ Outer Join","slug":"CSharp.LinqOuterJoin","date":"2017-05-24T01:30:00.000Z","updated":"2017-05-24T03:25:06.000Z","comments":true,"path":"2017/05/24/CSharp.LinqOuterJoin/","link":"","permalink":"http://DevStarSJ.github.io/2017/05/24/CSharp.LinqOuterJoin/","excerpt":"","text":"C# LINQ Outer JoinLINQ로 outer join 을 하는 방법을 검색해서 나오는 방법들이 대부분 Microsoft 공식 페이지에 나와있는 방법대로 하는 것들인데 문제는 그게 제대로 동작하지 않는다. https://docs.microsoft.com/en-us/dotnet/articles/csharp/linq/perform-left-outer-joins 그래서 더 찾아보니 GroupJoin 과 SelectMany를 활용해서 outer join 과 동일한 결과로 표현이 가능한 방법이 있었다. GroupJoin : Join을 수행하면서 outer table 기준으로 inner table 의 항목들을 Collection으로 만들어 줌. SelectMany : Select를 수행시 IEnumerable한 항목을 풀어서 수행한다.좀 더 쉽게 설명하자면 2중 List가 있을 경우 List안의 List를 풀어서 그냥 List로 만들어 준다.다른 언어의 rx의 FlatMap과 동일한 기능다. 이 둘을 이용해서 inner table을 GroupJoin으로 수행하면서 그 결과 값이 없는 경우 DefaultOfEmpty를 활용해서 생성한 후 SelectMany로 GroupJoin시 생성되었던 Collection을 flat하게 풀어주면 일반적인 형태의 outer join을 한것과 같은 결과를 얻을 수 있다. 예제 SQL문예제에 사용할 SQL 데이터 이다.참고로 Oracle의 EMP, DEPT 테이블의 내용이며, 아래 SQL 문법은 MySQL 용으로 작성되었다. 123456789101112131415161718192021222324252627282930313233343536CREATE TABLE EMP ( EMPNO INT PRIMARY KEY , ENAME VARCHAR(10), JOB VARCHAR(9), MGR INT, HIREDATE DATE, SAL DOUBLE, COMM DOUBLE, DEPTNO INT);INSERT INTO EMP VALUES (7369, 'SMITH', 'CLERK', 7902, '1980-12-17', 800, NULL, 20);INSERT INTO EMP VALUES (7499, 'ALLEN', 'SALESMAN', 7698, '1981-02-20', 1600, 300, 30);INSERT INTO EMP VALUES (7521, 'WARD', 'SALESMAN', 7698, '1981-02-22', 1250, 500, 30);INSERT INTO EMP VALUES (7566, 'JONES', 'MANAGER', 7839, '1981-04-02', 2975, NULL, 20);INSERT INTO EMP VALUES (7654, 'MARTIN', 'SALESMAN', 7698, '1981-09-28', 1250, 1400, 30);INSERT INTO EMP VALUES (7698, 'BLAKE', 'MANAGER', 7839, '1981-05-01', 2850, NULL, 30);INSERT INTO EMP VALUES (7782, 'CLARK', 'MANAGER', 7839, '1981-06-09', 2450, NULL, 10);INSERT INTO EMP VALUES (7788, 'SCOTT', 'ANALYST', 7566, '1982-12-09', 3000, NULL, 20);INSERT INTO EMP VALUES (7839, 'KING', 'PRESIDENT', NULL, '1981-11-17', 5000, NULL, 10);INSERT INTO EMP VALUES (7844, 'TURNER', 'SALESMAN', 7698, '1981-09-08', 1500, NULL, 30);INSERT INTO EMP VALUES (7876, 'ADAMS', 'CLERK', 7788, '1983-01-12', 1100, NULL, 20);INSERT INTO EMP VALUES (7900, 'JAMES', 'CLERK', 7698, '1981-12-03', 950, NULL, 30);INSERT INTO EMP VALUES (7902, 'FORD', 'ANALYST', 7566, '1981-12-03', 3000, NULL, 20);INSERT INTO EMP VALUES (7934, 'MILLER', 'CLERK', 7782, '1982-01-23', 1300, NULL, 10);CREATE TABLE DEPT ( DEPTNO INT PRIMARY KEY , DNAME VARCHAR(14), LOC VARCHAR(13));INSERT INTO DEPT VALUES (10, 'ACCOUNTING', 'NEW YORK');INSERT INTO DEPT VALUES (20, 'RESEARCH', 'DALLAS');INSERT INTO DEPT VALUES (30, 'SALES', 'CHICAGO');INSERT INTO DEPT VALUES (40, 'OPERATIONS', 'BOSTON'); 위까지가 원래 데이터이며, 테스트를 위해서 inner join에 해당하지 않는 데이터를 하나 추가하였다. 1INSERT INTO EMP VALUES (0, 'LUNA', 'MASTER', 7782, '1982-01-23', 1300, NULL, 0); LINQ 실행테스트를 위해 실행시킨 LINQ 문장은 아래와 같다. 123456789101112131415var emp = context.EMP.ToList();var dept = context.DEPT.ToList();var j1 = context.EMP.Join(context.DEPT, e =&gt; e.DEPTNO, d =&gt; d.DEPTNO, (e, d) =&gt; new &#123;e, d&#125;).ToList();var j2 = context.EMP.Join(context.DEPT.DefaultIfEmpty(), e =&gt; e.DEPTNO, d =&gt; d.DEPTNO, (e, d) =&gt; new &#123; e, d &#125;).ToList();var j3 = context.EMP.GroupJoin(context.DEPT, e =&gt; e.DEPTNO, d =&gt; d.DEPTNO, (e, d) =&gt; new &#123; e, d &#125;).ToList();var j4 = context.DEPT.GroupJoin(context.EMP, d =&gt; d.DEPTNO, e =&gt; e.DEPTNO, (d, e) =&gt; new &#123; d, e &#125;).ToList();var j5 = context.EMP.GroupJoin(context.DEPT, e =&gt; e.DEPTNO, d =&gt; d.DEPTNO, (e, d) =&gt; new &#123; e, d = d.DefaultIfEmpty() &#125;) .SelectMany(j =&gt; j.d.Select(d =&gt; new &#123; j.e, d&#125;)) .ToList();var j6 = context.EMP.GroupJoin(context.DEPT, e =&gt; e.DEPTNO, d =&gt; d.DEPTNO, (e, d) =&gt; new &#123; e, d = d.FirstOrDefault() &#125;).ToList(); 실행 결과에 대해서 IEnumerable의 Count를 먼저 살펴보자. EMP 와 DEPT는 테이블에 들어가 있는 레코드 수가 그대로 반영되었다. 1234var j1 = context.EMP.Join(context.DEPT, e =&gt; e.DEPTNO, d =&gt; d.DEPTNO, (e, d) =&gt; new &#123;e, d&#125;) .ToList(); j1은 보통 많이쓰는 Join으로 실행시켰다. inner join을 수행하므로 마지막에 테스트로 넣은 LUNA의 경우 DEPTNO로 조인이 되지 않아서 14개가 되는게 맞다. 1234var j2 = context.EMP.Join(context.DEPT.DefaultIfEmpty(), e =&gt; e.DEPTNO, d =&gt; d.DEPTNO, (e, d) =&gt; new &#123; e, d &#125;) .ToList(); j2는 Microsoft 공식 문서에 나와있는 방법대로 inner table 쪽에 DefaultIfEmpty를 수행했는데도 14개로 inner join한 것과 같은 결과가 나왔다. 1234var j3 = context.EMP.GroupJoin(context.DEPT, e =&gt; e.DEPTNO, d =&gt; d.DEPTNO, (e, d) =&gt; new &#123; e, d &#125;) .ToList(); j3을 보니 우리가 원하던대로 15개의 결과가 나왔다.결과를 좀 더 자세히 보니 LUNA에 조인된 d가 null로 들어와있다. 이제 원하는 결과를 얻었다고 생각이되지만, 나머지 항목에 대해서는 d가 Collection으로 되어 있으며 그 안에 DEPT가 1개씩 들어가 있어서 별로 보기에 좋지가 않다.일단 여기서 넘어가고 아래에서 좀 더 이쁘게 만들어 보겠다. 1234var j4 = context.DEPT.GroupJoin(context.EMP, d =&gt; d.DEPTNO, e =&gt; e.DEPTNO, (d, e) =&gt; new &#123; d, e &#125;) .ToList(); 위에서 설명한 GroupJoin이 어떻게 동작하는지 보기위해서 j4에서는 DEPT를 outer table로 하고 EMP를 inner table로 하여 수행해 보았다.d에 해당하는 e에 여러개의 EMP가 Collection으로 들어가 있는게 확인 가능하다. 12345678910var j5 = context.EMP.GroupJoin(context.DEPT, e =&gt; e.DEPTNO, d =&gt; d.DEPTNO, (e, d) =&gt; new &#123; e, d = d.DefaultIfEmpty() &#125;) .SelectMany(j =&gt; j.d.Select(d =&gt; new &#123; j.e, d&#125;)) .ToList();var j6 = context.EMP.GroupJoin(context.DEPT, e =&gt; e.DEPTNO, d =&gt; d.DEPTNO, (e, d) =&gt; new &#123; e, d = d.FirstOrDefault() &#125;) .ToList(); j5와 j6는 j3에서 이쁘지 않았던 모양을 좀 더 사용하기 좋도록 만든 것이다.j3에서 만든 Collection을 풀어서 flat하게 만들어주는게 j5, j6이다.이 경우에서는 둘의 결과는 똑같다. 하지만 모든 경우에 있어서 둘의 결과가 똑같지는 않다. j5에서는 EMP에 해당하는 DEPT가 여러 개 있는 경우 그걸 여러개의 결과로 나눠준다.j6에서는 EMP에 해당하는 DEPT가 여러 개가 있더라도 그중 1개만 결과로 남고 나머지는 무시된다. 위에서 생성한 테이블에서는 outer join을 할려는 목적이 DEPT가 1개이거나 없거나 하는 경우라서 j6방법으로 사용해도 되지만, 대부분의 경우에는 j5 방법대로 해야한다.","categories":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/categories/C/"},{"name":"C#","slug":"C/C","permalink":"http://DevStarSJ.github.io/categories/C/C/"}],"tags":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/tags/C/"}]},{"title":"AWS Lambda + API Gateway Binary Response 예제","slug":"AWS-Lambda-BinaryResponse","date":"2017-04-07T15:00:00.000Z","updated":"2017-05-23T23:29:46.000Z","comments":true,"path":"2017/04/08/AWS-Lambda-BinaryResponse/","link":"","permalink":"http://DevStarSJ.github.io/2017/04/08/AWS-Lambda-BinaryResponse/","excerpt":"","text":"AWS Lambda + API Gateway Binary Response 예제API Gateway의 Binary Response가 가능하기 때문에 이미지 파일(png, jpg)나 pdf 다운로드 같은걸 Lambda를 이용해서 구현이 가능하다.AWS 에서 제공해주는 예제는 AWS Compute Blog에 있는 Binary Support for API Integrations with Amazon API Gateway 란 포스팅이 있는데 이것을 읽고 실제로 구현을 하기에는 조금 부족하다. 그래서 바로 사용 가능한 예제 코드를 작성해 보았다. 이번에 회사(직방)에서 html to pdf API 내재화 (예전에는 외부 유료 서비스 사용) 작업을 진행하면서 Binary Response에 대해서 경험을 하게 되었다.그 과정에서 많은 삽질(?)을 하게 되었는데, 이런 예제 코드만 하나 검색으로 찾을 수 있었어도 시간을 많이 아낄수 있었을 꺼란 생각이 들었다. 1. Lambda 코드 작성Node.JS를 이용해서 작성하였다. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556\"use strict\";const fs = require(\"fs\");const qs = require(\"querystring\");const FILE = &#123; JPG: \"test.jpg\", PNG: \"test.png\", PDF: \"test.pdf\"&#125;;const CONTENT_TYPE = &#123; JPG: \"image/jpg\", PNG: \"image/png\", PDF: \"application/pdf\"&#125;;exports.handler = (event, context, callback) =&gt; &#123; console.info(JSON.stringify(event,null,2)); const qs = event.queryStringParameters || &#123;&#125;; const path = event.pathParameters.proxy; const body = getBody(event); const KEY = path.indexOf(\"jpg\") &gt;= 0 ? \"JPG\" : path.indexOf(\"png\") &gt;= 0 ? \"PNG\" : \"PDF\"; const content = fs.readFileSync(FILE[KEY]); const response = &#123; statusCode: 200, headers: &#123; \"Content-Type\": CONTENT_TYPE[KEY], \"Content-Disposition\": `inline; filename=\"$&#123;FILE[KEY]&#125;\"` &#125;, body: new Buffer(content).toString(\"base64\"), isBase64Encoded: true &#125; callback(null, response);&#125;;function getBody(event)&#123; if (!event.body) return null; const rawBody = event.isBase64Encoded ? new Buffer(event.body, \"base64\").toString() : event.body; const body = event.headers[\"Content-Type\"] === \"application/x-www-form-urlencoded\" ? qs.parse(rawBody) : rawBody; return body;&#125; 코드 대해서는 간략하게만 설명하겠다. 경로상에 pdf, png, jpg 가 있는 경우 각각 그 예제 바이너리를 리턴해주는 간단한 API다. API Gateway의 Lambda Proxy Integration를 이용해서 event를 받을 예정이다.예전에는 {proxy+} 리소스를 사용해야지만 프락시 통합이 사용가능했지만, 이제는 각각의 리소스, 메서드를 직접 지정하더라도 프락스 통합 사용이 가능하므로 이걸 사용하지 않을 이유가 없다. 이번 예제에서 body를 사용하지는 않을 예정이라 getBody 함수가 사실상 필요는 없지만, 바이너리로 body를 받을 경우에는 해당 코드를 참고해서 처리하면 된다. 위 그림과 같이 isBase64Encoded 값을 보고 body를 인코딩 해줘야 한다.인코딩 여부를 우리가 정할 수 있는지는 잘 모르겠지만, API Gateway에서 알아서 판단하여 인코딩 해주는것 같다.여러 번의 테스트를 해보니 isBase64Encoded가 false로 계속 전달되다가 API Gateway deploy 이후 true로 바뀐적도 있다. JavaScript에서의 switch-case 문에 대한 구현은 개인적으로 위와 같이 Object를 만들어서 key-value pair를 활용하는게 깔끔해 보인다. 2. Lambda 배포위 작성한 코드와 test.jpg, test.png, test.pdf 를 같은 폴더에 복사한 뒤 같이 압축해 주자. zip -r test.zip . 그리고 AWS Lambda Console로 가서 binaryTest 란 이름으로 Function을 생성하자. 런타임은 Node.js 6.10 을 선택하고 해당 압축파일을 업로딩하자. 다른 설정은 적당히 알아서 하면 된다. 이 예제는 S3나 다른 AWS 상의 리소스를 사용하지 않으니 Role 설정도 따로 복잡하게 할 것이 없다. 단, 메모리와 타임아웃은 적당히 여유있게 주길 바란다.바이너리 처리 자체가 파일을 읽고, 쓰는 작업이 필요하기 때문에 메모리가 많이 필요 할 수도 있고, 시간도 생각보다 오래 걸릴수 있기 때문이다. 3. API Gateway 생성 및 설정3.1 일단 API 생성 그냥 binaryTest로 하나 생성한다. 3.2 리소스 추가Action -&gt; Create Method 를 누른 뒤 proxy resource를 체크하고 Create Resource를 눌러주자. 이번 예제에서는 모든 경로에 대해서 하나의 Lambda를 실행시킬 것이다.단, 이 방법은 유효하지 않은 경로 등에 대해서도 모두 Lambda를 실행시키게 되므로 쓸데없는 비용이 발생 할 수도 있다는건 알아둬야 한다.Lambda에서 처리 가능한 경로에 대해서만 호출을 할 것이라면 리소스를 유효한 것만 따로 생성하는게 좋다. 해당 프락시 리소스에서 실행시킬 Lambda를 설정해 주자. 위에서 생성한 binaryTest Lambda Function으로 설정하자. 3.3 Binary Support 추가API Gateway 상의 Binary Support 탭을 눌러서 들어가자. 해당 API를 호출할 때 headers에서 Accept로 요청하는 형태들에 대해서 미리 정의해 줘야 한다. 만약 브라우저에서 url로 바로 호출할 것이라면 */*를 추가해 줘야 한다. 그 밖의 다른 곳에서 요청시 Accept로 명시해주는 형태에 대해서 추가를 해줘야 API Gateway에서 바이너리 형태로 응답을 제공한다. 3.4 배포다시 Resources 탭으로 가서 Actions -&gt; Deploy API를 눌러서 배포를 하자. 그냥 늘 하던데로 prod라는 이름으로 배포를 했다. 4. 테스트배포를 하면 url이 생성된다. 이 url 뒤에 /pdf , /png , /jpg를 붙여서 호출하여 바이너리 다운로드가 정상적으로 되는지 확인해 보자. 브라우저에서 직접 호출하면 바로 화면에 나타나겠고, curl 이나 POSTMAN을 사용할려면 header에 Accept값을 넣어서 호출하면 된다. curl -X GET -H “{Accept:application/pdf}” https://xxx/prod/pdf &gt; test.pdf POSTMAN의 경우 이미지는 바로 화면에 보여주지만, pdf는 정상적으로 보여주지 못한다. Lambda Binary 작업 Tip(?) : Native Module 사용Lambda로 binary response 작업을 할려면 몇가지만 미리 알아두더라도 삽질(?) 할 시간을 아낄 수 있다. Lambda가 실행되는 환경은 Linux 이다.Lambda Execution Environment and Available Libraries 에서 정확한 정보를 확인할 수 있다. Lambda에 50mb 정도의 디스크 사용이 가능하다./tmp 폴더내에 파일을 임시로 저장하고 사용하는게 가능하다.하지만 Lambda가 warm start로 실행될 경우 이미 만들어진 Lambda를 재사용하므로 해당 폴더에 임시로 만들어 놓은 파일은 계속 남아있게 된다.임시로 파일을 만들어서 활용할 경우 동일한 이름을 사용해서 항상 덮어쓰거나 아니면 해당 파일을 다 사용한 후에는 지워주는 코드를 넣어주도록 하자. Native Module을 사용할 경우바이너리 응답을 주는 기능 구현을 위해서는 native module을 사용하는 경우가 많다. native module를 사용한다면, 기본적으로 아래와 같은 과정으로 개발을 할 것이다. 해당 native module을 설치한다. (macos의 경우 brew를 사용) 해당 모듈의 wrapper npm이 있는지 검색한다. 있다면 그걸 활용한다. 없다면 직접 shell에서 실행시켜주는 wrapper를 구현해서 사용한다. 이걸 Lambda로 배포하려면 해당 native module을 같이 배포해야한다.그래서 아래 과정이 추가된다. wrapper npm을 활용한 경우라면 그 소스코드를 살펴보면서 해당 모듈을 시스템 상에 설치된 것을 사용하는지, 아니면 npm으로 설치할때 같이 다운로드 되는지 살펴본다. 시스템상 설치된 것을 사용한다면 native module의 실행파일을 압축해 본다. 압축 후 용량이 50mb가 넘으면 포기한다. ㅠㅠ 50 mb 이하라면 Lambda 를 배포할 폴더 아래에 해당 파일을 복사한다. 옮긴 실행 파일을 실행하도록 wrapper를 수정한다. 여기서 반드시 명싱해야 할것은 Lambda의 실행환경은 Linux이다. 지금 내 개발환경이 macos인 경우 이것을 그대로 Lambda로 배포하면 실행이 안된다. 해당 native module을 Linux용으로 바꿔서 배포해야한다. wrapper npm에서 native module을 같이 다운로드 받게 되어 있다면, 코드를 살펴보자. 분명 OS 타입별로 각각 다른 파일을 다운로드 하는 분기 코드가 있을 것이다. 그걸 보고 Linux용 실행파일을 다운로드 받자. 시스템 상에 설치된 실행파일을 사용하는 경우라면 따로 Linux용을 다운로드 받자. 로컬에서 테스트로 실행시켜볼 환경과 Lambda로 배포할 환경을 따로 만들어야 한다. 배포 스크립트를 만들면 편하다. 폴더 생성 Lambda 코드 복사 npm i --only=production native module을 linux 용으로 복사 배포 OS에 따라 Native Module의 결과가 다를 수 있다.같은 native module이라도 각 OS별로 다르게 동작할 수 있다.이 사실을 모르고 결과물을 개발 환경에 맞춰서 진행하다보면 Lambda 배포 후 결과가 다른걸 보고 또 다시 삽질을 해야할 수 있다.그러니 일단 동작하는게 확인되면 Lambda로 배포한 후 그 결과를 확인해보고 진행하는게 좋다. 마치며…잘못되었거나, 변경된 점, 기타 추가 사항에 대한 피드백은 언제나 환영합니다. - &#115;&#101;&#x6f;&#x6b;&#106;&#111;&#111;&#x6e;&#46;&#x79;&#117;&#x6e;&#x40;&#103;&#x6d;&#97;&#105;&#x6c;&#x2e;&#99;&#x6f;&#x6d;","categories":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/categories/AWS/"},{"name":"Lambda","slug":"AWS/Lambda","permalink":"http://DevStarSJ.github.io/categories/AWS/Lambda/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/tags/AWS/"},{"name":"Lambda","slug":"Lambda","permalink":"http://DevStarSJ.github.io/tags/Lambda/"},{"name":"APIGateway","slug":"APIGateway","permalink":"http://DevStarSJ.github.io/tags/APIGateway/"}]},{"title":"AWS Lambda에 Python Slack Chatbot을 통해서 미세먼지 대기정보 알림이 만들기","slug":"Lambda.Chatbot.01","date":"2017-03-25T15:00:00.000Z","updated":"2017-04-23T09:23:32.000Z","comments":true,"path":"2017/03/26/Lambda.Chatbot.01/","link":"","permalink":"http://DevStarSJ.github.io/2017/03/26/Lambda.Chatbot.01/","excerpt":"","text":"AWS Lambda에 Python Slack Chatbot을 통해서 미세먼지 대기정보 알림이 만들기Lambda를 이용해서 Slack용 Chatbot을 만들어 보았다.개발언어로는 Python을 사용했다.Lambda에는 Python 2.7만 지원되어서 작업하면서도 불편한 점이 많았다.특히 챗봇이다보니 유니코드(한글) 처리가 필수여서다.(Node.JS는 6.1까지 지원해주는데… Python도 3을 빨리 지원해주면 좋겠다.) 예제로 만들어본 챗봇은 서울시 종로구의 대기상태를 알려주는 기능을 제공한다.매일 아침 5시 20분(내 기상시간)과 오후 12시 20분(점심 먹으러 가기 전에 지하식당에서 먹을지 밖에 나가서 먹을지 생각하기 위해서)에 알려주도록 설정하였다.솔직히 오후 12시에 굳이 20분을 한 이유는 CloudWatch의 event 생성을 편하게 하기위해서이다.솔직히 12시 40분에 알려주는게 더 좋을것 같긴하지만, 그것 때문에 event를 추가로 생성하기엔 귀찮기도 하고, 관리포인트가 두군데가 생기기 때문에 그냥 20분으로 통일했다. 챗봇 구현을 위한 Lambda를 2개로 나누었다. Slack에 메세지를 전달해주는 Lambda 크롤링하여 대기상태 데이터를 뽑아내고 메세지를 만드는 Lambda 크롤링 Lambda는 SNS를 통해서 메세지 전달 Lambda를 호출한다.크롤링 Lambda는 CloudWatch의 event를 통해서 호출된다. 그 과정을 그림으로 표현하면 아래와 같다. 이전에 표스팅한 내용에 있는 것에 대해서는 설명을 생략하겠다.해당 내용에 대해서는 아래 링크를 참고하면 관련 내용이 있다. Python 코드를 Lambda에 배포하는 방법 : Lambda Python Packaging Lambda -&gt; SNS -&gt; Lambda 로 호출하는 방법 : Lambda에서 Lambda를 호출하는 방법 1. Slack에 메세지 보내기먼저 Slack Bot을 만들기 위해서는 API Token이 필요하다.자세한 생성방법은 검색하면 많이 나오니깐 생략하겠다.간략하게 설명없이 방법만 적겠다. Slack에서 채널명 클릭해서 나오는 메뉴에서 Apps &amp; intergrations 클릭 Bots 검색해서 클릭 Add Configuration클릭 안내대로 쭉 설정하고 나오는 화면에서 API Token값을 보고 기록해 놓음 이제 Slack에 메세지를 보내는 Python 함수를 먼저 만들어 보자. 만약 Python 버전이 2.7이 아닌 경우에는 virtualenv를 통해서 2.7 환경으로 만들어 놓고 작업을 해야한다.그 방법은 Lambda Python Packaging 링크를 통해서 확인하기 바란다. slacker라는 패키지를 이용하면 정말 쉽게 작성이 가능하다. 우리는 Lambda에 배포해야하니 pip로 패키지를 설치할 때 해당 폴더에 설치해야 한다. pip install slacker -t . 이제 index.py라는 파일명으로 아래 코드를 입력한다. 12345678910111213141516171819# -*- coding: utf-8 -*-from slacker import Slackertoken = '&#123;Slack Bot API Token&#125;'slack = Slacker(token)def handler(event, context): ch = event[\"channel\"] message = event[\"message\"] slack.chat.post_message(ch, msg)if __name__ == '__main__': event= &#123;&#125;; event[\"channel\"] = \"#general\"; event[\"message\"] = \"메인 테스트\"; handler(event, None); 실행을 했을 때 Slack의 #general 채널에 메세지가 출력되면 정상적으로 동작하는 것이다. python index.py 이제 Lambda로 올려서 테스트 해보자. zip -r bot.zip . 위 명령어로 압축을 한 후에 Lambda에 올려서 배포를 한 후 테스트 데이터를 아래와 같은 형태로 넣은 후 실행해서 Slack에 메세지가 나오면 성공한 것이다. 1234&#123; \"channel\": \"#general\", \"message\": \"람다람다 테스트\"&#125; 2. 대기정보를 얻기위해서 웹 크롤링하기위에 작성한 코드와는 다른 폴더에서 작업하겠다.왜냐면 다른 Lambda로 배포할 코드라 사용하지 않는 패키지까지 같이 포함되어 배포할 용량이 커지는걸 피하기 위해서다. 서울특별시 대기환경정보(http://cleanair.seoul.go.kr/air_city.htm?method=measure)에서 관련 데이터를 크롤링했다.(네이버는 크롤링을 막아놔서… ㅠㅠ 아마 적절히 User-Agent값을 넣는다던지, headers 정보를 감쪽같이 속인다던지, 웹브라우저 엔진을 이용한다던지 하는 방법을 이용하면 되겠지만… 뭐 대단한 거라고 그냥 다른 곳을 선택했다. 최대한 쉽게 쉽게…) 웹페이지 소스를 가져오기 위해서 requests를 사용했으며 해당 소스를 분석하기 위해서 beautifulsoup를 사용하였다.그동안 말로만 듣던 beautifulsoup를 처음 써봤는데, 100% 마음에 들지는 않았지만 그래도 원하는 기능들이 꽤 많이 구현되어 있었다.텍스트를 한줄 한줄 읽어가면서 분석해야하는 일을 많이 줄여주었다. pip install requests beautifulsoup -t . 위 페이지에서 개발자 도구를 열어서 소스도 살펴보고… 각 element 별로 클릭해서 적절한 id값도 찾아보고… 이래저래 해봤는데… 한방에 딱! 뽑아 낼 수 있는 구조가 아니다.그냥 일단 받아놓고 노가다로 찾아야 겠다. 1234567891011from BeautifulSoup import BeautifulSoupimport jsonimport requestsURL = 'http://cleanair.seoul.go.kr/air_city.htm?method=measure'response = requests.get(URL)html_doc = response.textsoup = BeautifulSoup(html_doc)print soup.prettify() 로 일단 찍어보자.여기서 뭘 보겠다는게 아니라 그냥 일단 잘 동작하나 보자.겁나 길게 html이 우루루 출력되면 성공한 것이다. 다시한번 개발자 도구로 해당페이지를 보니 아래쪽 표 부분에 서울시 각 도별로 대기상태 값들이 있다.&lt;table&gt; 태그 정보들에 대해서 값을 추출해 보자. 12tables = soup.findAll('table')print tables 3번째 테이블에 원하는 정보가 있다. 각 &lt;tr&gt;별로 살펴봐서 우리가 원하는 위치(종로구)에 관한 정보만 찾아보자. 123456dataTable = tables[2]trs = dataTable.findAll('tr')for tr in trs: if '종로구' in str(tr): print tr; 우리가 원하는 정보는 저기에 다 있는게 확인되었다.이제 이걸 이용해서 메세지를 만들어서 출력해 보겠다. 123456789101112dataTable = tables[2]trs = dataTable.findAll('tr')for tr in trs: if '종로구' in str(tr): tds = tr.findAll('td') message1 = u'종로구의 현재 통합대기환경지수는 &#123;&#125;(&#123;&#125;) 입니다.'.format(tds[7].getText(), tds[8].getText()) message2 = u'미세먼지: &#123;&#125;㎍/㎥, 초미세먼지: &#123;&#125;㎍/㎥, 오존: &#123;&#125;ppm, 이산화질소: &#123;&#125;ppm, 일산화탄소: &#123;&#125;ppm, 아황산가스: &#123;&#125;ppm'.format(tds[1].getText(), tds[2].getText(), tds[3].getText(), tds[4].getText(), tds[5].getText(), tds[6].getText()) messageTotal = message1 + u\"(\" + message2 + \")\" print messageTotal 종로구의 현재 통합대기환경지수는 보통(70) 입니다.(미세먼지: 44㎍/㎥, 초미세먼지: 25㎍/㎥, 오존: 0.036ppm, 이산화질소: 0.033ppm, 일산화탄소: 0.5ppm, 아황산가스: 0.004ppm) 이제까지의 코드를 한번 정리해 보겠다. 1234567891011121314151617181920212223242526272829303132# -*- coding: utf-8 -*-from BeautifulSoup import BeautifulSoupimport jsonimport requestsURL = 'http://cleanair.seoul.go.kr/air_city.htm?method=measure'def GetInfo(gu): response = requests.get(URL) html_doc = response.text soup = BeautifulSoup(html_doc) tables = soup.findAll('table'); dataTable = tables[2] trs = dataTable.findAll('tr') for tr in trs: if gu in str(tr): return tr;def MakeMessage(data): tds = data.findAll('td') message1 = u'종로구의 현재 통합대기환경지수는 &#123;&#125;(&#123;&#125;) 입니다.'.format(tds[7].getText(), tds[8].getText()) message2 = u'미세먼지: &#123;&#125;㎍/㎥, 초미세먼지: &#123;&#125;㎍/㎥, 오존: &#123;&#125;ppm, 이산화질소: &#123;&#125;ppm, 일산화탄소: &#123;&#125;ppm, 아황산가스: &#123;&#125;ppm'.format(tds[1].getText(), tds[2].getText(), tds[3].getText(), tds[4].getText(), tds[5].getText(), tds[6].getText()) messageTotal = message1 + u\"(\" + message2 + \")\" return messageTotalif __name__ == \"__main__\": print MakeMessage(GetInfo('종로구')) 3. SNS을 통해서 Slack Lambda 호출하기자세한 설명은 Lambda에서 Lambda를 호출하는 방법 링크를 통해서 확인하기 바란다. 해당 SNS를 통해서 메세지를 보내기 위해서 SNS의 ARN 주소를 어디에 적어 놓아야 한다. SNS 에서 Lambda 로 전달되는 메세지 형태를 처리하기 위해서는 위 코드를 수정해야 한다.참고로 Subject로 채널명을 입력받고 Message 전달할 메세지를 입력받도록 설정하였다. 12345678910111213141516171819202122232425262728# -*- coding: utf-8 -*-from slacker import Slackertoken = '&#123;Slack Bot API Token&#125;'slack = Slacker(token)def handler(event, context): keys = event.keys() ch = \"\" message = \"\" if 'channel' in keys: ch = event[\"channel\"] msg = event[\"message\"] else: ch = event['Records'][0]['Sns']['Subject']; msg = event['Records'][0]['Sns']['Message']; slack.chat.post_message(ch, msg)if __name__ == '__main__': event= &#123;&#125;; event[\"channel\"] = \"#general\"; event[\"message\"] = \"메인 테스트\"; handler(event, None); 4. 대기정보 Lambda에서 SNS로 메세지 보내기2번 항목에서 만든 코드에 SNS를 통해서 메세지를 전달하는 코드를 추가해 보자.먼저 AWS 서비스를 이용하기 위해 boto를 설치하자. pip install boto -t . 1234567891011121314151617181920212223242526272829303132333435363738394041424344# -*- coding: utf-8 -*-from BeautifulSoup import BeautifulSoupfrom datetime import datetimeimport jsonimport requestsimport boto.snsURL = 'http://cleanair.seoul.go.kr/air_city.htm?method=measure'REGION = '&#123;리전&#125;'TOPIC = '&#123;SNS ARN 주소&#125;'conn = boto.sns.connect_to_region( REGION )def GetInfo(gu): response = requests.get(URL) html_doc = response.text soup = BeautifulSoup(html_doc) tables = soup.findAll('table'); dataTable = tables[2] trs = dataTable.findAll('tr') for tr in trs: if gu in str(tr): return tr;def MakeMessage(data): tds = data.findAll('td') message1 = u'종로구의 현재 통합대기환경지수는 &#123;&#125;(&#123;&#125;) 입니다.'.format(tds[7].getText(), tds[8].getText()) message2 = u'미세먼지: &#123;&#125;㎍/㎥, 초미세먼지: &#123;&#125;㎍/㎥, 오존: &#123;&#125;ppm, 이산화질소: &#123;&#125;ppm, 일산화탄소: &#123;&#125;ppm, 아황산가스: &#123;&#125;ppm'.format(tds[1].getText(), tds[2].getText(), tds[3].getText(), tds[4].getText(), tds[5].getText(), tds[6].getText()) messageTotal = message1 + u\"(\" + message2 + \")\" return messageTotaldef handler(event, context): msg = MakeMessage(GetInfo('종로구')) pub = conn.publish( topic = TOPIC, subject =\"#general\" ,message = msg )if __name__ == \"__main__\": handler(None, None) Lambda로 올리기 전에 테스트로 실행해 본 후 정상적으로 실행되는지 확인해 보자. 위 코드 실행 후 Slcak을 통해서 메세지가 전달되었다면 성공한 것이다.위 코드도 폴더 전체를 압축해서 Lambda로 배포하자. 5. CloudWatch를 통해서 event 생성하기CloudWatch의 event를 통해서 특정 시점에 Lambda 를 실행시킬 수 있다. CloudWatch -&gt; Events -&gt; Create rule Add taget을 눌러서 위에 배포한 Lambda를 선택 : 별도로 인자로 받는게 없으므로 나머지 설정들은 기본 그대로 둠 Event Source를 Schedule로 선택 Cron Expression : 20 3,20 * * ? *로 입력 (UTC 기준 매일 3시 20분, 20시 20분에 실행을 시킨다는 뜻) 저장을 하면 끝이다. 이제 설정한 시간에 Lambda가 실행되어서 Slack에 메세지를 전달해 줄 것이다. 하루가 지난 시점에 확인해보니 설정한 시간에 꼬박꼬박 실행 중이다.","categories":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/categories/AWS/"},{"name":"Lambda","slug":"AWS/Lambda","permalink":"http://DevStarSJ.github.io/categories/AWS/Lambda/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/tags/AWS/"},{"name":"Lambda","slug":"Lambda","permalink":"http://DevStarSJ.github.io/tags/Lambda/"},{"name":"APIGateway","slug":"APIGateway","permalink":"http://DevStarSJ.github.io/tags/APIGateway/"},{"name":"Python","slug":"Python","permalink":"http://DevStarSJ.github.io/tags/Python/"}]},{"title":"Lambda에서 Lambda를 호출하는 방법","slug":"Lambda.invoke.Lambda","date":"2017-03-18T15:00:00.000Z","updated":"2017-04-23T09:24:55.000Z","comments":true,"path":"2017/03/19/Lambda.invoke.Lambda/","link":"","permalink":"http://DevStarSJ.github.io/2017/03/19/Lambda.invoke.Lambda/","excerpt":"","text":"Lambda에서 Lambda를 호출하는 방법AWS Lambda에서 Lambda를 호출하는 방법들에 대해서 소개하겠다. 언제 Lambda에서 Lambda를 호출하면 편리할까 ?첫째, 배치 성격의 작업을 여러 개로 나누어 병렬로 실행할 경우를 생각할 수 있다.Lambda 내에서 배치작업을 모두 다 실행시키도록 작성 할 수도 있겠지만,첫번째 Lambda에서 작업 전 필요한 준비작업을 한 후 이것을 다른 Lambda로 전달 할 수 있다.그 과정에서 다음 Lambda 1개에게 전달할게 아니라 비동기 invoke로 한 번에 여러 개의 Lambda를 생성하여 작업하면 전체 실행 시간을 줄일수 있을 것이다.(하지만 동시에 여러 Lambda가 실행될 경우 계정당 Lambda Limit 내에서 실행되도록 조정은 해야 한다.) 이 경우 AWS Step Functions 를 이용할 수도 있다.Step Functions를 사용하려고 살펴봤는데 아직까진 사용 사례도 없고, 그 과정에서의 비용도 있고, API Gateway와의 연동에 대해서도 확신이 없다.API Gateway에서 Step Function 호출을 지원한다는 글이 2017.02.15 에 올라오긴 했다. 둘째, 빠른 API 응답을 위해서 사용할 수 있다.Lambda를 만들었을 때의 원래 의도는 AWS 서비스 상에서의 event성 호출들에 대한 처리를 전적으로 할 목적이었다고 한다.하지만 API Gateway가 나온 이후로 Lambda를 이용하여 Serverless API를 구축하는게 가능하다.API를 호출한 사용자 입장에서 생각해 본다면 필요한 데이터를 빨리 응답해 주고, 나머지 작업들은 그 뒤에 따로 처리를 하는 방법이 있으면 좋을 것이다.예를 들어서 사용자가 접속시 호출해야하는 API가 있다고 가정해보자.이 API에서는 사용자가 이전에 어떤 작업을 하고 있었는지를 조회해서 알려줘야하며, 현재 시점의 접속 상태(시간, 위치, 접속한 기기정보 등)를 기록해야 한다면, 먼저 사용자에게 전달해야할 정보를 조회한 뒤, 기록해야 할 정보에 대해서 다른 Lambda를 비동기 invoke 한 후 응답을 하도록 설계가 가능하다. Lambda에서 Lambda 를 호출하는 방법에는 동기 invoke와 비동기 invoke 2가지가 있다. 동기 invoke : Lambda 호출 후 그 응답을 기다린다. 응답 결과를 보고 뭔가 처리를 해야할 경우에 사용된다. 비동기 invokde : Lambda 호출 후 응답을 기다리지 않고 지나간다. 동기든 비동기든 둘 다 Lambda 비용에 대해서 생각을 한다면 Lambda 를 2개 이상으로 나누는 것이 무조건 손해이다.Lambda는 과금이 설정 메모리 x 수행시간(100 ms 단위) 이다.만약 평균 수행시간 199 ms 인 작업을 2개의 Lambda로 나뉠 경우 100 ms + 99 ms로 나뉜다면 1개로 하는 것과 같은 비용이 들겠지만 101ms + 98ms 로 나뉜다면 100ms 수행시간에 대한 비용을 더 지불해야 한다. 이건 비동기 호출의 경우이고, 동기 호출이라면 첫번째 Lambda가 2번째 Lambda를 기다려야 하므로 최선의 경우라도 300 ms 만큼의 요금이 부과될 것이다. 더군다나 2번째로 호출되는 Lambda가 cold start 될 경우 첫번째 Lambda가 그 응답을 기다려야 하므로 비용은 훨씬 더 늘 것이다.이점을 충분히 고려해서 해당 비용을 감안하더라도 Lambda를 나누는것이 유리하다고 판단이 되는 작업을 나누길 바란다. 이제부터 Lambda에서 Lambda를 호출하는 방법들에 대해서 하나 하나씩 살펴보도록 하자. 예제는 Node.JS로 작업하겠다.AWS내의 event를 JSON Object로 전달하므로 Node.JS로 작업하는게 가장 편하다.다른 언어로 하려면 event 모양별로 model을 미리 선언해 주거나 stream을 이용해서 해당 언어별 JSON을 지원해주는 라이브러리로 전달하는 방법을 사용하여야 한다. 응답해야할 결과가 있고, 그것이 JSON Object일 경우에는 응답에도 똑같은 처리를 해줘야 한다. Python의 경우는 그나마 JSON 친화적(?) 이어서 Node.JS 다음으로 편한 것 같다. Lambda에서 Lambda를 호출하는 방법1. Lambda를 직접 invoke유일하게 Lambda 간의 동기 invoke가 가능한 방법이다.가장 쉬운 방법이기도 하다. 먼저 호출 될 Lambda를 먼저 등록하자.Lambda 등록에 대한 설명은 생략하겠다.이전에 포스팅한 글을 참조하길 바란다. AWS Lambda와 API Gateway를 이용해서 Serverless Web API 만들기 1.1 호출될 Lambda 등록아래 코드로 echoTest란 이름으로 Lambda를 등록한다. 12345678'use strict';const util = require('util');exports.handler = (event, context, callback) =&gt; &#123; console.info(util.inspect(event, &#123;depth:null&#125;)); callback(null, event);&#125;; 등록 후 오른쪽 위를 보면 ARN (Amazon Resource Name)을 볼 수 있다. ARN - arn:aws:lambda:{region}:{id}:function:echoTest 이걸 이용해서 aws-sdk를 사용해서 Lambda를 호출할 것이다. 1.2 동기 호출 코드이제 호출 할 Lambda를 작성해보록 하자. 먼저 local에서 테스트해보기 위해서는 aws-sdk를 설치해야 한다.Lambda 상에는 설치가 되어 있으므로 같이 올릴 필요가 없다. npm install aws-sdk –save 123456789101112131415161718'use strict'const aws = require('aws-sdk');const lambda = new aws.Lambda(&#123; region: 'ap-northeast-1' //change to your region&#125;);const event = &#123; id: \"1\", name:\"Luna\"&#125;;lambda.invoke(&#123; FunctionName: 'echoTest', Payload: JSON.stringify(event, null, 2) // pass params&#125;, function(error, data) &#123; if (error) &#123; console.info(error); &#125; else &#123; console.info(data); &#125;&#125;); 만약 위 코드를 index.js로 저장했다면 아래와 같이 실행하면 결과를 확인할 수 있다. node index.js 1&#123; StatusCode: 200, Payload: '&#123;\"id\":\"1\",\"name\":\"Luna\"&#125;' &#125; 1.3 비동기 호출 코드위 코드는 동기 invoke 하였다.비동기로 하기 위해서는 예전에는 InvokeAsync() 함수를 사용했는데 이 방법은 deprecated 되었다.지금은 InvocationType이란 인자에 Event값을 추가해주면 된다.참고로 default인 동기 호출의 설정값은 InvocationType: &#39;RequestResponse&#39;이다. 12345678910111213141516171819'use strict'const aws = require('aws-sdk');const lambda = new aws.Lambda(&#123; region: 'ap-northeast-1' //change to your region&#125;);const event = &#123; id: \"1\", name:\"Luna\"&#125;;lambda.invoke(&#123; FunctionName: 'echoTest', InvocationType: 'Event', Payload: JSON.stringify(event, null, 2) // pass params&#125;, function(error, data) &#123; if (error) &#123; console.info(error); &#125; else &#123; console.info(data); &#125;&#125;); 위와 같이 코드를 수정 후 호출하면 응답코드가 다르게 전달되는걸 확인할 수 있다. 1&#123; StatusCode: 202, Payload: '' &#125; 앞의 동기 invoke의 경우 200(성공)으로 서버가 요청을 정상적으로 처리했다는 코드를 보내왔지만,아래 비동기 invoke의 경우 202(허용됨)으로 서버가 요청을 접수했지만 아직 처리하지 않았다는 응답을 보내왔다. Lambda 상에서 제대로 처리된지 볼려면 echoTest에 console.info로 출력한 내용을 보면 된다. &gt; 11:52:05START RequestId: 094d4d3e-0c4f-11e7-ab68-a96f2d3f979f Version: $LATEST 11:52:052017-03-19T02:52:05.890Z 094d4d3e-0c4f-11e7-ab68-a96f2d3f979f { id: ‘1’, name: ‘Luna’ } 11:52:05END RequestId: 094d4d3e-0c4f-11e7-ab68-a96f2d3f979f 11:52:05REPORT RequestId: 094d4d3e-0c4f-11e7-ab68-a96f2d3f979f Duration: 208.59 ms Billed Duration: 300 ms Memory Size: 128 MB Max Memory Used: 15 MB 11:58:09START RequestId: e23bf84a-0c4f-11e7-81f6-25e9632564aa Version: $LATEST 11:58:092017-03-19T02:58:09.644Z e23bf84a-0c4f-11e7-81f6-25e9632564aa { id: ‘1’, name: ‘Luna’ } 11:58:09END RequestId: e23bf84a-0c4f-11e7-81f6-25e9632564aa 11:58:09REPORT RequestId: e23bf84a-0c4f-11e7-81f6-25e9632564aa Duration: 23.59 ms Billed Duration: 100 ms Memory Size: 128 MB Max 위 11:52에 수행된게 동기로 호출한 결과이며 아래 11:58에 수행된게 비동기로 호출한 결과이다. 둘 다 똑같이 console.info로 출력한 결과가 있는걸로 봐서 정상적으로 수행되었다고 판단할 수 있다. 수행시간이 다른건 앞에껀 cold start가 되었고, 뒤에껀 warm start가 된 결과로 보인다. 위 테스트 코드를 Lambda로 올리는 과정은 생략하겠다.수행할 코드들을 exports.handler = (event, context, callback) =&gt; { }로 감싸서 올리면 된다. 2. SNS의 Subscription으로 Lambda를 등록AWS SNS (Simple Notification Service)는 간단한 푸시 알림 서비스이다.SNS를 하나 만들어서 실행할 Lambda를 구독자로 등록해 놓고, 해당 SNS에 publish하는 방법으로 연동을 생각해 볼 수 있다. 2.1 SNS 생성 및 Lambda를 subscription으로 등록먼저 SNS를 생성한다. SNS dashboard에서 Create topic을 누름 (Topics에서 Create new topic를 눌러도 됨) Topic 생성 Topic name : testSns Display name : testSns Actions를 눌러서 Edit topic policy나 Edit topic delivery policy를 눌러서 각종 설정이 가능하다.여기에서는 그 내용에 대해서는 다루지 않겠다.별로 어렵지 않으니 필요할 경우 직접 해보길 바란다. 이제 해당 SNS에 Lambda를 등록할건데,앞에서 작성한 testEcho를 등록하도록 하자. 생성된 SNS의 ARN링크 arn:aws:sns:{region}:{id}:testSns를 눌러서 Topic details로 들어감 Create subscription을 누름 Protocol : AWS Lambda를 선택 Endpoint : 실행할 Lambda의 ARN을 선택 Version or alias : 일단 default 그대로 둠 (실제 서비스 할 경우에는 alias로 설정을 해야 편함) Version을 $LASTEST로 설정을 하면 관련 권한이 없다고 오류가 발생한다.일단은 그냥 넘어가자.실제 서비스 하는 경우라도 $LASTEST는 상당히 위험한 방법이다.Lambda 배포 후 테스트 과정을 거쳐서 검증되기 전까지는 alias를 사용해서 믿을만한 버전으로 서비스하는게 좋다. 2.2 SNS에서 Lambda 호출 테스트SNS 콘솔에서 Lambda를 제대로 호출하는지 테스트 해보자. Topic details 화면에서 Publish to topic를 누름 Subject : test subject Message format : JSON JSON message generator를 눌러서 Message에 입력 : 지켜보고 있다. Generate JSON 을 누름 Publish message 누름 이제 Lambda 의 CloudFront로 가서 제대로 호출되었는지 살펴보자. 12345678910111213141516&#123; Records: [ &#123; EventSource: 'aws:sns',EventVersion: '1.0',EventSubscriptionArn: 'arn:aws:sns&#123;region&#125;:&#123;id&#125;:testSns:1009056c-eb87-4f68-9cb1-de50b0024b90',Sns: &#123; Type: 'Notification',MessageId: 'd0e91f46-c46c-5ead-9633-4e013fb6c04d',TopicArn: 'arn:aws:sns&#123;region&#125;:&#123;id&#125;:testSns',Subject: 'test subject',Message: '지켜보고 있다.',Timestamp: '2017-03-19T03:23:06.272Z',SignatureVersion: '1',Signature: '...',SigningCertUrl: 'https://...',UnsubscribeUrl: 'https://...',MessageAttributes: &#123;&#125; &#125; &#125; ] &#125; 위의 결과가 출력된걸로 봐서 제대로 호출되었다고 판단이 가능하다. 2.3 코드에서 SNS를 호출하기아래와 같이 코드를 작성하자.그냥 sns.js로 저장하도록 하겠다. 12345678910111213141516171819202122232425'use strict'const AWS = require('aws-sdk');AWS.config.update(&#123; accessKeyId: \"...\", secretAccessKey: \"...\", region: '...'&#125;);const sns = new AWS.SNS();const params = &#123; TargetArn:'arn:aws:&#123;region&#125;:&#123;id&#125;:testSns', Message:'&#123;\"id\":\"snsFromNodeJS\", \"name\":\"Luna\"&#125;&#125;', Subject: 'TestSNS'&#125;;sns.publish(params, function(err,data)&#123; if (err) &#123; console.log('Error sending a message', err); &#125; else &#123; console.log('Sent message:', data.MessageId); console.info(data); &#125;&#125;); 실행하면 다음과 같은 응답을 얻을 수 있다. node sns.js 12&#123; ResponseMetadata: &#123; RequestId: '64efe66a-abfa-5a12-8abd-b72d55ebe4ce' &#125;, MessageId: '207e6adf-277a-5191-a94b-3b98d96b3f4d' &#125; Lambda 의 CloudFront로 가서 제대로 호출되었는지 살펴보자. 123456789101112131415[ &#123; EventSource: 'aws:sns',EventVersion: '1.0',EventSubscriptionArn: 'arn:aws:sns:&#123;region&#125;:&#123;id&#125;:testSns:1009056c-eb87-4f68-9cb1-de50b0024b90',Sns: &#123; Type: 'Notification',MessageId: '207e6adf-277a-5191-a94b-3b98d96b3f4d',TopicArn: 'arn:aws:sns:&#123;region&#125;:&#123;id&#125;:testSns',Subject: 'TestSNS',Message: '&#123;\"id\":\"snsFromNodeJS\", \"name\":\"Luna\"&#125;&#125;',Timestamp: '2017-03-19T03:32:33.996Z',SignatureVersion: '1',Signature: '...',SigningCertUrl: 'https://...',UnsubscribeUrl: 'https://...',MessageAttributes: &#123;&#125; &#125; &#125; ] &#125; 위 출력문으로 봐서 제대로 호출된게 확인 된다. 3. Kinesis로 Lambda 호출하기AWS Kinesis 는 스트리밍 데이터들을 처리하기 위한 용도로 만들어 졌다.입력받은 데이터들을 100개 단위(설정에서 변경 가능)로 묶어서 처리한다던지 그런 용도로 많이 사용한다.Kinesis를 Lambda에서 Lambda 호출용으로 사용하는건 좀 오바스럽긴 하지만 일단 한번 해보자. 3.1 Kinesis Stream 생성 Kinesis Streams 콘솔로 들어가서 Create stream를 누름 Stream name : testKinesis 입력 Number of shards : 1입력 Create stream을 누름 (나머지 설정은 그냥 건드리지 않음) Kinesis Stream이 만들어지고 난 다음 Details 탭으로 들어가서 ARN을 확인한다. arn:aws:kinesis:{region}:{id}:stream/testKinesis 3.2 Lambda에서 trggier로 Kinesis 등록하기먼저 Lambda의 Role에 Kinesis 관련 권한이 있는지 확인하고 없으면 추가해 준다. 1234&quot;kinesis:GetRecords&quot;,&quot;kinesis:GetShardIterator&quot;,&quot;kinesis:DescribeStream&quot;,&quot;kinesis:ListStreams&quot; 위에 나열한 권한이 필요하다. echoTest Lambda 설정으로 이동 Add trigger를 누름 Kinesis 선택 Kinesis stream : testKinesis 선택 Batch size : 1 입력 Start position : Trim horizon을 선택 Submit 누름 3.3 코드에서 Kinesis 호출하기아래와 같이 코드를 작성하자.그냥 kinesis.js로 저장하도록 하겠다. 123456789101112131415161718192021222324252627282930'use strict'const AWS = require('aws-sdk');AWS.config.update(&#123; accessKeyId: \"...\", secretAccessKey: \"...\", region: '...'&#125;);const kinesis = new AWS.Kinesis();const KinesisData = &#123; event_name: \"Kinesis 예제\", event_created_at: new Date()&#125;;const params = &#123; Data: JSON.stringify(KinesisData), PartitionKey: 'partition', StreamName: 'testKinesis'&#125;;kinesis.putRecord(params, function(err,data)&#123; if (err) &#123; console.log('Error sending a message', err); &#125; else &#123; console.info(data); &#125;&#125;); 이제 실행해보자. node kinesis.js 12&#123; ShardId: 'shardId-000000000000', SequenceNumber: '49571470617410410658004564491315382019801680888626937858' &#125; Lambda쪽 실행 결과를 살펴보자. 1234567891011121314&#123; Records: [ &#123; kinesis: &#123; kinesisSchemaVersion: '1.0',partitionKey: 'partition',sequenceNumber: '49571470617410410658004564491315382019801680888626937858',data: 'eyJldmVudF9uYW1lIjoiS2luZXNpcyDsmIjsoJwiLCJldmVudF9jcmVhdGVkX2F0IjoiMjAxNy0wMy0xOVQwNDo0ODo0My4xOTlaIn0=',approximateArrivalTimestamp: 1489898923.642 &#125;,eventSource: 'aws:kinesis',eventVersion: '1.0',eventID: 'shardId-000000000000:49571470617410410658004564491315382019801680888626937858',eventName: 'aws:kinesis:record',invokeIdentityArn: 'arn:aws:iam::768556645518:role/lambda2',awsRegion: 'ap-northeast-1',eventSourceARN: 'arn:aws:kinesis:ap-northeast-1:768556645518:stream/testKinesis' &#125; ] &#125; 살펴보니 data의 값이 누가봐도 암호화 된 것으로 보인다. eyJldmVudF9uYW1lIjoiS2luZXNpcyDsmIjsoJwiLCJldmVudF9jcmVhdGVkX2F0IjoiMjAxNy0wMy0xOVQwNDo0ODo0My4xOTlaIn0= Amazon Kinesis Streams Service API Reference 를 보면 base64로 암호화 되었다고 나온다. 3.4 Lambda 코드에서 Kinesis Data 복호화echoTest Lambda 코드를 아래와 같이 수정한다. 123456789101112131415&apos;use strict&apos;;const util = require(&apos;util&apos;);exports.handler = (event, context, callback) =&gt; &#123; const records = event.Records; console.log(&quot;records =&quot;, records); records.forEach(r =&gt; &#123; const data = new Buffer(r.kinesis.data, &apos;base64&apos;).toString(&apos;utf-8&apos;); console.info(data); &#125;); callback(null, event);&#125;; 다시 Kinesis 호출하는 코드를 실행해 보자. node kinesis.js 12&#123; ShardId: 'shardId-000000000000', SequenceNumber: '49571470617410410658004564491322635574719439376016736258' &#125; Lambda쪽 실행 결과를 살펴보자. 1234&#123; \"event_name\": \"Kinesis 예제\", \"event_created_at\": \"2017-03-19T05:05:52.273Z\"&#125; 데이터가 잘 전달된 것을 확인할 수 있다. Kinesis에서 받은 event를 보면 Records란 Key에 대해서 배열로 생성되어 있다.Kinesis에서 Data들을 설정된 값 단위로 배열을 전달해 준다.만약 100개로 선언되었다고 해서 항상 100개 단위로 주는건 아니다.그 갯수 이하라도 데이터를 전달해주니 그걸 고려해서 코드를 작성해야 한다. 4. 그 밖에 방법들앞의 Kinesis 연동 방법을 설정하는 중 Lambda의 Triggers 탭에서 본 것처럼 AWS 상의 여러 서비스에서 Lambda 수행이 가능하다.그걸 이용해서 호출하려는 Lambda에서 해당 서비스에 데이터를 전달하고 Lambda를 호출하는 방법으로의 설정이 얼마든지 가능하다.하지만 단순히 Lambda to Lambda 호출을 위해서 그런 방법을 사용하는건 비효율적인듯하다. 대신, 원래 하려는 작업이 S3나 DynamoDB에 데이터를 쌓는게 목적이라면 거기에 데이터를 저장하고 해당 작업에 대한 Trigger로 Lambda를 수행하도록 설정하는건 괜찮을것 같다. 이 내용에 대해서는 따로 다루지 않겠다.AWS 공식문서 상에 자습서를 참고해서 따라해보면 금방 익힐 수 있을 것이다. 자습서: DynamoDB 테이블에서 새 항목 처리","categories":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/categories/AWS/"},{"name":"Lambda","slug":"AWS/Lambda","permalink":"http://DevStarSJ.github.io/categories/AWS/Lambda/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/tags/AWS/"},{"name":"Lambda","slug":"Lambda","permalink":"http://DevStarSJ.github.io/tags/Lambda/"}]},{"title":"마이크로서비스 아키텍처 구축","slug":"hanbit.Build.Microservices","date":"2017-03-16T15:00:00.000Z","updated":"2017-04-30T03:41:44.000Z","comments":true,"path":"2017/03/17/hanbit.Build.Microservices/","link":"","permalink":"http://DevStarSJ.github.io/2017/03/17/hanbit.Build.Microservices/","excerpt":"","text":"마이크로서비스 아키텍처 구축 한빛미디어 옮긴이 : 정성권 책소개 Link : http://www.hanbit.co.kr/store/books/look.php?p_code=B8584207882 원서 : Building Microservices - Sam Newman - O’Reilly Media, Inc. : http://shop.oreilly.com/product/0636920033158.do 요즘 핫한 이슈 중 하나인 마이크로서비스 아키텍쳐에 관한 번역서이다.마이크로서비스를 기반으로 개발할 때 또는 기존의 모노리스 시스템을 마이크로서비스로 변경하고자 할때 무엇을 고려해야하는지, 조직을 어떻게 관리해야하는지부터해서 모든 것을 다 다루고 있다. 전통적인 개발론에 해당하는 설계, 테스트, 배포, 통합, 모니터링, 보안, 장애복구 등에 대해서도 마이크로서비스의 관점에서 다루었다.필자가 직접 경험한 내용을 사례로 들어서 소개해주고 있어서 더더욱 신뢰가 가고 이해하기 편했다.현재 내가 회사에서 하고 있는 일과도 직접적인 연관이 있는 부분이라 그런 사례에 대한 내용에 더욱더 공감이 되었다.이 많은 내용을 책한권에 다 담기는 사실상 불가능하다.그래서 읽고 이해가 잘 되지 않는 부분도 많았다.그러기에 저자는 간단한 설명과 참고하면 좋은 책들을 많이 소개하고 있다. 마이크로서비스를 염두에 둔 회사나 개발자라면 꼭 한번 읽어보기를 권한다.하지만 책 내용이 읽고 바로 이해하기에 쉽지는 않다.아키택쳐에 관련된 서적을 기존에 읽은 적이 있다면 많은 도움이 될 것이다. 일단은 전체적으로 책 내용을 읽은 다음 각각 세부적인 것에 대해서는 필요할때마다 찾아보고 좀 더 자세한 내용이 필요한 경우에는 책에 소개된 참고서적을 구입해서 같이 읽으면 좋을것이다.","categories":[{"name":"Book","slug":"Book","permalink":"http://DevStarSJ.github.io/categories/Book/"},{"name":"Review","slug":"Book/Review","permalink":"http://DevStarSJ.github.io/categories/Book/Review/"}],"tags":[{"name":"Book","slug":"Book","permalink":"http://DevStarSJ.github.io/tags/Book/"},{"name":"Review","slug":"Review","permalink":"http://DevStarSJ.github.io/tags/Review/"}]},{"title":"AWS Lambda 사용에 관련된 Tip","slug":"Lambda.Tips.01","date":"2017-03-10T15:00:00.000Z","updated":"2017-04-23T09:24:20.000Z","comments":true,"path":"2017/03/11/Lambda.Tips.01/","link":"","permalink":"http://DevStarSJ.github.io/2017/03/11/Lambda.Tips.01/","excerpt":"","text":"AWS Lambda 사용에 관련된 Tip그동안 AWS Lambda를 사용하면서 알게된 내용들과 최근 읽은 Lambda 관련 포스팅 내용들을 정리해 보았다. 1. Memory ConfigurationLambda의 과금은 실행 시간 x 사용한 메모리에 의해 결정된다. Lambda 실행에 메모리를 얼마나 사용하지는지를 볼려면 Lambda 내의 Test기능을 이용하면 확인이 가능하다. 위 그림을 보면 1024 MB로 설정되어 있으며, 실제 사용량은 29 MB란 것을 알 수 있다. Lambda가 실행하는 인스턴스의 성능은 메모리 설정값에 비례해서 CPU 성능도 결정되기 때문에 메모리 사용량이 적다고 무조건 거기에 맞게 설정을 하면 당연히 그만큼 수행시간이 길어 질 수가 있다. 메모리를 1/10 정도로 줄이니 수행시간도 10배 정도로 더 늘어난 것을 확인할 수 있다.그러므로 최소 과금으로 설정을 하기위해서 메모리를 무조건 수행가능한 최소로 설정하는 것보다는 설정값을 바꿔가면서 테스트를 해보고 결정을 하면 된다.이렇게 미리 테스트를 해보면 이왕이면 같은 금액이면서 좀 더 빠르게 수행하는 방향으로 설정하는게 가능하다. 과금보다 빠른 서비스가 더 중요한 경우라면 메모리를 무조건 최대로 설정하는게 좋다.하지만 메모리를 높인다고 해서 무조건 그만큼 더 빨리지는건 아니다. Lambda에서 동작하는 작업 성격에 따라 메모리 설정을 더 늘려도 더 이상 수행시간이 줄어들지 않거나 줄어드는 비중이 급격히 낮아지는 구간이 있으니 테스트 해본 후 적절히 설정하면 된다. 2. Warm StartLambda를 실행하면 해당 코드를 컨테이너 같은데 할당하여 EC2 instance 형식으로 수행하는 것으로 알려져 있다.그래서 최초 수행시 cold start(해당 자원을 할당받는 시간) 때문에 수행시간이 좀 더 걸린다.위에 그림을 보더라도 첫번째 그림과 두번째 그림의 메모리 설정값이 같은데 수행시간이 다르다. 그걸 방지하는 방법으로 CloudWatch Schedule Event를 이용해서 5분 간격으로 Lambda를 한번씩 호출해주면 늘 warm start(바로 수행이 가능한 상태)로 유지가 가능하다.실제로 Lambda가 수행되면 안될 경우에 호출되었을 때를 대비해서 따로 ping 같은 요청에 대해서 아무 일도 하지 않도록 코드를 추가해 주어야 한다. 하지만 이것이 모든것을 해결해주는 것 같지는 않다.회사에서 다른 동료분이 테스트 해본 결과를 보니 이미 warm start 가능한 Lambda가 떠있는 상태에서 호출이 많아져서 새로운 인스턴스로 Lambda를 올려야 하는 경우를 보니 cold start로 수행되는 것 같다는 결론에 도달했다.아직 정확히 어떻게 동작하는지에 대해서 알려진바가 없으니 테스트를 수행하면서 응답시간이 얼마나 걸리는지를 가지고 추측할 뿐이다. 3. Re-use Lambda위 항목에서 얘기했드시 Lambda가 warm start되는 경우 기존에 실행한 컨테이너를 재사용해서 수행한다.이를 이용해서 Lambda 수행시간을 짧게 할 수 있도록 코드 작성이 가능하다. 전역 변수를 선언해 놓고 그 값으로 테스트 해보니 warm start되는 Lambda의 경우 그 값을 계속해서 가지고 있다. 이를 이용해서 각종 라이브러리(npm 포함)들에 대한 초기화 코드를 handler 안에서가 아니라 전역에서 수행해두면 warm start의 경우 다시 초기화 코드를 수행하지 않아도 된다. 단, 이로 인해 발생하는 사이드 이펙트가 있는 경우에는 그것에 대한 방어코드가 추가되어야 한다. DB 커넥션 역시도 매번 연결 -&gt; 쿼리수행 -&gt; 종료를 수행하는것 보다는 전역에 커넥션 객체를 두고 연결이 안된 경우에만 연결을 수행하고 계속해서 재사용하는 것도 가능하다.이 경우 재사용되는 Lambda에서는 다시 연결할 필요가 없으니 빨라진다.하지만 자주 사용되지 않은 Lambda에 대해서는 DB 입장에서 비효율적이니 사용하면 안좋을 것이다. 그리고 필요없이 DB 커넥션이 오랫동안 유지될 수 있다는 단점도 있다.예를 들어 평균 초당 100번 수행되며 평균 수행시간이 100ms인 Lambda의 경우 10개의 인스턴스가 활성화되어 있을 것이다.그런데 갑자기 1초에 200개의 요청이 오고, 그 다음부터 다시 1초당 100번의 요청이 오는 경우를 생각해보자.갑자기 200개의 요청이 온 것 때문에 10개의 인스턴스가 추가로 할당될 것이다. 그 다음부터는 다시 10개의 인스턴스만 있어도 수행이 되기 때문에 나머지 10개의 인스턴스에서는 15분 가량동안 사용하지 않는 DB 커넥션을 끊지 않고 계속 가지고있게 된다. 장점과 단점을 같이 가지고 있는 방법이므로 판단은 각자 알아서 하길 바란다. 4. Lambda Limit각 리젼별로 Lambda가 100개 동시 수행이 가능한 것으로 기본설정 되어 있다.이를 넘길 경우 Lambda가 수행되지 않는다.그래서 동시 수행되는 Lambda수를 제어하기 위해서 SQS를 활용하는 방법이 있다.Lambda를 바로 요청하지 않고 해당 요청을 SQS로 보내고 SQS에서 동시 실행되는 Lambda 수를 고려해서 호출을 하는 방법이다. 관련 수식에 따르면 아래와 같이 계산이 가능하다. 1Concurrent Invocations = events (or requests) per second * function duration (in secs) 하지만 API Gateway + Lambda를 활용한 Web API Service와 같이 요청시간이 늘어나는 것이 안되는 경우도 있다.이 경우에는 AWS에 요청하면 늘려준다.이 경우 Lambda 뿐만 아니라 EC2의 Network Interface (350이 MAX)과 API Gateway (초당 1000번)의 리미트도 같이 늘려야 할수 있으니 잘 계산해서 같이 요청을 해야 한다.참고로 현재 회사에서 사용중인 리미트는 Lambda 6000, Network Interface 4000, API Gateway 6000 per second 로 늘려놓은 상태이다. 5. Devide Batch Task for Lambda참고로 이 내용은 직접 겪은게 아니라 Do’s and Don’ts of AWS Lambda를 참고한 내용이다. Lambda로 Batch 작업을 나눠서 작업해야 할 경우 해당 작업을 얼마나 잘게 나눠서 각 Lambda로 할당을 해야하는지에 대해서 고민을 해야한다.대체적으로 연산이 많아서 CPU 사용량이 많은 경우는 최대한 Lambda로 잘게 나누는게 좋다.반면 Lambda 자체의 연산보다는 외부 I/O 작업이 많은 경우는 Lambda 하나의 수행시간을 길게 가져가는게 좋다. 어찌보면 당연한 말같다.CPU 연산이 많으면 최대한 병렬로 나누어서 CPU를 많이 사용하는 것이 당연히 좋을 것이다.반면, DB 연결, SQS, Kinesis 등 다른 서비스 호출 등의 통신이 필요한 경우 커넥션을 맺는 오버해드가 있으니 한 번 연결을 맺고 계속해서 수행하는게 좋을 것이다. 6. Logging in LambdaLambda 수행 중 로그를 수집하기 위해서 외부 서비스를 사용하면 그만큼 Lambda 성능에 영향을 미치게 된다. 코드에서 Node.JS의 경우 console.log, console.info, .NET core의 경우 Console.Writeline로 출력을 하면 CloudWatch에서 확인이 가능하다.이 방법을 이용하면 Lambda 성능에는 거의 영향을 미치지 않고 로그를 남길 수 있다. 하지만, CloudWatch 사용 또한 유료이기 때문에 무한정 쌓아둘수는 없다. 특정 기간 이후에 것을 S3로 보관하는 것도 가능하며, CloudWatch에 쌓인 로그를 다른 방법으로 별도 로그 시스템으로 저장을하면 원래 수행중인 Lambda 성능에는 영향을 주지 않고도 로그 수집이 가능하다. 참고 Do’s and Don’ts of AWS Lambda : &#x68;&#116;&#x74;&#x70;&#115;&#58;&#x2f;&#47;&#109;&#x65;&#x64;&#x69;&#117;&#x6d;&#x2e;&#x63;&#x6f;&#x6d;&#x2f;&#x40;&#x74;&#106;&#x68;&#111;&#x6c;&#x6f;&#x77;&#97;&#121;&#x63;&#x68;&#x75;&#x6b;&#47;&#100;&#111;&#x73;&#45;&#x61;&#x6e;&#x64;&#x2d;&#100;&#111;&#110;&#x2d;&#116;&#115;&#x2d;&#x6f;&#102;&#45;&#97;&#x77;&#115;&#45;&#108;&#97;&#x6d;&#98;&#x64;&#x61;&#45;&#x37;&#100;&#x66;&#x63;&#97;&#x62;&#55;&#97;&#100;&#x31;&#49;&#53;&#35;&#x2e;&#x78;&#x6d;&#x39;&#x34;&#x75;&#x76;&#114;&#53;&#x6c; Best practices – AWS Lambda function : https://cloudncode.blog/2017/03/02/best-practices-aws-lambda-function","categories":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/categories/AWS/"},{"name":"Lambda","slug":"AWS/Lambda","permalink":"http://DevStarSJ.github.io/categories/AWS/Lambda/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/tags/AWS/"},{"name":"Lambda","slug":"Lambda","permalink":"http://DevStarSJ.github.io/tags/Lambda/"}]},{"title":"Monolith to Serverless using AWS Lambda (3)","slug":"MonolithToServerless.03","date":"2017-02-25T15:00:00.000Z","updated":"2017-04-23T09:32:51.000Z","comments":true,"path":"2017/02/26/MonolithToServerless.03/","link":"","permalink":"http://DevStarSJ.github.io/2017/02/26/MonolithToServerless.03/","excerpt":"","text":"Monolith to Serverless using AWS Lambda기존 모노리스 API 서버를 AWS Lambda를 이용하여 서버리스로 변경하기이전글 : 1편. 서버리스를 하려는 이유이전글 : 2편. 장애 대응 플랜 3편. Lambda 배포 후 겪게되는 일들서버리스를 가능하게 해주는 서비스 중 가장 많이 알려진게 AWS Lambda이다.간단하게 설명하자면 서버를 실행해 놓는게 아니라 실행될 코드를 올려놓고 해당 코드를 실행시킬 이벤트를 발생시키면 코드가 동작하는 것이다.코드가 어느 PC에서 동작하는지에 대해서는 우리가 신경쓸 필요없이 AWS에 전적으로 맡겨놓는다.과금은 Lambda 실행시간(100ms 단위)으로 한다.1편 글에서 얘기했듯, EC2 서버로 운영할때는 갑자기 요청이 몰리는 경우 서버에 장애가 발생할 수 있는데 Lambda의 경우는 그런 상황자체를 전부 AWS에서 알아서 해달라고 위임하는게 된다.이렇게 생각하는게 보다는 AWS에서 많은 사용자가 공통으로 사용할 굉장히 큰 서버를 띄워놓고 우리는 거기에서 우리 코드가 실제로 실행되는 시간만큼만 과금을 한다라고 생각하는게 더 쉬운가 ? Lambda를 수행하기 위해서는 aws-sdk를 이용해서 호출을 하거나, AWS 내의 각종 서비스들 CloudWatch, SQS, SNS, Kinesis, DynamoDB 등에서 트리거를 통해서 실행되게 할 수 있다.Lambda를 API로 사용하기 위해서는 API Gateway를 통해서 url 형식으로 외부 요청을 받아서 Lambda 실행이 가능하다.서버리스를 구현하기 위해서는 주로 이 방법을 사용한다. API 요청 정보 분석기존의 EC2로 수행하던 API 서버를 CloudFront를 통해서 수행되도록 설정하였다.CloudFront에서는 요청들에 대해서 S3로 로그를 생성해주는 기능을 제공한다.2편에서 설명한 장애 대응 플랜을 수행하는 동안 로그를 계속 쌓아두어서 이걸 분석하여 Lambda로 옮길 API의 순서를 정했다. 전체적으로 옮길 API수는 100개가 살짝 넘는 수였다.하지만 로그를 보니 이전체가 지금 사용되는 것은 아니었다.3주 동안 호출된 API의 수는 50 정도가 되었으며, 이 중 많이 호출되고 내부 코드가 비교적 간단한 것부터 작업을 시작했다. S3에 쌓아둔 로그는 python의 boto3를 이용해서 그냥 노트북으로 다운받아서 gz 압축을 풀고 내가 필요한 정보만 따로 추려서 csv로 만들어서 각 url path 별로 호출 빈도를 카운팅하였다.그런데 path를 인자로 사용하는 경우는 전부 다른 path url로 인식되어서 간단하게 그런 경우만 따로 path pattern을 만들어서 csv 파일을 만들도록 수정했다. S3에 쌓아둔 로그를 보니 querystring 정보는 볼 수 있었지만, POST 요청에 대한 body 정보는 없었다. headers의 정보가 전부 다 있는건 아니었지만 중요한 몇가지는 제공해주고 있었다. 첫번째로 옮길 API는 네번째로 자주 요청되는 사용자 정보를 JSON 형식으로 보내주는 API(/user/{id})로 정했다.Lambda 명칭도 그냥 api-user-id로 지었다. 첫번째 리미트 : Lambda 리미트AWS Lambda 리미트의 기본값은 각 리젼 당 100번이다.동시에 수행가능한 Lambda의 수를 뜻한다.대략적으로 수행시간이 100ms인 Lambda인 경우 초당 1천번까지 호출해도 괜찮다.물로 이 수치는 평균적인 것이지 이런 요청이 순간적으로 100번 이상 호출되면 실패가 발생한다.Lambda 리미트가 발생한 것은 Lambda쪽 CloudWatch 로그에서는 확인이 되지 않는다.왜냐면 수행 자체가 안되었기 때문에 Lambda에 로그가 발생하지 않는다.해당 Lambda로 연결된 API Gateway의 오류를 CloudWatch로 로그를 남기도록 설정하면 확인이 가능하다.정확인 오류 메세지는 기억이 나지 않지만 exceed로 검색을 한것 같다. 현재 회사 계정에서는 도쿄 리젼에 Lambda 리미트를 200개로 늘려놓은 상태였다. api-user-id를 배포한 후 얼마 지나지 않아서 5XX 오류가 분당 150번 정도 계속 발생하였다.일단 API를 원래대로 롤백한 후 로그를 보니 Lambda 리미트에 걸렸다.처음부터 너무 요청이 많은 API를 옮긴것 같다.AWS에 요청을 했다.EC2로 되어있는 서버를 Lambda로 옮기고 있다.100개가 넘는걸 모두 옮길려고 하는데 그 중 1개만 옮겼는데도 Lambda 리미트가 발생했다.1 ~ 2k 정도로 좀 올려달라고 요청을 했더니 이틀 뒤 아침에 출근해서 확인하니 2000개로 리미트를 올렸다는 내용을 확인 할 수 있었다. 두번째 리미트 : Subnet LimitLambda 리미트가 2000개로 증가되었다는 소식을 듣고 API를 다시 배포하였다.아침 일찍 배포했는데 정상적으로 잘 동작하고 있었다.오후 4시에 앱 푸시가 나간 뒤 Lambda 수행이 분당 1만번을 넘기면서 5XX 오류가 지속적으로 발생했다. 다시 API를 롤백하고 API Gateway쪽 오류를 살펴보니 처음보는 메세지 였다. 123456789Endpoint response body before transformations:&#123; &quot;Message&quot;: &quot;Lambda was not able to create an ENI in the VPC of the Lambda function because the limit for Network Interfaces has been reached.&quot;, &quot;Type&quot;: &quot;User&quot;&#125;Execution failed due to configuration error: Malformed Lambda proxy responseMethod completed with status: 502 VPC에서 ENI를 만들지 못했단다.Lambda를 VPC에서 수행되도록 설정할 필요는 없다.하지만 보안을 위해서 그렇게 설정해 놓는 경우가 많다.MySQL의 경우 사용자 ID, 비밀번호로만 보안을 설정해 놓는것 보다는 특정 대역대의 IP들만 접속을 허용해 놓는게 더 안전하다.Lambda 같은 경우는 어떤 IP로 생성되는지 우리가 알 수가 없으므로 VPC 설정을 통해서 특정 대역대의 subnet 안에서 생성되도록 설정이 가능하다.AWS VPC 서비스를 이용하여 생성된 VPC와 subnet을 설정해 두었다. subnet은 4000개짜리 2개를 설정했다.합이 8000개인데, 동시 수행수가 2000개짜리 Lambda가 리미트에 걸려서 생성되지 않았다니… 그래서 16000개짜리 subnet을 하나 더 생성하였다.기존에 수행중이던 Lambda도 많이 있었으므로, 이번에 새로 만든 api-user-id에는 기존의 4000개 subnet 하나와 새로만든 16000개 하나를 설정해 두었다.합이 2만개인데 당연히 부족하지 않으리라 판단했다. 세번째 리미트 : Network Interface 리미트사실상 두번째 리미트는 VPC 리미트가 아니라 Network Interface 리미트 였다. 이틀 뒤에 해당 API를 다시 배포했다.그런데 비슷한 시기에 비슷한 빈도로 5XX 오류가 발생하였다.분명 subnet의 수가 2배 이상으로 늘렸는데도 계속 오류가 발생하였다.왜 그럴까 생각을 해봤는데, subnet 2개 (4000개, 16000개)를 합쳐서 2만개 중에 1개로 할당하는게 아니라 2개의 subnet 중 하나를 선택해서 거기에 할당을 하는 식을 동작하는게 아닌가라 판단된다.그래서 바로 4000개의 subnet을 설정에서 삭제하였다.삭제하자마자 요청 대비 오류가 50% 가까이로 발생했다.다시 해당 API를 롤백했다.그 뒤에 생각해보니 요청을 삭제한 subnet쪽 주소로 계속해서 보냈던 것으로 추정된다.2개 중 1개를 삭제했으니 50% 정도의 오류가 발생한게 아닌가 생각된다. 그런데 문제는 subnet의 갯수가 부족해서가 아니라 다른 곳이었다.AWS에 문의를 하니 http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Appendix_Limits.html#vpc-limits-enis 링크를 보내주었다.리전당 Network Interface가 최대 350개라고 설명이 되어 있다. 더 늘리고 싶으면 문의를 하라고 되어있다.회사 동료분이 저 정보를 어디서 확인 가능한지 찾아주었다. EC2로 들어가서 왼쪽에 보면 Network Interface라는 탭이 있다.거기에 들어가보니 현재 사용중인 Network Interface가 341개 였고, 그중 Description이 AWS Lambda 로 시작하는게 240개가 넘었다.다시 AWS에 문의를 하여 해당 리미트를 늘려달라고 하였더니 2000개로 늘려줬다는 답변이 왔다. 일단 subnet을 4000개 6개로 다시 할당을 하여서 배포를 했는데, 그 뒤로는 해당 오류가 더 이상 발생하지 않고 정상적으로 동작하였다. 네번째 리미트 : API Gateway 리미트API Gateway에도 리미트가 있다.기본적으로는 평균 초당 1000번, 최대 1초당 2000번의 요청을 처리 가능하도록 되어있다. CloudWatch를 통해서 살펴보던 중 특정 시간대에 5XX 오류가 발생되었길래 그때를 살펴보니 1분에 2만번 정도의 요청이 있었다.초당 요청으로 계산하면 API Gateway의 리미트보다 작았지만, 혹시 짧은 시간에 2000번 이상의 요청이 있지 않았나 판단되어 AWS에 요청하였으나,API Gateway의 문제는 아니었고, Lambda 리미트가 발생한 것으로 판단되었다면서 Lambda 리미트를 3000개로 늘려주었다. 그 이후…그 뒤 해당 API는 잘 동작하고 있다.다른 API들도 작업해서 배포를 했는데 아무런 문제가 없다.하지만 앞으로 몇 개의 API를 더 배포하면 현재의 리미트를 다시 넘기지 않을까 걱정이 된다.그걸 미리 예측해서 AWS에 요청을 하면 과연 들어줄지 모르겠다.그래서 항상 API를 배포하고는 Lambda 실행수, Network Interface 수 등에 대해서 모니터링을 하고 있다. 기타 작업하면서 겪은 일들1. CloudFrontCloudFront에서 캐시설정 할 때 headers에 토큰 같은것을 전달하여 그것에 대해서 다른 값을 줘야할 경우에는 사용하면 안된다.headers에 다른 정보를 전달하더라도 쿼리스트링이 동일한 경우 캐시에서 같은 값으로 응답한다. CloudFront에서 API Gateway로 headers의 정보 중 포워드 할게 있는 경우 host 정보를 넘겨주면 CloudFront 오류가 발생한다. 2. LambdaLambda 작업시 console.log 같이 출력문을 넣어주면 해당 Lambda의 CloudWatch에서 출력문을 볼 수 있다.이걸 이용해서 초반에 테스트 할 때는 필요한 모든 곳에 console.log, console.info, console.dir 등을 이용해서 확인이 가능하며,서비스용으로 올릴때도 event 정보는 console.info로 출력을 해 놓으면 오류 발생시 뭐 때문이지 확인할때 편리하다.API Gateway의 로그를 보면 event정보가 짤려서 출력되기 때문에 전체 다를 볼려면 Lambda쪽에서 출력해줘야 한다.당연히 이렇게 하면 성능에 영향을 미치므로 그게 걱정스럽다면 최소한 try-catch를 이용해서 오류 상황에서만이라도 출력해 놓으면 나중에 디버깅 할 때 좋다. TypeScript로 작업할 경우 Node 4.3에서 정상적으로 동작하는 코드라도 Lambda에 올렸을 경우 동작하지 않을 수도 있으니 꼭 테스트를 먼저 해보고 작업을 하는게 좋다.class, async/await 등은 제대로 되지만 static, default parameter 등에 대해서는 제대로 동작하지 않는다. 3. API GatewayAPI Gateway는 Lambda 호출후 30초 동안만 기다린다.그러니 해당 Lambda 실행시간을 30초 이상으로 설정할 필요가 없다. API Gateway를 {proxy+} 설정으로 사용하고, 1개의 Lambda에서 2가지 이상의 API 코드가 들어있더라도, Lambda를 다른 이름으로 배포하여 각 API별로 할당하는게 좋다.만약 1개의 Lambda에 2개 이상의 API가 같이 처리 될 경우 오류 발생 상황에서 로그로 확인하는게 힘들다.이게 맘에 안든다면 더 이상 오류가 발생하지 않고 안정적으로 서비스되고 있는 상황에서 Lambda 및 API Gateway의 {proxy+} 설정을 합치면 된다. API Gateway에는 쿼리스트링을 파싱하여 JSON 형태로 Lambda에 전달된다.그런데 그 과정에서 기존의 다른 웹 프레임워크랑 다르게 동작한다.대표적인 예가 쿼리스트링의 경우 구분자로 &amp;를 사용하는데 API Gateway에서는 ;도 구분자로 인식은 한다.그렇기 때문에 ?idList=1;2;3&amp;filter=name;phone&amp;flag=1;2로 전달할 때 API Gateway는 {IdList: 1, 2: , 3: , filter:name, phone: , flag: 1} 식으로 해석을 해버린다.저런 모양이라도 억지로 해석해서 사용하는 방법도 있지만 그 과정에서 idList의 2와 flag의 2개 같은 key로 인식이 되어서 해석이 애매모호해진다.배열값을 ?id=1&amp;id=2&amp;id=3의 모양으로 전달할 경우에도 {id:3}으로 마지막값 하나만 남겨두고 다 사라진다.현재로서는 제대로 처리되도록 하는 방법을 찾지 못했다.CloudFront상의 리퀘스트 로그를 살펴보면 쿼리스트링의 모양이 그대로 남아있는 것으로 봐서는 LambdaEdge를 사용해서 쿼리스트링을 수정한 뒤 API Gateway로 전달하여 처리하는 방법도 있겠지만,현시점(2017년 2월) LambdaEdge는 프리뷰인데다가 리젼당 100개의 리미트 밖에 허용하지 않아서 실제 서비스에 사용하기에는 망설여진다.당연한 이야기지만 요청하는 쪽에서 ;를 인코딩하여 %3B로 전달하면 정상적으로 처리가 가능하다. Lambda와 API Gateway를 이용해서 Serverless Web API 만들기 Lambda 와 API Gateway 연동 #1 (GET, POST) Lambda 와 API Gateway 연동 #2 (ANY, Deploy Staging, Node.JS Route) Lambda 와 API Gateway 연동 #3 (Proxy Resource) Lambda Node.JS Packaging AWS Lambda에 Python Handler 만들기 Lambda Python Packaging Lambda C# Handler 만들기","categories":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/categories/AWS/"},{"name":"Lambda","slug":"AWS/Lambda","permalink":"http://DevStarSJ.github.io/categories/AWS/Lambda/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/tags/AWS/"},{"name":"Lambda","slug":"Lambda","permalink":"http://DevStarSJ.github.io/tags/Lambda/"},{"name":"Serverless","slug":"Serverless","permalink":"http://DevStarSJ.github.io/tags/Serverless/"}]},{"title":"Monolith to Serverless using AWS Lambda (2)","slug":"MonolithToServerless.02","date":"2017-02-24T15:00:00.000Z","updated":"2017-04-23T09:28:21.000Z","comments":true,"path":"2017/02/25/MonolithToServerless.02/","link":"","permalink":"http://DevStarSJ.github.io/2017/02/25/MonolithToServerless.02/","excerpt":"","text":"Monolith to Serverless using AWS Lambda기존 모노리스 API 서버를 AWS Lambda를 이용하여 서버리스로 변경하기이전글 : 1편. 서버리스를 하려는 이유 2편. 장애 대응 플랜기존에 잘 돌아가고 있는 API 서버 (EC2)를 서버리스(Lambda)로 변경하고자 한다.만약 람다로 구현한 API가 정상동작하지 않는 경우 기존의 EC2 서버로 되돌리면 된다.이게 끝. 심플하지 않은가 ?이 심플함을 구현하기 위해 얼마나 컴플랙스한 일들이 필요한지에 대한 것이 2편의 전반적인 내용이다. 기존 API 서버에 대한 정보만약 api.luna.com이란 이름의 API 서버를 EC2에 올려놓고 오토 스케일링 (AWS의 Elastic Beanstalk 을 통해 서비스하고 있는 경우라면,ELB에서 제공해 주는 url은 api-luna.elasticbeanstalk.com과 같은 이름이 된다. 이것을 api.luna.com란 이름의 도메인을 쓰기 위해서는 DNS 서비스를 이용해야 한다.회사에서는 CloudFlare라는 서비스를 이용하는데 CDN은 거의 사용하지 않고 DNS로만 사용한다. 즉, 아래와 같은 모양으로 되어 있다. 1- C#으로 되어 있는 API Server : ELB(api-luna.elasticbeanstalk.com) &lt;- DNS(api.luna.com) 만약 API의 url이나 파라메터 정보들을 수정하게 된다면, 해당 API를 사용하는 웹, 앱(안드로이드, 아이폰)도 함께 수정해서 배포를 해야하니 일이 커진다.그리고 만약 장애시 다시 되돌리지도 못한다.그래서 기존 url은 바꾸지 않고 가야한다.같은 url에 path 정보가 다른 것들에 대해서 서로 다른 엔드포인트로 보낼려면 어떻게 해야할까 ? (람다는 서버가 아니므로 그냥 엔드포인트(endpoint)로 하겠다.) AWS CloudFront라는 CDN을 사용하면 각 path 별로 캐시 정책, 엔드포인트 등의 설정을 다르게 할 수 있다.일단 기존에 ELB에서 돌아가는 서버를 CloudFront를 통해서 서비스 되도록 설정을 변경하였다. 123- 기존 API Server의 DNAME 변경 : ELB(api-luna.elasticbeanstalk.com) &lt;- DNS(api-origin.luna.com)- 기존 주소를 CloudFront로 연결 : CloudFront(cf1.cloudfront.net) &lt;- DNS(api.luna.com)- CF의 Default(*) Origin을 api-origin.luna.com 으로 설정 하나의 흐름으로 그려보면 아래와 같이 된다. 1ELB(api-luna.elasticbeanstalk.com) &lt;- DNS(api-origin.luna.com) &lt;- CloudFront(cf1.cloudfront.net) &lt;- DNS(api.luna.com) 새로만드는 람다를 API Gateway를 통해서 서비스 할 경우 CloudFront에서 해당 path에 대해서만 람다를 보도록 설정을 붙이기만 하면 된다.(람다로 만든 API의 path가 api.luan.com/user/{id}라고 가정하고, 람다명칭을 api-user-id라고 할 경우) 12ELB(api-luna.elasticbeanstalk.com) &lt;- DNS(api-origin.luna.com) &lt;- CloudFront(cf1.cloudfront.net) &lt;- DNS(api.luna.com)Lambda(api-user-id) &lt;- API Gateway(exec-api.amazonaws.com/service) &lt;- 이런 모양으로 구성이 된다.이건 API를 어떻게 구상하냐는 것에 대한 것이고 장애대응에 대한건 아직 고려되지 않은 형태이다. 장애대응앞에서 얘기했듯이 API가 정상적으로 동작하지 않아서 장애가 났을 때는 해당 API 대신 그냥 기존의 EC2(api-origin.luna.com)을 바라보게하면 된다.아주 심플하다.그럼 이 심플함을 어떻게 구성해야 할까. 첫번째 생각 : CloudFront에서 Behavior 삭제CloudFront에서 람다로 향하는 Behavior를 삭제한다.그러면 api-origin을 바라볼 것이다. 끝 ? 하지만…CloudFront는 특정 지역(region)별로 서비스되는게 아니라 글로벌로 서비스된다.그리고 설정을 변경하면 전체적으로 반영되는데 40분 정도의 시간이 걸린다.40분동안 장애난 상황을 멀뚱멀뚱 지켜만 봐도 될까 ?당연히 난리난다.일단 이 방법은 안된다. 테스트 해볼 가치도 없다.그냥 패스하자. 두번째 생각 : DNS만 살짝 바꿔서 다른 CloudFront를 바라보게 설정CloudFront를 2개를 만든다.위에서 설정한 cf1 과 api-origin만 바라보는 cf2.api.luna.com은 cf1을 향하게 하다가 장애 발생시 cf2를 바라보게 설정하면 된다.DNS 바꾸는건 바로 반영되기 때문에 장애 대응 시간을 2분 정도로 줄일 수 있다. 일정 기간동안 정상적으로 서비스되었다고 판단이 되는 api에 대해서는 cf2의 behavior에도 추가를 해놓으면 된다.그러면 장애 발생시 cf2로 되돌리더라도 새로 추가한 api에 대해서만 롤백이 된다. 1234ELB(api-luna.elasticbeanstalk.com) &lt;- DNS(api-origin.luna.com) &lt;- CloudFront(cf1.cloudfront.net) &lt;- DNS(api.luna.com)Lambda(api-user-id) &lt;- API Gateway(exec-api.amazonaws.com/service) &lt;-ELB(api-luna.elasticbeanstalk.com) &lt;- DNS(api-origin.luna.com) &lt;- CloudFront(cf2.cloudfront.net) 위 그림과 같이 서비스하다가 장애 발생시 api.luna.com의 주소만 cf2로 변경하면 된다.일단 cf2를 만들어 보았다.안만들어진다.CloudFront에서 DNS를 사용하기 위해서는 CNAMEs를 설정해야 한다.그런데 서로 다른 CloudFront가 같은 CNAME을 가지도록 설정이 안된다.왜 안된다는 건지 이해가 안된다.어차피 실제로 같은 DNS가 동시에 2개의 CloudFront를 바라보고 있다는거 자체가 말이 안되는데 그렇게 설정하게 좀 해줘도 상관없지 않나 ?일단 안된다니깐 이 방법은 사용할 수 없다. 세번째 생각 : 그럼 DNS를 여러개 설정CloudFront가 같은 CNAME으로 설정이 안되니 DNS를 여러개 만들어서 DNS단에서 스와핑을 하면 해결되지 않을까 ? 123456ELB(api-luna.elasticbeanstalk.com) &lt;- DNS(api-origin.luna.com) &lt;- CloudFront(cf1.cloudfront.net) &lt;- DNS(api1.luna.com)Lambda(api-user-id) &lt;- API Gateway(exec-api.amazonaws.com/service) &lt;-ELB(api-luna.elasticbeanstalk.com) &lt;- DNS(api-origin.luna.com) &lt;- CloudFront(cf2.cloudfront.net) &lt;- DNS(api2.luna.com)DNS(api1.luna.com) &lt;- DNS(api.luna.com) 이렇게 DNS 끼리 연결해두고 장애 발생시 api.luna.com 이 api2.luna.com 을 바라보게 설정하면 된다.너무 쉽다. 그런데…CloudFront의 CNAME에 api1.luna.com 이라 설정해두고, api1.luna.com &lt;- api.luna.com으로 설정을 하면 api.luna.com은 CNAME으로 설정되어 있지 않다고 오류가 발생한다.음… 어쨌든 안된단다. 다른 방법을 또 생각해 봐야지. 네번째 생각 : API Gateway에서 EC2를 바라보게 설정이 방법만은 사용하지 않으려 했는데…이 방법 밖에 없는것 같다. 12ELB(api-luna.elasticbeanstalk.com) &lt;- DNS(api-origin.luna.com) &lt;- CloudFront(cf1.cloudfront.net) &lt;- DNS(api1.luna.com)Lambda(api-user-id) &lt;- API Gateway(exec-api.amazonaws.com/service) &lt;- 위의 형태로 서비스를 하다가 api-user-id에 장애가 발생한 경우 12ELB(api-luna.elasticbeanstalk.com) &lt;- DNS(api-origin.luna.com) &lt;- CloudFront(cf1.cloudfront.net) &lt;- DNS(api1.luna.com)ELB(api-luna.elasticbeanstalk.com) &lt;- API Gateway(exec-api.ama...) &lt;- 이렇게 API Gateway에서 람다 대신에 api-origin을 바라보게 설정을 변경한다.먼저 이렇게 해서 장애 상황을 일단 해결한 후 CloudFront에서 behavior를 삭제하고 40분뒤에 적용되면 다시 API Gateway를 람다를 바라보도록 수정하고 API를 수정하는 식으로 작업을 진행하면 된다. 네번째 생각의 보완점들테스트해보니 원하는대로 동작한다.하지만 뭔가 찜찜한게 몇 가지 있다. 그 중 첫번째는 장애 발생시 마우스 클릭이나 미리 설정해놓은 스크립트 실행 같은 방법이 아니라 AWS 콘솔로 접속해서 설정을 하나하나 바꿔주면서 api-luna.elasticbeanstalk.com/user/{proxy} 또는 api-origin.luna.com/user/{proxy} 이렇게 입력해줘야 한다.완벽한 해결방법은 아니지만, API Gateway를 발행할때 먼저 api-origin을 바라보게 배포하고, 다시 수정해서 람다를 바라보게 배포하면 된다.그럼 해당 스테이징에 가보면 2가지 경우가 모두 Deployment History에 남아있어서 과거 버전을 선택한 후 Change Deployment 버튼을 누르면 된다. 두번째는 API Gateway url끝에 스테이지명을 항상 붙여줘야 한다.만약 스테이지를 service로 설정했다면 exec-api.amazonaws.com/service이런식의 url을 가지게 된다.url을 줄여주기 위해서 DNS를 설정하려고 해도 /service 때문에 원하는대로 설정이 안된다.그렇다고 DNS에서 주는 이름 뒤에 /service를 붙이는 것으로 CloudFront에서 behavior를 설정하려는 순간 막막해진다. API Gateway에 Custom Domain Names 탭으로 가면 이름을 이쁘게 지어줄수 있다.하지만 SSL용 인증서를 등록해야 하는데, AWS의 인증서는 또 지원을 해주지 않는다.그래서 무료 인증서인 Lets’ Encrypt에서 발급받으면 된다.발급받는것도 쉽지는 않다. 인증서 발급을 위해서 현재 해당 주소의 서버를 사용중이라 것을 증명해야하는데 API Gateway에서 그 인증을 해줄수가 있나 ?발급받은 방법이 여러가지 있는데…그 중 하나를 대충 설명하자면 nginx를 이용해서 임시로 서버를 하나 띄워서 DNS에서 그 서버를 바라보게 설정한 후 인증서를 발급받아서 사용하면 된다.구글에서 검색해보면 관련 방법 및 코드들이 쭉 나온다. 회사 동료분중 이미 해당 작업을 위한 코드를 만들어두고 발급받고 계신분이 있어서 그 분 도움을 받아서 쉽게 발급 받을 수 있었다. 처음엔 SSL 인증서 발급받는게 귀찮아서, Custom Domain Name을 사용하지 않을려고 그 과정 자체를 API Gateway &lt;- CloudFront &lt;- DNS 식으로 몇 단계를 더 거치게 했었는데그 과정에서도 CloudFront에서 SSL 인증서를 써야하고… (기존 서비스에 쓰던걸 같이쓰면 되긴 했다.) 설정 자체도 너무 복잡해져서 다시 Custom Domain Name을 사용하기로 결정했다. 실제로 적용처음 API를 배포할때는 네번째 방법(장애발생시 API Gateway에서 EC2를 바라보게 설정)을 사용했지만, 지금은 그냥 첫번째 방법(CloudFront에서 behavior를 삭제)을 사용한다.사실 삭제도 아니고 그냥 url 앞에 /test 이런걸 붙여서 주소만 바꿔버린다.40분동안 장애가 나도록 그냥 내버려 두고 있냐고 ?그건 당연히 아니다.CloudFront의 설정을 수정하면 그게 완벽하게 적용되었다고 콘솔상에 표시되는건 40분 정도가 걸리지만, 실제로 적용되는건 평균 1분 정도, 아무리 길어도 3분 이내에는 바뀌는게 확인되었다.내부적으로 어떻게 동작하는지 알 수는 없지만 현재 AWS 도쿄 리전만 사용을 하다보니 CloudFront에서도 일단 가장 많이 사용하는 도쿄 리전부터 적용해주는 것으로 보인다. 어떻게 이 사실을 알수가 있었냐면 새로운 API 배포시 해당 람다, API Gateway에 대한 주요 수치들에 대해서 CloudWatch Metrics에 미리 등록해두고 모니터링을 했다.배포전에 먼저 CloudWatch부터 띄워둔체로 배포를 하고 계속 수치 및 그래프를 확인하고 있으니깐 거의 바로 람다로 호출이 들어오는 것이 확인되었다.API 배포 초반에는 거의 배포하자마자 바로 장애가 났었다. 그래서 2주 동안은 배포, 롤백을 몇 번씩 겪었다. 그러면서 CloudWatch 상의 각종 수치들을 보고 어떻게 해석해야하는지에 대해서 자연스럽게 잘 알게 되었다.네번째 방법이 아무래도 첫번째 방법보다는 손이 많이 간다. 그렇게 해서 되돌리는 시간과 그냥 첫번째 방법으로 behavior만 삭제한 후 적용되는 시간의 차이가 거의 없었다. 오히려 첫번째 방법이 더 빠르게 적용되 되는 것으로 판단되었다. 다음 글에 계속…다음 글에는 람다 배포 후 들이닥치게 되는 각종 리미트들… 리미트 뒤에 숨어있는 또 다른 리미트들에 대한 이야기를 쓸 예정이다. 다음글 : 3편. Lambda 배포 후 겪게되는 일들","categories":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/categories/AWS/"},{"name":"Lambda","slug":"AWS/Lambda","permalink":"http://DevStarSJ.github.io/categories/AWS/Lambda/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/tags/AWS/"},{"name":"Lambda","slug":"Lambda","permalink":"http://DevStarSJ.github.io/tags/Lambda/"},{"name":"Serverless","slug":"Serverless","permalink":"http://DevStarSJ.github.io/tags/Serverless/"}]},{"title":"Monolith to Serverless using AWS Lambda (1)","slug":"MonolithToServerless.01","date":"2017-02-22T15:00:00.000Z","updated":"2017-04-23T09:28:24.000Z","comments":true,"path":"2017/02/23/MonolithToServerless.01/","link":"","permalink":"http://DevStarSJ.github.io/2017/02/23/MonolithToServerless.01/","excerpt":"","text":"Monolith to Serverless using AWS Lambda기존 모노리스 API 서버를 AWS Lambda를 이용하여 서버리스로 변경하기1편. 서버리스를 하려는 이유최근 새로 입사한 곳에서 하고 있는 작업이 기존의 모노리스로 운영중이던 API Server를 서버리스로 옮겨가는 작업을 하고 있다.그 과정에서 겪었던 여러가지 일들과 나의 생각들을 공유하고자 하는 차원에서 포스팅을 결심했다. 요즘 유행중인 단어 중에 Serverless Architecture 란 말이 있다.위키피디아에는 Serverless computing으로 들어가보면 잘 설명되어 있다.서버리스가 어떤 장점이 있길래 다들 서버리스, 서버리스 노래를 부를까 ? 서버리스의 장점 = 모노리스의 단점1. 서버 스케일링이 필요없다.요즘 서버를 직접 운영하는 경우는 잘 없고 대부분 클라우드 서비스를 이용한다. (ex. AWS의 EC2)서버가 죽는 대부분의 경우는 서버가 감당가능한 통신 대역폭, 메모리 용량, 컴퓨팅 능력을 넘어서는 요청이 들어오는 경우이다.대부분의 경우는 그렇게 요청이 많이 들어오는 것에 대해서 어느 정도 알 수 있으므로, 미리 서버를 많이 늘려놓으면 된다.그리고 요즘은 클라우드 서비스 상에 컨테이너를 이용해서 스케일링해주는 서비스를 대부분 제공해주므로, 오토 스케일링을 설정해 놓으면 해결된다.그렇게 하더라도 장애가 발생한다. 그럼 언제 엄청난 양의 요청이 갑자기 들어올까 ?대부분의 경우는 중요한 시점이다.여기서 말하는 중요한 시점은 서비스에 대한 홍보가 나갔을 경우를 말한다.지금 접속하면 선착순 몇명에게 쿠폰 증정, PPL을 통해 해당 서비스에 대한 홍보가 방송에 나간 경우, 앱에 푸시를 발송한 경우 등이 있을 것이다.만약 오늘 밤에 하는 드라마에 PPL로 우리 서비스가 소개될 예정이다. 드라마가 10시에 시작하고, PPL이 나갈 시간이 대략 10시 40분쯤 될것 같다고 한다면 ???관련자들은 퇴근을 못한다. 그 시간 이전에 서버를 충분히 늘려놓고, 계속 서버 상태를 모니터링 하고 있다가, 요청수가 줄어들면 서버를 다시 줄이던지 아니면 오토 스케일링 설정을 조정해줘야 한다.오토 스케일링 ? 그럼 자동으로 되어야 하는것 아닌가 ? 하지만 컨테이너에 서버 이미지를 복사해서 가동하는데 대략 15분의 시간이 걸린다고 가정했을 때,15분동안 기존에 실행하고 있던 서버들이 죽지않고 요청들을 잘 처리해 준다면 문제가 되지 않지만 그러지 못할 경우에는 바로 장애가 발생하는거다. 그럼 그게 무슨 오토 스케일링이냐 ? 라고 생각할 수 있지만, 그럼 현재 서비스되고 있는 서버수를 어떻게 설정할 것인가 ? 언제 서버를 더 늘릴것인가 ? 에 대한 고민을 서버 관리자는 항상해야하는데,그 고민에서 어쩌면 가장 중요한 포인트는 비용이다. 서버가 죽지 않으면서 최적의 비용으로 운영을 하는게 최대한의 이익이 나는 것이기에 그 설정을 최대한 타이트하게 하는게 좋다.만약 설정을 장애에 죽지 않는것이 최고라고 생각하고 늘 많이 띄워놓으면 그만큼 과금은 많이되고 서버는 많은 시간을 놀고 있게 된다.요청에 대해서 스케일링하는 정책 자체를 느슨하게 하면 평소라도 한순간 요청이 몰릴 경우 바로 서버를 새로 올리게 되고, 올리는데 15분이 걸리는데 막상 15분 뒤에는 그 서버가 필요없게 되는 경우가 많이 발생할 것이다. 서버리스로 간다면 실질적인 서버 운영을 클라우드 서비스 업체에게 완전 넘길수 있으므로, 이런 고통에서 벗어날 수 있다.(하지만, 실제로는 이것도 모니터링해야 한다. 그 이유는 뒤에 따로 설명하겠다. 아주 간략하게만 얘기하자면 클라우드 서비스에게 사용자에게 서버리스에서 사용될 자원을 무한히 주지않고 제한하기 때문이다.) 2. 비용싸다. 다른 말이 더 필요한가 ?AWS EC2 서버로 운영하는것 보다 Lambda + API Gateway를 이용해서 API를 서비스 해보니 훨씬 더 싸다.EC2의 경우에는 운영중인 서버수 x 서버 인스턴스의 비용 x 서버가 운영중인 기간 (1시간 단위)로 과금이 이루어 진다.Lambda의 경우는 코드가 수행된 시간을 100ms 단위로 올림하여 과금한다. API Gateway의 경우 100만 요청 당 3.5 USD가 과금된다.이렇게 봐서는 과연 더 싼지 바로 판단이 안되겠지만, 실제로 운영해보니 훨씬 더 싸다. 비교도 안되게 싸다. 일단 이 두가지가 직접 겪었던 큰 이유다.이것 말고도 여러가지 발표자료들을 찾아보면 다른 장점들이 많다.하지만 그건 옵션 사항인듯 하다. 3. 폴리그랏이 가능각 API 기능별로 다른 언어로 개발이 가능하다.당연히 그렇겠지. 각각 따로 디플로이 되어서 관리되니깐…하지만 그렇게 각각의 API를 서로 다른 언어로 서로 다른 프레임워크를 써서 만들어 올리면 관리는 누가하나 ?정말 급하게 서비스해야 되어서 아웃소싱으로 가장 자신있는 언어로 최대한 빨리 해주세요. 가 아닌 이상 한 조직에서 이렇게 했을때 과연 장점이 더 클지 단점이 더 클지…아니면 개발 조직이 엄청나게 크고, API 개발자가 수십명 있을 경우라면 나름 괜찮을것 같기도 하다.당장 나의 경우만 보더라도 가장 자신있고 가장 빨리 개발이 가능한 언어는 C# 이다.하지만 Node.JS 로 API를 개발 중이다.(여기에는 다른 이유도 있긴있다. 아직 AWS Lambda에서 .Net CORE 지원이 믿을만한 수준은 아니라서…) 이 쯤되면 서버리스를 안 할 이유가 없어보인다.정말로 그렇게 생각이 든다면… 일단 서버리스 약을 파는데 조금은 성공했단 생각이 든다. 으흐흐…. Serverless로 갈아타기 위한 조건이미 정상적으로 서비스되고 있는 API를 옮겨야 하는 작업이다보니 가장 중요한 것은 서비스에 지장을 주지 않아야 한다는 점이다.그걸 어떻게 확신 할 수 있을까 ? 테스트를 완벽하게 꼼꼼하게 잘 해서 기존 API와 똑같이 동작하는 것을 증명해 낸다. 새로 올린 API가 잘못되었을 때 (한마디로 장애가 났을 때) 다시 되돌리는데 걸리는 시간을 최소화 한다. 이 두 가지 점에 대해서 확실한 계획을 세워서 결정권자를 설득시켜야 한다.완벽한 테스트는 일단 포기했다.포기한 가장 큰 이유는 일단 시간이다.이 작업은 사업적인 측면에서 봤을땐 전혀 필요없는 작업일 수도 있기 때문에 긴 시간을 들여서 작업하기 힘들다.사실상 회사내의 개발팀이 아닌 다른 사람들이 봤을 땐 그냥 사업적인 영역 하나를 맡아서 진행하는게 아니라서, 그냥 아무것도 안하고 놀고 있는 걸로 보일 수도 있다.그리고 아무리 테스트를 완벽하게 한다고 한들 그렇다고 장애 대응에 대해서 전혀 생각을 안해도 되는게 아니기 때문에 완벽한 테스트는 포기하고 장애 대응 시간 최소화에 좀 더 촛점을 맞춰서 준비를 시작했다.(실제 작업에 들어간 뒤에 알게된 점이지만, 장애 포인트가 API를 잘못 옮긴 것보다는 AWS 내부적인 문제가 훨씬 더 컸었다. 망할놈의 리미트… 끊임없는 리미트… 리미트 뒤에 숨어있는 다른 리미트…) 장애 대응 플랜에 대해서는 다음 글에서 좀 더 자세히 설명하겠다. 다음글 : 2편. 장애 대응 플랜다음글 : 3편. Lambda 배포 후 겪게되는 일들","categories":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/categories/AWS/"},{"name":"Lambda","slug":"AWS/Lambda","permalink":"http://DevStarSJ.github.io/categories/AWS/Lambda/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/tags/AWS/"},{"name":"Lambda","slug":"Lambda","permalink":"http://DevStarSJ.github.io/tags/Lambda/"},{"name":"Serverless","slug":"Serverless","permalink":"http://DevStarSJ.github.io/tags/Serverless/"}]},{"title":"Get Request Body in Action Method","slug":"CSharp.Aspnet.RequestBodyLog","date":"2017-01-22T15:00:00.000Z","updated":"2017-05-24T03:25:12.000Z","comments":true,"path":"2017/01/23/CSharp.Aspnet.RequestBodyLog/","link":"","permalink":"http://DevStarSJ.github.io/2017/01/23/CSharp.Aspnet.RequestBodyLog/","excerpt":"","text":"Get Request Body in Action Method123456string body = \"\";Request.InputStream.Seek(0, SeekOrigin.Begin);using (StreamReader reader = new StreamReader(Request.InputStream))&#123; body = reader.ReadToEnd();&#125;","categories":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/categories/C/"},{"name":"ASP.NET","slug":"C/ASP-NET","permalink":"http://DevStarSJ.github.io/categories/C/ASP-NET/"}],"tags":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/tags/C/"},{"name":"ASP.NET","slug":"ASP-NET","permalink":"http://DevStarSJ.github.io/tags/ASP-NET/"}]},{"title":"AWS Lambda에 C# Handler 만들기","slug":"Lambda.CSharp","date":"2016-12-02T15:00:00.000Z","updated":"2017-04-23T08:21:19.000Z","comments":true,"path":"2016/12/03/Lambda.CSharp/","link":"","permalink":"http://DevStarSJ.github.io/2016/12/03/Lambda.CSharp/","excerpt":"","text":"AWS Lambda에 C# Handler 만들기AWS Lambda에 대해 다루는 7번째 글입니다. Lambda 와 API Gateway 연동 #1 (GET, POST) Lambda 와 API Gateway 연동 #2 (ANY, Deploy Staging, Node.JS Route) Lambda 와 API Gateway 연동 #3 (Proxy Resource) Lambda Node.JS Packaging AWS Lambda에 Python Handler 만들기 Lambda Python Packaging 2016년 12월 1일부터 (글쓴 날 기준으로 이틀 전) AWS Lambda에서 C#을 지원해 줍니다.(관련글 : https://aws.amazon.com/about-aws/whats-new/2016/12/aws-lambda-supports-c-sharp) .NET Framework를 사용할리는 없겠구요.(그 무거운 프레임워크 위에서 돌리는 버전은 당연히 아니겠죠.).NET Core 1.0 runtime 을 이용하여 C# 코드를 컴파일하고 실행해 줍니다.AWS에서 지원해준다니깐 잘되는지 직접 한 번 해봤습니다. 개발 환경현재 macOS를 사용중이지만, C# 개발 환경으로 가장 쾌적하고 좋은건 역시 Windows에서 실행시키는 Visual Studio 입니다.Visual Studio for Mac 이 출시되긴 했으나, 사용해보니 너무나도 느리고 답답하더라구요.차라리 Parallels Desktop에 Windows 10을 띄우고 거기서 Visual Studio Community 2015로 하는게 훨씬 더 빠르고 편했습니다. 아래의 개발도구들을 사용했습니다. Visual Studio 2015 Community with Update 3 , .NET Core 1.0.1 tools Preview 2 : https://www.microsoft.com/net/core AWS Toolkit for Visual Studio : https://aws.amazon.com/visualstudio Project 생성 Visual Studio 실행한 뒤 File -&gt; New -&gt; Project 선택 Visual C# -&gt; AWS Lambda -&gt; AWS Lambda Project (.NET Core) 선택 Name : AWSLambdaTest 라고 입력한 후 OK 버튼 클릭 Select Blueprint 창에서 Empty Function을 선택한 후 Finish 버튼 클릭 이제 테스트 프로젝트가 완성되었습니다. AWS Explorer 에 로그인AWS Lambda 배포를 좀 더 편하게 하기위해서 미리 AWS Explorer에 로그인해 두도록 하겠습니다.화면에 AWS Explorer가 없다면, View -&gt; AWS Explorer를 선택하시면 됩니다.만약 해당 메뉴가 나오지 않는다면 AWS Toolkit for Visual Studio를 설치하지 않은 것이므로 위 링크에서 설치를 하신 뒤 진행해 주세요.이미 로그인 된 상태라면 아래 과정을 진행 할 필요가 없습니다. New Account Profile 선택 Profile Name : 아무거나 입력. 화면에 표시될 내용이므로 구분하기 쉽게 Access Key ID , Secret Access Key : AWS에서 발급받은 값으로 입력 로그인이 제대로 되었다면 아래 그림과 같이 AWS Service 목록이 나옵니다. Projeject 코드 설명먼저 빌드를 한 번 해보세요.만약 빌드가 안된다면 Solution Explorer를 열어서 Project 내의 References를 열어봐 주세요.설치된 어셈블리 중에 잘못 된게 있으면 노란색 느낌표가 뜹니다.그럴 경우 우클릭하여서 Restore Packages를 선택해 주세요. 자동 생성된 Function.cs 파일을 열어보겠습니다. 눈여겨 볼 부분이 두 곳 정도 있네요. 12// Assembly attribute to enable the Lambda function's JSON input to be converted into a .NET class.[assembly: LambdaSerializerAttribute(typeof(Amazon.Lambda.Serialization.Json.JsonSerializer))] 주석에 적혀있는 대로 라면 JSON으로 입력된 것에 대해서 자동으로 .NET class로 변경해준다는 말이네요.AWS Lambda에 Java 코드를 올릴 경우에도 입력이 JSON일 경우 해당 JSON내용이랑 똑같은 class를 생성해야만 했습니다.더군다나 Java에서는 setter , getter 매서드 들도 다 만들어 줘야 했습니다.다행히 C#에서는 attribute로 선언시 오른쪽에 { get; set; }만 적어주면 되기 때문에 Java보다는 훨씬 편하지만,그래도 여간 귀찮은 일이 아닙니다. 관련 내용으로 Facebook애서 좀 장장댔더니 고수이신 패친분들이 JSON을 읽어서 class를 만들어주는 방법들에 대해서 소개를 해 주셨습니다.(엯촋 이규원님, 이종인님 감사드립니다.)보니깐 Visual Studio에는 이미 그런 기능이 있군요. 저렇게 class로 만들기 싫다면, 그냥 Stream으로 주고 받는 방법도 있습니다.아래 내용에서는 Stream으로 주고 받는 방법으로 진행하도록 하겠습니다. 1234public string FunctionHandler(string input, ILambdaContext context)&#123; return input?.ToUpper();&#125; string을 입력받아서 대문자로 변경한 뒤에 string 타입으로 응답해주는 핸들러입니다. 일단은 이 코드 그대로 배포해 보도록 하겠습니다. Lambda 배포 및 테스트Visual Studio 내에서 배포 및 테스트가 바로 되기 떄문에 편리합니다. Solution Explorer상의 Project(AWSLambdaTest)에서 마우스 우 클릭 Publish to AWS Lambda… 선택 Function Name: 새로 생성할 (또는 기존에 생성되어 있는 것 중 덮어 쓸) Lambda Function 명칭을 입력 Assembly Name (Project 명), Type Name (핸들러가 포함되어 있는 class명을 namespace 포함한 값), Method Name (핸들러 이름)이 제대로 되어 있는지 확인합니다. Next 버튼 클릭 Role Name: 기존에 만들어 놓은 role또는 새로 만들어서 선택 참고로 role은 AWS내의 다른 서비스 들과의 연계에서 필요한 권한 등을 설정해 놓는 것입니다. Upload 버튼 클릭 이제 기다리면 업로딩이 끝난 뒤 해당 Lambda의 설정창이 뜹니다.기본적으로 Test Function 탭이 선택된 상태인데 Sample Input란에 아무거나 입력한 뒤 Invoke 버튼을 누르면 입력한 값들이 모두 대문자로 변한 값으로 응답이 오는 것을 확인 할 수 있습니다. 만약 입력하는 문자열이 JSON 형식일 경우에는 오류가 발생합니다. 앞에서 살펴 본 코드에 따르면 JSON을 읽어서 자동으로 .NET class로 변경해주는 작업을 해준다고 했는데, 아마 그 작업을 시도하는 모양입니다. JSON으로 입력 받기그럼 JSON을 Stream을 이용해서 입력받아 보도록 하겠습니다. 2개의 using문을 위에 써주세요. 12using System.IO;using System.Text; FunctionHandler 메서드를 아래와 같이 수정해 주세요. 123456789101112131415public string FunctionHandler(Stream stream, ILambdaContext context)&#123; List&lt;byte&gt; bytes = new List&lt;byte&gt;(); while (stream.CanRead) &#123; int readByte = stream.ReadByte(); if (readByte != -1) bytes.Add((byte)readByte); else break; &#125; string text = Encoding.UTF8.GetString(bytes.ToArray()); return text;&#125; Stream으로 입력받아서 string으로 변환하여 그래도 응답하도록 수정하였습니다. 위 다시 배포한 뒤 위에서 오류난 JSON으로 테스트 하니 입력한 값을 그대로 문자열로 응답해 줍니다. 하지만 출력한 값이 string라서 이상한 \\r\\n등도 포함되어 있으며 바로 JSON으로 파싱도 안됩니다. JSON으로 응답 하기위해서이제 응답도 string이 아니라 Stream으로 해보겠습니다.받은 값을 그래도 응답만 하는건 재미없자나요.그래도 JSON에 항목 한 개 만이라도 추가해서 보내겠습니다. C#에서 JSON Obejct관련 작업에 가장 많이 사용하는 건 Newtonsoft.Json이라는 nuget package입니다. Solution Explorer에서 Project 선택한 뒤 우클릭하여 뜬 메뉴에서 Manage nuget packages…를 눌러줍니다. json만 입력해도 바로 가장 위에 Newtonsoft.Json이 나옵니다. 선택하여 설치해 줍니다. using문에 다음을 추가해 주세요. 1using Newtonsoft.Json.Linq; FunctionHandler 메서드를 아래와 같이 수정해 주세요. 12345678910111213141516171819202122public Stream FunctionHandler(Stream stream, ILambdaContext context)&#123; List&lt;byte&gt; bytes = new List&lt;byte&gt;(); while (stream.CanRead) &#123; int readByte = stream.ReadByte(); if (readByte != -1) bytes.Add((byte)readByte); else break; &#125; string text = Encoding.UTF8.GetString(bytes.ToArray()); var json = JObject.Parse(text); json[\"name\"] = \"LunaSter\"; text = json.ToString(); MemoryStream stream1 = new MemoryStream(Encoding.UTF8.GetBytes(text)); return stream1;&#125; 위 코드에서 text를 JObject로 변경한 다음 항목을 하나 추가해서 MemoryStream으로 응답하는게 추가되었습니당. 다시 배포한 뒤 테스트 해보니 이쁘게 JSON 형식으로 응답이 옵니다.추가한 항목에 대해서도 확인됩니다. 마치며…이번 포스팅에서 알아본 내용들은 다음과 같습니다. Lambda에 C# 코드 작업에 필요한 도구들 (설치법은 셀프!) Project 생성 Visual Studio에서 Lambda 배포 및 테스트 JSON Object로 입력 및 응답을 주고 받는 방법 API Gateway와의 연동 및 path, querystring, HTTP Method에 따라 다른 작업 및 응답을 발성하는 방법에 대해서는 제가 앞서 작성한 Node.JS로 AWS Lambda 올리는 곳의 코드와 구조가 똑같습니다.그래서 이 부분에 대해서는 따로 다루지 않겠습니다. 잘못되었거나, 변경된 점, 기타 추가 사항에 대한 피드백은 언제나 환영합니다. - &#x73;&#101;&#x6f;&#107;&#106;&#111;&#x6f;&#x6e;&#46;&#x79;&#x75;&#x6e;&#64;&#x67;&#x6d;&#x61;&#x69;&#108;&#46;&#99;&#111;&#109; 참고 AWS 공식 문서들 https://aws.amazon.com/about-aws/whats-new/2016/12/aws-lambda-supports-c-sharp/ http://docs.aws.amazon.com/toolkit-for-visual-studio/latest/user-guide/getting-set-up.html http://docs.aws.amazon.com/lambda/latest/dg/lambda-dotnet-how-to-create-deployment-package.html http://docs.aws.amazon.com/lambda/latest/dg/lambda-dotnet-create-deployment-package-toolkit.html http://docs.aws.amazon.com/lambda/latest/dg/dotnet-programming-model.html http://docs.aws.amazon.com/lambda/latest/dg/dotnet-programming-model-handler-types.html","categories":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/categories/AWS/"},{"name":"Lambda","slug":"AWS/Lambda","permalink":"http://DevStarSJ.github.io/categories/AWS/Lambda/"}],"tags":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/tags/C/"},{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/tags/AWS/"},{"name":"Lambda","slug":"Lambda","permalink":"http://DevStarSJ.github.io/tags/Lambda/"},{"name":"APIGateway","slug":"APIGateway","permalink":"http://DevStarSJ.github.io/tags/APIGateway/"}]},{"title":"Lambda Node.JS Packaging","slug":"Lambda.Packaging.Node","date":"2016-11-27T06:54:51.000Z","updated":"2017-04-23T08:21:19.000Z","comments":true,"path":"2016/11/27/Lambda.Packaging.Node/","link":"","permalink":"http://DevStarSJ.github.io/2016/11/27/Lambda.Packaging.Node/","excerpt":"","text":"Lambda Node.JS PackagingLabmda에 Node.JS로 구현하는 내용에 대해서는 아래 3개의 Link를 참고해 주세요. Lambda 와 API Gateway 연동 #1 (GET, POST) Lambda 와 API Gateway 연동 #2 (ANY, Deploy Staging, Node.JS Route) Lambda 와 API Gateway 연동 #3 (Proxy Resource) 이제껏 1개의 Node.JS 파일에 npm module을 하나도 사용하지 않은 예제만 살펴보았는데,실제로 개발할 상황에서는 파일도 여러 개로 나눠서 개발하고 npm module도 많이 사용할 경우가 많습니다.이렇게 개발한 코드들을 어떻게 Lambda로 올리는지 이번 포스팅에서 살펴보도록 하겠습니다. Lambda 와 API Gateway 연동 #3까지 구현되어 있다는 가정하에서 진행하겠습니다. Node.JS 코드에 npm 사용 이전까지 작업한 코드를 index.js란 이름으로 작업할 폴더에 저장 npm으로 lodash 설치 : npm install lodash 코드를 아래와 같이 수정 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647'use strict';const _ = require('lodash');function get(userId) &#123; return &#123; body: &#123; id: userId, name: \"test\" &#125; &#125;;&#125;function post(userId, header, body) &#123; return &#123; body: &#123; id: userId, header: header, body: body &#125; &#125;;&#125;const routeMap = &#123; '/test': &#123; 'GET': (event, context) =&gt; &#123; const userId = _.get(event,'queryStringParameters.id'); return get(userId); &#125;, 'POST': (event, context) =&gt; &#123; const userId = _.get(event,'queryStringParameters.id'); const body = JSON.stringify(_.get(event,'body')); const header = event.headers; return post(userId, header, body); &#125; &#125;&#125;;function router(event, context) &#123; const controller = routeMap[event.path][event.httpMethod]; if(!controller) &#123; return &#123; body: &#123; Error: \"Invalid Path\" &#125; &#125;; &#125; return controller(event, context);&#125;exports.handler = (event, context, callback) =&gt; &#123; let result = router(event, context); callback(null, &#123;body:JSON.stringify(result)&#125;);&#125; routeMap 내부에 lodash.get 함수를 사용하는 것으로 코드를 변경하였습니다. zip 파일로 압축 : zip -r ./sample.zip ./ Lambda에 zip 파일로 배포먼저 해당 Lambda 설정으로 이동합니다. Code 탭 Code entry type : Upload a .ZIP file 선택 Upload 버튼을 눌러서 위에서 생성한 sample.zip을 올림 확인API Gateway는 변경사항이 없으므로 결과는 3장과 똑같이 나옵니다. GET 요청 : https://.../prod/test?id=2 1&#123;\"body\":&#123;\"id\":\"2\",\"name\":\"test\"&#125;&#125; POST 요청 : URL은 GET과 동일 123456789&#123; \"body\": &#123; \"id\": \"2\", \"header\": &#123; ... &#125;, \"body\": \"\\\"&#123;\\\\n \\\"id\\\": \\\"123\\\",\\\\n \\\"age\\\": \\\"25\\\"\\\\n&#125;\\\"\" &#125;&#125; 여러 파일을 함께 배포이미 npm module을 포함하여 베포하였으므로 여러 파일을 묶어서 배포하는게 확인되었지만, 우리가 작성한 소스코드 자체도 나눠서 배포해 보도록 하겠습니다.위에 작성한 코드를 4개의 파일로 나눠서 올려보겠습니다. index.js 12345678'use strict';const router = require('./router');exports.handler = (event, context, callback) =&gt; &#123; let result = router(event, context); callback(null, &#123;body:JSON.stringify(result)&#125;);&#125; router.js 123456789101112131415161718192021222324252627282930'use strict';const _ = require('lodash');const routeMap = &#123; '/test': &#123; 'GET': (event, context) =&gt; &#123; const userId = _.get(event,'queryStringParameters.id'); return require('./controllers/test/get')(userId); &#125;, 'POST': (event, context) =&gt; &#123; const userId = _.get(event,'queryStringParameters.id'); const body = JSON.stringify(_.get(event,'body')); const header = event.headers; return require('./controllers/test/post')(userId, header, body); &#125; &#125;&#125;;module.exports = (event, context) =&gt; &#123; const controller = routeMap[event.path][event.httpMethod]; if(!controller) &#123; return &#123; body: &#123; Error: \"Invalid Path\" &#125; &#125;; &#125; return controller(event, context);&#125;; /controllers/test/get.js 12345module.exports = (userId) =&gt; &#123; return &#123; body: &#123; id: userId, name: \"test\" &#125; &#125;;&#125;; /controllers/test/post.js 12345module.exports = (userId, header, body) =&gt; &#123; return &#123; body: &#123; id: userId, header: header, body: body &#125; &#125;;&#125;; npm으로 lodash 설치 : npm install lodash zip 파일로 압축 : zip -r ./sample.zip ./ 위에서와 같은 방법으로 Lambda에 배포 후 확인을 해보면 같은 결과가 출력됩니다. Lambda에 zip 파일로 배포먼저 해당 Lambda 설정으로 이동합니다. Code 탭 Code entry type : Upload a .ZIP file 선택 Upload 버튼을 눌러서 위에서 생성한 sample.zip을 올림 확인API Gateway는 변경사항이 없으므로 결과는 3장과 똑같이 나옵니다. GET 요청 : https://.../prod/test?id=2 1&#123;\"body\":&#123;\"id\":\"2\",\"name\":\"test\"&#125;&#125; POST 요청 : URL은 GET과 동일 123456789&#123; \"body\": &#123; \"id\": \"2\", \"header\": &#123; ... &#125;, \"body\": \"\\\"&#123;\\\\n \\\"id\\\": \\\"123\\\",\\\\n \\\"age\\\": \\\"25\\\"\\\\n&#125;\\\"\" &#125;&#125; 마치며…이번 포스팅에서 알아본 내용들은 다음과 같습니다. Lambda에 여러 파일을 .zip으로 묶어서 함께 배포 npm module을 함께 배포 여러 파일로 작성된 소스코드들을 함께 배포 잘못되었거나, 변경된 점, 기타 추가 사항에 대한 피드백은 언제나 환영합니다. - &#x73;&#101;&#111;&#107;&#x6a;&#111;&#x6f;&#110;&#46;&#x79;&#x75;&#x6e;&#64;&#103;&#109;&#x61;&#x69;&#x6c;&#46;&#x63;&#111;&#x6d; 참고 AWS 공식 가이드 : http://docs.aws.amazon.com/lambda/latest/dg/nodejs-create-deployment-pkg.html","categories":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/categories/AWS/"},{"name":"Lambda","slug":"AWS/Lambda","permalink":"http://DevStarSJ.github.io/categories/AWS/Lambda/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/tags/AWS/"},{"name":"Lambda","slug":"Lambda","permalink":"http://DevStarSJ.github.io/tags/Lambda/"},{"name":"APIGateway","slug":"APIGateway","permalink":"http://DevStarSJ.github.io/tags/APIGateway/"},{"name":"Node.JS","slug":"Node-JS","permalink":"http://DevStarSJ.github.io/tags/Node-JS/"}]},{"title":"Lambda Python Packaging","slug":"Lambda.Packaging.Python","date":"2016-11-24T07:54:51.000Z","updated":"2017-04-23T08:21:19.000Z","comments":true,"path":"2016/11/24/Lambda.Packaging.Python/","link":"","permalink":"http://DevStarSJ.github.io/2016/11/24/Lambda.Packaging.Python/","excerpt":"","text":"Lambda Python PackagingAWS Lambda에 대해 다루는 6번째 글입니다. Lambda 와 API Gateway 연동 #1 (GET, POST) Lambda 와 API Gateway 연동 #2 (ANY, Deploy Staging, Node.JS Route) Lambda 와 API Gateway 연동 #3 (Proxy Resource) Lambda Node.JS Packaging AWS Lambda에 Python Handler 만들기 지난번 글에서 1개의 Python 파일로 구현하여 AWS Lambda에 올리는 방법에 대해서 다뤘는데,이번 글에서는 여러 개의 파일로 나뉘어서 구현한 경우와 외부 라이브러리를 pip로 설치할 경우 어떻게 해야하는지에 대해서 다뤄보겠습니다. Previously on Lambda seriesLambda의 생성 및 API Gateway와의 연결은 되어 있다는 가정하에 진행하겠습니다.관련 내용들은 앞의 글들에 다 있지만 읽기 귀찮으시다는 분들을 위해 간략한 따라하기를 살없이 뼈만 추려서 먼저 소개하고 시작하겠습니다. Create Lambda AWS 로그인 후 Lambda 탭으로 이동 Create a Lambda Function 선택 Select blueprint에서 Blank Function 선택 Configure function 에서 일단 바로 Next 선택 (미리 연결할 API Gateway가 있다면 여기서 연결하면 됨) Configure function에서 함수 정의 Name : testLambda-luna Runtime : Python 2.7 Code : 아래 소개되어 있는 Python Lambda Code를 입력 Role &amp; Existing role : 일단은 적당히 선택 (만약 Lambda에서 다른 AWS 서비스 RDS, S3 등을 연동할려면 필요) 아래 코드 입력 후 Next 선택 Create Function 선택 Set API Gateway AWS 메인 화면으로 이동 후 API Gateway 탭으로 이동 Create API 선택 API name : testAPI-luna Create API 선택 /에서 Actions -&gt; Create Resource를 선택 Configure as proxy resource 를 체크한 후 Create Resource를 누름 ANY 선택 Integration Request 선택 Integration type : Lambda Function Lambda Region : 람다를 생성한 지역 서버 선택 Lambda Function : 람다 명칭 기입 Actions -&gt; Deploy API 선택 후 그냥 prod로 스테이징 Python Lambda Code123456789101112131415161718192021222324252627282930import jsondef get(event): user_id = event['queryStringParameters']['id'] return &#123; 'body': &#123; 'id': user_id, 'name': \"test\" &#125; &#125;def post(event): user_id = event['queryStringParameters']['id'] body = event['body'] header = event['headers'] return &#123; 'body': &#123; 'id': user_id, 'header': header, 'body': body &#125; &#125;route_map = &#123; '/test': &#123; 'GET': get, 'POST': post &#125;&#125;;def router(event): controller = route_map[event['path']][event['httpMethod']]; if not controller: return &#123; 'body': &#123; 'Error': \"Invalid Path\" &#125; &#125; return controller(event);def handler(event, context): result = router(event); return &#123; 'body' : json.dumps(result) &#125; Python Code 패키징 연습새로운 코드를 만드는것 보다는 일단 정상적으로 동작하는 것이 확인된 코드를 파일로 나눠가면서 진행하겠습니다. Step 1. 통파일을 그냥 .zip으로 압축하여 올리기작업할 폴더를 하나 만듭니다. 일단 packaging.test 라는 이름으로 만들어 보겠습니다. 12mkdir packaging.testcd packaging.test 그 안에 원래 Lambda에 올려놓은 코드를 그대로 복사하여 index.py로 생성합니다. index.py123456789101112131415161718192021222324252627282930import jsondef get(event): user_id = event['queryStringParameters']['id'] return &#123; 'body': &#123; 'id': user_id, 'name': \"test\" &#125; &#125;def post(event): user_id = event['queryStringParameters']['id'] body = event['body'] header = event['headers'] return &#123; 'body': &#123; 'id': user_id, 'header': header, 'body': body &#125; &#125;route_map = &#123; '/test': &#123; 'GET': get, 'POST': post &#125;&#125;;def router(event): controller = route_map[event['path']][event['httpMethod']]; if not controller: return &#123; 'body': &#123; 'Error': \"Invalid Path\" &#125; &#125; return controller(event);def handler(event, context): result = router(event); return &#123; 'body' : json.dumps(result) &#125; .zip파일로 압축할 때 해당 index.py 파일이 루트에 위치해야 합니다.즉, packaging.test 폴더를 압축하는게 아니라 그 안에 들어와서 압축을 해야 합니다. 1zip sample.zip index.py 이제 Lambda에 올리신 후 테스트 해보면 됩니다.올리는 방법과 테스트 방법은 계속 동일하기 때문에 여기서 한 번만 소개하고 밑에서는 따로 소개하지 않겠습니다. 먼저 해당 Lambda 설정으로 이동합니다. Code 탭 Code entry type : Upload a .ZIP file 선택 Upload 버튼을 눌러서 위에서 생성한 sample.zip을 올림 GET 요청 (브라우저에서 주소 입력) : https://.../prod/test?id=2 1&#123;\"body\":&#123;\"id\":\"2\",\"name\":\"test\"&#125;&#125; POST 요청 (POSTMAN이나 curl등을 활용) : URL은 GET과 동일 123456789&#123; \"body\": &#123; \"id\": \"2\", \"header\": &#123; ... &#125;, \"body\": \"\\\"&#123;\\\\n \\\"id\\\": \\\"123\\\",\\\\n \\\"age\\\": \\\"25\\\"\\\\n&#125;\\\"\" &#125;&#125; Step 2. 파일 나누기위의 파일을 2개로 나누어서 올려보겠습니다.같은 폴더에 router.py파일을 하나 생성 한 후 파일 내용을 아래와 같이 수정해 주세요. index.py123456import jsonfrom router import routerdef handler(event, context): result = router(event); return &#123; 'body' : json.dumps(result) &#125; router.py123456789101112131415161718192021222324def get(event): user_id = event['queryStringParameters']['id'] return &#123; 'body': &#123; 'id': user_id, 'name': \"test\" &#125; &#125;def post(event): user_id = event['queryStringParameters']['id'] body = event['body'] header = event['headers'] return &#123; 'body': &#123; 'id': user_id, 'header': header, 'body': body &#125; &#125;route_map = &#123; '/test': &#123; 'GET': get, 'POST': post &#125;&#125;;def router(event): controller = route_map[event['path']][event['httpMethod']]; if not controller: return &#123; 'body': &#123; 'Error': \"Invalid Path\" &#125; &#125; return controller(event); .zip 파일로 압축합니다. 1zip sample.zip . 코드를 올린 후 테스트 했을 때 똑같은 결과가 나와야 합니다. Step 3. 폴더로 나누기작업 중인 폴더에 /controllers/test의 2단계의 폴더를 추가 합니다. 123mkdir controllerscd controllersmkdir test 그런 다음 2개의 폴더에 각각 __init__.py라는 파일을 만듭니다.내용은 아무것도 없는 빈 파일로 생성합니다.앞으로 작성할 2개의 파일도 미리 생성해 놓겠습니다. 12345touch __init__.pycd testtouch __init__.pytouch post.pytouch get.py /controllers/test/안에 post.py, get.py에 기존에 있던 router.py의 내용을 나눠서 수정합니다. index.py123456import jsonfrom router import routerdef handler(event, context): result = router(event); return &#123; 'body' : json.dumps(result) &#125; router.py1234567891011121314151617import controllers.test.getimport controllers.test.postroute_map = &#123; '/test': &#123; 'GET': controllers.test.get.handler, 'POST': controllers.test.post.handler &#125;&#125;;def router(event): controller = route_map[event['path']][event['httpMethod']]; if not controller: return &#123; 'body': &#123; 'Error': \"Invalid Path\" &#125; &#125; return controller(event); controllers/test/post.py12345def handler(event): user_id = event['queryStringParameters']['id'] body = event['body'] header = event['headers'] return &#123; 'body': &#123; 'id': user_id, 'header': header, 'body': body &#125; &#125; controllers/test/get.py123def handler(event): user_id = event['queryStringParameters']['id'] return &#123; 'body': &#123; 'id': user_id, 'name': \"test\" &#125; &#125; index.py가 위치한 폴더로 이동하여 압축을 합니다. 1zip -r sample.zip . 코드를 올린 후 테스트 했을 때 똑같은 결과가 나와야 합니다. Step 4. 외부 라이브러리를 pip로 설치하여 같이 올리기외부 라이브러리 설치를 하기위해서는 주의해야 할 사항들이 몇가지 있습니다. 외부 라이브러리를 해당 폴더 내에 설치하기 위해서는 virtualenv를 사용하여 가상환경을 구성해주는게 편합니다.그렇지 않으면 이미 해당 라이브러리가 설치된 경우 충돌이 일어 날수가 있어서 설치 자체가 쉽지 않습니다.그리고 현재 기본적으로 실행되는 Python의 버전이 3.x.x 버전일 경우에도 문제가 됩니다.현재 AWS Lambda에서 지원하는 Python이 2.7버전이기 때문입니다. Python 3에서도 virtualenv 환경으로 Python 2.7로 생성이 가능합니다만, 필자는 구글에서 찾아봐서 몇 번 시도를 해봤는데 계속 실패하더라구요.그래서 그냥 과감하게 그 당시 기본으로 설치된 Python 3.5.12 (Conda)를 날려버렸습니다.그리고 따로 Python 공식 페이지에 들어가서 2.7.12와 3.5.12를 설치했습니다.Python 설치는 homebrew 같은것으로 설치하는 것보다는 그냥 공홈에서 .pkg 같은걸로 다운받아서 설치하는게 정신 건강에 좋습니다. 12$ python -VPython 2.7.12 기본 버전이 2.7.12 라는 것이 확인되었으니 그냥 virtualenv로 가상환경을 만들면 되겠네요.먼저 index.py가 위치한 곳으로 이동 후 다음과 같이 입력하여 실행해주세요. 1virtualenv myvenv 이제 가상 환경으로 활성화 합니다. 1source myvenv/bin/activate 이제 원하는 라이브러리를 로컬로 해당 폴더에 설치하면 됩니다. 예제로 작성할 코드라 가볍고 사용하기 쉬운 requests를 설치해 보도록 하겠습니다. 1pip install requests -t . 일단은 단순하게 그냥 index.py만 수정해서 requests가 동작하는 코드로 수정 후 올려보도록 하죠. index.py1234567891011121314import jsonimport requestsfrom router import routerdef handler(event, context): result = router(event); URL = 'http://www.tistory.com' response = requests.get(URL) result['request_data'] = response.text return &#123; 'body' : json.dumps(result) &#125; 해당 폴더 이하를 몽땅 압축하여 올립니다. (myvenv 는 제외하고 싶은데… 어떻게 하는지 잘 모르겠습니다.) 1zip -r sample.zip . 테스트를 하면 request_data안에 데이터들이 추가된 것을 확인 할 수 있습니다. Step 5. 좀 더 새련된 패키징 처리Step 4에서 살펴본 내용만으로는 실제 서비스 가능한 수준의 코드를 만드는데는 몇가지 문제가 있습니다. 압축파일의 크기가 너무 크다. virtualenv용 파일은 제외하고 압축하고 싶다. pip를 이용한 모듈을 로컬에 설치했는데, 그럼 index.py와 router.py같이 루트폴더에 있는 파일들말고 get.py나 post.py같이 서브폴더에 있는 파일에서는 어떻게 모듈들을 사용해야 할까 ? 첫번째 문제에 대해서는 저도 맥에서 zip명령어를 사용해서 어떻게 특정 파일/폴더를 빼고 압축을 할수 있는지에 대해서 못찾았습니다.그래서 그냥 src라는 폴더를 하나 만들어 그 안에서 작업을 하고 해당 폴더 안에서 .zip파일로 패키징해서 올리니 virtualenv관련 파일들은 자연스럽게 빠지게 되었습니다. 두번째 문제에 대해서 부모디렉토리의 모듈에 대해서 접근하는 여러가지 방법을 시도해 봤는데 코드가 많이 지저분해더군요.코드를 깔끔하게 유지하면서 해결가능한 방법으로는 2가지 정도가 있습니다. 해당 모듈이 사용되는 최하위 폴더에 설치한다.이 경우에는 해당 폴더의 상위에서는 모두 사용이 가능합니다.하지만 그 상위 폴더와 같은 레벨의 다른 폴더에서의 접근은 힘듭니다.그 폴더에서도 사용하려면 그 폴더내의 어딘가에 또 설치를 하는 방법으로 해결을 해야 합니다.이 방법은 별로 좋은 방법 같지 않으니 패스하기로 합니다. 최상위 모듈에서 하위 폴더내 모듈에게 전달한다.개인적으로 추천하는 방법입니다.index.py 같이 프로그램 내의 시작점에 해당되는 곳에서 사용되는 모든 모듈들의 객체를 선언하여 이것을 하위 폴더내의 모듈을 호출할 때 같이 전달하는 방식입니다.설명으로만 느낌이 잘 안오실수 있으니 예제 코드로 살펴보겠습니다. 위 Step 4 예제를 조금 변경하여 /test경로로 GET방식으로 요청한 경우 쿼리 스트링으로 url값을 받아서 해당 사이트의 내용을 requests 모듈을 이용해서 가져오는 코드로 변경해 보겠습니다. Step 4까지 진행되었다는 가정하에 진행할 경우에는 바로 하면 되지만 새로운 폴더에 작업을 하는 경우라면 아래와 같이 virtualenv를 이용한 가상환경으로 들어가서 pip를 로컬로 설치해 주신뒤 코드를 작성해 주세요. 1234virtualenv myvenvsource myvenv/bin/activatemkdir srccd src 압축할 때 myvenv내의 파일들이 같이 압축되지 않도록 작업을 src폴더 내에서 하겠습니다. 123mkdir modulestouch modules/__init__.pypip install requests -t modules/ modules을 다른 폴더에서 불러오기 위해서는 해당 폴더내에 __init__.py 파일이 있어야 합니다. 12345678mkdir controllerscd controllersmkdir testtouch __init__.pycd testtouch __init__.pycd ..cd .. index.py에서 requests 모듈에 대한 객체를 선언하여 그것을 /controllers/test/get.py까지 전달하는 코드를 작성해 보겠습니다. index.py12345678910111213import jsonimport modules.requestsfrom router import routerdef handler(event, context): packages = &#123;&#125; packages['requests'] = modules.requests result = router(packages, event); return &#123; 'body' : json.dumps(result) &#125; router.py에서는 전달받은 packages를 그대로 전달해주는 코드만 추가했습니다. router.py1234567891011121314151617import controllers.test.getimport controllers.test.postroute_map = &#123; '/test': &#123; 'GET': controllers.test.get.handler, 'POST': controllers.test.post.handler &#125;&#125;;def router(packages, event): controller = route_map[event['path']][event['httpMethod']]; if not controller: return &#123; 'body': &#123; 'Error': \"Invalid Path\" &#125; &#125; return controller(packages, event); post.py에서 외부 모듈을 사용하지는 않지만, 일단 받아줍시다. 공짠데요. controllers/test/post.py12345def handler(packages, event): user_id = event['queryStringParameters']['id'] body = event['body'] header = event['headers'] return &#123; 'body': &#123; 'id': user_id, 'header': header, 'body': body &#125; &#125; get.py에서는 전달받은 packages에서 requests 객체를 가져와서 사용하는 코드가 추가되었습니다. controllers/test/get.py1234567def handler(packages, event): requests = packages['requests'] request_url = event['queryStringParameters']['url'] response = requests.get('http://' + request_url) return &#123; 'body': &#123; 'url': request_url, 'text': response.text &#125; &#125; 이제 index.py가 있는 위치로 와서 압축한 뒤에 Lambda에 올려 놓고 테스트 해 보겠습니다. 1zip -r sample.zip . https://본인 Lambda 주소.../prod/test?url=www.naver.com 식으로 브라우저에서 입력하여 결과가 제대로 오는지 확인하시면 됩니다. 마치며…이번 포스팅에서 알아본 내용들은 다음과 같습니다. Lambda에 Python 코드를 패키징해서 올리는 방법 vitrualenv를 활용해서 원하는 폴더에 pip로 모듈을 설치하는 방법 로컬에 pip로 설치한 모듈들을 서브 폴더내에서도 활용하는 방법 잘못되었거나, 변경된 점, 기타 추가 사항에 대한 피드백은 언제나 환영합니다. - &#x73;&#101;&#111;&#107;&#106;&#111;&#111;&#110;&#x2e;&#121;&#x75;&#110;&#64;&#103;&#109;&#x61;&#x69;&#108;&#x2e;&#x63;&#111;&#109; 참고 AWS 공식 가이드 : http://docs.aws.amazon.com/lambda/latest/dg/lambda-python-how-to-create-deployment-package.html","categories":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/categories/AWS/"},{"name":"Lambda","slug":"AWS/Lambda","permalink":"http://DevStarSJ.github.io/categories/AWS/Lambda/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/tags/AWS/"},{"name":"Lambda","slug":"Lambda","permalink":"http://DevStarSJ.github.io/tags/Lambda/"},{"name":"APIGateway","slug":"APIGateway","permalink":"http://DevStarSJ.github.io/tags/APIGateway/"},{"name":"Python","slug":"Python","permalink":"http://DevStarSJ.github.io/tags/Python/"}]},{"title":"AWS Lambda에 Python Handler 만들기","slug":"Lambda.Python","date":"2016-11-24T06:54:51.000Z","updated":"2017-04-23T08:21:19.000Z","comments":true,"path":"2016/11/24/Lambda.Python/","link":"","permalink":"http://DevStarSJ.github.io/2016/11/24/Lambda.Python/","excerpt":"","text":"AWS Lambda에 Python Handler 만들기AWS Lambda 관련 5번째 포스트 입니다.지난 글들의 목록은 다음과 같습니다. Lambda 와 API Gateway 연동 #1 (GET, POST) Lambda 와 API Gateway 연동 #2 (ANY, Deploy Staging, Node.JS Route) Lambda 와 API Gateway 연동 #3 (Proxy Resource) Lambda Node.JS Packaging 이번에는 Python으로 구현해 보겠습니다. Previously on Lambda seriesLambda 와 API Gateway 연동 #3 (Proxy Resource)까지 진행되었다는 가정하에 진행하겠습니다.아직 위 내용들을 보지 않으셨던 분은 아래대로 따라하시면 준비가 끝납니다. 그 과정을 간략하게 살없이 뼈만 간추리면 다음과 같습니다.관련 내용은 위 포스트 들을 참조해주세요.그냥 읽어봐서 이해가 안되신다면 한 번 아무생각없이 따라해 보시면 이해가 되실겁니다. Create Lambda AWS 로그인 후 Lambda 탭으로 이동 Create a Lambda Function 선택 Select blueprint에서 Blank Function 선택 Configure function 에서 일단 바로 Next 선택 (미리 연결할 API Gateway가 있다면 여기서 연결하면 됨) Configure function에서 함수 정의 Name : testLambda-luna Runtime : Node.js 4.3 Code : 일단 아무거나 입력 Role &amp; Existing role : 일단은 적당히 선택 (만약 Lambda에서 다른 AWS 서비스 RDS, S3 등을 연동할려면 필요) 아래 코드 입력 후 Next 선택 Create Function 선택 Set API Gateway AWS 메인 화면으로 이동 후 API Gateway 탭으로 이동 Create API 선택 API name : testAPI-luna Create API 선택 /에서 Actions -&gt; Create Resource를 선택 Configure as proxy resource 를 체크한 후 Create Resource를 누름 ANY 선택 Integration Request 선택 Integration type : Lambda Function Lambda Region : 람다를 생성한 지역 서버 선택 Lambda Function : 람다 명칭 기입 Actions -&gt; Deploy API 선택 후 그냥 prod로 스테이징 Hello Python Lambda Handler먼저 가장 기초적인 핸들러를 작성해보록 하죠. 앞서 생성한 Lambda 설정에 들어가셔서 Configuration 탭 Runtime : Python 2.7 선택 Handler : index.handler라고 되어 있는지 확인 Code 탭 으로 와서 아래 코드 입력 12def handler(event, context): return &#123; 'event': str(event), 'context': str(context) &#125; 그런 다음 API Gateway의 주소를 브라우저에서 입력하면 오류가 발생합니다.주소 확인하는 법은 API Gateway 설정에서 Stages를 눌러서 해당 스테이징(prod)를 선택하면 Invoke URL에 표시됩니다 그 이유는 현재 {proxy+} 이하로는 ANY로 설정된게 있는데 /에는 아무것도 설정된게 없기 때문입니다. 좌측 해당 항목에서 Resources로 이동 /에서 Actions -&gt; Create Method를 눌러서 ANY를 생성 생성된 ANY를 눌러서 Integration type : Lambda Function Lambda Region : 람다를 생성한 지역 서버 선택 Lambda Function : 람다 명칭 기입 Save를 누른 뒤 화면이 바뀌면 Integration Request 선택 Body Mapping Templates 선택 Add mapping template 선택 application/json이라고 입력한 뒤 적용 Generate template : Method Request passthrough 선택 Save 선택 API Gateway는 설정 변경 후 반드시 Deploy해줘야만 적용됩니다. Actions -&gt; Deploy API 선택 후 그냥 prod로 스테이징 이제 다시 Invoke URL로 접속하면 뭔가 화면에 결과가 나타나는 것을 볼 수 있습니다. {&quot;event&quot;: &quot;{u&#39;body-json&#39;: {}, u&#39;params&#39;: {u&#39;path&#39;: {}, u&#39;querystring&#39;: {}, ...} 뭔가 이런 지저분한 모양입니다. u라고 따옴표 앞에 붙은것을 다 지우고 홀따옴표(&#39;)를 쌍따옴표(&quot;)로 수정한 뒤 JSON 모양으로 나타내 보면 아래와 같이 됩니다.우리가 필요한 항목들만 적어봤습니다. 12345678910111213141516171819&#123; \"event\": &#123; \"body-json\": &#123;&#125;, \"params\": &#123; \"path\": &#123;&#125;, \"querystring\": &#123;&#125;, \"header\": &#123; \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36\", &#125; &#125;, \"stage-variables\": &#123;&#125;, \"context\": &#123; \"http-method\": \"GET\", \"resource-path\": \"/\", \"source-ip\": \"112.217.228.202\", &#125; &#125;, \"context\": \"&lt;__main__.LambdaContext object at 0x7f629a39aa10&gt;\"&#125; Node.JS와 똑같은 모양으로 나옵니다.context는 뭔가 dict타입이 아니라서 그대로 출력이 되지 않는군요.공식문서 (http://docs.aws.amazon.com/lambda/latest/dg/python-context-object.html)를 보시면 context 오브젝트에 대한 자세한 내용이 나옵니다. 이제 기본 Invoke URL 뒤에 /test?id=2라고 적은 뒤 브라우저로 요청을 해보겠습니다. 당연히 오류가 발생합니다. {proxy+}로 요청하는 데이터의 형식도 다르며 여기에 대한 응답은 JSON 오브젝트 body에 JSON 형식의 문자열로 전달해야 합니다. Lambda쪽 코드를 아래와 같이 수정 후 다시 요청해보면 정상적으로 답변이 오는 것이 확인 됩니다. POSTMAN을 통해서 POST로 요청을 해도 정상적으로 답변이 오는 것을 볼 수 있습니다.(JSON 객체형태가 아니기 때문에 출력 형식을 Text로 해야 보입니다.) 그래서 JSON 형식으로 응답하도록 코드를 조금 수정해 봤습니다. 1234import jsondef handler(event, context): return &#123; 'body' : json.dumps(event) &#125; 이제는 JSON 오브젝트로 응답하므로 POSTMAN에서도 바로 결과를 볼 수 있습니다. Python Routing Example조금 더 복잡한 예제를 작성해 보겠습니다.예제의 내용은 Node.JS로 진행한 예제와 같은 것입니다. /test?id=? 라는 주소로 GET, POST요청에 대해서 각각 다른 작업을 하는 코드를 작성해 보겠습니다. 각각 함수에 대한 설명은 Lambda 와 API Gateway 연동 #2 (ANY, Deploy Staging, Node.JS Route) 포스팅을 참고해 주세요. 바로 코드 들어갑니다. 123456789101112131415161718192021222324252627282930import jsondef get(event): user_id = event['queryStringParameters']['id'] return &#123; 'body': &#123; 'id': user_id, 'name': \"test\" &#125; &#125;def post(event): user_id = event['queryStringParameters']['id'] body = event['body'] header = event['headers'] return &#123; 'body': &#123; 'id': user_id, 'header': header, 'body': body &#125; &#125;route_map = &#123; '/test': &#123; 'GET': get, 'POST': post &#125;&#125;;def router(event): controller = route_map[event['path']][event['httpMethod']]; if not controller: return &#123; 'body': &#123; 'Error': \"Invalid Path\" &#125; &#125; return controller(event);def handler(event, context): result = router(event); return &#123; 'body' : json.dumps(result) &#125; 결과 확인 GET 요청 : https://.../prod/test?id=2 1&#123;\"body\":&#123;\"id\":\"2\",\"name\":\"test\"&#125;&#125; POST 요청 : URL은 GET과 동일 123456789&#123; \"body\": &#123; \"id\": \"2\", \"header\": &#123; ... &#125;, \"body\": \"\\\"&#123;\\\\n \\\"id\\\": \\\"123\\\",\\\\n \\\"age\\\": \\\"25\\\"\\\\n&#125;\\\"\" &#125;&#125; Node.JS 와 똑같은 결과로 출력되는 것이 확인 가능합니다. 마치며…Python Packaging는 나누어서 다음 포스팅에 작성하겠습니다.간략하게 방법을 설명드리지만 virtualenv로 작업 환경을 만든 뒤 pip install 모듈명 -t 프로젝트폴더로 작업폴더에 모듈을 설치한 뒤 .zip파일로 압축하여 올리시면 됩니다.(Node.JS Packaging과 크게 다르지 않습니다.) 이번 포스팅에서 알아본 내용들은 다음과 같습니다. Lambda에 Python 코드로 핸들러 작성 Python에서 API Gateway의 {proxy+}요청에 대하여 구분해서 작업하는 방법 잘못되었거나, 변경된 점, 기타 추가 사항에 대한 피드백은 언제나 환영합니다. - &#115;&#101;&#111;&#x6b;&#106;&#111;&#x6f;&#x6e;&#46;&#121;&#117;&#110;&#64;&#x67;&#109;&#x61;&#105;&#x6c;&#x2e;&#99;&#111;&#109; 참고 AWS 공식 가이드 : http://docs.aws.amazon.com/lambda/latest/dg/python-programming-model-handler-types.html 다음글 Lambda Python Packaging","categories":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/categories/AWS/"},{"name":"Lambda","slug":"AWS/Lambda","permalink":"http://DevStarSJ.github.io/categories/AWS/Lambda/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/tags/AWS/"},{"name":"Lambda","slug":"Lambda","permalink":"http://DevStarSJ.github.io/tags/Lambda/"},{"name":"APIGateway","slug":"APIGateway","permalink":"http://DevStarSJ.github.io/tags/APIGateway/"},{"name":"Python","slug":"Python","permalink":"http://DevStarSJ.github.io/tags/Python/"}]},{"title":"AWS Lambda와 API Gateway를 이용해서 Serverless Web API 만들기 (3) - Proxy","slug":"Lambda+APIGateway.03.Proxy","date":"2016-11-22T07:54:51.000Z","updated":"2017-04-23T08:21:19.000Z","comments":true,"path":"2016/11/22/Lambda+APIGateway.03.Proxy/","link":"","permalink":"http://DevStarSJ.github.io/2016/11/22/Lambda+APIGateway.03.Proxy/","excerpt":"","text":"AWS Lambda와 API Gateway를 이용해서 Serverless Web API 만들기 (3)API Gateway Proxy Resource 활용API Gateway에서 각각의 route path(API Gateway에서는 Resource로 불림) 및http-method(API Gateway에서는 Method로 불림)에 대해서 Lambda를 설정하는 것은 여간 번거러운 작업이 아닙니다.그 경우에 따라 각각 다른 Lambda로 연결이 되는 경우라면 당연히 따로 설정을 해야하지만,하나의 Lambda로 연결하는 경우에 대해서라면 필요없는 번거로운 작업이 될 수도 있습니다.앞 장에서 http-method에 대해서는 ANY를 이용해서 같은 Lambda로 모두 연결이 가능하도록 작성하였는데,이번 장에서는 Proxy Resource를 이용해서 모든 Resource 및 Method를 같은 Lambda로 연결하는 방법에 대해서 익혀보겠습니다. 전편의 내용을 안다는 가정하에 진행하겠습니다.처음 이 글부터 보시는 분들은 아래 Link에서 내용을 숙지한 후에 진행해 주세요. Lambda 와 API Gateway 연동 #1 (GET, POST) : https://github.com/DevStarSJ/Study/blob/master/Blog/Cloud/AWS/Lambda%2BAPIGateWay.01.md Lambda 와 API Gateway 연동 #2 (ANY, Deploy Staging, Node.JS Route) : https://github.com/DevStarSJ/Study/blob/master/Blog/Cloud/AWS/Lambda%2BAPIGateway.02.Route.md API Gateway 에 Proxy Resource 등록먼저 API Gateway에 등록된 모든 Resource 및 Method를 삭제한 뒤 다음 단계로 진행해주세요. /에서 Actions -&gt; Create Resource를 선택 Configure as proxy resource 를 체크한 후 Create Resource를 누름 그럼 다음 그림과 같이 설정 됩니다. ANY 선택 Integration Request 선택 Integration type : Lambda Function Lambda Region : 람다를 생성한 지역 서버 선택 Lambda Function : 람다 명칭 기입 모든 설정이 끝났습니다.앞에서 해왔던 설정 중 mapping template를 설정하지 않았습니다.해당 설정을 하는 곳을 찾지 못했습니다.그게 없으면 요청이 어떤 모양으로 오는지 알기 힘든데…그냥 Lambda에서 출력해 보겠습니다. API Gateway를 수정했으면 ???잊지말고 Deploy를 해줘야 적용됩니다. Actions -&gt; Deploy API 선택 후 그냥 prod로 스테이징 Lambda에서 요청을 그대로 출력2편에서 작성한 코드를 그대로 두고 우선 실행해보도록 하겠습니다.API Gateway의 Invoke URL을 그대로 브라우저에서 입력하니 오류가 발생합니다. 1&#123;\"message\":\"Missing Authentication Token\"&#125; 어라… 안되네요. 다른 분에게 도움을 요청하였더니, body에 JSON 형식의 string을 담아서 응답을 보내야 한다고 합니다.네. 그렇답니다… http://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-set-up-simple-proxy.html 위 공식문서에 가면 자세한 내용이 있습니다. 그래서 다음과 같이 hander를 수정 후 실행해 보았습니다. 12345exports.handler = (event, context, callback) =&gt; &#123; let result = router(event, context); //let result = &#123;\"event\" : event, \"context\" : context&#125; callback(null, &#123;body:JSON.stringify(result)&#125;);&#125; 결과는 똑같이 안됩니다. ;;;음… 그냥 요청을 그대로 출력해 보겠습니다. 12345exports.handler = (event, context, callback) =&gt; &#123; //let result = router(event, context); let result = &#123;\"event\" : event, \"context\" : context&#125; callback(null, &#123;body:JSON.stringify(result)&#125;);&#125; 왜 안될까 생각을 해보니… API Gateway상에 설정을 보면 /에는 아무런 method가 추가되어 있지 않고 /{proxy+}에 ANY가 등록되어 있습니다.Invoke URL에 뭐라도 더 붙여서 보내니깐 정상적으로 동작합니다. 1https://..../prod/test 뭔가 답변이 나옵니다.좀 더 다양한 정보를 보기 위해서 쿼리스트링도 포함하여 보낸 다음 JSON을 살펴보도록 하겠습니다. 1https://..../prod/test?id=123;name=Luna 123456789101112131415161718192021222324252627282930&#123; \"event\": &#123; \"resource\": \"/&#123;proxy+&#125;\", \"path\": \"/test\", \"httpMethod\": \"GET\", \"headers\": &#123; ... \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36\", &#125;, \"queryStringParameters\": &#123; \"name\": \"Luna\", \"id\": \"123\" &#125;, \"pathParameters\": &#123; \"proxy\": \"test\" &#125;, \"stageVariables\": null, \"requestContext\": &#123; ... &#125;, \"resourcePath\": \"/&#123;proxy+&#125;\", \"httpMethod\": \"GET\", &#125;, \"body\": null, \"isBase64Encoded\": false &#125;, \"context\": &#123; ... &#125;&#125; 2장 라우팅에서 사용한 변수들의 이름이 바뀌어 있습니다.위 모양을 보고 그대로 수정을 해주면 되겠네요.POST로 body값을 추가하여 보내보도록 하겠습니다. 12345678910111213141516171819&#123; \"event\": &#123; \"resource\": \"/&#123;proxy+&#125;\", \"path\": \"/test\", \"httpMethod\": \"POST\", ... \"queryStringParameters\": &#123; \"name\": \"Luna\", \"id\": \"123\" &#125;, \"pathParameters\": &#123; \"proxy\": \"test\" &#125;, ... \"body\": \"&#123;\\n \\\"id\\\": \\\"123\\\",\\n \\\"age\\\": \\\"25\\\"\\n&#125;\", ... &#125; ...&#125; Lambda 코드 수정위 결과를 보고 2장과 똑같은 기능을 하도록 Lambda 쪽의 Node.JS코드를 수정하려고 생각해보니/test/{userId}와 같이 path parameter를 감안하여 path를 생성해주지 않으므로 그대로는 사용을 못하겠고 다르게 처리를 해줘야 합니다.path parameter를 사용하지 않고 query string을 이용하는 방법도 있겠구요. 아니면 해당 패턴이 되도록 비교문을 이용해서 라우팅해야 합니다. 편의상 query string을 사용하도록 수정하였으며 /로 접근하던 부분은 삭제하였습니다.코드에 대한 자세한 설명은 2장 포스팅을 참조해 주세요. 123456789101112131415161718192021222324252627282930313233343536373839404142434445'use strict';function get(userId) &#123; return &#123; body: &#123; id: userId, name: \"test\" &#125; &#125;;&#125;function post(userId, header, body) &#123; return &#123; body: &#123; id: userId, header: header, body: body &#125; &#125;;&#125;const routeMap = &#123; '/test': &#123; 'GET': (event, context) =&gt; &#123; const userId = event.queryStringParameters.id; return get(userId); &#125;, 'POST': (event, context) =&gt; &#123; const userId = event.queryStringParameters.id; const body = JSON.stringify(event.body); const header = event.headers; return post(userId, header, body); &#125; &#125;&#125;;function router(event, context) &#123; const controller = routeMap[event.path][event.httpMethod]; if(!controller) &#123; return &#123; body: &#123; Error: \"Invalid Path\" &#125; &#125;; &#125; return controller(event, context);&#125;exports.handler = (event, context, callback) =&gt; &#123; let result = router(event, context); callback(null, &#123;body:JSON.stringify(result)&#125;);&#125; 결과 확인 GET 요청 : https://.../prod/test?id=2 1&#123;\"body\":&#123;\"id\":\"2\",\"name\":\"test\"&#125;&#125; POST 요청 : URL은 GET과 동일 123456789&#123; \"body\": &#123; \"id\": \"2\", \"header\": &#123; ... &#125;, \"body\": \"\\\"&#123;\\\\n \\\"id\\\": \\\"123\\\",\\\\n \\\"age\\\": \\\"25\\\"\\\\n&#125;\\\"\" &#125;&#125; 마치며…이번 포스팅에서 알아본 내용들은 다음과 같습니다. API Gateway에서 {proxy+}를 여러가지 path와 http-method 요청을 하나의 Lambda로 요청하는 방법 {proxy+}로 접근할 경우 Lambda에서 필요한 요청값들의 변수명 잘못되었거나, 변경된 점, 기타 추가 사항에 대한 피드백은 언제나 환영합니다. - &#x73;&#101;&#111;&#x6b;&#x6a;&#x6f;&#x6f;&#x6e;&#46;&#x79;&#117;&#110;&#x40;&#103;&#109;&#97;&#x69;&#108;&#46;&#99;&#111;&#109; 다음글 Lambda Node.JS Packaging : https://github.com/DevStarSJ/Study/blob/master/Blog/Cloud/AWS/Lambda.Packaging.Node.md","categories":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/categories/AWS/"},{"name":"Lambda","slug":"AWS/Lambda","permalink":"http://DevStarSJ.github.io/categories/AWS/Lambda/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/tags/AWS/"},{"name":"Lambda","slug":"Lambda","permalink":"http://DevStarSJ.github.io/tags/Lambda/"},{"name":"APIGateway","slug":"APIGateway","permalink":"http://DevStarSJ.github.io/tags/APIGateway/"},{"name":"Node.JS","slug":"Node-JS","permalink":"http://DevStarSJ.github.io/tags/Node-JS/"}]},{"title":"AWS Lambda와 API Gateway를 이용해서 Serverless Web API 만들기 (2) - Route","slug":"Lambda+APIGateway.02.Route","date":"2016-11-22T06:54:51.000Z","updated":"2017-04-23T08:21:19.000Z","comments":true,"path":"2016/11/22/Lambda+APIGateway.02.Route/","link":"","permalink":"http://DevStarSJ.github.io/2016/11/22/Lambda+APIGateway.02.Route/","excerpt":"","text":"AWS Lambda와 API Gateway를 이용해서 Serverless Web API 만들기 (2)Routing 예제Web API를 구현하기 위해서는 여러가지 URL에 대해서 각각 다른 기능을 구현하는것은 필수적입니다.각각의 URL을 별도의 Lambda로 구현하여 API Gateway에서 연결하는 방법도 있지만 하나의 Lambda에서 처리하는 방법에 대해서 알아 보도록 하겠습니다.이번에는 전편과는 다르게 약간의 설명을 하면서 진행하겠습니다.전편의 내용을 안다는 가정하에 진행하겠습니다.처음 이 글부터 보시는 분들은 아래 Link에서 내용을 숙지한 후에 진행해 주세요. https://github.com/DevStarSJ/Study/blob/master/Blog/Cloud/AWS/Lambda%2BAPIGateWay.01.md API Gateway 설정아래와 같이 API Gateway를 설정해 주세요. 1편에서 설정한 Path를 그대로 두셔도 되지만, ANY 에 대해서 연습할겸 모든 Resource, Method를 삭제한 후 다음 단계대로 추가해 주세요. ANY는 모든 http-method (GET, POST, PUT, DELETE, …) 를 모두 같은 Lambda로 연결하게 해주는 역할을 합니다.ANY와 같은 위치에 다른 method를 추가하면 그것을 제외한 나머지에 대해서만 ANY로 연결합니다. (ex. ANY, GET을 같은 위치에 선언하면 GET을 제외한 나머지 연결에 대해서는 ANY가 처리) /에서 Actions -&gt; Create Method를 눌러서 ANY를 생성 /에서 Actions -&gt; Create Resource를 눌러서 test를 추가 /test에서 Actions -&gt; Create Resource를 눌러서 {userId}를 추가 /{userId}에서 Actions -&gt; Create Method를 눌러서 ANY를 생성 위까지 한 다음에 ANY로 된 2 곳을 각각 눌러서 Integration type : Lambda Function Lambda Region : 람다를 생성한 지역 서버 선택 Lambda Function : 람다 명칭 기입 Save를 누른 뒤 화면이 바뀌면 Integration Request 선택 Body Mapping Templates 선택 Add mapping template 선택 application/json이라고 입력한 뒤 적용 Generate template : Method Request passthrough 선택 Save 선택 API Gateway는 수정한 후 반드시 Deploy를 해주어야만 적용이 됩니다.Actions -&gt; Deploy API를 선택하면 Deployment stage를 입력하여야하는데 기존에 동일한 이름으로 하면 해당 설정을 덮어쓰게 되며,[New Stage]를 선택한 후 다른 이름을 입력하면 기존의 설정상태를 남겨둔체 새로운 이름으로 생성이 가능합니다.앞에서의 예제에서 prod로 생성을 하였는데 이번에는 test로 생성해 보겠습니다.[New Stage]를 선택한 후 test를 입력하고 Deploy 버튼을 누릅니다. Invoke URL에 연결가능한 주소가 나오는데, 기존과 달라진 점이 마지막에 /prod 대신에 /test가 붙었다는것 밖에 없습니다.브라우저에서 해당 주소로 접속을 하면 2가지 주소가 다 동작한다는 것이 확인됩니다.API Gateway 상에서도 Stages 메뉴로 들어가서 각각의 스테이징 명칭을 누르면 설정된 내용들을 볼 수 있습니다. Lambda 의 Node.JS 코드 수정API Gateway에서 여러 경로로 들어오면 요청들을 모두 하나의 Lambda로 연결하였으니,이젠 Lambda 상에서 여러 경로에 대해서 각각 다른 기능을 하도록 구현해보겠습니다. 가장 중요한 것이 어떤 경로(resource-path)로 들어왔는지 어떤 메서드(http-method)로 요청했는지에 대해서 알아야 합니다.JSON object로 전달된 event 안에 2가지 정보가 모두 있는데각각의 위치가 event.context.resource-path 와 event.context.http-method에 있습니다.그런데 -(dash)가 포함된 명칭이 있어서 .(dot)을 이용하여 읽으려면 오류가 발생하므로event.context[&quot;resource-path&quot;] , event.context[&quot;http-method&quot;] 식으로 접근해야 합니다.API Gateway에서의 template에서 -(dash)가 없는 명칭으로 수정한 뒤 .(dot)을 이용하여 읽어도 됩니다만일단 여기서는 기본설정 그대로 진행하겠습니다. 3가지 경로에 대해서 각각 기능을 구현해보겠습니다. /로 GET 요청 : 요청한 JSON Object를 그대로 응답 /test/{userId}로 GET 요청 : { id: userId, name: “test” }로 응답 /test/{userId}로 POST 요청 : { id: userId, header: header, body: body }로 응답 먼저 위 3가지 기능에 대해서 각각 구현을 해보겠습니다. /로 GET 요청에 대해서는 앞 장에서 사용했던 코드 그대로 전달을 하면 됩니다. 1return &#123;\"event\" : event, \"context\" : context&#125;; /test/{userId}로 GET, POST 요청에 대해서는 각각 get, post라는 이름의 함수로 생성하겠습니다. 1234567891011function get(userId) &#123; return &#123; body: &#123; id: userId, name: \"test\" &#125; &#125;;&#125;function post(userId, header, body) &#123; return &#123; body: &#123; id: userId, header: header, body: body &#125; &#125;;&#125; 다음 순서로 위 3가지 기능을 담은 Map을 생성하겠습니다.JavaScript이기 때문에 그냥 간단하게 JSON Object형식으로 생성을 하면 됩니다.event.context[&quot;resource-path&quot;] -&gt; event.context[&quot;http-method&quot;] -&gt; 각각의 기능 순서대로 접근하면 되도록 생성하였습니다. 1234567891011121314151617181920const routeMap = &#123; '/': &#123; 'GET': (event, context) =&gt; &#123; let result = &#123;\"event\" : event, \"context\" : context&#125; return result; &#125; &#125;, '/test/&#123;userId&#125;': &#123; 'GET': (event, context) =&gt; &#123; const userId = event.params.path.userId; return get(userId); &#125;, 'POST': (event, context) =&gt; &#123; const userId = event.params.path.userId; const body = JSON.stringify(event[\"body-json\"]); const header = event.params.header; return post(userId, header, body); &#125; &#125;&#125;; 이제 실질적으로 Router기능을 수행하는 함수를 생성해 보겠습니다.event와 context를 전달받아 routeMap에서 해당 기능들을 수행하고 그 결과를 다시 전달하는게 이 함수 기능의 전부입니다. 1234567891011function router(event, context) &#123; const controller = routeMap[event.context[\"resource-path\"]][event.context[\"http-method\"]]; if(!controller) &#123; return &#123; body: &#123; Error: \"Invalid Path\" &#125; &#125;; &#125; return controller(event, context);&#125; 이제 모든 기능 구현은 끝났습니다.Lambda의 진입점인 exports.handler에서 router 함수를 호출해주기만 하면 됩니다. 1234exports.handler = (event, context, callback) =&gt; &#123; let result = router(event, context); callback(null, result);&#125; 전체 코드앞에 설명한 내용들을 실제 소스코드로 작성하면 아래와 같이 됩니다. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051'use strict';function get(userId) &#123; return &#123; body: &#123; id: userId, name: \"test\" &#125; &#125;;&#125;function post(userId, header, body) &#123; return &#123; body: &#123; id: userId, header: header, body: body &#125; &#125;;&#125;const routeMap = &#123; '/': &#123; 'GET': (event, context) =&gt; &#123; let result = &#123;\"event\" : event, \"context\" : context&#125; return result; &#125; &#125;, '/test/&#123;userId&#125;': &#123; 'GET': (event, context) =&gt; &#123; const userId = event.params.path.userId; return get(userId); &#125;, 'POST': (event, context) =&gt; &#123; const userId = event.params.path.userId; const body = JSON.stringify(event[\"body-json\"]); const header = event.params.header; return post(userId, header, body); &#125; &#125;&#125;;function router(event, context) &#123; const controller = routeMap[event.context[\"resource-path\"]][event.context[\"http-method\"]]; if(!controller) &#123; return &#123; body: &#123; Error: \"Invalid Path\" &#125; &#125;; &#125; return controller(event, context);&#125;exports.handler = (event, context, callback) =&gt; &#123; let result = router(event, context); callback(null, result);&#125; Lambda에 위 코드를 입력한 후 저장하면 됩니다. 결과 확인 API Gateway의 Invoke URL을 이용하여 호출하여 그 결과값을 확인해 보겠습니다. /로 GET 요청 : Invoke URL 을 브라우저에 입력 요청 JSON을 그대로 응답한 것으로, 앞장에서 살펴본 예제의 결과와 동일하게 나옵니다. /test/{userId}로 GET 요청 : Invoke URL에 /test/LunaStar를 붙여서 브라우저에 입력 123456&#123; \"body\": &#123; \"id\": \"LunaStar\", \"name\": \"test\" &#125;&#125; /test/{userId}로 POST 요청 : POSTMAN에서 Invoke URL에 /test/LunaStar를 붙이고 적당히 header, body를 입력하여 요청 123456789&#123; \"body\": &#123; \"id\": \"LunaStar\", \"header\": &#123; ... &#125;, \"body\": \"&#123;\\\"id\\\":\\\"123\\\",\\\"age\\\":\\\"25\\\"&#125;\" &#125;&#125; 마치며…이번 포스팅에서 알아본 내용들은 다음과 같습니다. API Gateway에서 ANY를 이용해서 여러가지 http-method 요청을 하나의 Lambda로 요청하는 방법 API Gateway에서 Staging을 나누어 Deploy하여 각각의 Staging으로 접근하는 방법 Lambda내에서 요청한 URL 및 http-method 별로 다른 작업을 하는 Node.JS 코드 작성법 잘못되었거나, 변경된 점, 기타 추가 사항에 대한 피드백은 언제나 환영합니다. - &#x73;&#x65;&#x6f;&#x6b;&#106;&#111;&#x6f;&#110;&#46;&#121;&#x75;&#110;&#x40;&#103;&#109;&#x61;&#105;&#108;&#x2e;&#99;&#x6f;&#109; 다음글 Lambda 와 API Gateway 연동 #3 (Proxy Resource) : https://github.com/DevStarSJ/Study/blob/master/Blog/Cloud/AWS/Lambda%2BAPIGateway.03.Proxy.md","categories":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/categories/AWS/"},{"name":"Lambda","slug":"AWS/Lambda","permalink":"http://DevStarSJ.github.io/categories/AWS/Lambda/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/tags/AWS/"},{"name":"Lambda","slug":"Lambda","permalink":"http://DevStarSJ.github.io/tags/Lambda/"},{"name":"APIGateway","slug":"APIGateway","permalink":"http://DevStarSJ.github.io/tags/APIGateway/"},{"name":"Node.JS","slug":"Node-JS","permalink":"http://DevStarSJ.github.io/tags/Node-JS/"}]},{"title":"AWS Lambda와 API Gateway를 이용해서 Serverless Web API 만들기","slug":"Lambda+APIGateWay.01","date":"2016-11-22T05:54:51.000Z","updated":"2017-04-23T08:21:19.000Z","comments":true,"path":"2016/11/22/Lambda+APIGateWay.01/","link":"","permalink":"http://DevStarSJ.github.io/2016/11/22/Lambda+APIGateWay.01/","excerpt":"","text":"AWS Lambda와 API Gateway를 이용해서 Serverless Web API 만들기AWS Lambda 란 코드를 AWS 내에 올려두고 필요할 때에만 해당 코드를 실행해주는 서비스를 말합니다.서버를 24시간 가동시키게 아니라, 그냥 해당 코드가 실행되면서 사용하는 컴퓨팅 시간에 대해서만 과금을 하는 방식입니다.즉, 서버없이 서비스를 할 수 있는 편리한 구조면서도 실제로 코드가 동작하는 만큼만 과금이 되다보니 보통의 경우 서버를 띄워놓는거보다 훨씬 저렴한 비용으로 서비가 가능하며 스케일링에 대한 관리를 해줄 필요가 없습니다. 람다에 올려둔 코드는 AWS 내의 다른 서비스에서 이벤트 형식으로 해당 코드가 실행되게 할 수 있는데, API Gateway 를 붙이면 웹서비스로 활용이 가능합니다. 이 두가지 AWS의 서비스를 이용해서 서버없이 API 서비스를 구축하는 튜토리얼을 진행하겠습니다. 아무 생각없이 그냥 따라하시다 보면 그 과정과 원하는 값을 전달하고 받는 것에 대해서 이해가 되실 겁니다. Lambda 생성 AWS 로그인 후 Lambda 탭으로 이동 Create a Lambda Function 선택 Select blueprint에서 Blank Function 선택 Configure function 에서 일단 바로 Next 선택 (미리 연결할 API Gateway가 있다면 여기서 연결하면 됨) Configure function에서 함수 정의 Name : testLambda-luna Runtime : Node.js 4.3 Code : 아래 코드를 입력 참고로 callback(null, result);와 context.succeed(result);는 둘 다 결과를 return 해주는 코드로 아무거나 사용해도 됨 Role &amp; Existing role : 일단은 적당히 선택 (만약 Lambda에서 다른 AWS 서비스 RDS, S3 등을 연동할려면 필요) 아래 코드 입력 후 Next 선택 1234567'use strict';exports.handler = (event, context, callback) =&gt; &#123; let result = &#123;\"event\" : event, \"context\" : context&#125; context.succeed(result); //callback(null, result);&#125;; Create Function 선택 Action -&gt; Configure test event 선택 원하는 값으로 수정 후 Save and test 선택하면 아래와 같이 나옴. 123456789101112131415161718&#123; \"event\": &#123; \"key3\": \"value3\", \"key2\": \"value2\", \"key1\": \"value1\" &#125;, \"context\": &#123; \"callbackWaitsForEmptyEventLoop\": false, \"logGroupName\": \"/aws/lambda/testLambda-luna\", \"logStreamName\": \"2016/11/16/[$LATEST]3906ef41b5df4f1d89c6501dda78253c\", \"functionName\": \"testLambda-luna\", \"memoryLimitInMB\": \"128\", \"functionVersion\": \"$LATEST\", \"invokeid\": \"be8f2961-aba7-11e6-8ffb-6d91b83819cf\", \"awsRequestId\": \"be8f2961-aba7-11e6-8ffb-6d91b83819cf\", \"invokedFunctionArn\": \"arn:aws:lambda:ap-northeast-1:768556645518:function:testLambda-luna\" &#125;&#125; 만약 name이란 값을 event로 넘겨서 Hello + name 을 출력하고 싶다면 위 Lambda Code를 아래와 같이 수정 1234567'use strict';exports.handler = (event, context, callback) =&gt; &#123; let result = &#123;\"event\" : event, \"context\" : context&#125; let name = event.name || 'no name'; context.succeed('Hello ' + name);&#125;; 그런 다음 Configure test event에 name을 넣어주면 아래와 같이 출력됨. 123&#123; \"name\" : \"Luna\"&#125; 1&quot;Hello Luna&quot; API Gateway 생성 &amp; Lambda 연결 AWS 메인 화면으로 이동 후 API Gateway 탭으로 이동 Create API 선택 API name : testAPI-luna Create API 선택 Actions -&gt; Create Resource 선택 (API Path를 추가) Resource name : test Resource Path : test Create Resource 선택 /test가 선택된 상태에서 Actions -&gt; Create Resource 선택 Resource name : name Resource Path : {name} (Path Variable 추가) Create Resource 선택 /{name}이 선택된 상태에서 Actions -&gt; Create Method 선택 GET 선택 후 확인 Lambda Region : 람다를 생성한 region 선택 Lambda Function : testLambda-luna (좀 전에 생성한 람다명 입력) Integration Request 선택 Body Mapping Templates 선택 Add mapping template 선택 application/json 입력 No, use current settings 선택 Generate template: Method Request passthrough 선택 Save 선택 /test/{name} [GET] 선택 TEST 선택 Path {name} : 원하는 값 입력 Test 버튼 선택 아래와 같이 출력되면 성공 123456789101112131415161718192021&#123; \"event\": &#123; \"body-json\": &#123;&#125;, \"params\": &#123; \"path\": &#123; \"name\": \"Luna\" &#125;, \"querystring\": &#123;&#125;, \"header\": &#123;&#125; &#125;, \"stage-variables\": &#123;&#125;, \"context\": &#123; ... &#125; &#125;, \"context\": &#123; \"callbackWaitsForEmptyEventLoop\": true, \"logGroupName\": \"/aws/lambda/testLambda-luna\", ... &#125;&#125; 배포 Actions -&gt; Deploy API 선택 Deployment Stage : [New Stage] 선택 Stage name : prod 입력 Deploy 버튼 선택 Invoke URL 복사 테스트 Invoke URL + /test/luna 로 Web Browser에서 주소 입력 위 JSON 같은 모양으로 출력되면 성공 Invoke URL + /test/luna?id=345;dept=개발팀과 같이 QueryString 을 포함하여 호출 아래와 같이 querystring 에서 확인되면 성공 12345678910111213141516&#123; \"event\": &#123; \"body-json\": &#123;&#125;, \"params\": &#123; \"path\": &#123; \"name\": \"Luna\" &#125;, \"querystring\": &#123; \"dept\": \"개발팀\", \"id\": \"345\" &#125;, ... &#125; &#125;&#125; POST로 배포 API Gateway에 testAPI-luna로 이동 /{name}이 선택된 상태에서 Actions -&gt; Create Method 선택 POST 선택 후 확인 Lambda Region : 람다를 생성한 region 선택 Lambda Function : testLambda-luna 바로 Test 버튼을 눌러서 확인 Path {name} : 원하는 값 입력 Request Body에 아래 JSON 값 입력 1234&#123; \"id\": \"123\", \"age\": \"25\"&#125; 결과 123456789&#123; \"event\": &#123; \"id\": \"123\", \"age\": \"25\" &#125;, \"context\": &#123; ... &#125;&#125; name 값이 정상적으로 전달되지 않았으므로 GET 작업한것 처럼 template 설정 Integration Request 선택 Body Mapping Templates 선택 Add mapping template 선택 application/json 입력 No, use current settings 선택 Generate template: Method Request passthrough 선택 Save 선택 Test 로 들어가서 위와 같은 JSON 입력 12345678910111213141516&#123; \"event\": &#123; \"body-json\": &#123; \"id\": \"123\", \"age\": \"25\" &#125;, \"params\": &#123; \"path\": &#123; \"name\": \"Luna\" &#125;, \"querystring\": &#123;&#125;, \"header\": &#123;&#125; &#125;, ... &#125;&#125; 다시 배포 Actions -&gt; Deploy API 선택 Deployment Stage : [New Stage] 선택 Stage name : prod 입력 Deploy 버튼 선택 Invoke URL 복사 Postman 을 통해서 테스트 만약 설치되지 않았다면, Chrome App Postman 설치 후 실행 POST 메서드로 선택 주소에 Invoke URL + /test/luna?id=345 입력 Headers 탭 선택 headerValue1 : 123 입력 Body 탭 선택 위 예제의 JSON 입력 Send 선택 결과 12345678910111213141516171819202122232425262728293031323334353637383940&#123; \"event\": &#123; \"body-json\": &#123; \"id\": \"123\", \"age\": \"25\" &#125;, \"params\": &#123; \"path\": &#123; \"name\": \"luna\" &#125;, \"querystring\": &#123; \"id\": \"345\" &#125;, \"header\": &#123; \"Accept\": \"*/*\", \"Accept-Encoding\": \"gzip, deflate, br\", \"Accept-Language\": \"ko-KR,ko;q=0.8,en-US;q=0.6,en;q=0.4\", ... \"Content-Type\": \"application/json\", \"headerValue1\": \"123\", ... &#125; &#125;, \"stage-variables\": &#123;&#125;, \"context\": &#123; ... \"http-method\": \"POST\", ... \"source-ip\": \"112.217.228.202\", \"user\": \"\", \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36\", ... \"resource-path\": \"/test/&#123;name&#125;\" &#125; &#125; &#125;, \"context\": &#123; ... &#125;&#125; 활용 Lambda에서 전달받은 값 활용 event body-json : BODY에서 전달해온 값 params path : URL 상에서 경로로 얻어오는 변수들 header : HEADER에서 전달해온 값 querystring : URL 상의 QueryString로 전달된 변수들 context http-method : 호출한 METHOD (GET, POST, …) resource-path : 하나의 Lambda에서 여러 URL을 처리할 경우 경로 정보 참고 아웃사이더님 Blog : https://blog.outsider.ne.kr/1205 , https://blog.outsider.ne.kr/1206 AWS : http://docs.aws.amazon.com/ko_kr/apigateway/latest/developerguide/api-gateway-mapping-template-reference.html 원문 : https://github.com/DevStarSJ/Study/blob/master/Blog/Cloud/AWS/Lambda%2BAPIGateWay.01.md 잘못되었거나, 변경된 점, 기타 추가 사항에 대한 피드백은 언제나 환영합니다. - &#115;&#x65;&#x6f;&#x6b;&#x6a;&#111;&#111;&#110;&#x2e;&#121;&#117;&#x6e;&#64;&#x67;&#109;&#97;&#105;&#x6c;&#x2e;&#99;&#x6f;&#109; 다음글 Lambda 와 API Gateway 연동 #2 (ANY, Deploy Staging, Node.JS Route) : https://github.com/DevStarSJ/Study/blob/master/Blog/Cloud/AWS/Lambda%2BAPIGateway.02.Route.md","categories":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/categories/AWS/"},{"name":"Lambda","slug":"AWS/Lambda","permalink":"http://DevStarSJ.github.io/categories/AWS/Lambda/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://DevStarSJ.github.io/tags/AWS/"},{"name":"Lambda","slug":"Lambda","permalink":"http://DevStarSJ.github.io/tags/Lambda/"},{"name":"APIGateway","slug":"APIGateway","permalink":"http://DevStarSJ.github.io/tags/APIGateway/"},{"name":"Node.JS","slug":"Node-JS","permalink":"http://DevStarSJ.github.io/tags/Node-JS/"}]},{"title":"Squel.js","slug":"JavaScript.Squel","date":"2016-11-07T15:00:00.000Z","updated":"2017-04-23T09:39:53.000Z","comments":true,"path":"2016/11/08/JavaScript.Squel/","link":"","permalink":"http://DevStarSJ.github.io/2016/11/08/JavaScript.Squel/","excerpt":"","text":"Squel.jsJavaScript 의 SQL query string의 작성을 도와주는 package 입니다.C# 의 LINQ와 비슷한 형식으로 함수들의 체인을 이용해서 정의하면 해당 기능을 동작하는 query string을 작성해 줍니다. 단순히 query string만을 만들어 주는 역할만을 합니다.이게 장점일수도 단점일수도 있는데, C# 의 LINQ의 경우에는 Inline View나 Subquery, JOIN을 표현하기가 상당히 복잡했습니다. 그래서 단순한 문장이 아닌 경우는 그냥 raw query로 작성하는게 더 편했습니다.하지만 squel의 경우에는 어차피 결과물은 String이기 때문에 이것들을 잘 조합하면 얼마든지 복잡한 문장도 표현이 가능합니다. 여기에서는 자주 사용되는 간단한 예제들을 중심으로 소개를 드릴 예정이며,자세한 내용은 공식 사이트 https://hiddentao.com/squel 를 참조해주세요. 설치Node.js1npm install squel 1var squel = require(\"squel\"); Browser1234&lt;script type=\"text/javascript\" src=\"/your/path/to/squel.min.js\"&gt;&lt;/script&gt;&lt;script&gt; console.log( squel.VERSION ); /** version string **/&lt;/script&gt; 사용법SELECT 문장 select() : SELECT 에 대한 query builder 인스턴스를 생성합니다. from(&quot;table&quot;, alias = null) : FROM 절에 해당하는 테이블을 지정합니다. alias 생략 가능 field(&quot;column&quot;) : 읽어올 컬럼들을 지정합니다. field절을 실행한 순서대로 왼쪽부터 출력됩니다. where(&quot;condition&quot;) : WHERE 절 조건을 지정합니다. distinct() : DISTINCT 한 결과로 출력합니다. (중복제거) order(&quot;column&quot;, ASC = true) : ORDER BY 절에 해당하는 sorting연산을 수행합니다. order절을 수행한 순서대로 왼쪽부터 기술되며 ASC, DESC 여부를 2번째 인자에 true,false로 전달이 가능합니다. group() : GROUP BY 절에 해당하는 그룹화 기능을 수행합니다. having(&quot;condition&quot;) : HAVING 절에 해당하는 조건을 지정합니다. limit(number) : TOP-N query를 수행합니다. 앞서 지정한 limit기능을 제거하고 싶으면 .limit(0)을 수행하면 됩니다. offset(number) : SKIP 연산을 수행합니다. limit와 마찬가지로 .offset(0)을 수행하면 앞서 지정한 offset기능을 제거할 수 있습니다. function(&#39;string&#39;) : Scalar 값이나 DB Function 수행시 활용이 가능합니다. JOIN join(&quot;table&quot;, alias = null, onCondition = null) : INNER JOIN을 수행합니다. alias와 ON절은 필요 없을시 생략이 가능합니다. outer_join(...) : 해당 하수에서 지정한 테이블을 OUTER JOIN으로 지정 left_join(...) : LEFT OUTER JOIN right_join(...) : RIGHT OUTER JOIN union(&#39;squel select instance&#39;) : UNION 연산을 수행합니다. 모든 필요한 기능을 다 수행한 후 toString()를 실행하면 query string이 생성됩니다. UNION ALL 연산에 대한 대해서는 현재 제공되고 있지 않습니다. 필요할 경우 그냥 string concatenation을 해야합니다. 모든 조건(condition)에 대해서는 string format형식으로 입력이 가능합니다. (ex. where(&#39;id = ?&#39;, 1)) 관련 예제들 123456var squel = require(\"squel\");var q = squel.select() .from(\"emp\", \"e\") .field(\"**\") .toString(); 1SELECT ** FROM emp `e` 12345678var s = squel.select() .from('emp', 'e') .where('e.id IN ?', idList) .where('e.sal &gt; ?', 2000) .join('dept', 'd', 'e.deptno = d.id') .field('e.name') .field('d.name') .toString(); 1234SELECT e.name, d.name FROM emp `e` INNER JOIN dept `d` ON (e.deptno = d.id) WHERE (e.id IN (1, 2, 3)) AND (e.sal &gt; 2000) UPDATE / INSERT / DELETEUPDATE 와 INSERT, DELETE 문장 작성에 대한 함수는 거의 비슷하므로 같이 다루겠습니다.SELECT 에서 사용된 함수들에 대해서는 중복으로 설명 드리지 않겠습니다. update() : UPDATE 에 대한 query builder 인스턴스를 생성합니다. table(&quot;table&quot;, alias = null) : 수행할 테이블을 지정합니다. insert() : INSERT 에 대한 query builder 인스턴스를 생성합니다. into(&quot;table&quot;, alias = null) : 수행할 테이블을 지정합니다. delete() : DELETE 에 대한 query builder 인스턴스를 생성합니다. from(&quot;table&quot;, alias = null) : 수행할 테이블을 지정합니다. set(&#39;field&#39;, value, options = null) : UPDATE, INSERT에서 해당 컬럼에 저장할 값을 지정합니다. value에 함수를 지정할 경우 문자열로 인식하여 따옴표를 씌우게 되는데 그럼 함수로 동작하지 않습니다. 그럴 경우 options 란에 { dontQuote: true}를 입력해주면 value에 따옴표 표시를 하지 않아서 함수로 동작하게 가능합니다. 12345var uf = squel.update() .table('emp') .set('hire_date', 'GETDATE()', &#123; dontQuote: true &#125;) .where('dept = ?', 10) .toString(); 1UPDATE emp SET hire_date = GETDATE() WHERE (dept = 10) setFields({JSON}) : 입력된 JSON의 key와 value로 set()함수를 수행합니다. setFieldsRows([JSON LIST]) : INSERT 에서만 수행이 가능하며 여러 줄 입력으로 setFields() 함수를 수행합니다. 1234var im = squel.insert() .into('emp') .setFieldsRows([&#123;id:1, name:\"Luna\"&#125;, &#123;id:2, name:\"Star\"&#125;]) .toString(); 1INSERT INTO emp (id, name) VALUES (1, 'Luna'), (2, 'Star') fromQuery : SELECT 수행 결과를 INSERT 합니다. 1234567891011var is = squel.insert() .into('emp') .fromQuery( ['id', 'name'], squel .select() .from('candidates') .field('id') .field('name') ) .toString(); 1INSERT INTO emp (id, name) (SELECT id, name FROM candidates) 나머지 함수들 where(), limit(), order(), JOIN 연산 등은 SELECT 와 동일합니다. Parameters위에서 살펴본 예제들은 모두 Binding Parameters 를 사용하지 않고 query에 하드코딩 되어 있습니다.parameterized query 로 생성하려면 .toString() 대신에 .toParam()을 실행하면 됩니다. 123456var pq = squel.select() .from(`emp`) .where('id = ?', 10) .where('dept = ?', 20) .field('*') .toParam(); 12&#123; text: 'SELECT * FROM emp WHERE (id = ?) AND (dept = ?)', values: [ 10, 20 ] &#125; ?가 아니라 numbered parameter ($1, $2, …)를 사용하려면 toParam()의 인자로 { numberedParameters: true, numberedParametersStartAt: 1 } 을 전달하면 됩니다.","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://DevStarSJ.github.io/categories/JavaScript/"},{"name":"Node.JS","slug":"JavaScript/Node-JS","permalink":"http://DevStarSJ.github.io/categories/JavaScript/Node-JS/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://DevStarSJ.github.io/tags/JavaScript/"},{"name":"Node.JS","slug":"Node-JS","permalink":"http://DevStarSJ.github.io/tags/Node-JS/"}]},{"title":"Zero to One","slug":"ZeroToOne","date":"2016-10-19T15:00:00.000Z","updated":"2017-04-30T03:45:22.000Z","comments":true,"path":"2016/10/20/ZeroToOne/","link":"","permalink":"http://DevStarSJ.github.io/2016/10/20/ZeroToOne/","excerpt":"","text":"Zero to One경쟁하지 말고 독점하라 지은이 : 피터 틸, 블레이크 매스터스 옮긴이 : 이지연 페이팔의 공동 창업자 피터 틸의 창업 마인드에 대해 알 수 있는 책입니다. 경쟁하지 말고 독점하라 이 한마디가 모든 걸 다 이야기 해주고 있습니다. 1에서 100으로 올리는거는 100배의 성과이지만,0에서 1로 창조하는 거는 무한대의 성과라는 것이 그의 주장입니다. 이 내용을 시작으로 하여 스타트업 조직 운영 및 구성원들에 대한 지은이의 생각에 대한 내용이 나옵니다.","categories":[{"name":"Book","slug":"Book","permalink":"http://DevStarSJ.github.io/categories/Book/"},{"name":"Review","slug":"Book/Review","permalink":"http://DevStarSJ.github.io/categories/Book/Review/"}],"tags":[{"name":"Book","slug":"Book","permalink":"http://DevStarSJ.github.io/tags/Book/"},{"name":"Review","slug":"Review","permalink":"http://DevStarSJ.github.io/tags/Review/"}]},{"title":"Drive 창조적인 사람들을 움직이는 자발적 동기부여의 힘","slug":"Drive","date":"2016-10-19T15:00:00.000Z","updated":"2017-04-30T03:46:19.000Z","comments":true,"path":"2016/10/20/Drive/","link":"","permalink":"http://DevStarSJ.github.io/2016/10/20/Drive/","excerpt":"","text":"DriveThe Surprising Truth About What Motivates Us창조적인 사람들을 움직이는 자발적 동기부여의 힘 지은이 : 다니엘 핑크 옮긴이 : 김주환 그 동안 봐왔던 대중서적과는 조금 다른 분위기의 책이었습니다.말로만 듣던 논문 형식의 책 느낌이 살짝 들었습니다.하지만 거부감 없이 술술 읽혀 갔습니다. 읽기 시작한지 만 24시간도 안되서 다 읽었습니다. 인센티브를 지급할 경우 업무효율이 올라갈 거라고 보통 생각을 많이 하는데, 여기에 대한 실험을 했는 결과를 다루고 있습니다.결과부터 얘기하자면 창조적인 일을 하는 사람에게는 오히려 효율을 떨어트리며, 집중력을 요구하는 일에 대해서는 어느 정도 효과가 있다고 얘기합니다. 마지막 챕터에서는 창조적인 사람들을 자발적으로 동기부여를 하게 하는 방법들에 대해서 구체적인 방법들을 제시해줍니다. 개발자 같이 창조적인 일을 하는 조직에서 어느 정도 중간급 매니저 이상 분들은 한번씩 읽어 보시길 추천드립니다.","categories":[{"name":"Book","slug":"Book","permalink":"http://DevStarSJ.github.io/categories/Book/"},{"name":"Review","slug":"Book/Review","permalink":"http://DevStarSJ.github.io/categories/Book/Review/"}],"tags":[{"name":"Book","slug":"Book","permalink":"http://DevStarSJ.github.io/tags/Book/"},{"name":"Review","slug":"Review","permalink":"http://DevStarSJ.github.io/tags/Review/"}]},{"title":"Think Bayes","slug":"Python.ThinkBayes","date":"2016-09-20T15:00:00.000Z","updated":"2017-04-30T03:15:02.000Z","comments":true,"path":"2016/09/21/Python.ThinkBayes/","link":"","permalink":"http://DevStarSJ.github.io/2016/09/21/Python.ThinkBayes/","excerpt":"","text":"Think Bayes (파이썬을 활용한 베이지안 통계) 원서명 : Think Bayes: First Principles with Python 지은이 : Allen B. Downey 원서 : http://greenteapress.com/wp/think-bayes/ 번역서 : http://www.hanbit.co.kr/store/books/look.php?p_code=B7186764823 저자 ipynb 코드 :https://github.com/rlabbe/ThinkBayes This posting is made in .ipynb, so the original file can be modified and executed in the Jupiter Notebook. Location : https://github.com/DevStarSJ/Study/blob/master/Blog/Python/ThinkBayes 01. Bayes Theorem - 2016-09-21 02. Computational Statistics - 2016-09-21 03. Estimation - 2016-09-22 04. More Estimation - 2016-09-22 05. Odds and Addends - 2016-09-26","categories":[{"name":"Python","slug":"Python","permalink":"http://DevStarSJ.github.io/categories/Python/"},{"name":"DataScience","slug":"Python/DataScience","permalink":"http://DevStarSJ.github.io/categories/Python/DataScience/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://DevStarSJ.github.io/tags/Python/"},{"name":"DataScience","slug":"DataScience","permalink":"http://DevStarSJ.github.io/tags/DataScience/"}]},{"title":"선대인의 빅픽처 저성장 시대의 생존 경제학","slug":"DataScienceWithScratch","date":"2016-09-02T15:00:00.000Z","updated":"2017-04-30T03:38:40.000Z","comments":true,"path":"2016/09/03/DataScienceWithScratch/","link":"","permalink":"http://DevStarSJ.github.io/2016/09/03/DataScienceWithScratch/","excerpt":"","text":"밑바닥부터 시작하는 데이터 과학 원서명 : Data Science from Scratch: First Principles with Python 지은이 : Joel Grus 원서 : http://shop.oreilly.com/product/0636920033400.do 번역서 : http://www.insightbook.co.kr/books/programming-insight 출판사 예제코드 : https://github.com/insight-book/data-science-from-scratch 관련 스터디 교제라서 사서 본 책입니다. 제목이 굉장히 자극적입니다. 밑바닥부터 시작하는 데이터 과학네. 분명 밑바닥부터 시작하는 책 맞습니다.저자의 의도는 이 책에서 소개하는 대부분의 기능들을 잘 지원해주는 라이브러리가 존재하지만,그런 것들을 사용하지 않고 직접 구현을 해 보아서 그 동작 원리를 이해하는데 그 목적을 둔다고 하셨습니다. 하지만, 삽한자루 없이 맨손으로 흙을 파서 쌓아 올리는 것! 이까지는 좋습니다.그런데 그렇게 바벨탑을 쌓고 있습니다. 자세한 설명없이, 이렇게 하면 바벨탑이 쌓입니다.이렇게 데이터를 계산해서 시각화가 가능합니다 라는게 바로 나옵니다. 초보자 분들이 보기에는 상당히 버겁습니다. 어느 정도 관련 내용을 아시는 분들이 그 원리를 좀 더 자세히 알기 위해서, 또는 전체적인 프로세스의 큰 그림을 보고 싶으신 분들에겐 적합한 책이라 생각됩니다.각 장마다 마지막에 관련 라이브러리에 대한 소개가 있습니다. 저는 아직 초보라서 보기에 상당히 버거웠습니다. 출퇴근 길 지하철에서 끝까지 다 읽었습니다.읽을땐 이해가 안되지만 다음에 시간내서 예제코드를 따라해보면 이해가 되겠지라 생각했는데…예제를 따라해도 전혀 이해가 안됩니다.베이지안 추론에 대해서 자세한 설명없이 2페이지 정도에 예제코드를 보여주고 실행하면 결과가 나옵니다. 전 8장 정도까지 예제코드를 따라하다가 결국은 너무 버거워서 포기했습니다.다른 책으로 좀 더 공부를 한 뒤에 다시 봐야할 것 같습니다.","categories":[{"name":"Book","slug":"Book","permalink":"http://DevStarSJ.github.io/categories/Book/"},{"name":"Review","slug":"Book/Review","permalink":"http://DevStarSJ.github.io/categories/Book/Review/"}],"tags":[{"name":"Book","slug":"Book","permalink":"http://DevStarSJ.github.io/tags/Book/"},{"name":"Review","slug":"Review","permalink":"http://DevStarSJ.github.io/tags/Review/"}]},{"title":"파이썬으로 풀어보는 수학","slug":"DoingMathWithPython","date":"2016-09-02T15:00:00.000Z","updated":"2017-04-30T03:39:29.000Z","comments":true,"path":"2016/09/03/DoingMathWithPython/","link":"","permalink":"http://DevStarSJ.github.io/2016/09/03/DoingMathWithPython/","excerpt":"","text":"파이썬으로 풀어보는 수학 원서명 : Doing Math with Python: Use Programming to Explore Algebra, Statistics, Calculus, and More! (ISBN 9781593276409) 지은이 : 아미트 사하(Amit Saha) 원서 및 관련자료 : https://www.nostarch.com/doingmathwithpython 번역서 : http://www.acornpub.co.kr/book/doing-math-with-python 정말 쉽고 재밌는 책입니다.수학에 대해서 잘 알지 못해도 풀이 과정을 증명하는 것처럼 풀어서 설명을 해주며,파이썬에 대해서 잘 알지 못해도 책에 있는 예제코드만 따라해도 관련 문법을 어떻게 응용하면 되겠다 라는 것을 알 수 있습니다. 물론 수학에 대한 내용을 깊게 다루지도 않으며, 파이썬 문법에 대해서도 자세히 설명해주지는 않습니다. 하지만, 그 둘을 다 모르는 사람도 보기에 편한 책이니 만큼 수식을 보는데 두려움이 있는 개발자 분들이나,파이썬을 처음 접해보려는데 문법책만 보니깐 너무 어렵고 지루하다고 느끼시는 분들은 이 책을 한 번 다 읽고, 예제들도 따라해 보신 후자신이 관심이 가는 다른 책을 보시는 것을 추천드립니다. 저같은 경우에는 출퇴근길에 지하철에서 전체 책을 먼저 한번 읽어 본 뒤,시간이 날때마다 책의 예제를 따라해보면서 해당 내용을 Jupyter notebook을 통해 정리를 하였습니다.작업한 파일은 Github (http://goo.gl/UFieM5) 에 올려두었습니다. Github에서 직접 렌더링하여 보여주는 기능을 제공하지만, 수식의 경우 깨져서 나오므로,블로그 상의 글을 참조하시거나 nbviewer로 접근해서 보시면 정상적으로 보입니다.","categories":[{"name":"Book","slug":"Book","permalink":"http://DevStarSJ.github.io/categories/Book/"},{"name":"Review","slug":"Book/Review","permalink":"http://DevStarSJ.github.io/categories/Book/Review/"}],"tags":[{"name":"Book","slug":"Book","permalink":"http://DevStarSJ.github.io/tags/Book/"},{"name":"Review","slug":"Review","permalink":"http://DevStarSJ.github.io/tags/Review/"}]},{"title":"Client WebSocket Example without ASP.NET","slug":"CSharp.ClientWebSocketExample","date":"2016-08-30T17:00:00.000Z","updated":"2017-05-24T03:25:12.000Z","comments":true,"path":"2016/08/31/CSharp.ClientWebSocketExample/","link":"","permalink":"http://DevStarSJ.github.io/2016/08/31/CSharp.ClientWebSocketExample/","excerpt":"","text":"Client WebSocket Example without ASP.NETASP.NET을 사용하지 않고 일반적인 C# (Console, Winform) 에서 WebSocket Server에 접속하는 코드 예제 입니다. 결론만 말씀드리자면… WebSocketSharp 만 사용하세요. https://github.com/sta/websocket-sharp 그래도 나머지의 사용법도 설명해 드리겠습니다. 1. WebSocketSharpNuget Manager에서 WebSocketSharp를 include prerelease를 체크한 상태에서 검색해서 설치하세요. 12345678910111213using WebSocketSharp;WebSocket ws = new WebSocket(url: \"ws://localhost:5000\");ws.Connect();ws.Send(new byte[] &#123; 0x01, 0x02, 0x03 &#125;);ws.OnMessage += (sender, e) =&gt;&#123; Console.WriteLine(e.Data); // string byte[] data = e.RawData // byte []&#125;; 2. WebSocketSharp-clone 사용nuget manager에서 websocket-sharp.clone 로 검색하면 나옵니다. WebSocketSharp에 비해 사용하기 조금 더 까다롭습니다.하지만, 비동기(async)처리를 지원해 줍니다. OnMessage 이벤트를 생성자에게 입력해줘야 하는데, 타입이 까다로워서 쉽지 않습니다.(저도 구현해보려고 시도하다가 귀찮아서 관뒀습니다.) 1234567891011using WebSocketSharp;WebSocket ws = new WebSocket(url: \"ws://localhost:5000\");await ws.Connect();Console.WriteLine(ws.ReadyState); // Openbool result = await ws.Send(new byte[] &#123; 0x03, 0x01, 0x10, 0xFF &#125;);Console.WriteLine(result.ToString()); // true 3. System.Net.WebSockets 사용별도의 nuget 설치 필요없이 사용이 가능합니다. SendAsync()가 실행 중 다시 실행하면 오류가 발생합니다.그러니 별도의 Lock작업을 해주던지 메세지 전송을 Queue처리해서 한 곳에서만 동작하게 구현을 해줘야 합니다. ReceiveAsync()를 호출해서 값을 읽어야 하므로, 구현하기에 불편함이 있습니다.해당 함수를 이용해서 Event를 만들어서 구현을 해주면 편리하게 사용이 가능할거라 생각됩니다.귀찮아서 저도 그렇게 구현해 보려다 말았습니다. 1234567891011using System.Net.WebSockets;ClientWebSocket ws = new ClientWebSocket();Uri uri = new Uri(\"ws://localhost:5000\");await ws.ConnectAsync(uri, CancellationToken.None);Console.WriteLine(ws.State); // openvar segment = new ArraySegment&lt;byte&gt;(new byte[] &#123; 0x03, 0x01, 0x10, 0xFF &#125;);await ws.SendAsync(segment, WebSocketMessageType.Binary, true, CancellationToken.None);","categories":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/categories/C/"},{"name":"C#","slug":"C/C","permalink":"http://DevStarSJ.github.io/categories/C/C/"}],"tags":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/tags/C/"}]},{"title":"Jupyter notebook markdown에 내가 원하는 css 적용하기 (Linux / macOS)","slug":"Tips.JupyterNotebook.custom.css.mac","date":"2016-08-26T15:00:00.000Z","updated":"2017-04-30T03:23:21.000Z","comments":true,"path":"2016/08/27/Tips.JupyterNotebook.custom.css.mac/","link":"","permalink":"http://DevStarSJ.github.io/2016/08/27/Tips.JupyterNotebook.custom.css.mac/","excerpt":"","text":"Jupyter notebook markdown에 내가 원하는 css 적용하기 (Linux / macOS)Windows에서 설정하는 방법에 대해서는 저번에 포스팅 한 적이 있습니다. http://seokjoonyun.blogspot.kr/2016/08/jupyter-notebook-markdown-css.html 하지만… Mac OS에서는 다르더군요.(아마 Linux와 Max OS는 같을 것으로 추정됩니다.)디렉토리 구조도 다르고, 참조하는 css 파일의 종류, 개수, 순서… 다 다릅니다.찾기도 쉽지 않았습니다.결국 찾긴 했지만요.이번 포스팅에서는 제가 찾기 위해 삽질한 방법들과 수정 방법, 그 결과를 공유하고자 합니다. 1. Macbook에서 Jupyter notebook을 실행맥북 구입후 Python 및 Anaconda를 설치한 후, 부푼 맘을 가진체 Jupyter notebook을 실행해 보았습니다. 역시 맥북용 폰트는 이쁩니다. 그런데, Windows에서 설정한 한 Markdown의 렌더링결과가 적용되어 있지 않습니다.당연한 거지요.새로 설치했으니깐요.그래서 Windows에서 제가 수정한 내용을 토대로 sytle.min.css를 찾아서 수정을 했습니다.폴더 구조가 조금은 달랐지만, 대충 Anaconda 밑에 있는 Notebook 폴더 중 가장 최신 버전을 수정했는데… 아무 것도 변한게 없습니다.어라~ 흠… 2. 용의자 확보Cmd + Opt + I를 눌러서 적용된 css를 다시 찾아봤습니다. 제가 적용한 내용들이 모두 빨간줄 찍찍찍.그리고 그 위에 뭔가 다른 css가 우선순위가 높게 적용되어 있군요.일단 진범이 있다는 사실은 확보했습니다.이제 저 녀석을 잡아야 합니다.분명 범인은 어딘가 흔적을 남겼을 것이기에 그것을 찾아서 추적해 보았습니다. Windows에서 수정할때는 위 스샷의 css정보만으로도 잡을 수 있었는데, 이번엔 범인도 좀 더 스마트해 졌습니다.그래서 좀 더 무식한 방법으로 찾아봤습니다.그냥 html 자체를 열어봤습니다. 저 내용을 일단 다른 에디터로 열었습니다.(필자의 경우는 Visual Studio Code를 사용)그래서 .css로 검색을 했죠. 총 7개가 나왔군요.이제 용의자를 확보되었습니다.한 명씩 직접 만나서 확인을 해 보겠습니다. 3. 진범을 찾아서…한 명씩 직접 찾아가 보도록 하겠습니다.상대경로가 있긴하지만, 정확히 어느 위치에서 Notebook이 실행되는지 정확히 잘 모르니깐, 그 정보를 토대로 범인의 집을 찾아가긴 힘들 것 같고…일단 범인이 우리나라 (내 맥북 안)에 거주하는건 확실하기 때문에 전체에서 찾아 봤습니다. 1sudo find / -name &apos;jquery-ui.min.css&apos; 겁나 많이 뜹니다.그렇겠죠 jQuery를 사용하는 곳은 한 두 곳이 아닐테니깐요.수사 범위를 좀 좁혀봤습니다.우리나라 전체가 아닌 범행이 일어난 도시 (내 루트폴더 안)에서만 검색해 봤습니다. 1sudo find ~ -name &apos;jquery-ui.min.css&apos; 12345678910/Users/seokjoonyun/.pyenv/versions/anaconda3-4.1.0/lib/python3.5/site-packages/matplotlib/backends/web_backend/jquery/css/themes/base/jquery-ui.min.css/Users/seokjoonyun/.pyenv/versions/anaconda3-4.1.0/lib/python3.5/site-packages/notebook/static/components/jquery-ui/themes/smoothness/jquery-ui.min.css/Users/seokjoonyun/.pyenv/versions/anaconda3-4.1.0/pkgs/matplotlib-1.5.1-np111py35_0/lib/python3.5/site-packages/matplotlib/backends/web_backend/jquery/css/themes/base/jquery-ui.min.css/Users/seokjoonyun/.pyenv/versions/anaconda3-4.1.0/pkgs/notebook-4.2.1-py35_0/lib/python3.5/site-packages/notebook/static/components/jquery-ui/themes/smoothness/jquery-ui.min.css/Users/seokjoonyun/.pyenv/versions/anaconda3-4.1.0/pkgs/notebook-4.2.2-py35_0/lib/python3.5/site-packages/notebook/static/components/jquery-ui/themes/smoothness/jquery-ui.min.css/Users/seokjoonyun/anaconda/lib/python3.5/site-packages/matplotlib/backends/web_backend/jquery/css/themes/base/jquery-ui.min.css/Users/seokjoonyun/anaconda/lib/python3.5/site-packages/notebook/static/components/jquery-ui/themes/smoothness/jquery-ui.min.css/Users/seokjoonyun/anaconda/pkgs/matplotlib-1.5.1-np111py35_0/lib/python3.5/site-packages/matplotlib/backends/web_backend/jquery/css/themes/base/jquery-ui.min.css/Users/seokjoonyun/anaconda/pkgs/notebook-4.2.1-py35_0/lib/python3.5/site-packages/notebook/static/components/jquery-ui/themes/smoothness/jquery-ui.min.css/Users/seokjoonyun/anaconda/pkgs/notebook-4.2.2-py35_0/lib/python3.5/site-packages/notebook/static/components/jquery-ui/themes/smoothness/jquery-ui.min.css 그래도 좀 많군요.근데 21C에… Termianl에서 키보드로 명령 내려서… 뭐하는 짓인가 싶더라구요.우린 문명인이고 마우스라는 좋은 도구가 있습니다.난 도구를 사용할 줄 아는 사피엔스니깐요. 도구를 사용하도록 하겠습니다. 저런식으로 찾아서 css 파일을 열어서 내용 중 위 그림에서 보았던 .rendered_html code가 있는지 검색해 보았습니다. 범인이 아니라는 군요. 혹시 내가 올 줄 알고 미리 증거를 인멸한게 아니냐는 의구심이 들지만, 아직 다른 용의자가 많이 남았기에 그냥 보내주었습니다. 계속해서 반복해서 용의자들을 직접 만나보았습니다. 4. 유력한 용의자 확보 !용의자들을 한 명씩 찾아가서 증거 (.rendered_html code)에 대해서 물어보던 중 한 녀석이 걸렸습니다. 1~/anaconda/lib/python3.5/site-packages/notebook/static/style/style.min.css 딱 걸렸습니다.위 그림에서 보았던 .rendered_html code의 내용과도 완벽하게 일치합니다.얼릉 해당 파일을 style.min.original.css로 사본을 만들어 놓은 뒤 Windows에 적용했던 css내용들로 수정했습니다.혹시 진범이 아닐 수도 있으니깐요.그럴땐 다시 원래대로 되돌려 놓아야 하니깐요. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859.rendered_html pre,.rendered_html code &#123; font-family: Consolas,\"Andale Mono WT\",\"Andale Mono\",\"Lucida Console\",\"Lucida Sans Typewriter\",\"DejaVu Sans Mono\",\"Bitstream Vera Sans Mono\",\"Liberation Mono\",\"Nimbus Mono L\",Monaco,\"Courier New\",Courier,monospace;&#125;p code,li code &#123; border: solid 1px #e1e4e5; white-space: nowrap; background: #fff; color: #E74C3C; padding: 0 5px; overflow-x: auto;&#125;blockquote &#123; background-color: #fcf2f2; border-color: #dFb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;&#125;.rendered_html h1 &#123; font-size: 250%; margin: 1.08em 0 0 0; font-weight: bold; line-height: 1.0;&#125;.rendered_html h2 &#123; font-size: 200%; margin: 1.27em 0 0 0; font-weight: bold; line-height: 1.0;&#125;.rendered_html h3 &#123; font-size: 180%; margin: 1.55em 0 0 0; font-weight: bold; line-height: 1.0;&#125;.rendered_html h4 &#123; font-size: 150%; margin: 2em 0 0 0; font-weight: bold; line-height: 1.0;&#125;.rendered_html h5 &#123; font-size: 130%; margin: 2em 0 0 0; font-weight: bold; line-height: 1.0;&#125;.rendered_html h6 &#123; font-size: 110%; margin: 2em 0 0 0; font-weight: bold; line-height: 1.0;&#125; 위의 tag 들을 찾아서 수정했습니다.해당 tag가 모두 다 있었습니다.그 내용또한 Winodws에서 수정하기 전의 모습과 거의 유사했습니다.일단 심증적으로는 진범일꺼란 확신이 들었습니다. 5. 진범 검거수정한 내용을 저장하고 Jupyter notebook 종료 후 다시 실행해 보았습니다. 바뀌었습니다.다른 부분도 살펴보았습니다. 고친 곳이 한곳 더 있는데… 해당 Markdown을 사용한 곳이 없어서 즉석해서 수정을 해 봤습니다. 그런 후 렌더링을 해보니… 원하는대로 되었습니다. 6. 정리1~/anaconda/lib/python3.5/site-packages/notebook/static/style/style.min.css 버전에 따라, 설치한 방법에 따라 위치가 달라질 수는 있지만, anaconda 밑에 있는 python3.5 이하에 있는 style.min.css를 수정해야 합니다.notebook 아래에도 같은 파일이 같은 내용으로 존재하지만, 저 파일을 먼저 적용하고 그 다음에 적용하기 때문에 같은 tag가 둘 다 존재할 경우 뒤에 읽는건 무시됩니다.","categories":[{"name":"Tips","slug":"Tips","permalink":"http://DevStarSJ.github.io/categories/Tips/"},{"name":"JupyterNotebook","slug":"Tips/JupyterNotebook","permalink":"http://DevStarSJ.github.io/categories/Tips/JupyterNotebook/"}],"tags":[{"name":"JupyterNotebook","slug":"JupyterNotebook","permalink":"http://DevStarSJ.github.io/tags/JupyterNotebook/"}]},{"title":"Running Multiple Coroutines Concurrently","slug":"Python.RunMultipleCoroutinesConcurrently","date":"2016-08-18T15:00:00.000Z","updated":"2017-04-30T03:29:37.000Z","comments":true,"path":"2016/08/19/Python.RunMultipleCoroutinesConcurrently/","link":"","permalink":"http://DevStarSJ.github.io/2016/08/19/Python.RunMultipleCoroutinesConcurrently/","excerpt":"","text":"Python : Running Multiple Coroutines Concurrently파이썬에서 asyncio로 만들어진 Coroutine들 여러 개를 동시에 돌리는 방법에 대해서 소개해 드리겠습니다. 파이썬 코루틴들은 event_loop에 등록이 되어서 동작합니다. 가장 먼저 생각할 수 있는 방법으로는 멀티쓰레드를 이용한 방법입니다만, Python의 쓰레드는 동시에 동작하지 않습니다.그래서 멀티스레드 작업은 같은 작업을 싱글스레드에서 하는것보다 더 느립니다.더군다나 하나의 프로세스에서 동작하는 코루틴 들에 event_loop 등록을 각각하게 되면 오류가 발생합니다.그래서 멀티쓰레드로 구현하는 방법은 일단 제외하겠습니다. 1. 멀티프로세스(multiprocessing)로 구현파이썬은 멀티프로세스로 작업을 구현하는것이 가능합니다.이 경우 주의해야 할 점은 프로세스간에는 메모리 공유가 되지 않습니다.서로 공유해야할 데이터가 있을 경우에는 다른 방법으로 공유하는 것을 추가구현하여야 합니다. 아래 간단한 예제코드 입니다.전체 코드가 아니라 실행되는 코드는 아니니 구현방법에 대해서만 참조해 주시기 바랍니다. 1234567891011121314151617import multiprocessingdef run_server_source(): ...def run_server_client(): ...if __name__ == \"__main__\": process1 = multiprocessing.Process(target=run_server_source) process2 = multiprocessing.Process(target=run_server_client) process1.start() process2.start() process1.join() process2.join() 2. 이벤트 루프(event_loop)를 공유하나의 프로세스 안에서 이벤트 루프를 공유하는 방법입니다.단일 프로세스 내에서 동작하기 때문에 데이터를 공유할 일이 있는 경우에는 이 방법이 편리합니다. 이벤트 루프를 공유한다는게 말같지도 않게 들리죠 ?몇개의 코루틴이든 그냥 get_event_loop()를 해서 사용하면 됩니다.통상적으로 class 내부에서 코루틴을 사용하는 경우 내부에서 get_event_loop()를 매번 호출해서 사용하는 경우도 있고,get_event_loop()로 반환받은 loop를 멤버로 저장한 뒤 계속 사용하는 방법도 있습니다. 이 경우에 class 외부에서 loop를 주입받아서 사용하도록 class 구현을 수정한 뒤 외부에서 get_event_loop()로 가져온 loop로 코루틴을 사용하는 모든 class로 주입을 하면 해당 class들이 모두 정상적으로 동작합니다.그렇게 사용할 모든 class에 주입한 다음 run_forever()를 한번만 호출하면 됩니다.너무나도 당연한 말인데, 해당 키워드로 검색 및 질문들이 stackoverflow에 등록되어 있으며, 아주 복잡한 방법으로의 답변들만 등록되어 있더군요. 아래는 간단한 예제 코드입니다. from event_server import run_event_server from client_server import run_client_server from asyncio import get_event_loop from log_console import ConsoleClientLogger, ConsoleEventLogger if __name__ == \"__main__\": loop = get_event_loop() client_server = run_client_server(loop, ConsoleClientLogger()) source_server = run_event_server(loop, client_server, ConsoleEventLogger()) loop.run_forever()","categories":[{"name":"Python","slug":"Python","permalink":"http://DevStarSJ.github.io/categories/Python/"},{"name":"Python","slug":"Python/Python","permalink":"http://DevStarSJ.github.io/categories/Python/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://DevStarSJ.github.io/tags/Python/"}]},{"title":"Chapter 7 Exceptions, Memory, and Performance","slug":"TypeScript.07.Exceptions, Memory, and Performance","date":"2016-08-15T15:00:00.000Z","updated":"2017-04-23T09:46:06.000Z","comments":true,"path":"2016/08/16/TypeScript.07.Exceptions, Memory, and Performance/","link":"","permalink":"http://DevStarSJ.github.io/2016/08/16/TypeScript.07.Exceptions, Memory, and Performance/","excerpt":"","text":"Chapter 7 Exceptions, Memory, and Performance 예외(Exception) 및 메모리 관리(MM : Memory Management)를 잘 알면 프로그램 작성에 도움이 됨 TypeScript, JavaScript의 예외가 C#, Java, PHP 등 다른 언어를 다뤄본 개발자들에게는 친숙해 보이겠지만, 미묘한 차이가 있음 7장에서 MM 과 GC(Garbage Collection) 의 최적화 테스트를 위한 측정 방법에 대해서 다룰 예정 1. 예외 (Exceptions) 예외는 프로그램이나 모듈이 계속해서 처리하는게 불가능함을 나타내기 위해 사용됨 하지만, Program Logic 상의 문제를 예외를 통해서 처리하는 경우가 종종 있는데, 이 경우에는 예외처리 없이 Logic으로 검증하는게 더욱 바람직함 예외에 대해서 별도의 처리를 해주지 않으면 JavaScript 콘솔에 표시됨. (콘솔에는 개발자가 별도의 출력을 할 수도 있음) 최신 브라우저 들은 콘솔 기능을 모두 제공함 Windows, Linux는 Ctrl + Shift + I 또는 F12 , Mac은 Cmd + Opt + I를 누르면 개발자 도구, 브라우저 콘솔이 열림 1.1 예외 발생 (Throwing Exceptions) throw 키워드를 이용해서 예외를 발생시킴 예외로 어떤 타입의 객체라도 전달이 가능하지만, 가능하다면 Error객체에 메세지를 포함시키는 것이 바람직함 #####Listing 7-1. Using the throw keyword123456789function errorsOnThree(input: number) &#123; if (input === 3) &#123; throw new Error('Three is not allowed'); &#125; return input;&#125;var result = errorsOnThree(3); Error 타입의 예외를 전달하는 예제인데, 사용자 정의 예외를 직접 구현하는 것도 가능합니다.toString() 메서드를 구현해주면 콘솔에 출력되는 정보를 보기 좋게 할 수 있습니다. #####Listing 7-2. Custom error1234567891011121314class ApplicationError implements Error &#123; public name = 'ApplicationError'; constructor(public message: string) &#123; if (typeof console != 'undefined') &#123; console.log('Creating ' + this.name + ' \"' + message + '\"'); &#125; &#125; toString() &#123; return this.name + ': ' + this.message; &#125;&#125; InputError 는 ApplicationError를 상속받아서 아무런 구현도 하지 않음 errorsOnThree 함수에서 잘못된 입력에 대해서 InputError를 발생 #####Listing 7-3. Using inheritance to create special exception types123456789101112131415161718192021class ApplicationError implements Error &#123; public name = 'ApplicationError'; constructor(public message: string) &#123; &#125; toString() &#123; return this.name + ': ' + this.message; &#125;&#125;class InputError extends ApplicationError &#123;&#125;function errorsOnThree(input: number) &#123; if (input == 3) &#123; throw new InputError('Three is not allowed'); &#125; return input;&#125; ApplicationError를 사용하지 않고 Error를 바로 발생시켜도 되지만, 우리가 작성한 코드에서의 오류를 모두 ApplicationError 또는 이것을 상속받은 오류만 발생시킬 경우 우리가 작성한 코드 이외의 곳에서 발생한 오류와 구분이 쉬워짐 1.2 예외 처리 (Exception Handling) 예외발생시 별도의 처리를 하지 않으면 프로그램이 종료됨 예외를 처리하기 위해서는 예외가 발생한 곳을 try-catch-finally 블록으로 감싸줘야 함 #####Listing 7-4. Unconditional catch block12345try &#123; var result = errorsOnThree(3);&#125; catch (err) &#123; console.log('Error caught, no action taken');&#125; 위 예제는 모든 종류의 예외에 대해서 처리를 하는 코드인데, 이런식의 처리는 좋은 방법이 아닙니다.우리가 예상가능하고 처리가능한 예외에 대해서만 처리를 하고 나머지 예외에 대해서는 다시 발생시키는 것이 더 올바른 방법입니다. #####Listing 7-5. Checking the type of error123456789try &#123; var result = errorsOnThree(3);&#125; catch (err) &#123; if (!(err instanceof ApplicationError)) &#123; throw err; &#125; console.log('Error caught, no action taken');&#125; 위 예제는 ApplicationError와 이 것을 상속받은 오류에 대해서만 처리를 하고 나머지에 대해서는 처리를 하지 않는 코드입니다. #####Figure 7-1. Error class hierarchy ApplicationError 대신 InputError에 대해서 처리하도록 했다면, 아래 그림과 같이 InputError, BelowMinError, AboveMaxError, InvalidLengthError에 대해서는 처리를 해주지만, 나머지에 대해서는 처리를 하지 않고 Call Stack에 오류를 전달하게 됩니다. #####Figure 7-2. Handling InputError exceptions ApplicationError에 대해서는 아래 7가지 오류에 대해서 처리를 해줍니다. #####Figure 7-3. Handling ApplicationError exceptions 로우레벨 관련 코드를 작업하는 경우에는 예외의 타입을 정확하게 분류하여 작업을 할 필요가 있지만, UI 작업과 같은 경우에는 좀더 일반적인 예외 종류에 대해서 처리를 하여도 무방합니다.예외는 성능 비용이 큰 편에 속하기 때문에 단순히 루프를 빠져나가기 위한 신호 같은 용도로 사용하는 것은 적절하지 않습니다. 2. 메모리 (Memory)TypeScript 같은 고차원 언어에서는 메모리 관리가 자동으로 됩니다.우리가 생성한 변수나 객체의 경우 범위를 넘어서 사용된다던지, 댕글링 포인트(dangling pointer)가 되지 않습니다.대부분의 메모리 관련 오류는 자동으로 처리되지만 Out of Memory같이 처리가 되지 않는 오류도 있습니다.이번 장에서는 어떻게 하면 그런 오류들을 피할 수 있을 것인지에 대해서 다뤄볼 예정입니다. 2.1 자원 해제 (Releasing Resources)타입스크립트에서는 관리되지 않는 자원을 사용할 경우가 있습니다.대부분의 API들은 작업이 완료되었을 경우 인자가 전달되는 비동기 패턴으로 되어 있습니다.센서에 가까이 있을 때 검출되는 API에 대한 사용 예제를 보도록 하겠습니다. #####Listing 7-6. Asynchronous pattern12345678var sensorChange = function (reading) &#123; var proximity = reading.near ? 'Near' : 'Far'; alert(proximity);&#125;window.addEventListener('userproximity', sensorChange, true); 비동기 패턴을 통해 근접 센서로부터 정보를 얻어 올수 있지만, 통신 채널을 통한 응답을 보장해 주지는 못합니다.오류가 발생할 경우에 대해서 대비하기 위해서 try-finally 블록을 이용해야 합니다. #####Listing 7-7. Imaginary unmanaged proximity sensor1234567891011121314151617181920var sensorChange = function (reading) &#123; var proximity = reading.near ? 'Near' : 'Far'; alert(proximity);&#125;var readProximity = function () &#123; var sensor = new ProximitySensor(); try &#123; sensor.open(); var reading = sensor.read(); sensorChange(reading); &#125; finally &#123; sensor.close(); &#125;&#125;window.setInterval(readProximity, 500); finally 블록을 통해서 sensor의 open, read, sensorChange 중 어디에서 오류가 발생하더라도 close가 호출되는 것을 보장해 주게 됩니다. 2.2 가비지 콜렉션 (Garbage Collection)메모리가 더 이상 사용되지 않을 경우 GC를 통해서 해제되게 됩니다.예전 방식의 브라우저의 경우 참조 카운트(Reference Count)가 0이 되었을 경우 해제를 하게 되는데,만약 2개의 객체가 서로 참조하는 경우에는 RC가 0이 되지 않아서 해제되지 않게 됩니다. #####Table 7-1. Reference counting garbage collection 최신의 브라우저의 경우에는 루트에 도달 가능한 모든 객체를 찾아낸 뒤, 나머지 객체에 대해서 마크앤스윕(mark-and-sweep) 알고리즘을 이용해서 해결합니다.GC 수행 시간은 더 걸릴 수 있지만, 메모리 누수의 발생 가능성을 줄여 줍니다. #####Figure 7-4. Mark and sweep Table 7-1과 Figure 7-4가 동일한 객체일 경우 RC를 사용하는 경우라면 E에 대해서만 해제를 하지만, MAS를 사용하는 경우라면 서로 참조하고 있는 A,B에 대해서도 해제가 가능합니다. 3. 성능 (Performance)개발자들이 별로 중요하지도 않은 성능과 효율 등에 대해 고려하는 경우가 많습니다.하지만 대부분의 경우(97%)는 고려하지 않아도 될만큼 효율이 작은 것입니다만,치명적인 부분(3%)에 대해서는 간과하면 안됩니다. 측정 가능한 성능 문제가 발견되기 전까지는 최적화를 하지 않는게 좋습니다.지역 변수는 객체의 속성보다 느리기 때문에 사용하지 말아야 한다는 주장이 있습니다.이 말이 사실일 수는 있지만, 프로그램 디자인을 지저분하게 할 여지가 있기 때문에 조심해야 합니다.최적화와 좋은 디자인은 트레이드-오프 관계에 있는 경우가 많기 때문에 신중하게 결정해야 합니다. TypeScript의 성능은 여러 브라우저에서 측정해봐야 합니다. 그렇지 않으면 특정 브라우저에서만 빠르고 다른 곳에서는 느려질 수도 있습니다. 아래 코드는 간단한 성능 테스트용입니다.CommunicationLines 클래스는 팀 구성원 들 사이의 의사 소통 라인 수를 N(N-1)/2 알고리즘을 이용해서 구합니다.testCommunicationLines 함수는 사이즈가 4, 10 인 경우에 대해서 계산하는 것으로 테스트 합니다. #####Listing 7-8. Calculating lines of communication12345678910111213141516171819202122class CommunicationLines &#123; calculate(teamSize: number) &#123; return (teamSize * (teamSize - 1)) / 2 &#125;&#125;function testCommunicationLines() &#123; var communicationLines = new CommunicationLines(); var result = communicationLines.calculate(4); if (result !== 6) &#123; throw new Error('Test failed for team size of 4.'); &#125; result = communicationLines.calculate(10); if (result !== 45) &#123; throw new Error('Test failed for team size of 10.'); &#125;&#125;testCommunicationLines(); 아래 코드는 함수와 실행 횟수를 인자로 받아서 성능을 테스트 해주는 클래스 입니다.performance.now()로 전달받은 함수를 감싸고 있습니다.기본적으로는 10,000번 실행을 해서 총 시간 및 평균 시간을 출력합니다. #####Listing 7-9. Performance.ts runner12345678910111213141516171819202122232425262728293031323334353637383940class Performance &#123; constructor(private func: Function, private iterations: number) &#123; &#125; private runTest() &#123; if (!performance) &#123; throw new Error('The performance.now() standard is not supported in this runtime.'); &#125; var errors: number[] = []; var testStart = performance.now(); for (var i = 0; i &lt; this.iterations; i++) &#123; try &#123; this.func(); &#125; catch (err) &#123; // Limit the number of errors logged if (errors.length &lt; 10) &#123; errors.push(i); &#125; &#125; &#125; var testTime = performance.now() - testStart; return &#123; errors: errors, totalRunTime: testTime, iterationAverageTime: (testTime / this.iterations) &#125;; &#125; static run(func: Function, iterations = 10000) &#123; var tester = new Performance(func, iterations); return tester.runTest(); &#125;&#125;export = Performance; 앞에서 작성한 CommunicationLines 클래스에 대한 성능 측정을 Performance로 성능 측정을 하는 것에 대한 예제 입니다. #####Listing 7-10. Running the performance test12345678910111213141516171819202122232425import perf = require('./performance');class CommunicationLines &#123; calculate(teamSize: number) &#123; return (teamSize * (teamSize - 1)) / 2 &#125;&#125;function testCommunicationLines() &#123; var communicationLines = new CommunicationLines(); var result = communicationLines.calculate(4); if (result !== 6) &#123; throw new Error('Test failed for team size of 4.'); &#125; result = communicationLines.calculate(10); if (result !== 45) &#123; throw new Error('Test failed for team size of 10.'); &#125;&#125;var result = perf.run(testCommunicationLines);console.log(result.totalRunTime + ' ms'); 위 테스트 결과가 2.73ms로 나왔습니다. (communicationLines.calculate()를 2만번 호출)이런식으로 테스트는 최적화 위치를 적절하게 찾는 것에 도움이 됩니다. 하지만 아래 코드와 같이 예외가 발생하게 된다면 전혀 다른 결과가 나옵니다. #####Listing 7-11. Running the performance test with exceptions1234567891011121314151617181920212223242526import perf = require('./performance');class CommunicationLines &#123; calculate(teamSize: number) &#123; return (teamSize * (teamSize - 1)) / 2 &#125;&#125;function testCommunicationLines() &#123; var communicationLines = new CommunicationLines(); var result = communicationLines.calculate(4); // This test will now fail if (result !== 7) &#123; throw new Error('Test failed for team size of 4.'); &#125; result = communicationLines.calculate(10); if (result !== 45) &#123; throw new Error('Test failed for team size of 10.'); &#125;&#125;var result = perf.run(testCommunicationLines);console.log(result.totalRunTime + ' ms'); 위 테스트 결과는 214.45ms 즉 78배나 더 느려졌습니다. 다양한 조건 및 실행회수로 테스트를 해 볼 수 있습니다. 다음 결과는 Performance 클래스를 통해 여러가지 다른 방법으로 구현했을 떄의 수치입니다. Iteration : 0.74ms Global variables: 0.80 ms (0.06 ms slower per iteration) Closures: 1.13 ms (0.39 ms slower per iteration) Properties: 1.48 ms (0.74 ms slower per iteration) 이렇듯 어떻게 구현하냐에 따라 실행결과가 각각 다르게 나타나기 때문에, 최적화를 하기 전에 이런식으로 측정을 해보고 결정을 하는 것이 좋습니다. Summary 중요한 3가지 점에 대해서 살펴보았는데, 이런 것을 잘 고려하면 좀 더 쉽게 지름길로 가듯 코드를 작성 할 수 있습니다. 예외 처리를 잘하면 프로그램이 비정상적으로 종료되는 현상을 방지할 수 있습니다.사용자 정의 예외를 작성하면 각각 오류에 대해서 구분을 할 수 있어서 도움이 되며,해결 가능한 예외만 catch절에서 처리해야 합니다. 요즘의 브라우저들은 mark-and-sweep 알고리즘을 이용하므로 순환 참조에 대한 메모리 누수는 신경을 쓸 필요가 없습니다.가비지 컬렉터에 대해서는 신경쓰지 않고 작업을 하면 됩니다만, 성능을 측정한다던지 가비지 컬랙터에 문제가 있는 경우에는 좀 더 작은 객체를 생성하는 것이 좋습니다. 최적화 작업을 하기전에는 반드시 성능측정을 하는 것이 좋습니다.여러 가지 환경에서의 성능을 측정한 뒤에 모든 상황에 대해서 고려하여 최적화 작업을 해야 합니다. Key Points throw로 모든 종류의 객체를 전달하는게 가능은 하지만, 되도록이면 사용자 지정 Error의 서브클래스를 사용하는 것이 좋습니다. try-catch-finally 블록으로 예외를 직접 처리할 수 있습니다. 특정 예외만 catch 블록으로 잡을 수는 없지만, 그 안에서 예외의 타입을 체크할 수 있습니다. 대부분의 API가 비동이 패턴이므로 try-finally 블록을 이용해서 자원을 관리하는게 좋습니다. 성능 최적화 작업을 할때는 코드 변경 전후에 대해서 수치적으로 측정을 하는게 좋습니다.","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://DevStarSJ.github.io/categories/JavaScript/"},{"name":"TypeScript","slug":"JavaScript/TypeScript","permalink":"http://DevStarSJ.github.io/categories/JavaScript/TypeScript/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://DevStarSJ.github.io/tags/JavaScript/"},{"name":"TypeScript","slug":"TypeScript","permalink":"http://DevStarSJ.github.io/tags/TypeScript/"}]},{"title":"C# Attribute 상속 후 override 할 경우 부모 값도 잘 가져오는지 확인","slug":"CSharp.AttributeInherit","date":"2016-08-09T17:00:00.000Z","updated":"2017-05-24T03:25:12.000Z","comments":true,"path":"2016/08/10/CSharp.AttributeInherit/","link":"","permalink":"http://DevStarSJ.github.io/2016/08/10/CSharp.AttributeInherit/","excerpt":"","text":"C# Attribute 상속 후 override 할 경우 부모 값도 잘 가져오는지 확인C# Attribute class 생성 및 사용, 상속시에 동작 등에 대해서 확인 가능한 예제코드 입니다. 코드 다운로드 : https://github.com/DevStarSJ/Study/tree/master/Blog/CSharp/AttributeInheritTest Step 1. Attribute 존재여부 검사AttributeInheritTest.01.cs12345678910111213141516171819202122232425262728293031323334353637383940using System;public class Test1Attribute : Attribute&#123; public int t1 &#123; get; set; &#125; public Test1Attribute(int t) &#123; t1 = t; &#125;&#125;public class Test2Attribute : Attribute&#123; public int t2 &#123; get; set; &#125; public Test2Attribute(int t) &#123; t2 = t; &#125;&#125;public class Parent&#123; [Test1(1)] [Test2(2)] public int id &#123; get; set; &#125;&#125;class Program&#123; static void Main(string[] args) &#123; var propertyInfo = typeof(Parent).GetProperty(nameof(Parent.id)); var attributes = Attribute.GetCustomAttributes(propertyInfo, true); foreach (var a in attributes) &#123; Console.WriteLine(a.GetType().ToString()); &#125; &#125;&#125; 12Test2AttributeTest1Attribute Step 2. Attribute 내부 값 사용하기foreach 내부만 수정 AttributeInheritTest.02.cs12345678910111213foreach (var a in attributes)&#123; Console.WriteLine(a.GetType().ToString()); if (a.GetType() == typeof(Test1Attribute)) &#123; Console.WriteLine((a as Test1Attribute).t1); &#125; else if (a.GetType() == typeof(Test2Attribute)) &#123; Console.WriteLine((a as Test2Attribute).t2); &#125;&#125; 1234Test2Attribute2Test1Attribute1 Step 3. 상속받은 후 Attribute 존재여부 검사 및 값 사용하기Child 정의 및 propertyInfo 생성 부분만 수정 AttributeInheritTest.03.cs12345public class Child : Parent&#123;&#125;var propertyInfo = typeof(Child).GetProperty(nameof(Child.id)); 1234Test2Attribute2Test1Attribute1 Step 4. 상속받은 후 property를 override한 후 Attribute 재정의재정의한 Attribute만 바뀌었고, 나머지는 부모의 것을 가져오는 것을 확인 할 수 있습니다. Parent의 id를 virtual처리 하였고, Child의 id를 override한 후 Test2Attribute만 재정의 하였습니다. AttributeInheritTest.04.cs123456789101112public class Parent&#123; [Test1(1)] [Test2(2)] public virtual int id &#123; get; set; &#125;&#125;public class Child : Parent&#123; [Test2(3)] public override int id &#123; get; set; &#125;&#125; 1234Test2Attribute3Test1Attribute1","categories":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/categories/C/"},{"name":"C#","slug":"C/C","permalink":"http://DevStarSJ.github.io/categories/C/C/"}],"tags":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/tags/C/"}]},{"title":"Jupyter notebook markdown에 내가 원하는 css 적용하기","slug":"Tips.JupyterNotebook.custom.css","date":"2016-08-07T15:00:00.000Z","updated":"2017-04-30T03:23:08.000Z","comments":true,"path":"2016/08/08/Tips.JupyterNotebook.custom.css/","link":"","permalink":"http://DevStarSJ.github.io/2016/08/08/Tips.JupyterNotebook.custom.css/","excerpt":"","text":"Jupyter notebook markdown에 내가 원하는 css 적용하기요즘 파이썬을 공부하는데 Jupyter notebook를 많이 사용합니다.파이썬 코드를 편집하고 실행시킬 수 있으며, 그 결과까지 함께 저장이 됩니다.그리고 마크다운 문서를 삽입할 수도 있어서 발표자료 작성 및 블로그 기록용으로도 좋습니다.하지만 딱 하나 걸리는게 있었습니다.바로 마크다운 렌더링 결과가 너무나도 안이쁩니다.파이썬 소스코드에 대한 syntax highlighting은 어느 정도 봐줄만 합니다. 이 화면을 렌더링 했더니… 말이 됩니까 ??? 분명 inline code로 처리했는데… 이거 티도 안납니다. 이거 역시 왜 이모양인지… 그래서 찾아봤습니다. css 수정을 통해서 해결이 가능한지 jupyter notebook markdown css 로 구글신님께 여쭤보니 custom.css파일을 특정 위치에 넣어라고 하시는데… 그런 위치가 없습니다. 12345from IPython.core.display import HTMLdef css_styling(): styles = open(\"./styles/custom.css\", \"r\").read() return HTML(styles)css_styling() 그냥 css 파일을 만들어서 위 문장을 Jupyter notebook에서 실행하면 된다고 하길래 해봤는데… 진짜로 됩니다.하지만, 기본적으로 설정된 css에서 해당 내용을 덮어버려서 적용이 되지 않습니다. Chrome에서 F12를 눌러서 적용된 css를 열어보니깐 죄다 먼저 선언된 .rendered_heml code때문에 아래에 제가 설정한 p code 부분의 내용들이 적용이 안됩니다.더군다나 기본적으로 설정된 css에서 너무나도 안이뻐서 저걸 건드리지 않고서는 내가 원하는 모양대로 만드는게 힘들어 보입니다.그래서 결국 그 css파일 자체를 고치기로 마음 먹었습니다.그럴려면 먼저 css 파일을 찾아야 겠죠 ? 난 벤자민이 아닌데… 위치가 좀 이상하긴 합니다만, 폴더 구조라던지 눈여겨 볼만한게 있어서 저 정보를 기초로 해서 찾아보았습니다.스크린샷에는 못담았는데, 다른 렌더링된 결과에 대해서 css를 열어보다가 style.min.css 파일을 찾을 수 있었습니다. 1C:\\Anaconda3\\Lib\\site-packages\\notebook\\static\\style 그러다 위의 위치에 style.min.css를 찾았습니다..rendered_html code로 검색해보니 Chrome에서 본것과 똑같은 정의가 나왔습니다. 1234567891011.rendered_html pre &#123; margin: 1em 2em;&#125;.rendered_html pre,.rendered_html code &#123; border: 0; background-color: #fff; color: #000; font-size: 100%; padding: 0px;&#125; 이 녀석들을 고쳐봐야 겠습니다.근데, 어떤 모양으로 고쳐야 이쁠까요 ?제가 스스로 뭔가 모양을 만드는건 솔직히 믿음이 안가서, 그냥 이쁜 모양의 블로그나 사이트들을 찾아나섰습니다. 요즘 업무때문에 자주 들어가는 ASP.NET Core 사이트 https://docs.asp.net/en/latest/tutorials/first-mvc-app/adding-view.html에 들어가서 F12를 눌러서 css를 까보았습니다. 1234567891011121314151617181920212223242526.rst-content tt.literal, .rst-content tt.literal, .rst-content code.literal &#123; color: #E74C3C;&#125;.rst-content tt, .rst-content tt, .rst-content code &#123; color: #000; padding: 2px 5px;&#125;code, .rst-content tt, .rst-content code &#123; white-space: nowrap; max-width: 100%; background: #fff; border: solid 1px #e1e4e5; font-size: 75%; padding: 0 5px; font-family: Consolas,\"Andale Mono WT\",\"Andale Mono\",\"Lucida Console\",\"Lucida Sans Typewriter\",\"DejaVu Sans Mono\",\"Bitstream Vera Sans Mono\",\"Liberation Mono\",\"Nimbus Mono L\",Monaco,\"Courier New\",Courier,monospace; color: #E74C3C; overflow-x: auto;&#125;pre, code, .rst-content tt, .rst-content code, kbd, samp &#123; font-family: monospace,serif; _font-family: \"courier new\",monospace; font-size: 1em;&#125; 위 내용들이 필요할듯하여 일단 가져왔습니다. 같은 방식으로 TypeScript 공식 사이트 https://www.typescriptlang.org/docs/tutorial.html에서도 css 내용을 가져왔으며, 12345.docs-container li code, .docs-container p code, .docs-container td code &#123; background-color: transparent; color: #bf414a; font-size: 1em;&#125; Pycon 2016의 Tutorial 신청페이지 https://www.pycon.kr/2016apac/program/tutorial/7에서도 가져왔습니다. 12345678910111213141516171819202122232425262728293031323334.label-info &#123; background-color: #5bc0de;&#125;.label &#123; display: inline; padding: .2em .6em .3em; font-size: 75%; font-weight: 700; line-height: 1; color: #fff; text-align: center; white-space: nowrap; vertical-align: baseline; border-radius: .25em;&#125;* &#123; font-family: 'Open Sans', 'Helvetica Neue', 'Apple SD Gothic Neo', 'Nanum Gothic', 'Arial', 'Apple Gothic', sans-serif; font-weight: 400; line-height: 172%; -webkit-font-smoothing: antialiased; -webkit-text-size-adjust: 100%; -moz-osx-font-smoothing: grayscale; text-rendering: geometricPrecision; -webkit-transition: background 0.2s; -moz-transition: background 0.2s; -o-transition: background 0.2s; transition: background 0.2s;&#125;* &#123; -webkit-box-sizing: border-box; -moz-box-sizing: border-box; box-sizing: border-box;&#125; 이제 고쳐서 제대로 동작하는지 확인해 보도록 하겠습니다.먼저 style.min.css 파일 원본을 잘 보관하도록 하겠습니다.style.min.original.css로 복사하였습니다.그리고 마음에 드는 모양으로 변경하였습니다. 1234567891011121314151617181920.rendered_html pre,.rendered_html code &#123; white-space: nowrap; /* border: 0; */ background: #fff; border: solid 1px #e1e4e5; font-family: Consolas,\"Andale Mono WT\",\"Andale Mono\",\"Lucida Console\",\"Lucida Sans Typewriter\",\"DejaVu Sans Mono\",\"Bitstream Vera Sans Mono\",\"Liberation Mono\",\"Nimbus Mono L\",Monaco,\"Courier New\",Courier,monospace; font-size: 75%; padding: 0 5px;&#125;p code &#123; color: #E74C3C; overflow-x: auto;&#125;blockquote &#123; background-color: #fcf2f2; border-color: #dFb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;&#125; 기존의 .rendered_html pre, .rendered_html code를 수정하고 p code와 blockquote를 추가하였습니다. Jupyter notebook을 종료했다가 다시 재가동해야지만 적용됩니다.아마 실행시 읽어서 계속해서 적용시키는 듯합니다.그럼 재 실행해서 화면을 보도록 하겠습니다. 먼가 바뀌기는 했는데, 좀 이상하네요. 선이라든지 글자 크기와 관계된 것은 .rendered_html pre, .rendered_html code에서 한번에 해주는 것보다는 따로따로 적용되도록 고쳐줘야 겠습니다.blockquote는 그대로 두고 위의 2개만 내용을 수정하였습니다. 12345678910111213.rendered_html pre,.rendered_html code &#123; font-family: Consolas,\"Andale Mono WT\",\"Andale Mono\",\"Lucida Console\",\"Lucida Sans Typewriter\",\"DejaVu Sans Mono\",\"Bitstream Vera Sans Mono\",\"Liberation Mono\",\"Nimbus Mono L\",Monaco,\"Courier New\",Courier,monospace;&#125;p code &#123; border: solid 1px #e1e4e5; white-space: nowrap; background: #fff; color: #E74C3C; padding: 0 5px; overflow-x: auto;&#125; 이정도만 되어도 기존의 렌더링보다는 훨씬더 마음에 드네요. 앞으로 시간을 두고 조금씩 이쁘게 꾸며봐야 겠습니다.","categories":[{"name":"Tips","slug":"Tips","permalink":"http://DevStarSJ.github.io/categories/Tips/"},{"name":"JupyterNotebook","slug":"Tips/JupyterNotebook","permalink":"http://DevStarSJ.github.io/categories/Tips/JupyterNotebook/"}],"tags":[{"name":"JupyterNotebook","slug":"JupyterNotebook","permalink":"http://DevStarSJ.github.io/tags/JupyterNotebook/"}]},{"title":"Data Science from Scratch","slug":"Python.DataScienceFromScratch","date":"2016-08-06T15:00:00.000Z","updated":"2017-04-30T03:28:19.000Z","comments":true,"path":"2016/08/07/Python.DataScienceFromScratch/","link":"","permalink":"http://DevStarSJ.github.io/2016/08/07/Python.DataScienceFromScratch/","excerpt":"","text":"Data Science from Scratch (밑바닥부터 시작하는 데이터 과학) 원서명 : Data Science from Scratch: First Principles with Python 지은이 : Joel Grus 원서 : http://shop.oreilly.com/product/0636920033400.do 번역서 : http://www.insightbook.co.kr/books/programming-insight 출판사 예제코드 : https://github.com/insight-book/data-science-from-scratch This posting is made in .ipynb, so the original file can be modified and executed in the Jupiter Notebook. Location : https://github.com/DevStarSJ/Study/blob/master/Blog/Python/DataScienceFromScratch 01. 들어가며 - 2016-08-07 03. 데이터 시각화 (Visualizing Data) - 2016-08-11 04. 선형 대수 (Linear Algebra) - 2016-08-19 05. 통계 (Statistics) - 2016-08-20 06. 확률 (Probability) - 2016-08-20 07. 가설과 추론 (Hypothesis and Inference) - 2016-08-31 08. 경사 하강법 (Gradient Descent) (미완성) - 2016-09-10","categories":[{"name":"Python","slug":"Python","permalink":"http://DevStarSJ.github.io/categories/Python/"},{"name":"DataScience","slug":"Python/DataScience","permalink":"http://DevStarSJ.github.io/categories/Python/DataScience/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://DevStarSJ.github.io/tags/Python/"},{"name":"DataScience","slug":"DataScience","permalink":"http://DevStarSJ.github.io/tags/DataScience/"}]},{"title":"Doing Math with Python","slug":"Python.DoingMathWithPython","date":"2016-07-08T15:00:00.000Z","updated":"2017-04-30T03:00:23.000Z","comments":true,"path":"2016/07/09/Python.DoingMathWithPython/","link":"","permalink":"http://DevStarSJ.github.io/2016/07/09/Python.DoingMathWithPython/","excerpt":"","text":"Doing Math with Python (파이썬으로 풀어보는 수학) 원서명 : Doing Math with Python: Use Programming to Explore Algebra, Statistics, Calculus, and More! (ISBN 9781593276409) 지은이 : 아미트 사하(Amit Saha) 원서 및 관련자료 : https://www.nostarch.com/doingmathwithpython 번역서 : http://www.acornpub.co.kr/book/doing-math-with-python This posting is made in .ipynb, so the original file can be modified and executed in the Jupiter Notebook. Location : https://github.com/DevStarSJ/Study/blob/master/Blog/Python/DoingMathWithPython 01. Working with Numbers (숫자, 연산) - 2016-07-09 02. Visualizing Data with Graphs (그래프로 데이터 가시화) - 2016-07-12 03. Describing Data with Statistics (통계값을 이용한 데이터 설명) - 2016-07-16 04. Algebra and Symbolic Math with SymPy (SymPy를 이용한 대수와 부호 수학) - 2016-07-18 05. Playing with Sets and Probability (집합과 확률) - 2016-07-24 06. Drawing Geometric Shapes and Fractals (기하학적 형상과 프랙탈 그리기) - 2016-07-28 07. Solving Calculus Problems (미적분 문제 풀기) - 2016-07-31","categories":[{"name":"Python","slug":"Python","permalink":"http://DevStarSJ.github.io/categories/Python/"},{"name":"DataScience","slug":"Python/DataScience","permalink":"http://DevStarSJ.github.io/categories/Python/DataScience/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://DevStarSJ.github.io/tags/Python/"},{"name":"DataScience","slug":"DataScience","permalink":"http://DevStarSJ.github.io/tags/DataScience/"}]},{"title":"Using async method in static constructor ( C# )","slug":"CSharp.StaticConstructorAsync","date":"2016-06-11T17:00:00.000Z","updated":"2017-05-24T03:25:12.000Z","comments":true,"path":"2016/06/12/CSharp.StaticConstructorAsync/","link":"","permalink":"http://DevStarSJ.github.io/2016/06/12/CSharp.StaticConstructorAsync/","excerpt":"","text":"Using async method in static constructor ( C# )static constructor 내부에서 async 함수를 호출할 경우 제대로 동작을 하지 않습니다.(왠만해서는 이런식으로 code가 이루어지지 않도록 해야하지만, 어쩔수 없이 이렇게 사용해야 할 경우가 발생 할 수 있습니다.) 참고로 static constructor는 해당 class가 가장 먼저 사용 될 때 실행됩니다. CLR-internal lockstatic constructor는 정확히 1번만 실행되어야 합니다.그러므로 static constructor가 실행될 때는 내부적으로 CLR-internal lock으로 해당 code를 1번만 실행되도록 수행합니다.이렇게 lock이 걸린 상태에서 async를 이용하여 다른 thread로 작업을 수행할 경우 thread-lock과 CLR-internal lock간의 deadlock이 발생해서 안된다고 생각 할 수 있습니다. http://blogs.msdn.com/b/pfxteam/archive/2011/05/03/10159682.aspx 링크의 posting을 보면 설명이 되어 있습니다. http://blog.stephencleary.com/2013/01/async-oop-2-constructors.html 링크의 posting에도 절대로 static constructor에서 async 작업을 하는 건 BAD CODE!!!라고 경고하고 있습니다. 참고로 위 Link에 있는 posting에서 안된다고 하는 예제들을 만들어서 해보면 잘 됩니다.진짜로 async 한 작업 (DB, Network, disk I/O) 을 이용하는 경우에는 안 될 수 있지만, 단순히 async 키워드만 붙였다고 해서 deadlock이 재현되지는 않습니다. 내가 상상하는 안되는 이유…위 내용들은 어느정도 검증(?)된 posting을 바탕으로 한 내용이구요.제가 생각했을 때 안되는 이유를 말씀드리겠습니다.어디까지나 혼자만의 상상의 나래로 기록한 썰(?)이지, 검증된 내용은 아닙니다. constructor라 함은 object가 생성될때 가장 먼저 해줘야 하는 작업입니다.static constructor는 해당 class의 static properties, method들이 사용되기 전에 먼저 실행되어야 할 code들을 모아둔 곳이어야 겠죠.C++98까지의 modern하지 않은 C++에서는 member variable (C# 의 properties) 들을 초기화 하는 작업을 constructor에서 했습니다.C++11 에서는 C# 과 같이 선언과 동시에 초기값를 바로 써 줄 수 있지만, 아마 동작은 constuctor실행시 할 거라 생각됩니다.C# 도 편의상 선언과 동시에 초기값을 써 줄 수는 있지만, 아마 동작은 constuctor 수행시 할 거라 생각됩니다. static constuctor는 해당 class의 static method보다 먼저 수행되어야 할 code라는 썰을 전제로 생각해 본다면,그럼 static constructor에서 다른 static method를 호출하면 어떻게 될까요 ???아마 그 시점에 해당 static method의 code를 실행가능 하도록 해주지 않을까 예상됩니다.(memory에 load한다던지, 아니면 다른 방법으로 실행가능하게 뭔가 조치를 해주겠죠.)이게 동일 thread 내에서는 당연히 판단이 가능하여서 아무런 문제가 없이 동작하지만,static constructor가 수행중이고 아직 완료되지 않은 시점에,갑자기 다른 thread가 해당 class의 다른 static method에 접근을 할 경우에는 어떻게 해야 할까요 ?아마 static constructor가 수행중이니 CLR-internal lock으로 보호되고 있겠지요 ?이 lock은 static constructor가 수행을 종료해야 풀리겠구요.그런데 그 다른 thread가 static method를 수행완료해야만 static constructor가 종료될 수 있다면 ???여기서 dead lock이 발생할 것입니다.동일 thread 내에서는 CLR-internal lock 내부에서 수행이 되도록 잘 설계 했습니다.당연히 다른 thread에서 접근은 lock으로 보호해야하는 건 맞구요.하지만, 해당 thread가 종료되길 기다리는게 static constructor인 경우에는 ??? 그래서 아래에 제가 적어놓은 해결 방법 중에,static constructor에서 자신의 class가 아닌 다른 class의 async 작업을 기다리는 경우는 잘 동작합니다.이것을 이용해서 async한 작업을 별도 class로 나누면 역시나 잘 동작합니다. Deadlock in async method in static constuctor강제로 deadlock을 발생시키는 code를 만들어 보았습니다. 123456789101112131415161718192021222324252627282930313233using System.Collections.Generic;using System.Threading.Tasks;class StaticClass&#123; public static IEnumerable&lt;string&gt; Names &#123; set; get; &#125; static StaticClass() &#123; Names = Task.Run(async () =&gt; &#123; return await GetNamesAsync(); &#125;).Result; &#125; public static async Task&lt;IEnumerable&lt;string&gt;&gt; GetNamesAsync() &#123; List&lt;string&gt; nameList = new List&lt;string&gt; &#123; \"Luna\", \"Star\", \"Philip\" &#125;; return nameList; &#125;&#125;class Program&#123; static void Main(string[] args) &#123; foreach (string name in StaticClass.Names) &#123; System.Console.WriteLine(name); &#125; &#125;&#125; 이런 code를 어떻게 고쳐야 하는지 3가지 방법을 살펴보겠습니다. 1. async한 구현의 method를 추가위 예제의 경우 GetNamesAsync() method와 같은 기능을 하는 sync한 method인 GetNames()를 추가하는 방법이 있습니다.동일한 구현이 2개가 되므로 별로 추천드리는 방법은 아닙니다. 참고로 아래 예제도 썩 그렇게 좋은 예제코드는 아닙니다. 12345678910111213141516171819202122232425262728293031323334353637383940414243using System.Collections.Generic;using System.Threading.Tasks;class StaticClass&#123; public static IEnumerable&lt;string&gt; Names &#123; set; get; &#125; static StaticClass() &#123; Names = GetNames(); &#125; public static async Task&lt;IEnumerable&lt;string&gt;&gt; GetNamesAsync() &#123; List&lt;string&gt; nameList = new List&lt;string&gt; &#123; \"Luna\", \"Star\", \"Philip\" &#125;; return nameList; &#125; public static IEnumerable&lt;string&gt; GetNames() &#123; List&lt;string&gt; nameList = new List&lt;string&gt; &#123; \"Luna\", \"Star\", \"Philip\" &#125;; return nameList; &#125;&#125;class Program&#123; static void Main(string[] args) &#123; foreach (string name in StaticClass.Names) &#123; System.Console.WriteLine(name); &#125; &#125;&#125; 하지만 sync한 작업으로 구현 자체가 될 것을 굳이 async로 선언할 일은 잘 없습니다.그러므로 이렇게 해결될 수 있는 일이라면 애초에 async로 구현한거 자체가 제대로 된 설계가 아닐 수 있습니다. 2. async 작업을 별도 class로 분리 (또는 async 작업 호출을 별도 class로 제한)async 작업을 별도 class로 분리하거나,static constructor에서 호출하는 async 작업을 다른 class의 method로 제한하는 방법이 있습니다.이렇게 구현할 경우 원래 class에서 sync한 구현과 async한 구현이 모두 필요할 경우 1번과 같은 code 모양이 될 경우가 많습니다.static constructor에서 호출하는 async method가 다른 class의 method일 경우에는 deadlock이 걸리지 않았습니다. 1234567891011121314151617181920212223242526272829303132333435363738394041using System.Collections.Generic;using System.Threading.Tasks;class StaticClass&#123; public static IEnumerable&lt;string&gt; Names &#123; set; get; &#125; static StaticClass() &#123; Names = GetNames(); &#125; public static IEnumerable&lt;string&gt; GetNames() &#123; return Task.Run(async () =&gt; &#123; return await AsyncClass.GetNamesAsync(); &#125;).Result; ; &#125;&#125;class AsyncClass&#123; public static async Task&lt;IEnumerable&lt;string&gt;&gt; GetNamesAsync() &#123; List&lt;string&gt; nameList = new List&lt;string&gt; &#123; \"Luna\", \"Star\", \"Philip\" &#125;; return nameList; &#125;&#125;class Program&#123; static void Main(string[] args) &#123; foreach (string name in StaticClass.Names) &#123; System.Console.WriteLine(name); &#125; &#125;&#125; 3. 초기화 작업을 별도 Init method로 분리개인적으로 이 방법이 가장 깔끔해 보입니다.해당 class가 사용되기 전에 Init()을 호출한 뒤에 사용하면 됩니다.Init()함수가 호출되기 전에 이미 해당 class의 static constructor가 실행된 상태이기 때문에 CLR-internal lock은 이미 unlcok된 상태에서 async작업을 수행하게 됩니다.하지만 여러 thread에서 Init() 함수가 호출될 가능성이 있을 경우에는 사용자가 별도로 lock을 걸어서 호출을 해야 합니다.해당 기능은 clsss가 최초로 사용되기 이전 시점의 아무 곳에서나 호출이 가능하므로, lock이 필요없는 적당한 시점에 호출시켜 주는 것이 좋습니다. 123456789101112131415161718192021222324252627282930313233343536373839using System.Collections.Generic;using System.Threading.Tasks;class StaticClass&#123; public static IEnumerable&lt;string&gt; Names &#123; set; get; &#125; static StaticClass() &#123; ... &#125; public static void Init() &#123; Names = Task.Run(async () =&gt; &#123; return await GetNamesAsync(); &#125;).Result; &#125; public static async Task&lt;IEnumerable&lt;string&gt;&gt; GetNamesAsync() &#123; List&lt;string&gt; nameList = new List&lt;string&gt; &#123; \"Luna\", \"Star\", \"Philip\" &#125;; return nameList; &#125;&#125;class Program&#123; static void Main(string[] args) &#123; StaticClass.Init(); foreach (string name in StaticClass.Names) &#123; System.Console.WriteLine(name); &#125; &#125;&#125;","categories":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/categories/C/"},{"name":"C#","slug":"C/C","permalink":"http://DevStarSJ.github.io/categories/C/C/"}],"tags":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/tags/C/"}]},{"title":"Newtonsoft.Json 사용법","slug":"CSharp.NewtonJSON","date":"2016-06-11T17:00:00.000Z","updated":"2017-05-24T03:25:12.000Z","comments":true,"path":"2016/06/12/CSharp.NewtonJSON/","link":"","permalink":"http://DevStarSJ.github.io/2016/06/12/CSharp.NewtonJSON/","excerpt":"","text":"Newtonsoft.Json 사용법C# 에서 JSON document를 다루기 위해 가장 많이 사용되는 것은 Newtonsoft.Json입니다.nuget manager에서 JSON으로 검색시 가장 먼저 나옵니다.그만큼 많이 사용되며, 사용법 또한 간단합니다. ##1. 설치 및 namespace 솔루션 탐색기 (Solution Explorer)에서 마우스 우클릭 하신뒤 Manage nuget packages...을 누르셔서 Browse 탭에서 Newtonsoft.Json을 검색하셔서 Install을 누르면 됩니다. 다른 방법으로는 도구(Tools) -&gt; Nuget package manager -&gt; Package Manager Console 로 가셔서 아래와 같이 입력하시면 됩니다. 1PM&gt; Install-Package Newtonsoft.Json 사용시 소스코드에서 아래의 namespace를 추가해 주시면 됩니다. 1using Newtonsoft.Json.Linq; 2. 간단한 특징 설명2개의 Object를 이용해서 사용하시면 됩니다. JObject : JSON Object 입니다. JObject 자체가 name값을 가질 수는 없습니다. (key, value) pair 들을 가질 수 있습니다. key : string 값입니다. value : JToken 타입이며 대부분의 premitive type들과 DateTime, TiemSpan, Uri 값을 직접대입 가능하며, 기타 Object도 입력이 가능합니다. value에 다른 JObject나, JArray를 넣을 수 있습니다. JArray : JSON Array 입니다. JObject와 특징이 거의 비슷하나 key 없이 value 들을 가지고 있습니다. 즉, JObject나 Jarray 자체는 name을 가질 수 없으나, 다른 JObject에 value로 소속될 경우에는 key값을 가져야 하며, 다른 JArray에 소속될 경우에는 key값 없이 입력됩니다 3. JObject 사용법너무나 간단하기 때문에 별도 설명은 필요 없을듯 합니다. 생성 : new JObject() Element 추가 : .add(key, value) 바로 예제를 보도록 하겠습니다. 3.1 Element 추가3.1.1 기본적인 사용법123456var json = new JObject();json.Add(\"id\", \"Luna\");json.Add(\"name\", \"Silver\");json.Add(\"age\", 19);Console.WriteLine(json.ToString()); 12345&#123; \"id\": \"Luna\", \"name\": \"Silver\", \"age\": 19&#125; 3.1.2 JSON 형식의 문자열로 생성1234var json2 = JObject.Parse(\"&#123; id : \\\"Luna\\\" , name : \\\"Silver\\\" , age : 19 &#125;\");json2.Add(\"blog\", \"devluna.blogspot.kr\");Console.WriteLine(json2.ToString()); 123456&#123; \"id\": \"Luna\", \"name\": \"Silver\", \"age\": 19, \"blog\": \"devluna.blogspot.kr\"&#125; 3.1.3 다른 class Object로부터 생성1234User u = new User &#123; id = \"SJ\", name = \"Philip\", age = 25 &#125;;var json3 = JObject.FromObject(u);Console.WriteLine(json3.ToString()); 12345&#123; \"id\": \"SJ\", \"name\": \"Philip\", \"age\": 25&#125; 3.1.4 무명형식으로 생성123var json4 = JObject.FromObject(new &#123; id = \"J01\", name = \"June\", age = 23 &#125;);Console.WriteLine(json4.ToString()); 12345&#123; \"id\": \"J01\", \"name\": \"June\", \"age\": 23&#125; 3.1.5 다른 JObject를 Element로 추가1234567var json5 = JObject.Parse(\"&#123; id : \\\"sjy\\\" , name : \\\"seok-joon\\\" , age : 27 &#125;\");json5.Add(\"friend1\", json);json5.Add(\"friend2\", json2);json5.Add(\"friend3\", json3);json5.Add(\"friend4\", json4);Console.WriteLine(json5.ToString()); 1234567891011121314151617181920212223242526&#123; \"id\": \"sjy\", \"name\": \"seok-joon\", \"age\": 27, \"friend1\": &#123; \"id\": \"Luna\", \"name\": \"Silver\", \"age\": 19 &#125;, \"friend2\": &#123; \"id\": \"Luna\", \"name\": \"Silver\", \"age\": 19, \"blog\": \"devluna.blogspot.kr\" &#125;, \"friend3\": &#123; \"id\": \"SJ\", \"name\": \"Philip\", \"age\": 25 &#125;, \"friend4\": &#123; \"id\": \"J01\", \"name\": \"June\", \"age\": 23 &#125;&#125; 3.2 Element값 사용하기3.2.1 Element값 읽기[ ] 연산자에 key값을 넣어주면 해당 value를 얻을 수 있습니다. 123var json4_name = json4[\"name\"];Console.WriteLine(json4_name); 1June 3.2.2 Element값 삭제하기.Remove(key)를 이용해서 삭제가 가능합니다. 123json4.Remove(\"name\");Console.WriteLine(json4.ToString()); 1234&#123; \"id\": \"J01\", \"age\": 23&#125; .RemoveAll()로 모든 Element를 다 삭제 할 수도 있습니다. 123json5.RemoveAll();Console.WriteLine(json5.ToString()); 1&#123;&#125; 4. JArray 사용법Element 입력시 key를 가지지 않는 다는 것을 빼고는 JObject와 거의 같습니다. 4.1 Element 추가하기4.1.1 기본적인 사용법123456var jarray = new JArray();jarray.Add(1);jarray.Add(\"Luna\");jarray.Add(DateTime.Now);Console.WriteLine(jarray.ToString()); 12345[ 1, \"Luna\", \"2016-05-21T09:45:27.1049839+09:00\"] 4.1.2 JObject를 Element로 추가1234567var jFriends = new JArray();jFriends.Add(json);jFriends.Add(json2);jFriends.Add(json3);jFriends.Add(json4);Console.WriteLine(jFriends.ToString()); 12345678910111213141516171819202122[ &#123; \"id\": \"Luna\", \"name\": \"Silver\", \"age\": 19 &#125;, &#123; \"id\": \"Luna\", \"name\": \"Silver\", \"age\": 19, \"blog\": \"devluna.blogspot.kr\" &#125;, &#123; \"id\": \"SJ\", \"name\": \"Philip\", \"age\": 25 &#125;, &#123; \"id\": \"J01\", \"age\": 23 &#125;] 4.1.3 JArray를 Element로 추가12345var jarray2 = new JArray();jarray2.Add(jarray);jarray2.Add(jFriends);Console.WriteLine(jarray2.ToString()); 1234567891011121314151617181920212223242526272829[ [ 1, \"Luna\", \"2016-05-21T09:51:03.2882071+09:00\" ], [ &#123; \"id\": \"Luna\", \"name\": \"Silver\", \"age\": 19 &#125;, &#123; \"id\": \"Luna\", \"name\": \"Silver\", \"age\": 19, \"blog\": \"devluna.blogspot.kr\" &#125;, &#123; \"id\": \"SJ\", \"name\": \"Philip\", \"age\": 25 &#125;, &#123; \"id\": \"J01\", \"age\": 23 &#125; ]] 4.2 Element값 사용하기4.2.1 Element값 읽기[ ] 연산자로 읽을 수 있습니다. 123var jf0 = jFriends[0];Console.WriteLine(jf0.ToString()); 12345&#123; \"id\": \"Luna\", \"name\": \"Silver\", \"age\": 19&#125; for , foreach로 iteration이 가능합니다.12345foreach(JObject fElement in jFriends)&#123; var fName = fElement[\"name\"] ?? \"&lt;NULL&gt;\"; Console.WriteLine(fName);&#125; 1234SilverSilverPhilip&lt;NULL&gt; 4.2.2 Element값 삭제하기1234jFriends.Remove(jFriends[1]);jFriends.Remove(jFriends[2]);Console.WriteLine(jFriends.ToString()); 123456789101112[ &#123; \"id\": \"Luna\", \"name\": \"Silver\", \"age\": 19 &#125;, &#123; \"id\": \"SJ\", \"name\": \"Philip\", \"age\": 25 &#125;] 5. JObject에 JArray 추가하기123json2.Add(\"Friends\", jFriends);Console.WriteLine(json2.ToString()); 123456789101112131415161718&#123; \"id\": \"Luna\", \"name\": \"Silver\", \"age\": 19, \"blog\": \"devluna.blogspot.kr\", \"Friends\": [ &#123; \"id\": \"Luna\", \"name\": \"Silver\", \"age\": 19 &#125;, &#123; \"id\": \"SJ\", \"name\": \"Philip\", \"age\": 25 &#125; ]&#125;","categories":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/categories/C/"},{"name":"C#","slug":"C/C","permalink":"http://DevStarSJ.github.io/categories/C/C/"}],"tags":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/tags/C/"}]},{"title":"Entity Framework Code First (Table 생성 및 수정)","slug":"CSharp.EF.CodeFirst","date":"2016-06-11T17:00:00.000Z","updated":"2017-05-24T03:25:12.000Z","comments":true,"path":"2016/06/12/CSharp.EF.CodeFirst/","link":"","permalink":"http://DevStarSJ.github.io/2016/06/12/CSharp.EF.CodeFirst/","excerpt":"","text":"Entity Framework Code First (Table 생성 및 수정)Code First란 ?전통적인 방식의 경우 SQL을 이용하여 Database에 Table을 생성한 다음 Application에서 개발을 시작합니다.Code First방식이란 Domain Class의 명세를 이용하여 Application 실행 시 해당 Table이 없는 경우 자동으로 생성을 해주는 방식을 말합니다. Entity Framework 4.1 이후부터 지원해주는 방식이며, Domain Driven Design의 경우 유용합니다. http://www.entityframeworktutorial.net/code-first/what-is-code-first.aspx . Modify Models after Scaffolding Code First 실습1. Project 생성 및 Entity Framework 설치 Visual Studio에서 C# Console Application Project를 하나 생성합니다. Nuget Package Manager를 실행합니다. (아래 방법 중 하나로 실행이 가능합니다.) Solution Explorer에서 Project에서 우클릭하여 Manage Nuget Packages... 상단 Menu에서 Tools -&gt; Nuget Package Manager -&gt; Manage Nuget Packages for Solution... EntityFramework를 검색하여 설치합니다. (4.1 이후 버전으로 설치합니다. 이 Post를 작성할 당시 6.1.3 버전이 최신입니다.) 2. Domain Model 정의아래와 같이 School 과 Standard라는 2개의 Domain Model을 정의합니다. 12345678910111213141516171819class Student&#123; public int StudentID &#123; get; set; &#125; public string StudentName &#123; get; set; &#125; public DateTime? DateOfBirth &#123; get; set; &#125; public byte[] Photo &#123; get; set; &#125; public decimal Height &#123; get; set; &#125; public float Weight &#123; get; set; &#125; public Standard Standard &#123; get; set; &#125;&#125;class Standard&#123; public int StandardID &#123; get; set; &#125; public string StandardName &#123; get; set; &#125; public ICollection&lt;Student&gt; Students &#123; get; set; &#125;&#125; School은 Standard의 참조를 가지고 있으며, Standard는 School의 집합을 가지고 있습니다. 3. Entity Framework Context 정의1using System.Data.Entity; DbContext를 사용하기 위해서는 System.Data.Entity를 using해주면 편합니다. 12345class SchoolContext : DbContext&#123; public DbSet&lt;Student&gt; Students &#123; get; set; &#125; public DbSet&lt;Standard&gt; Standards &#123; get; set; &#125;&#125; 2개의 Domain Model을 DbSet Property로 정의합니다. 특정 Database로의 접근을 원할 경우 DbContext의 생성자로 Connection String를 전달하도록 생성자를 정의해주면 됩니다.Console Application Project에서 default일 경우 Visual Studio와 함께 설치된 LocalDB로 연결 됩니다. 4. Context 실행12345678910111213class Program&#123; static void Main(string[] args) &#123; using (var context = new SchoolContext()) &#123; Student s = new Student() &#123; StudentName = \"New Student\" &#125;; context.Students.Add(s); context.SaveChanges(); &#125; &#125;&#125; Database에 따로 Table을 생성하지 않고 위 Code를 실행하면 자동으로 Table이 생성됩니다. 그림에서 확인되는 것을 보면 Standard에는 Student에 대한 항목이 없으며,Student에는 Standard_StandardID라는 Foreign Key가 추가 된 것이 확인됩니다. 개발 또는 운영 중 새로운 Table이 추가 될 경우에는 Domain Model을 선언하고 Context의 DbSet Property를 선언해주면 됩니다. Change Models after Scaffolding1. Domain Model 수정먼저 Teacher Model을 추가한 뒤, 12345class Teacher&#123; public int TeacherID &#123; get; set; &#125; public string TeacherName &#123; get; set; &#125;&#125; Student에 Teacher의 참조를 추가합니다. 123456789101112class Student&#123; public int StudentID &#123; get; set; &#125; public string StudentName &#123; get; set; &#125; public DateTime? DateOfBirth &#123; get; set; &#125; public byte[] Photo &#123; get; set; &#125; public decimal Height &#123; get; set; &#125; public float Weight &#123; get; set; &#125; public Standard Standard &#123; get; set; &#125; public Teacher Teacher &#123; get; set; &#125;&#125; 2. Context 실행F5를 눌러서 실행을 하면 오류가 발생합니다. Domain Model의 새로운 Property가 추가될 경우에는 오류가 발생합니다.(Table 입장에서는 Column이 추가되어야 할 경우) 이 경우에는 Migration 이라는 작업을 따로 해 줘야 합니다. 여러 가지 방법이 존재합니다. Package Manager Console에서 Enable-Migrations 명령어를 이용 Connection String에서 Database name을 변경 Entity Framework에서 Database Initializer를 사용 위 방법 중 3번 방법이 가장 편하므로, 해당 방법만 설명 드리겠습니다. 나머지 방법에 대해서는 아래 Posting을 참조하시기 바랍니다.https://blogs.msdn.microsoft.com/webdev/2013/11/01/tips-when-making-changes-in-entity-framework-code-first-models-after-scaffolding 3. Database Initializer 선언1234567class SchoolInitializer : DropCreateDatabaseIfModelChanges&lt;SchoolContext&gt;&#123; protected override void Seed(SchoolContext context) &#123; base.Seed(context); &#125;&#125; 별도의 작업이 필요한 경우 Seed() 안에서 정의를 해주면 됩니다.현재는 별 다른 작업이 필요 없으므로 Seed()를 Override하지 않고 삭제해도 됩니다. 4. Database Initializer 실행Application 실행시 Database Initializer를 먼저 실행시켜 주면 오류 없이 Table이 수정됩니다.심지어 DbSet Property에 Teacher를 추가하지 않았는데도 불구하고 Teacher Table이 추가되었습니다. 123456789101112131415class Program&#123; static void Main(string[] args) &#123; Database.SetInitializer&lt;SchoolContext&gt;(new SchoolInitializer()); using (var context = new SchoolContext()) &#123; Student s = new Student() &#123; StudentName = \"New Student\" &#125;; context.Students.Add(s); context.SaveChanges(); &#125; &#125;&#125; 일단 오류없이 실행은 되었습니다.Database를 확인해 보면 Table 정보가 수정된 것을 볼 수 있습니다.","categories":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/categories/C/"},{"name":"C#","slug":"C/C","permalink":"http://DevStarSJ.github.io/categories/C/C/"}],"tags":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/tags/C/"}]},{"title":"Chapter 3 Object Orientation in TypeScript","slug":"TypeScript.03.ObjectOrientationInTypeScript","date":"2016-06-10T15:00:00.000Z","updated":"2017-04-23T09:45:30.000Z","comments":true,"path":"2016/06/11/TypeScript.03.ObjectOrientationInTypeScript/","link":"","permalink":"http://DevStarSJ.github.io/2016/06/11/TypeScript.03.ObjectOrientationInTypeScript/","excerpt":"","text":"Chapter 3 Object Orientation in TypeScript 소프트웨어를 디자인하는 방법 2가지가 있습니다.하나는 간단하게 만들어서 명백하게 결함을 없게하는 것이고,다른 방법은 복잡하게 만들어서 병백한 결함을 없게하는 것입니다.전자가 조금 더 어렵습니다. 그것은 마치 복잡한 자연의 섭리와 같은 기술, 헌신, 통찰력, 영감 등을 요구합니다. Tony Hoare 객체지향 프로그래밍은 현실 세계와 유사하게 데이터와 관련된 행위를 코드로 표현합니다.이것을 보통 변수(property)와 함수(method)를 포함하는 클래스(class)로 표현하고 있으며,해당 클래스로부터 객체(object)를 생성합니다. https://en.wikipedia.org/wiki/Object-oriented_programming https://ko.wikipedia.org/wiki/객체_지향_프로그래밍 Obejct Orientation in TypeScript타입스크립트는 다양한 OOP 개념들을 지원하고 있습니다. 클래스(Classes) 객체(Instance of classes) 함수(Methods) 상속(Inheritance) : https://en.wikipedia.org/wiki/Inheritance_(object-oriented_programming) 열린 재귀(Open recursion) : https://en.wikipedia.org/wiki/This_(computer_programming)#Open_recursion 캡슐화(Encapsulation) : https://en.wikipedia.org/wiki/Encapsulation_(computer_programming) 위임(Delegation) : https://en.wikipedia.org/wiki/Delegation_(computing) 다형성(Polymophism) : https://en.wikipedia.org/wiki/Polymorphism_(computer_science) Classes, Instace of classes, Methods, Inheritacne는 Chapter.01에서 이미 살펴보았습니다. 열린 재귀(Open Recursion)열린 재귀란 재귀의 조합과 늦은 바인딩입니다.클래스 내에서 메서드가 자기자신을 호출한 경우, 서브클래스에 정의된 함수를 호출 할 수도 있습니다.그냥 함수 override를 설명하는 개념인 것 같습니다.List 3-1은 디렉토리의 내용을 읽는 클레스입니다.FileReader 클래스는 입력받은 경로에서 내용들을 읽습니다.모든 파일은 파일트리에 추가되지만, 디렉토리에 대해서는 this.getFiles를 재귀적으로 호출합니다.이러한 재귀호출은 모든 하위 경로내의 파일들을 추가할때 까지 계속됩니다.fs.readdirSync와 fs.statSync 메서드는 NodeJS에 있는 것 입니다. List 3-1 Open Recursion1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253interface FileItem &#123; path: string; contents: string[];&#125;class FileReader &#123; getFiles(path: string, depth: number = 0) &#123; var fileTree = []; var files = fs.readdirSync(path); for (var i = 0; i &lt; files.length; i++) &#123; var file = files[i]; var stats = fs.statSync(file); var fileItem; if (stats.isDirectory()) &#123; // Add directory and contents fileItem = &#123; path: file, contents: this.getFiles(file, (depth + 1)) &#125;; &#125; else &#123; // Add file fileItem = &#123; path: file, contents: [] &#125;; &#125; fileTree.push(fileItem); &#125; return fileTree; &#125;&#125;class LimitedFileReader extends FileReader &#123; constructor(public maxDepth: number) &#123; super(); &#125; getFiles(path: string, depth = 0) &#123; if (depth &gt; this.maxDepth) &#123; return []; &#125; return super.getFiles(path, depth); &#125;&#125;// instatiating an instance of LimitedFileReadervar fileReader = new LimitedFileReader(1);// results in only the top level, and one additional level being readvar files = fileReader.getFiles('path'); 예제에서는 간단한 Sync 함수를 사용했지만,실제로 구현할때에는 readdir, stat와 같이 콜백함수를 사용하는 것이 좋습니다. LimitedFileReader는 FieReader의 서브클레스입니다.LimitedFileReader의 객체를 생성할 때 클레스에 표시되는 파일 트리의 깊이를 지정해야 합니다.이 예제에서는 this.getFiles를 열린재귀로 어떻게 호출하는가를 보여줍니다.FileReader로 객체를 생성한 경우 this.getFiles는 단순한 일반적인 재귀호출이 됩니다만,LimitedFileReader로 인스턴스를 생성한 경우 FileReader.getFiles 메서드 내에서 thid.getFiles는 LimitedFileReader.getFiles를 호출하게 됩니다. 열린재귀는 부모클래스를 변경하지 할 필요도 없고, 서브클래스에 대한 사항을 몰라도 된다는 점입니다.서브클래스는 부모클래스의 코드를 재사용하기 위해서 코드를 중복적으로 작성할 필요가 없습니다. 캡슐화(Encapsulation)타입스크립트는 캡슐화를 완벽히 지원합니다.클래스 객체는 변수과 함수를 가지고 있으며, private 제한자를 이용해 외부로부터 숨길 수 있습니다.캡슐화란 데이터를 숨겨서 외부에서 해당 데이터에 대한 접근을 방지하는 것을 말합니다. List 3-2의 예를 보면 Totalizer 클래스의 경우 private으로 total 변수를 가지고 있어서 외부에서는 수정을 할 수 없습니다.수정하기 위해서는 클래스내에 선언된 함수 호출로 가능합니다.이런 점은 다음의 위험을 제거합니다. taxRebate를 추가하지 않으면서 amount를 추가하는 외부 코드 amount가 0보다 크지 않은 경우 코드 여러곳에서 호출되는 taxRebate 계산 코드 여러곳에 나타는 taxRateFactor List 3-2 Encapsulation12345678910111213141516171819202122232425class Totalizer &#123; private total = 0; private taxRateFactor = 0.2; addDonation(amount: number) &#123; if (amount &lt;= 0) &#123; throw new Error('Donation exception'); &#125; var taxRebate = amount * this.taxRateFactor; var totalDonation = amount + taxRebate; this.total += totalDonation; &#125; getAmountRaised() &#123; return this.total; &#125;&#125;var totalizer = new Totalizer();totalizer.addDonation(100.00);var fundsRaised = totalizer.getAmountRaised();// 120console.log(fundsRaised); 캡슐화를 하면 프로그램상에서 중복 코드를 예방할 수 있는 도구로 보여지지만 사실상 그렇지 않습니다.private 키워드를 사용하여 외부에서 값을 수정하는 것을 방지할 수 있습니다.복제의 가장 일반적인 경우는 논리적 분리입니다.예를 들어서 if나 switch 문의 경우 private에 숨겨진 요소를 바탕으로 프로그램을 제어 할 수 있습니다.요소를 변경할 경우 이러한 논리적 분리 상에 있는 모든 코드들을 다 살펴봐야 할 필요가 있습니다. 위임 (Delegation)프로그램 재사용 측면에서 가장 중요한 개념중 하나는 바로 위임입니다.레퍼(Wrapper) 클래스가 위임한 클래스를 호출하기 위해 인자로 키워드를 전달해야하는 경우 위임한 클레스는 래퍼클레스의 메서드를 호출 할 수 있습니다. 이것은 레퍼와 위임한 클래스가 서브클레스와 부모클레스로 동작하는것을 가능하게 합니다.레퍼가 자기자신에게 참조를 전달하지 못할 경우, 해당 작업은 위임보다는 전달(Forwarding)로 알려져 있습니다.위임과 전달에서는 클래스의 함수를 호출할 수 있지만, 해당 클래스는 그것을 다른 클래스로 넘겨줍니다.Listing 3-3이 거기에 대한 예제입니다. 위임과 전달은 두 클래스간의 관계가 ia a 테스트에 실패하여 상속이 안되는 경우 좋은 대안입니다. Listing 3-3. Delegation1234567891011121314151617181920212223242526272829303132333435363738394041424344454647interface ControlPanel &#123; startAlarm(message: string): any;&#125;interface Sensor &#123; check(): any;&#125;class MasterControlPanel &#123; private sensors: Sensor[] = []; constructor() &#123; // Instantiating the delegate HeatSensor this.sensors.push(new HeatSensor(this)); &#125; start() &#123; for (var i= 0; i &lt; this.sensors.length; i++) &#123; // Calling the delegate this.sensors[i].check(); &#125; window.setTimeout(() =&gt; this.start(), 1000); &#125; startAlarm(message: string) &#123; console.log('Alarm! ' + message); &#125;&#125;class HeatSensor &#123; private upperLimit = 38; private sensor = &#123; read: function() &#123; return Math.floor(Math.random() * 100); &#125; &#125;; constructor(private controlPanel: ControlPanel) &#123; &#125; check() &#123; if (this.sensor.read() &gt; this.upperLimit) &#123; // Calling back to the wrapper this.controlPanel.startAlarm('Overheating!'); &#125; &#125;&#125;var cp = new MasterControlPanel();cp.start(); List 3-3은 위임의 간단한 예제입니다.HeatSensor의 생성자로 ControlPanel 객체를 전달합니다.HeatSensor 클레스가 ControlPanel의 startAlarm 메서드를 필요할때 호출할 수 있습니다. ControlPanel은 센서들의 갯수를 조정할수 있으며,각각의 센서는 ControlPanel에 콜백을 통해서 문제가 발생했을때 경보를 알릴수 있습니다. 그림 3-1은 다양한 자동차 구성 요소 사이의 관계를 설명합니다. 새시는 자동차에 내장된 일반 골격입니다.엔진, 구동샤프트, 트랜스미션이 섀시에 장착될 때, 그 결합을 롤링 섀시라고 합니다. 그림 3-1 캡슐화와 상속 다형성(Polymorphism)다형성이란 하나의 시그너쳐를 여러가지 다른 형태로 구현하는 능력을 말합니다.타입스크립트에서 다형성은 여러가지 다른 형태로 가능합니다. 많은 클래스에 의해 구현된 인터페이스 많은 개체에 의해 구현된 인터페이스 많은 함수에 의해 구현된 인터페이스 여러 서브 클래스를 가진 슈퍼 클래스 유사한 스트럭쳐를 많이 가진 스트럭쳐 리스트 중 마지막 부분에 보면 “유사한 스트럭쳐를 많이 가진 스트럭쳐”란 형태가 같은 타입스크립트 스트럭쳐 타입을 말합니다. Listing 3-4. Polymorphism123456789101112131415161718192021222324252627interface Vehicle &#123; moveTo(x: number, y: number);&#125;class Car implements Vehicle &#123; moveTo(x: number, y: number) &#123; console.log('Driving to ' + x + ' ' + y); &#125;&#125;class SportsCar extends Car &#123;&#125;class Airplane &#123; moveTo(x: number, y: number) &#123; console.log('Flying to ' + x + ' ' + y); &#125;&#125;function navigate(vehicle: Vehicle) &#123; vehicle.moveTo(59.9436499, 10.7167959);&#125;var airplane = new Airplane();navigate(airplane);var car = new SportsCar();navigate(car); navigate함수는 Vehicle인터페이스와 호환되는 어떤 타입이라도 다 받아들입니다.2개의 number타입을 인수로 받는 moveTo 메서드를 가진 어떠한 클래스나 객체라도 다 가능합니다. 예제의 모든 타입은 Vehicle의 정의와 호환됩니다.Car는 명시적으로 인터페이스를 구현한 것이며,SportsCar는 Car를 상속받았으므로 Vehicle인터페이스를 구현하였습니다.Airplane는 명시적으로 Vehicle 인터페이스를 구현하지 않았지만, moveTo 메서드 가지고 있으므로 navigate 함수에 호환됩니다. SOLID Principleshttps://en.wikipedia.org/wiki/SOLID_(object-oriented_design) 1. 단일 책임 원칙 (Single responsibility priciple)클레스는 오직 한 가지 작업만 수행하며, 단 한 가지 이유에 의해서만 변경되는 코드를 작성하도록 권장하는 원칙이다. 2. 개방/폐쇄 원칙 (Open/closed principle)클래스 내부를 수정하지 않고서도 확장할 수 있어야 한다. (여기에 대해서는 사람마다 해석하는 방법이 다르다.) 확장에 대한 개방 : 새로운 요구 사항 발생시 추가가 가능해야 한다. 수정에 대한 폐쇄 : 수정될때 그 결과 인해 모듈의 소스 혹은 바이너리 코드가 변경되어서는 안된다. 3. 리스코프 치환 원칙 (Liskov substitution principle)슈퍼 클래스가 사용되는 곳에 서브 클래스로 치환하더라도 문제를 일으키지 않고 동작해야 한다. 4. 인터페이스 분리 (Interface segregation principle)작은 인터페이스로 많이 분리하는 것이 일반적인 경우에도 다 사용가능한 하나의 인터페이스보다 더 좋다. 5, 의존성 주입 (Dependency inversion principle)직접적으로 의존하지 말고 추상화에 의존하라. 단일 책임 원칙 (Single responsibility priciple)클레스가 변경되는 이유는 딱 한가지여야 합니다.클레스 설계시 통상 관련있는 항목 들을 같이 넣어서 변경시 관련 있는 것들을 모아둡니다.이러한 프로그램은 매우 결합력이 있을수 있습니다. 여기에서의 결합력의 의미는 클래스나 모듈에서 기능의 관련성을 의미합니다.기능들이 관련성이 낮으면 클래스는 낮은 결합력을 가지는 것이며 여러가지 이유에 의해서 변경 될 수 있습니다.높은 응집력은 SRP의 결과입니다. 코드를 추가할 경우 어디에 추가할지에 대해서 결정을 해야 하는데 대부분의 명백히 맞다, 틀리다라고 말하기 애매한 경우가 많습니다.클래스는 시간이 지날수록 점점 더 원래의 목적과 멀어지는 경우가 많습니다. SRP를 클래스에 적용한다고 생각할 것이 아니라함수를 만들때도 그것은 한가지 일만 수행해야 하고, 한가지 이유에 의해서만 수정해야 합니다.모듈 또한 마찬가지고 한가지 목적을 가지고 있는 것들의 집합으로 생성해야 합니다. List 3-5는 SRP에 어긋한 사례를 보여줍니다.언뜻보면 모든 함수들이 Movie 클래스의 속성을 사용하여 작업하므로 맞게 된 것으로 보이지만,Movie 객체를 사용하는 것과 Repository로 사용하는 것 사이에서 그 경계가 애매모호 한 점이 보입니다. Listing 3-5. Single responsibility principle (SRP) violation123456789101112class Movie &#123; private db: DataBase; constructor(private title: string, private year: number) &#123; this.db = DataBase.connect('user:pw@mydb', ['movies']); &#125; getTitle() &#123; return this.title + ' (' + this.year + ')'; &#125; save() &#123; this.db.movies.save(&#123; title: this.title, year: this.year &#125;); &#125;&#125; 이 클래스가 더 커지기전에 수정하고자 한다면,Movie에 관련된 것과 MovieRepository에 관련된 것으로 구분이 가능합니다.Movie에 관련된 기능을 추가할 경우 MovieRepository는 변경할 필요가 없습니다.반대로 MovieRepository를 변경한 경우 Movie는 변경할 필요가 없습니다. Listing 3-6. Separate reasons for change12345678910111213141516171819202122232425class Movie &#123; constructor(private title: string, private year: number) &#123; &#125; getTitle() &#123; return this.title + ' (' + this.year + ')'; &#125;&#125;class MovieRepository &#123; private db: DataBase; constructor() &#123; this.db = DataBase.connect('user:pw@mydb', ['movies']); &#125; save(movie: Movie) &#123; this.db.movies.save(JSON.stringify(movie)); &#125;&#125;// Movievar movie = new Movie('The Internship', 2013);// MovieRepositoryvar movieRepository = new MovieRepository();movieRepository.save(movie); SRP를 클래스 레벨에 대해서 고려하는 것은 개념적으로 생각하기 쉽습니다.하지만 함수 레벨에 적용을 하는게 더 중요합니다.각각의 함수는 한가지 작업만을 수행하며, 함수명은 그 의도를 명확히 보여주어야 합니다.Uncle Bob (http://blog.cleancoder.com)은 당신이 떨어져 나갈때까지 분리하라.고 하였습니다.즉, 함수가 몇줄 안될때까지 한가지 작업만 할 수 있도록 리팩토링을 하라는 의미입니다.이러한 함수를 리팩토링하는 방법은 전체적인 디자인을 재구성할 경우 쉽게 가능하도록 하는데 큰 도움이 됩니다. 개방/폐쇄 원칙 (Open/closed principle)OCP는 다음 문장으로 요약됩니다. 소프트웨어는 확장에 대해서는 개방적이어야 하지만, 수정을 하는데는 폐쇄적이어야 한다. 실질적으로 아무리 설계를 잘하더라도, 수정으로부터 완벽하게 보호하는 것은 힘듭니다.그러나 아무리 사소한거라도 기존 코드를 변경하는 것은 위험합니다. OCP를 따를려면 프로그램의 변경가능성을 고려해야 합니다.예를 들어, 나중에 교체되거나 확장가능한 함수를 포함하는 클래스들을 식별해야 합니다.하지만, 미래를 예측하는 것은 가능한 일이 아니며, 나중을 위해 생성한 코드는 거의 대부분 사용되지 않습니다.무슨 일이 일어날지 예측하는 것은 까다롭습니다.이 코드가 나중에 필요없게 될수도 있고, 예측한 것과는 다른 방향으로 흘러 갈 수도 있습니다.그래서 실제로 문제가 일어났을 때만 해결하려고 노력을 한다는 것을 윈칙으로 하는것이 좋습니다. OCP를 따르는 방법중 가장 일반적인 것은 필요할 경우 클래스를 다른 클래스도 대체할 수 있도록 구현하는 것입니다.객체지향 언어로 이렇게 구현하는 것은 그렇게 어려운 일이 아닙니다.물론 타입스크립트도 예외는 아닙니다.목록 3-7은 RewardPointsCalculator라는 포인트 카드의 리워드를 계산해주는 클래스를 보여줍니다.보통의 경우 달러 당 4점의 포인트를 보상해 줍니다.VIP 손님과 같이 2배로 포인트를 보상해 주려고 할때 DoublePointsCalculator라는 서브클래스로 대체할 수 있습니다.getPoints()함수 호출하면 슈퍼클래스의 함수가 무시되고 서브클레스에서 수행합니다. Listing 3-7. Open–closed principle (OCP)1234567891011121314151617class RewardPointsCalculator &#123; getPoints(transactionValue: number) &#123; // 4 points per whole dollar spent return Math.floor(transactionValue) * 4; &#125;&#125;class DoublePointsCalculator extends RewardPointsCalculator &#123; getPoints(transactionValue: number) &#123; var standardPoints = super.getPoints(transactionValue); return standardPoints * 2; &#125;&#125;var pointsCalculator = new DoublePointsCalculator();alert(pointsCalculator.getPoints(100.99)); RewardPointsCalculator의 기능을 대체하기 위해서 해당 클래스에 대한 수정 없이 서브클래스를 생성하여 원래 기능을 대체함으로써 구현을 하였습니다.OCP를 잘 지키면 유지 보수 및 재사용 가능한 코드로 작성되는 경향이 높습니다.변화가 필요한 경우에도 기존에 잘 동작하는 코드는 수정하지 않으면서 새로운 코드를 요구 사항에 맞게 처리하도록 추가할 수 있습니다. 리스코프 치환 원칙 (The Liskov Substitution Principle) (LSP)바바라 리스코프(Barbara Liskov)가 1988년에 데이터 추상화와 계층구조(Data Abstraction and Hierarchy)라는 제목의 기조연설에서 이런말을 했습니다. S가 T의 하위속성이라면 프로그램의 변경없이 T의 객체를 S로 교체(치환)할 수 있어야 한다. 서브클레스가 슈퍼클래스를 대체할 경우 클래스를 사용하는 코드가 대체한다는 사실을 알 필요가 없다는 것입니다.개체의 타입에 대해서 테스트하는 코드가 있는 경우에는 LSP를 위반하고 있을 가능성이 높습니다. 서브타입에서의 함수 인자 호환성 :슈퍼클래스에 Cat을 입력받는 함수가 있는 경우, 서브클레스는 Cat 혹은 Animal을 인자로 받을수 있어야 합니다. 서브타입에서의 리턴 타입 호환성 :슈퍼클래스에 Animal을 리턴하는 함수가 있는 경우, 서브클레스는 Animal이나 Animal의 서브클래스 (Cat)를 반환할 수 있어야 합니다. 서브타입에서의 발생 예외 호환성 :서브클래스가 예외를 발생할 경우, 슈퍼클래스와 같은 예외이거나 그 예외의 서브타입을 발생시켜야 합니다.타입스크립스의 경우에는 예외 클래스 뿐만 아니라 단순한 예외를 문자열로 throw하게 지정할 수 있습니다.List 3-8과 같이 오류 클래스를 생성할 수도 있습니다.여기서 말하고자하는 것은 예외 처리 코드의 경우 서브클레스라고 해서 다르게 처리되어서는 안된다는 뜻입니다. Listing 3-8. Error classes123456class ApplicationError implements Error &#123; constructor(public name: string, public message: string) &#123; &#125;&#125;throw new ApplicationError('Example Error', 'An error has occurred'); LSP는 새로운 함수를 추가할 때 예전에 사용되던 함수 대신 사용이 가능하다는 것을 보장해 줌으로 OCP를 지원합니다.서브클래스가 직접 슈퍼클래스를 대체할 수 없는 경우,서브클래스를 추가하는 작업은 기존에 잘 작동하던 코드를 수정해야 한다는 뜻이며,객체 타입에 따라 실행이 나뉘게 되는 식으로 프로그램을 작성해야 할 수도 있다는 말이 됩니다. 책에서는 소개되지 않았지만 LSP를 제대로 지키기 위한 가이드 라인을 소개해 드리겠습니다. 계약 규칙 서브타입에서 더 강력한 사전 조건을 정의할 수 없다. 서브타입에서 더 완화된 사후 조건을 정의할 수 없다. 슈퍼타입의 불변식(항상 참으로 유지되는 조건들)은 서브타입에서도 반드시 유지되어야 한다. 가변성 규칙 서브타입의 메서드 인수는 반 공변성(contravariance)을 가져야 한다. (더 작은 파생형식을 사용할 수 있다.) 서브타입의 리턴 타입은 공변성(variance)을 가져야 한다. (더 많은 파생형식을 사용할 수 있다.) 서브타입은 슈퍼타입이 발생시키는 것과 동일한 타입 예외나 그 보무 타입의 예외 혹은 자식 타입의 예외만 사용해야 한다. 인터페이스 분리 (The Interface Segregation Principle) (ISP)인터페이스를 통해 클래스가 어떤 역할을 하는지를 알 수 있습니다.통상적으로 클래스를 먼저 생성한 후에 인터페이스를 작성합니다.List 3-9는 복사,출력, 분류 작업을 하는 Printer 인터페이스입니다.이 인터페이스는 프린터 동작을 단순히 포함하는 식이기 때문에 폴딩, 봉투 입력, 팩스, 스캔, 이메일 전송 등의 작업을 추가하는 식으로 점점 더 커질 수 있습니다. Listing 3-9. Printer interface12345interface Printer &#123; copyDocument(); printDocument(document: Document); stapleDocument(document: Document, tray: number);&#125; ISP는 큰 인터페이스를 만드는 대신 더 작고 구체적인 인터페이스로 분리하는 것을 권장합니다.각각의 인터페이스는 필요한 함수만을 제공하도록 정의합니다.이렇게 함으로써 클래스 내에 인터페이스를 구현할 때 필요없는 기능에 대해서 구현할 필요가 없게 할 수 있습니다. List 3-9의 Printer 인터페이스를 구현할때 인쇄, 복사는 구현이 가능한데 분류가 불가능할 경우 해당 함수에 대해서는 오류를 발생시키도록 해야 할 수도 있습니다.추후에 Printer 인터페이스에 새로운 함수를 추가할 경우 이미 구현된 클래스들에 영향을 주기 때문에 추가 자체가 어려워 집니다.List 3-10은 기존의 Printer 인터페이스를 나눠서 SimplePrinter와 SuperPrinter에서 구현을 다르게 한 것을 보여줍니다. Listing 3-10. Segregated interfaces1234567891011121314151617181920212223242526272829interface Printer &#123; printDocument(document: Document);&#125;interface Stapler &#123; stapleDocument(document: Document, tray: number);&#125;interface Copier &#123; copyDocument();&#125;class SimplePrinter implements Printer &#123; printDocument(document: Document) &#123; //... &#125;&#125;class SuperPrinter implements Printer, Stapler, Copier &#123; printDocument(document: Document) &#123; //... &#125; copyDocument() &#123; //... &#125; stapleDocument(document: Document, tray: number) &#123; //... &#125;&#125; ISP를 잘 지키면 클라이언트 코드는 사용하지 않는 함수에 대해서 구현할 필요가 없습니다. 의존성 주입 (The Dependency Inversion Principle) (DIP)전통적인 OOP에서는 상위 컴퍼넌트는 계층구조 상의 하위 컴퍼넌트들에게 의존적입니다.컴퍼넌트간의 결합으로 인해 시스템을 수정하기 힘들게 됩니다.또한 해당 모듈을 재사용하기 위해서는 의존 관계에 있는 모든 컴퍼넌트들을 다 신경써야 하므로, 결과적으로 재사용성을 떨어트립니다. List 3-11은 전통적인 종속성을 보여주는 예제입니다.LightSwitch 클래스는 Light 클래스에 의존성을 가지고 있습니다. Listing 3-11. High-level dependency on low-level class12345678910111213141516171819202122232425262728interface LightSource &#123; switchOn(); switchOff();&#125;class Light &#123; switchOn() &#123; //... &#125; switchOff() &#123; //... &#125;&#125;class LightSwitch &#123; private isOn = false; constructor(private light: Light) &#123; &#125; onPress() &#123; if (this.isOn) &#123; this.light.switchOff(); this.isOn = false; &#125; else &#123; this.light.switchOn(); this.isOn = true; &#125; &#125;&#125; DIP는 OCP와 LSP를 확장한 개념입니다.추상화에 의존하게 함으로써, 구체적인 클래스와의 결합성을 낮출수 있습니다.이 원리를 따르는 가장 간단한 방법은 클래스가 아닌 인터페이스에 의존적으로 구현하는 것입니다. 디자인 패턴 (Design Patterns)디자인 패턴이란 이미 알려진 문제점들에 대해서 그 해결책을 디자인을 통해서 제공해주는 것을 의미합니다.하지만 패턴이 과도하게 사용되어서는 안됩니다.디자인 패턴에 관해 가장 알려진 것은 Gang of Four의 Design Patterns: Elements of Reusable Object-Oriented Software (Gamma, Helm, Johnson, &amp; Vlissides, Addison Wesley, 1995)가 있습니다. 디자인 패턴들을 자바스크립트에서도 적용이 가능합니다.Diaz and Harmes의 Pro JavaScript Design Patterns, Apress, 2007란 책도 나와 있습니다.자바스크립트에서 가능한 것은 타입스크립트에서도 물론 가능합니다.타입스크립트는 클래스 기반의 객체 지향을 사용하기 때문에 전통적인 디자인 패턴 예제를 타입스크립트로 적용하는 것이 가능합니다.몇 가지 디자인 패턴 샘플들에 대해서 소개해 드리겠습니다.(전략 패턴, 추상 팩토리 패턴)GOF의 디자인패턴에는 총 23가지 패턴이 있습니다. 전략 패턴 (The Strategy Pattern)전략패턴은 알고리즘을 캡슐화하는 방법을 제공합니다.그림 3-2에서 Context 클래스는 인터페이스의 구체적인 구현을 제공하는 Strategy에 의존적입니다.인터페이스를 구현하는 클래스는 런타임에 Context에 제공되어 집니다. 그림 3-2 전략 패턴 추상 팩토리 패턴 (The Abstract Factory Pattern)추상 팩토리 패턴은 창조적인 디자인 패턴입니다.개체 생성을 위해서 구체적인 클래스를 지정하지 않고 인터페이스로 지정할 수 있습니다.그래서 런타임시 구체적인 클래스를 전달하는 것입니다. 그림 3-3 추상 팩토리 패턴 예제새차 시스템에 전략 패턴과 추상 팩토리 패턴을 이용한 예를 살펴보겠습니다.가격에 따라 다른 서비스를 제공하는 시스템입니다.List 3-13은 휠청소 클래스에 대한 인터페이스와 2가지 기본, 고급의 2가지 전략을 보여줍니다. Listing 3-13. Wheel cleaning123456789101112131415161718interface WheelCleaning &#123; cleanWheels(): void;&#125;class BasicWheelCleaning implements WheelCleaning &#123; cleanWheels() &#123; console.log('Soaping Wheel'); console.log('Brushing wheel'); &#125;&#125;class ExecutiveWheelCleaning extends BasicWheelCleaning &#123; cleanWheels() &#123; super.cleanWheels(); console.log('Waxing Wheel'); console.log('Rinsing Wheel'); &#125;&#125; List 3-14는 차체 청소를 위한 전략을 보여줍니다. Listing 3-14. Body cleaning123456789101112131415161718interface BodyCleaning &#123; cleanBody(): void;&#125;class BasicBodyCleaning implements BodyCleaning &#123; cleanBody() &#123; console.log('Soaping car'); console.log('Rinsing Car'); &#125;&#125;class ExecutiveBodyCleaning extends BasicBodyCleaning &#123; cleanBody() &#123; super.cleanBody(); console.log('Waxing car'); console.log('Blow drying car'); &#125;&#125; List 3-15는 추상 팩토리 패턴이 사용되기 전의 CarWashProgram입니다.세척 클래스들과 강력한 결합을 가지고 있으며, 선택된 것에 대하여 클래스를 생성합니다. Listing 3-15. CarWashProgram class before the abstract factory pattern12345678910111213141516171819202122232425262728class CarWashProgram &#123; constructor(private washLevel: number) &#123; &#125; runWash() &#123; var wheelWash: WheelCleaning; var bodyWash: BodyCleaning; switch (this.washLevel) &#123; case 1: wheelWash = new BasicWheelCleaning(); wheelWash.cleanWheels(); bodyWash = new BasicBodyCleaning(); bodyWash.cleanBody(); break; case 2: wheelWash = new BasicWheelCleaning(); wheelWash.cleanWheels(); bodyWash = new ExecutiveBodyCleaning(); bodyWash.cleanBody(); break; case 3: wheelWash = new ExecutiveWheelCleaning(); wheelWash.cleanWheels(); bodyWash = new ExecutiveBodyCleaning(); bodyWash.cleanBody(); break; &#125; &#125;&#125; 추상 팩토리란 구체적인 팩토리들이 수행가능한 인터페이스 입니다.List 3-16에서 ValetFactory 인터페이스는 WheelCleaning와 BodyCleaning를 얻을 수 있는 기능을 제공합니다.휠청소와 차체청소를 필요로하는 클래스는 이 인터페이스에 의존적일 수 있습니다.또한 각각의 청소를 클래스로 부터 해제하는 일이 필요할 수도 있습니다. Listing 3-16. Abstract factory1234interface ValetFactory &#123; getWheelCleaning() : WheelCleaning; getBodyCleaning() : BodyCleaning;&#125; List 3-17에서 금,은,동 등급의 3개의 팩토리를 선언합니다.각각의 팩토리는 해당 등급에 맞는 청소클래스를 제공합니다. Listing 3-17. Concrete factories1234567891011121314151617181920212223242526class BronzeWashFactory implements ValetFactory &#123; getWheelCleaning() &#123; return new BasicWheelCleaning(); &#125; getBodyCleaning() &#123; return new BasicBodyCleaning(); &#125;&#125;class SilverWashFactory implements ValetFactory &#123; getWheelCleaning() &#123; return new BasicWheelCleaning(); &#125; getBodyCleaning() &#123; return new ExecutiveBodyCleaning(); &#125;&#125;class GoldWashFactory implements ValetFactory &#123; getWheelCleaning() &#123; return new ExecutiveWheelCleaning(); &#125; getBodyCleaning() &#123; return new ExecutiveBodyCleaning(); &#125;&#125; List 3-18은 추상 팩토리 패턴이 사용된 예제입니다.CarWashProgram 플래스는 더이상 구체적인 클래스에 대해서 알 필요가 없습니다.이제는 각각의 청소 클래스를 제공하는 팩토리로 구성되어 있습니다.이것은 컴파일 타임이나 런타임에 수행됩니다. Listing 3-18. Abstract factory pattern in use12345678910class CarWashProgram &#123; constructor(private cleaningFactory: ValetFactory) &#123; &#125; runWash() &#123; var wheelWash = this.cleaningFactory.getWheelCleaning(); wheelWash.cleanWheels(); var bodyWash = this.cleaningFactory.getBodyCleaning(); bodyWash.cleanBody(); &#125;&#125; Mixinshttps://en.wikipedia.org/wiki/Mixin Mix-in은 디자인 패턴에서는 다루지 않는 응용 프로그램을 구성하는 다른 방법입니다.믹스인은 미사추세츠, 소머빌에 있는 시트브 아이스크림이란 가게에서 고객이 고를수 있는 아이스크림 디저트의 이름을 따왔습니다.아이스 크림을 고른 뒤 막대 사탕 같은 다른 기호에 맞는 것들을 추가할 수가 있습니다. 프로그래밍의 믹스인도 이와 유사합니다.인자로 재사용 가능한 클래스들을 받아서 그것들을 조합하여 사용합니다.믹스인 클래스의 일부는 인터페이스이며 일부는 구현입니다. TypeScript Mixins아직 타입스크립트에서 믹스인이 완벽하게 지원되지는 않습니다만, 간단한 정도는 구현이 가능합니다.List 3-19에 믹스인을 적용한 함수가 있습니다.이 함수는 각각의 증강 클래스(augumented class) 배열을 baseCtors로 전달하고 구현할 클래스를 derivedCtor로 전달합니다.이 함수를 통해서 믹스인을 적용하고 싶을 때는 언제든지 적용이 가능합니다. Listing 3-19. Mixin enabler function123456789function applyMixins(derivedCtor: any, baseCtors: any[]) &#123; baseCtors.forEach(baseCtor =&gt; &#123; Object.getOwnPropertyNames(baseCtor.prototype).forEach(name =&gt; &#123; if (name !== 'constructor') &#123; derivedCtor.prototype[name] = baseCtor.prototype[name]; &#125; &#125;) &#125;);&#125; Listing 3-20에는 재사용 가능한 증강 클래스가 정의 되어 있습니다.구체적인 구분은 없지만, Sings, Dances, Acts에 대해서 정의했습니다.이러한 클래스는 서로 다른 조합으로 구성되어 실행이 가능합니다. Listing 3-20. Reusable classes1234567891011121314151617class Sings &#123; sing() &#123; console.log('Singing'); &#125;&#125;class Dances &#123; dance() &#123; console.log('Dancing'); &#125;&#125;class Acts &#123; act() &#123; console.log('Acting'); &#125;&#125; 이 클래스들은 SRP를 매우 잘 지키고 있습니다.타입스크립트에서는 implements 키워드 뒤에 믹스인 리스트(증강 클래스)를 콤마로 나열해서 클래스를 구성할 수 있습니다. Listing 3-21. Composing classes12345678910111213class Actor implements Acts &#123; act: () =&gt; void;&#125;applyMixins(Actor, [Acts]);class AllRounder implements Acts, Dances, Sings &#123; act: () =&gt; void; dance: () =&gt; void; sing: () =&gt; void;&#125;applyMixins(AllRounder, [Acts, Dances, Sings]); Actor와 AllRounder 클래스에는 구현되어 있는게 아무것도 없습니다.증강 클래스에서 제공받을 수 있는 공간만을 할당해놓고 있습니다.이 클래스를 사용하는 것은 다른 클래스를 사용하는 것과 다르지 않습니다. Listing 3-22. Using the classes1234567var actor = new Actor();actor.act();var allRounder = new AllRounder();allRounder.act();allRounder.dance();allRounder.sing(); 타입스크립트에서 다중 상속은 허용되지 않습니다.마치 다중 상속처럼 보이겠지만, extends를 사용한 것이 아닌 impliments를 사용했다는 것이 중요합니다. 언제 믹스인을 써야 하는가믹스인을 타입스크립트에서 일부 지원하지만, 사용할때 무엇을 염두해 두어야 할까요 ?무엇보다도, 구현이 클래스에 주입되었는지에 대해서 확인하는 방법이 없으므로 applyMixins 함수를 정확한 클래스 명의 리스트로 호출하는것을 신경써야 합니다.그렇지 않으면 테스트 할때 제대로 잘 안되더라도 원인을 찾기 힘들 것입니다. 믹스인을 사용할지 일반적인 클래스를 사용할지는 클래스간의 관계를 보고 결정을 해야 합니다.상속에는 통상 is a를 사용하고 위임에서는 has a를 사용합니다. A car has a chassis. A rolling chassis is a chassis. 믹스인에서는 can do를 사용하는 것으로 그 관계를 설명할 수 있습니다. An actor can do actingor An actor acts. Acting과 Acts와 같이 이름 지정으로서 믹스인 관계를 식별하도록 할 수 있습니다.그렇게 하면 클래스 선언이 마치 문장 처럼 보일 수 있습니다. (Actor implements Acting)믹스인은 작은 단위가 합쳐서 큰 것으로 되는 것이 가능하기 때문에, 다음에 열거한 시나리오들은 믹스인으로 구성되기 좋은 것들입니다. 추가적인 옵션을 갖는 클래스 (믹스인 함수를 옵션으로 구현) 여러 클래스에서 동일한 함수를 재사용 비슷한 기능들의 조합으로 여러 가지 클래스를 만들어야 할 경우 제한점믹스인 함수를 private 멤버로 사용하면 안됩니다.왜냐면 컴파일러가 증강 클래스가 구현이 안되었을 경우 오류를 발생합니다.또한 믹스인 함수와 증강 클래스가 둘 다 동일한 이름의 private 멤버를 가지고 있는 경우에도 오류를 발생합니다. 믹스인의 또다른 제한점은 함수는 증강 클래스로 매핑되지만, 속성은 안됩니다. (List 3-23)증강 클래스 안에 속성을 구현한 경우 믹스인 함수에서 초기화해줘야 합니다.실수를 방지하기 위해서는 증강 클래스 안에 있는 속성에 대해서는 디폴트값을 정의하지 않는 것이 좋습니다. Listing 3-23. Properties not mapped123456789101112131415161718class Acts &#123; public message = 'Acting'; act() &#123; console.log(this.message); &#125;&#125;class Actor implements Acts &#123; public message: string; act: () =&gt; void;&#125;applyMixins(Actor, [Acts]);var actor = new Actor();// Logs 'undefined', not 'Acting'actor.act(); 속성이 특정 개체에 종속되지 않는다면 static으로 선언하는 방법도 있습니다.List 3-24는 List 3-23의 문제점을 static 요소로 선언하는 것으로 해결한 것입니다.객체마다 다른 값이 필요한 경우 해당 요소는 믹스인 함수에서 초기화해줘야 합니다. Listing 3-24. Static properties are available123456class Acts &#123; public static message = 'Acting'; act() &#123; alert(Acts.message); &#125;&#125; Summary 타입스크립트에는 객체 지향적인 요소들을 대부분 포함하고 있습니다. SOLID 이론은 코드가 계속 유지될 수 있도록 해주는 것을 그 목표로 하고 있습니다. 디자인 패턴은 일반적으로 알려준 문제들에 대한 해법이 될 수 있습니다. 디자인 패턴에서 설명한 그대로 구현할 필요는 없습니다. 믹스인은 각 가수어품들을 대체 할수 있는 방법을 제공합니다.","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://DevStarSJ.github.io/categories/JavaScript/"},{"name":"TypeScript","slug":"JavaScript/TypeScript","permalink":"http://DevStarSJ.github.io/categories/JavaScript/TypeScript/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://DevStarSJ.github.io/tags/JavaScript/"},{"name":"TypeScript","slug":"TypeScript","permalink":"http://DevStarSJ.github.io/tags/TypeScript/"}]},{"title":"ASP.NET MVC 05. View","slug":"CSharp.Aspnet.05.View ","date":"2016-05-23T19:00:00.000Z","updated":"2017-05-24T03:25:11.000Z","comments":true,"path":"2016/05/24/CSharp.Aspnet.05.View /","link":"","permalink":"http://DevStarSJ.github.io/2016/05/24/CSharp.Aspnet.05.View /","excerpt":"","text":"ViewView 란?MVC Framework에서 사용자에게 결과를 보여주는 역할을 합니다. https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller ASP.NET에서는 Razor Engine을 이용하여 View를 조금 더 편하게 작성 할 수 있습니다. (.cshtml)Razor Engine이 무엇인지 간단하게 얘기하자면 View (HTML page) 작성시 C# 문법과 .NET Framework를 사용할 수 있습니다.Layout, Partial View를 이용하여 특정 영역만 따로 rendering 하는 것도 가능하며,각종 Helper method를 제공하여서 반복적인 HTML TAG 작성 작업을 줄여주며, 직접 Helper method를 작성하여서도 활용 할 수 있습니다. View의 기본적인 사용법은 Controller and Action 절에서 예제 작성시 간단히 언급했으므로 생략하도록 하겠습니다. https://github.com/DevStarSJ/Study/blob/master/Blog/MVC/04.ControllerAndAction.md View를 편리하게 사용하기 위한 방법(주로 재활용 방안) 위주로 진행하겠습니다. 1. Layout sectionLayout (주로 _Layout.cshtml 식의 명칭) 내부에는 section을 제공해 줍니다. @RenderBody() : 해당 Layout을 사용하는 View의 내용이 이 위치에 삽입됩니다. @RenderSection(&quot;Name&quot;) : View 에서 @section Name { ... } 의 내용이 해당 section에 삽입됩니다. Layout에서 선언한 @RenderSection(&quot;...&quot;)이 View에서 사용하지 않으면 오류가 발생합니다.해당 section에 선택적으로 사용을 하려면 (View에서 사용하지 않아도 오류가 발생하지 않게 하려면) @RenderSection(&quot;...&quot;, false)로 선언을 하면 됩니다. *_Layout.cshtml 123456789101112131415// _Layout.cshtml...&lt;body&gt; @RanderSection(\"Header\") ... @RanderBody() ... @RanderSection(\"Footer\", required = false)&lt;/body&gt; Index.cshtml 123456789101112@&#123; Layout = \"_Layout\";&#125;@section Header &#123;&lt;div&gt;This is Header&lt;/div&gt;&#125;&lt;div&gt; RenderBody contains every contents in this document, except @section ...&lt;/div&gt; 2. Partial ViewRazor Tag, HTML Markup 으로 이루어진 동일한 코드를 반복적으로 사용할 경우 유용합니다. Partial.cshtml 1234&lt;div&gt; This is Partial View. @Html.ActionLink(\"The Link of Index on this Controller\", \"Index\")&lt;/div&gt; List.cshtml 12345678@&#123; ViewBag.Title = \"List\"; Layout = null;&#125;&lt;h3&gt;List&lt;/h3&gt;@Html.Partial(\"Partial\") 위의 경우 List.cshtml에서 Partial.cshtml의 Partial view를 사용하였는데, Partial view 내부를 보면 ActionLink를 Controller 이름을 명시하지 않았습니다.Partial View를 Rednering하는 곳이 List.cshtml 내부이기 때문에 해당 Controller를 기준으로 동작합니다. Partial View도 ViewModel을 가질 수 있습니다. (Strongly Typed Partial View) 그럴 경우 @Html.Partial(...) 의 두번째 인자로 ViewModel을 전달해 줘야 합니다. Partial2.cshtml 12@model IEnumerable&lt;string&gt;... List.cshtml 12...@Html.Partial(\"Partial2\", new [] &#123; \"Luna\" , \"Star\" &#125; ) 3. Child ActionView 에서 호출되는 Action Method를 의미합니다.@Html.Action(...) helper method를 사용하면 모든 Action method를 View에서 호출이 가능하지만,[ChileActionOnly] 이란 attribute를 붙이면 Routing System에서 사용되지 않고 순수히 View에서 호출할 경우에만 동작하는 것을 의미합니다. HomeController.cs 123456...[ChildActionOnly]public ActionResult Time()&#123; return PartialView(DateTime.Now);&#125; Time.cshtml 1234@model DateTime&lt;div&gt; @Model.ToShortTimeString()&lt;/div&gt; List.cshtml 12...@Html.Action(\"Time\") Child Action에 매개변수가 필요한 경우에는 무명형식을 이용해서 전달이 가능합니다.단 파라메터의 이름이 같아야 합니다. HomeController.cs 123456...[ChildActionOnly]public ActionResult Time(DateTime time)&#123; return PartialView(DateTime.Now);&#125; List.cshtml 12...@Html.Action(\"Time\", new &#123; time = DateTime.Now &#125;)","categories":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/categories/C/"},{"name":"ASP.NET","slug":"C/ASP-NET","permalink":"http://DevStarSJ.github.io/categories/C/ASP-NET/"}],"tags":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/tags/C/"},{"name":"ASP.NET","slug":"ASP-NET","permalink":"http://DevStarSJ.github.io/tags/ASP-NET/"}]},{"title":"ASP.NET MVC 04. Controller and Action","slug":"CSharp.Aspnet.04.ControllerAndAction","date":"2016-05-11T18:00:00.000Z","updated":"2017-05-24T03:25:11.000Z","comments":true,"path":"2016/05/12/CSharp.Aspnet.04.ControllerAndAction/","link":"","permalink":"http://DevStarSJ.github.io/2016/05/12/CSharp.Aspnet.04.ControllerAndAction/","excerpt":"","text":"Controller and Action1. Controlleer 와 Action이란 ?1.1 ControllerMVC Framework에서 가장 핵심이되는 역할을 수행하는 Component입니다. Model을 조작 User의 요청을 처리 UI에 출력할 View를 결정 MVC Framework에서 사용자, View, Model은 서로 아무런 연결고리가 없이 이루어집니다.Controller가 그 중심에서 처리를 수행합니다. https://ko.wikipedia.org/wiki/모델-뷰-컨트롤러 1.2 Action한마디로 설명드리자면 Controller가 수행하는 각각의 method들을 Action이라고 부릅니다.하나의 Controller는 여러가지 일을 수행 할 수 있습니다.Action에서는 사용자가 요청하는 작업을 정의합니다.기본적으로 Action의 이름과 그 결과를 출력하는 View의 이름은 같습니다. 123456789101112public class HomeController : Controller&#123; public ActionResult Index() &#123; return View(); &#125; public ActionResult Hello() &#123; return View(); &#125;&#125; 위와 같이 정의된 Home Controller가 있는 경우, http://mySite.com/Home/Index 라는 요청을 하면 Index()라는 Action method가 실행되어 /Views/Home/Index.cshtml을 출력하며, http://mySite.com/Home/Hello 라는 요청을 하면 Hello()라는 Action method가 실행되어 /Views/Home/Hello.cshtml을 출력합니다. 2. Controller 구현 방법2.1 IController interface로 구현지금은 잘 사용하지 않는 방법입니다. 12345//System.Web.Mvc.IController Interfacepublic interface IController&#123; void Execute(RequestContext requestContext);&#125; Execute()라는 하나의 구현을 제공해주기 때문에 해당 method 안에서 RequestContext를 분석하여 실행합니다. 123456789101112131415161718public BasicController : IController&#123; public void Execute (RequestContext requestContext) &#123; string controller = (string)requestContext.RouteData.Values[\"controller\"]; string action = (string)requestContext.RouteData.Values[\"action\"]; switch (action) &#123; case \"Index\": ... break; case \"Hello\": ... break; &#125; &#125;&#125; 2.2 Controller를 상속받아 구현많이 사용하는 방법입니다.Controller는 3가지 핵심 기능을 제공합니다. Action Method : 작업들을 여러 method로 나눌 수 있으며, 서로 다른 URL로 노출됩니다. Action Result : Action method의 결과를 사용자에게 return 합니다. Rendering한 View JSON, XML 등의 document 다른 URL로 Indirect Filter : Reusable한 기능들을 Filter로 Capsulation할 수 있습니다. 예제 Code는 1.2 Action의 예제를 참고하시면 됩니다. 3. 요청 데이터 받기Action method에서 요청 데이터를 가져오는 방법들에 대해서 알아보도록 하겠습니다. 3.1 Context를 통해서 데이터 가져오기ASP.NET Platform에서 제공해주는 Context 개체들이 많이 있습니다.그 중 자주 사용되는 값들에 대해서 몇가지 소개 드리겠습니다. Request. QueryString(NameValueCollection) : Request와 함께 전송된 GET 변수들 Form (NameValueCollection) : Request와 함께 전송되어 오는 POST 변수들 e.g. Request.Form[&quot;newName&quot;] (string) Cookies (HttpCookieCollection) : Browser가 Request와 함께 전달한 Cookie HttpMethod (string) : Request에 사용된 HTTP method (GET, POST, DELETE …) Headers (NameValueCollection) : Request와 함께 전송된 HTTP Header Url (Uri) : Request URL UserHostAddress (string) : Request한 User의 IP Address RouteData. Route (RouteBase) : Request에 대해 선택된 RouteTable.Routes Entry Values (RouteValueDictionary) : Route parameters (URL로부터 추출된 값이나 기본값) HttpContext. Application (HttpApplicationStateBase) : Applcation 상태 Repository Cache (Cache) : Application Cache Repository Items (IDictionary) : 현재 Request에 대한 상태 Repository Session (HttpSessionStateBase) : 방문자 Session에 대한 상태 Repository Timestamp (DateTime) : Request한 시간 User (IPrincipal) : Login된 사용자의 인증정보 .Identity.Name (string) : 사용자 명칭 TempData (TempDataDictionary) : 현재 사용자에 대한 임시 데이터 항목들 Server.MachineName (string) : Server 명칭 자세한 정보는 MSDN에서 System.Web.Mvc.Controller , System.web.Mvc.ControllerContext를 살펴보시면 됩니다. 3.2 매개변수 사용하기위에서 살펴본 것처럼 Context를 통해서 값을 읽어 올 수 있지만, Action Method에서 매개변수를 선언할 경우 해당 매개변수로 값이 전달되어서 편리하게 사용이 가능합니다.Request.Form, Request.QueryString, Request.Files, RouteData.Values에서 매개변수와 타입, 명칭을 비교해서 매칭이 되는 경우 매개변수에 값으로 전달을 해 줍니다.좀 더 자세히 말씀드리자면 Value Provider가 위 Context들에서 값을 가져오면 Model Binder가 해당 Value들을 Action Method에서 요구하는 형식으로 제공합니다. 단 Action Method에서는 Reference Parameter(ref)는 제공하지 않으며, Value Type (premitive type, struct)에 default value가 설정되지 않은 경우 해당 값이 오지 않으면 Exception이 발생합니다.nullable (int?, DateTime? …)로 선언을 하면 해당 값이 없더라도 null로 해당 Action Method가 수행됩니다.Reference Type (class)에 대해서는 default value가 없더라도 값이 없는 경우 null로 전달되므로 Exception이 발생하지 않습니다. 4. 출력 (return)Action Method의 처리 결과를 사용자에게 전달(return)해줘야 합니다. 4.1 직접 구현하기지금은 잘 사용하지 않는 방법이지만 IController를 구현했을 경우에는 직접 구현을 해줘야만 했습니다. 123456789101112131415public class BaseController : IController&#123; public void Execute(RequestContext requestContext) &#123; string action = (string)requestContext.RouteData.Value[\"action\"]; if (action.ToLower() == \"redirect\") &#123; requestContext.HttpContext.Response.Redirect(\"Derived/Index\"); &#125; else &#123; requestContext.HttpContext.Response.Write($\"Action : &#123;action&#125;\"); &#125; &#125;&#125; 물론 Controller를 상속 받았을 경우에도 직접 구현은 가능합니다. 1234567public class HomeController : Controller&#123; public void Index() &#123; Reponse.Write(\"Hello from the Index Action Method\"); &#125;&#125; 4.2 ActionResult로 return4.2.1 ActionResult 란 ?Response 개체를 직접 다루는게 아니라, MVC Framework에게 우리를 대신해서 만들어내도록 전달하게 해주는 역할을 합니다.MVC Framework는 전달받은 ActionResult에 해당하는 ExecuteResult() 를 호출하여 출력을 생성합니다. 4.2.2 ActionResult 타입 ViewResult (View()) : View template을 rendering PartialViewResult (PartialView()) : Partial view template을 rendering RedirectToRouteResult : Route System를 통해 URL을 생성하거나 Action Method나 Route Entry로 HTTP 301 or 302 redirect를 수행 (RedirectToAction(), RedirectToActionPermanent(), RedirectToRoute(), RedirectToRoutePermanent()) RedirectResult (Redirect()) : 특정 URL로 HTTP 301 or 302 redirect 수행 ContentResult (RedirectPermanent(), Content()) : Text 타입의 데이터를 Browser로 return. content-text header 설정 (optional) FileResult (File()) : Binary File을 Browser로 직접 전송 JsonResult (Json()) : .NET object를 JSON으로 Serialization하여 전송. Web API에서 보편적으로 사용 JavaScriptResult (JavaScript()) : JavaScript source를 Browser로 전송 HttpUnauthorizedResult : HTTP 401 (인증되지 않음)으로 처리 HttpNotFoundResult (HttpNotFound()) : HTTP 404 (찾을 수 없음) 으로 처리 HttpStatusCodeResult : 특정 HTTP code로 처리 EmptyResult : 아무것도 안함 4.2.3 Returning HTML for View RenderingActionResult 중 가장 기본인 ViewResult에 대한 간단한 사용법 입니다. 12345678public ViewResult Index()&#123; return View(\"Homepage\"); // Route System에게 Homepage라는 segment에 해당하는 View를 rendering하도록 전달 return View(\"Index\", \"_AlternateLayoutPage\"); // 특정 Layout을 지정하여 rendering하도록 전달 return View(\"~/Views/Home/Index.cshtml\"); // Route System을 통하지 않고 직접 특정 View를 지정&#125; 4.3 Action Method에서 View로 Data 전달4.3.1 ViewModelViewModel(View에서 사용할 Model)을 parameter로 전달하면 됩니다. 12345678public class HomeController : Controller&#123; public ViewResult Index() &#123; DataTime now = DateTime.Now; return View(now); &#125;&#125; DateTime 타입의 ViewModel을 전달한 경우 View에서는 2가지 방법으로 전달받은 ViewModel을 사용할 수 있습니다. 4.3.1.1 Weakly Typed View약한 형식 뷰 (또는 무형식(Untyped) 뷰)라고 불리는 방법으로, ViewModel을 특정 타입으로 지정하지않고 object instance로 취급합니다.그렇기 때문에 사용시 형 변환을 해줘야 합니다.이 경우에는 intellisense가 제공되지 않을 뿐더러, code가 다소 지저분해 질 수 있습니다. 12345@&#123; ViewBag.Title = \"Index\";&#125;&lt;h1&gt;Index&lt;/h1&gt;&lt;div&gt;The day is: @(((DateTime)Model).DayOfWeek)&lt;/div&gt; 4.3.1.2 Strongly Typed View강력한 형식 뷰에서는 @model 키워드로 ViewModel type을 지정합니다.그러면 View내에서 @Model 키워드로 사용이 가능합니다.이 경우 intellisense 기능을 사용할 수가 있어서 편리하며, code도 깔끔하게 만들 수 있습니다. 123456@model DateTime@&#123; ViewBag.Title = \"Index\";&#125;&lt;h1&gt;Index&lt;/h1&gt;&lt;div&gt;The day is: @Model.DayOfWeek&lt;/div&gt; 4.3.2 ViewBagAction Method에서 ViewBag이라는 dynamic object에 임의의 속성을 정의하면 View에서 읽을 수 있습니다. 123456789public class HomeController : Controller&#123; public ViewResult Index() &#123; ViewBag.Now = DateTime.Now; ViewBag.MyName = \"Luna\"; return View(); &#125;&#125; 123456@&#123; ViewBag.Title = \"Index\";&#125;&lt;h1&gt;Index&lt;/h1&gt;&lt;div&gt;The day is: @ViewBag.Now.DayOfWeek&lt;/div&gt;&lt;div&gt;My name is @ViewBag.MyName&lt;/div&gt; 여러 개의 값을 전달할 경우 ViewModel보다 편리하게 사용할 수 있습니다.위 예제와 같이 DateTime 과 string 2개의 값을 ViewModel로 전달하고자 한다면, 따로 정의를 해야합니다. 12345public class IndexViewModel&#123; public DateType Now; public string MyName;&#125; TempData와 SessionData를 이용한 전달도 가능한데, 이것은 Redirect 시에 주로 사용되므로 다음에 그때 가서 설명드리겠습니다. 5. Redirect (재전송)Action Method의 결과를 직접적으로 출력하는게 아니라, 다른 URL로 재전송해야 하는 경우 사용합니다. 만약 HTTP POST 요청에 대해서 처리결과를 바로 출력할 경우, 사용자가 다시 Browser Refresh를 할 경우 POST요청이 다시 수행되게 됩니다.그래서 이런 경우에는 POST에 관련된 처리를 한 후 그 결과를 보여주는 View를 따로 생성하여 GET 요청으로 URL Redirect를 수행하는 것이 더 안전합니다.그럼 사용자가 Refresh를 하더라도 POST 요청이 다시 수행되지 않습니다. Redirect에는 2가지 방식이 있습니다. HTTP 302 : 임시적인 재전송을 의미합니다. 가장 많이 사용되는 방식이며, Post/Redirect/Get 패턴을 사용할 경우에도 302로 전송되어야 합니다. HTTP 301 : 영구적인 재전송을 의미합니다. 이 경우 원본 URL은 더이상 사용되지 않을 것이고, Redirect된 새로운 URL이 앞으로 사용됩니다. 5.1 Action Method에서 Redirect하는 방법12345678910111213141516171819public RedirectResult Index()&#123; return Redirect(\"/Example/Index\"); // 문자열로 URL을 작성하여 Redirect return RedirectPermanent(\"/Example/Index\"); // 영구적인 Redirect (Redirect(\"...\", true);를 사용하는 것도 가능)&#125;public RedirectToRouteResult Index()&#123; return RedirectToRoute(new &#123; // Redirect to Routing System URL controller = \"Example\", action = \"Index\", ID = \"Luna\" &#125;); return RedirectToAction(\"Index\"); // Redirect to Action Method return RedirectToAction(\"Index\", \"Example\"); // other Controller&#125; 5.2 Redirect시 Data 전달5.2.1 TempDataRedirect하기 전에 TempData에 필요한 값들을 저장합니다. 123456public RedirectToRouteResult Index()&#123; TempData[\"MyName\"] = \"Luna\"; TempData[\"Now\"] = DateTime.Now; return RedirectToAction(\"Hello\");&#125; 전달받은 TempData는 값을 읽기 전까지는 유지가 되며, 읽으면 삭제됩니다.값을 읽는 방법은 TempData[&quot;MyName&quot;]으로 읽을 수 있습니다.TempData.Peek(&quot;&quot;MyName)을 이용하면 값을 삭제하지 않고 읽을 수 있습니다. 이 값을 View까지 전달하고자 한다면 TempData에서 읽어서 ViewBag이나 ViewModel에 넣어서 전송을 하면 됩니다. 123456public ViewResult Hello()&#123; ViewBag.MyName = TempData[\"MyName\"]; ViewBag.Now = TempData[\"Now\"]; return View();&#125; 그냥 따로 전달하지 않고, View에서 바로 읽는 것도 가능합니다. 12345&lt;strong&gt;@TempData.TryPeek(\"MyName\") Entered.&lt;/strong&gt;&lt;/p&gt;The day is : @(((DateTime)TempData[\"Now\"]).DayOfWeek) &lt;/p&gt;My Name is @TempData[\"MyName\"] 5.2.2 Session DataTempData와 비슷한 방법으로 사용이 가능하지만, 해당 Session 내에서 계속해서 유지가 된다는 차이점이 있습니다.일회성으로 사용할 정보는 TempData를 활용하는 것이 좋고, Session 내에서 계속해서 필요한 정보는 Session을 사용하는게 좋습니다. 6. HTTP Code, Error 전송12345678public HttpStatusCodeResult StatusCode()&#123; return new HttpStatusCodeResult(404, \"URL cannot be serviced\"); // 직접 생성해서 반환 return HttpNotFound(); // 404 return HttpUnauthorizedResult(); // 401&#125;","categories":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/categories/C/"},{"name":"ASP.NET","slug":"C/ASP-NET","permalink":"http://DevStarSJ.github.io/categories/C/ASP-NET/"}],"tags":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/tags/C/"},{"name":"ASP.NET","slug":"ASP-NET","permalink":"http://DevStarSJ.github.io/tags/ASP-NET/"}]},{"title":"Deploying .NET Core Web App with Visual Studio and Git","slug":"CSharp.AspnetCore.Depoly.VS.Git","date":"2016-05-10T15:00:00.000Z","updated":"2017-04-23T10:32:43.000Z","comments":true,"path":"2016/05/11/CSharp.AspnetCore.Depoly.VS.Git/","link":"","permalink":"http://DevStarSJ.github.io/2016/05/11/CSharp.AspnetCore.Depoly.VS.Git/","excerpt":"","text":"Deploying .NET Core Web App with Visual Studio and Git ASP.NET Core 개발환경으로는 Windows에서 Visual Studio를 사용하는 것이 가장 편합니다.이번 포스팅에서는 Windows에서 ASP.NET Core Web App을 작성하여 Git을 이용하여 Ubuntu에서 실행하는 것을 소개해 드리겠습니다. 1. Github에 Repository 생성하기본인의 GitHub 계정으로 가셔서 아래와 같이 원하는 이름으로 Repository를 생성합니다. 2. PC에 GitHub Repository Clone 하기원하시는 폴더로 가셔서 GitHub Repository에 연결하세요.(아래에서 github 주소란에는 본인의 Repository 주소로 적어주세요.) 123456789mkdir WebAppcd WebAppgit initgit remote add origin https://github.com/DevStarSJ/WebApp.gitgit pull origin master 3. Visual Studio로 Web App 예제 만들기ASP.NET Core Web Application으로 프로젝트를 생성합니다.위치를 좀 전에 Git Repository로 지정한 곳으로 해주세요. 다음 그림에서는 Web Application을 선택한 후에 OK를 눌러주세요. 제대로 만들어졌는지, F5를 눌러서 확인해봅니다. 4. GitHub에 올리기12345git add --allgit commit -m &quot;Initial Commit&quot;git push origin master 5. Ubuntu에서 내려받기아직 git이 설치되어 있지 않다면 아래와 같이 설치를 해주세요. 1sudo apt-get install git 이제 원하는 폴더로 가셔서 GitHub에서 내려받습니다. 위에 Windows에서 한것과 명령어가 같습니다. 123456789mkdir WebAppcd WebAppgit initgit remote add origin https://github.com/DevStarSJ/WebApp.gitgit pull origin master 이제 WebApp 폴더로 들어가서 project.json의 framework부분을 아래와 같이 수정합니다. 1cd WebApp/src/WebApp 123456789101112\"frameworks\": &#123; \"netcoreapp1.0\": &#123; \"dependencies\": &#123; \"Microsoft.NETCore.App\": &#123; \"type\": \"platform\", \"version\": \"1.0.0\" &#125;, \"Microsoft.AspNetCore.Server.Kestrel\": \"1.0.0\" &#125;, \"imports\": \"dnxcore50\" &#125;&#125;, 저장한 뒤 이제 실행합니다. 12345dotnet restoredotnet builddotnet run","categories":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/categories/C/"},{"name":"ASP.NET Core","slug":"C/ASP-NET-Core","permalink":"http://DevStarSJ.github.io/categories/C/ASP-NET-Core/"}],"tags":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/tags/C/"},{"name":"ASP.NET Core","slug":"ASP-NET-Core","permalink":"http://DevStarSJ.github.io/tags/ASP-NET-Core/"}]},{"title":".NET Core Install for Ubuntu 14.04","slug":"CSharp.AspnetCore.Install.Net.Core","date":"2016-05-10T15:00:00.000Z","updated":"2017-05-24T03:25:12.000Z","comments":true,"path":"2016/05/11/CSharp.AspnetCore.Install.Net.Core/","link":"","permalink":"http://DevStarSJ.github.io/2016/05/11/CSharp.AspnetCore.Install.Net.Core/","excerpt":"","text":".NET Core Install for Ubuntu 14.04.NET Core를 Ubuntu에 설치하는 과정에 대해서 소개해드리겠습니다. Ubuntu 설치는 필자의 경우는 Microsoft Azure에 설치하였습니다.(참고로 Azure에 Ubuntu설치시 SSH (22)번 빼고는 모두 막혀있습니다. Portal에서 원하시는 포트를 열어야 합니다.) 1. .NET Core 설치 후 Hello World 출력해보기먼저 .Net Core를 컴파일하고 실행할 수 있도록 SDK를 설치하겠습니다. 공식문서에 설명이 잘 되어 있습니다. (https://www.microsoft.com/net/core#ubuntu)아래 설명대로 해서 잘 안되면 Link의 공식문서에 바뀐 점이 있는지 보시고 따라해주세요. 아래 명령어를 하나씩 입력해주세요. 1234567sudo sh -c &apos;echo &quot;deb [arch=amd64] https://apt-mo.trafficmanager.net/repos/dotnet/ trusty main&quot; &gt; /etc/apt/sources.list.d/dotnetdev.list&apos;sudo apt-key adv --keyserver apt-mo.trafficmanager.net --recv-keys 417A0893sudo apt-get updatesudo apt-get install dotnet-dev-1.0.0-preview2-003121 이제 .Net Core SDK 설치가 끝났습니다.제대로 설치가 되었는지 기본 예제를 실행해 보겠습니다. 123456789mkdir hwappcd hwappdotnet newdotnet restoredotnet run 아래와 같이 출력이 나오면 제대로 설치가 된 것입니다. 2. ASP.NET Core 용 실행환경 구성먼저 Web App 생성에 필요한 것들을 설치해야 합니다. 자세한 설명은 다음 Link에 되어 있습니다. (https://docs.asp.net/en/1.0.0-rc1/getting-started/installing-on-linux.html#installing-on-ubuntu-14-04) 2.1 .NET Version Manager (DNVM) 설치Linux 상에서 여러 버전의 .NET 실행 환경 (.NET Execution Environment) DNX를 관리해주는 도구입니다. 123sudo apt-get install unzip curlcurl -sSL https://raw.githubusercontent.com/aspnet/Home/dev/dnvminstall.sh | DNX_BRANCH=dev sh &amp;&amp; source ~/.dnx/dnvm/dnvm.sh 2.2 .NET Execution Environment (DNX) 설치Linux 상에서 .NET 프로젝트를 빌드하고 실행해주는 도구입니다. 123sudo apt-get install libunwind8 gettext libssl-dev libcurl4-openssl-dev zlib1g libicu-dev uuid-devdnvm upgrade -r coreclr 2.3 libuv 설치libuv는 멀티플랫폼 비동기 IO 라이브러리 입니다.Kestrel에서 libuv를 사용합니다.Kestrel은 ASP.NET Core를 호스팅하기 위한 크로스-플랫폼 HTTP 서버 입니다. 1234567891011121314151617sudo apt-get install make automake libtool curlcurl -sSL https://github.com/libuv/libuv/archive/v1.8.0.tar.gz | sudo tar zxfv - -C /usr/local/srccd /usr/local/src/libuv-1.8.0sudo sh autogen.shsudo ./configuresudo makesudo make installsudo rm -rf /usr/local/src/libuv-1.8.0 &amp;&amp; cd ~/sudo ldconfig 3. ASP.NET Core Web App 생성하기다음 Link의 공식문서를 보고 작성하였습니다. (https://docs.asp.net/en/latest/getting-started.html) 좀 전에 생성한 예제 코드로 이동하겠습니다. 1cd ~/hwapp project.json의 dependencies란에 다음과 같이 Kestrel를 추가해주세요. 1234567891011121314151617181920&#123; \"version\": \"1.0.0-*\", \"buildOptions\": &#123; \"debugType\": \"portable\", \"emitEntryPoint\": true &#125;, \"dependencies\": &#123;&#125;, \"frameworks\": &#123; \"netcoreapp1.0\": &#123; \"dependencies\": &#123; \"Microsoft.NETCore.App\": &#123; \"type\": \"platform\", \"version\": \"1.0.0\" &#125;, \"Microsoft.AspNetCore.Server.Kestrel\": \"1.0.0\" &#125;, \"imports\": \"dnxcore50\" &#125; &#125;&#125; 패키지를 project에 다운로드 합니다. 1dotnet restore Startup.cs파일을 추가하려 다음의 내용으로 작성합니다. 123456789101112131415161718using System;using Microsoft.AspNetCore.Builder;using Microsoft.AspNetCore.Hosting;using Microsoft.AspNetCore.Http;namespace aspnetcoreapp&#123; public class Startup &#123; public void Configure(IApplicationBuilder app) &#123; app.Run(context =&gt; &#123; return context.Response.WriteAsync(\"Hello from ASP.NET Core!\"); &#125;); &#125; &#125;&#125; Program.cs파일을 다음과 같이 수정해주세요. 123456789101112131415161718using System;using Microsoft.AspNetCore.Hosting;namespace aspnetcoreapp&#123; public class Program &#123; public static void Main(string[] args) &#123; var host = new WebHostBuilder() .UseKestrel() .UseStartup&lt;Startup&gt;() .Build(); host.Run(); &#125; &#125;&#125; 그런 다음 실행합니다. 1dotnet run 위 그림과 같은 메세지가 나오면 성공한 것입니다. 웹브라우저로 붙어보면 아래와 같은 그림이 나옵니다. 4. 외부에서 접속가능하게 배포하기다음 Link의 공식문서를 보고 따라했습니다.(https://docs.asp.net/en/latest/publishing/linuxproduction.html) Nginx를 설치합니다. 1sudo apt-get install nginx 이제 우리가 띄운 Web App으로 접속하도록 Proxy를 설정합니다. 설정파일은 /etc/nginx/sites-available/default 입니다. 1sudo vi /etc/nginx/sites-available/default 버전별로 내용이 조금 다룰수 있는데 눈여겨 볼 부분은 다음과 같습니다. 4.1 외부에서 접속할 Port 설정아래 80부분을 원하는 Port로 설정하면 됩니다.123server &#123; listen 80 default_server; listen [::]:80 default_server ipv6only=on; 4.2 내부로 연결한 주소 설정location부분을 아래와 같이 설정합니다. 12345678location / &#123; proxy_pass http://localhost:5000; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection keep-alive; proxy_set_header Host $host; proxy_cache_bypass $http_upgrade;&#125; 중요한 부분만 그림으로 보면 다음과 같습니다. 수정한 내용에 이상은 없는지 확인한 후 실행합니다. 123sudo nginx -tsudo service nginx start 만약 수행 중 변경 후 반영하려면 다음과 같이 입력해야 합니다. 1sudo nginx -s reload 이제 외부에서 Web App으로 접근이 가능합니다","categories":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/categories/C/"},{"name":"ASP.NET Core","slug":"C/ASP-NET-Core","permalink":"http://DevStarSJ.github.io/categories/C/ASP-NET-Core/"}],"tags":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/tags/C/"},{"name":"ASP.NET Core","slug":"ASP-NET-Core","permalink":"http://DevStarSJ.github.io/tags/ASP-NET-Core/"}]},{"title":"WebSockets in .NET Core","slug":"CSharp.AspnetCore.WebSocket","date":"2016-05-10T15:00:00.000Z","updated":"2017-05-24T03:25:12.000Z","comments":true,"path":"2016/05/11/CSharp.AspnetCore.WebSocket/","link":"","permalink":"http://DevStarSJ.github.io/2016/05/11/CSharp.AspnetCore.WebSocket/","excerpt":"","text":".NET Core (현재는 ASP.NET 5)로 간단한 Web Socket을 구현하는 예제코드와 설명입니다. 작업은 Visual Studio 2015 , ASP.NET5-rc1 으로 진행하였습니다. 개요 .NET Core (ASP.NET 5 Template)로 Web Application Project를 생성 Server : Echo Server 를 Web Socket으로 구현 Client에서 전달한 Text Message를 그대로 전달 Client : jQuery를 이용한 간단한 Web Socket page를 생성 여러 Client가 접속한 경우 접속된 모든 Client에게 echo message를 전달 1. Project 생성C# -&gt; Web -&gt; ASP.NET Web Application 선택 후 ASP.NET 5 Templates -&gt; Web Appliacaion으로 Project를 생성합니다.ASP.NET 5 Templates가 설치되지 않은 경우 아래 설치 버튼이 활성화되며, 설치가 짧은 순간에 끝나지는 않으니 조금 기다리셔야 합니다. 2. Server Web Socket 구현Startup.cs 파일을 열어서 public void Configure() 함수에 아래 Code를 추가합니다.단 app.UseMvc()보다 위에 위치해야 합니다. 12345678910111213141516171819202122232425262728293031323334app.UseWebSockets();app.Use(async (http, next) =&gt;&#123; if (http.WebSockets.IsWebSocketRequest) &#123; var webSocket = await http.WebSockets.AcceptWebSocketAsync(); if (webSocket != null &amp;&amp; webSocket.State == WebSocketState.Open) &#123; // Handle the socket here while (webSocket.State == WebSocketState.Open) &#123; var token = CancellationToken.None; var buffer = new ArraySegment&lt;byte&gt;(new byte[4096]); var received = await webSocket.ReceiveAsync(buffer, token); switch (received.MessageType) &#123; case WebSocketMessageType.Text: var request = Encoding.UTF8.GetString(buffer.Array, buffer.Offset, buffer.Count); // Handle request here await webSocket.SendAsync(buffer, WebSocketMessageType.Text, true, token); break; &#125; &#125; &#125; &#125; else &#123; await next(); &#125;&#125;); 위 Code가 실행되려면 Assembly를 하나 추가해 줘야합니다. “Microsoft.AspNet.WebSockets.Server”: “1.0.0-rc1-final” Nuget package manager를 사용하지 않더라도 오류가 발생한 Code에서 Ctrl + . (Quick Action)을 이용하면 자동으로 추가가 됩니다. 또 필요한 namespace를 using에 추가를 해주는 작업도 Ctrl +.으로 쉽게 작업이 가능합니다. Client에서 Connection을 연결할때마다 app.Use안에 선언한 함수가 실행됩니다.Request가 아닌 경우에는 그냥 무시 (next();)를 하며 Request인 경우에는 Accept수행 후 Receive작업을 기다리며 Pending 상태가 됩니다. 1234567891011121314var webSocket = await http.WebSockets.AcceptWebSocketAsync();if (webSocket != null &amp;&amp; webSocket.State == WebSocketState.Open)&#123; while (webSocket.State == WebSocketState.Open) &#123; var token = CancellationToken.None; var buffer = new ArraySegment&lt;byte&gt;(new byte[4096]); var received = await webSocket.ReceiveAsync(buffer, token); // Processing received message &#125;&#125; Message가 도착하면 await webSocket.ReceiveAsync()의 Pending이 해제되면서 다음 Line을 수행합니다.현재 예제는 Text 타입에 대해서만 그대로 Client에게 echo message를 전달하고 있습니다. 123456switch (received.MessageType)&#123; case WebSocketMessageType.Text: await webSocket.SendAsync(buffer, WebSocketMessageType.Text, true, token); break;&#125; 3. Client Web Socket 구현편의상 추가로 Controller를 추가하지 않고 Home Controller에 Chat이라는 Action Method를 추가하도록 하겠습니다.Controllers/HomeController.cs파일을 열어서 아래 Action을 추가해 주세요. 1234public ActionResult Chat()&#123; return View();&#125; 아무런 내용없이 그냥 기본 Routing되는 View를 return합니다. Views/Home 폴더 아래에 Chat.cshtml파일을 추가해서 다음과 같이 입력해주세요. 1234567891011121314151617181920212223242526272829303132333435@&#123; ViewData[\"Title\"] = \"WebSocket Chat Page\";&#125;&lt;form id=\"chatform\" action=\"\"&gt; &lt;input id=\"inputbox\" /&gt;&lt;/form&gt;&lt;div id=\"message\" /&gt;&lt;script src=\"//code.jquery.com/jquery-1.11.0.min.js\"&gt;&lt;/script&gt;&lt;script type=\"text/javascript\"&gt; $(document).ready(function() &#123; var username = prompt('Enter your name: '); var uri = 'ws://localhost:9258'; var ws = new WebSocket(uri); ws.onopen = function () &#123; $('#message').prepend('&lt;div&gt;Connected.&lt;/div&gt;'); $('#chatform').submit(function (event) &#123; ws.send('&lt;strong&gt;' + username + ' : &lt;/strong&gt;' +$('#inputbox').val()); $('#inputbox').val(''); event.preventDefault(); &#125;); &#125;; ws.onerror = function (event) &#123; $('#message').prepend('&lt;div&gt;ERROR&lt;/div&gt;'); &#125;; ws.onmessage = function (event) &#123; $('#message').prepend('&lt;div&gt;' + event.data + '&lt;/div&gt;'); &#125;; &#125;);&lt;/script&gt; 접속주소(uri) 값은 Server 실행시 port 번호를 보고 수정해 주세요. jQuery를 nuget으로 설치해도 되지만 편의상 online으로 참조하였습니다. 해당 View가 열릴때 WebSocket()으로 접속합니다. 접속에 성공하면 (ws.onopen) chatform의 submit작업으로 ws.send()를 실행하도록 설정합니다. WebSocket으로 부터 message를 전달받으면 (ws,onmessage)를 화면에 출력합니다. 최대한 군더더기 없이 간단하게 구현하였습니다. 4. 실행F5를 눌러서 Debug 수행후 접속주소에 /Home/Chat를 붙여서 우리가 생성한 View를 열어주세요. 이름을 입력해서 접속을 한 후에, 채팅 메세지를 입력하면 화면에 메세지가 출력됩니다. 위 메세지는 Client에서 출력을 한 것이 아니라 Server로 부터 전달받은 메세지 입니다.믿기 힘드시겠다면, 여러 Client끼리 Chat을 할 수 있도록 Server를 수정해 보도록 하겠습니다. 5. Server를 여러 Client에게 메세지 전달하도록 수정Startup.cs 파일의 public class Startup에 thread-safety한 map을 하나 선언합니다. 1ConcurrentBag&lt;WebSocket&gt; _sockets = new ConcurrentBag&lt;WebSocket&gt;(); 다음으로는 Client에서 접속시 _sockets에 socket들을 저장해 놓습니다.// Handle the socket here 바로 윗 부분에 아래 Code를 추가합니다. 1_sockets.Add(webSocket); Client에게 SendAsync()를 하는 부분을 전체 Client에게 전송하도록 수정합니다.// Handle request here 아래에 있는 await webSocket.SendAsync()줄을 지우고 아래 Code를 입력해주세요. 1234foreach (var socket in _sockets)&#123; await socket.SendAsync(buffer, WebSocketMessageType.Text, true, token);&#125; 6. 실행이제 실행하여 Browser를 2개 띄워서 Test해보면 한 쪽에서 입력해도 양쪽으로 모두 메세지가 출력되는 것을 확인 할 수 있습니다. 참조 Site ASP.NET 5 Server Web Socket &#x68;&#x74;&#x74;&#112;&#x73;&#x3a;&#47;&#x2f;&#109;&#101;&#100;&#105;&#x75;&#109;&#46;&#x63;&#x6f;&#x6d;&#47;&#64;&#116;&#x75;&#x72;&#111;&#119;&#x69;&#x63;&#122;&#47;&#119;&#x65;&#98;&#115;&#111;&#x63;&#107;&#x65;&#116;&#115;&#x2d;&#105;&#x6e;&#45;&#97;&#x73;&#112;&#45;&#x6e;&#x65;&#116;&#45;&#53;&#x2d;&#x36;&#x30;&#57;&#x34;&#x33;&#49;&#57;&#x61;&#49;&#53;&#x61;&#x32;&#x23;&#x2e;&#114;&#112;&#x66;&#116;&#x37;&#54;&#54;&#119;&#98; Client jQuery Web Socket https://blogs.msdn.microsoft.com/youssefm/2012/07/17/building-real-time-web-apps-with-asp-net-webapi-and-websockets","categories":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/categories/C/"},{"name":"ASP.NET Core","slug":"C/ASP-NET-Core","permalink":"http://DevStarSJ.github.io/categories/C/ASP-NET-Core/"}],"tags":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/tags/C/"},{"name":"ASP.NET Core","slug":"ASP-NET-Core","permalink":"http://DevStarSJ.github.io/tags/ASP-NET-Core/"}]},{"title":"Using SignalR in ASP.NET Core","slug":"CSharp.AspnetCore.SignalR","date":"2016-05-08T15:00:00.000Z","updated":"2017-05-24T03:25:11.000Z","comments":true,"path":"2016/05/09/CSharp.AspnetCore.SignalR/","link":"","permalink":"http://DevStarSJ.github.io/2016/05/09/CSharp.AspnetCore.SignalR/","excerpt":"","text":"SignalR을 ASP.NET 5 Template에서 사용하기 위해서는 Startup.cs의 public void Configure(IApplicationBuilder app, ...)에서 아래와 같은 구문이 필요합니다. 123456789101112public class Startup&#123; public void Configure(IApplicationBuilder app) &#123; app.UseServices(services =&gt; &#123; services.AddSignalR(); &#125;); app.UseFileServer(); app.UseSignalR(); &#125;&#125; app.UserServices()를 사용하기 위해서는 Microsoft.AspNet.RequestContainer assembly를 포함시켜야 IApplicationBuilder의 extention method인 UseServices의 사용이 가능한데, 현재 version에서는 ASP.NET 4.5.1을 지원하지 않아서 사용이 불가능 합니다. https://github.com/aspnet/Hosting/tree/8f16060f941b71551be09015d76efb86770d84d7/src/Microsoft.AspNet.RequestContainer 위 Github repository의 ContainerExtensions.cs에 구현되어 있습니다. 추후에라도 적용시키기 위해서는 아래 Link를 참고하시기 바랍니다. http://dotnetthoughts.net/using-signalr-in-asp-net-5/","categories":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/categories/C/"},{"name":"ASP.NET Core","slug":"C/ASP-NET-Core","permalink":"http://DevStarSJ.github.io/categories/C/ASP-NET-Core/"}],"tags":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/tags/C/"},{"name":"ASP.NET Core","slug":"ASP-NET-Core","permalink":"http://DevStarSJ.github.io/tags/ASP-NET-Core/"}]},{"title":"ASP.NET MVC 03. Advanced Routing","slug":"CSharp.Aspnet.03.Route.adv","date":"2016-05-07T17:00:00.000Z","updated":"2017-05-24T03:25:11.000Z","comments":true,"path":"2016/05/08/CSharp.Aspnet.03.Route.adv/","link":"","permalink":"http://DevStarSJ.github.io/2016/05/08/CSharp.Aspnet.03.Route.adv/","excerpt":"","text":"고급 Routing1. View에서 outgoing URL 생성 (using routing system)View에서 왜 굳이 routing system을 사용해서 outgoing URL을 생성해야 할까요 ?그냥 static link를 사용해서 쉽게 생성이 가능한데 말이죠. 1&lt;a href=\"/Home/Index\"&gt;Home&lt;/a&gt; Static link (정적 링크)의 문제점은 URL Schema가 바뀔 경우 hard-coding된 URL들을 모두 찾아서 바꿔줘야 합니다.그러므로 Route 시스템을 이용하여 outgoing URL을 동적으로 생성하는게 더 바람직합니다. 1.1 동일 Controller에서의 다른 Action Method 호출1@Html.ActionLink(\"This is a outgoing URL\", \"ActionMethod\") Html.ActionLink helper method를 이용하여 rendering된 page의 html을 보면 아래와 같이 생성이 됩니다 1&lt;a href=\"/Home/ActionMethod\"&gt;This is a outgoing URL&lt;/a&gt; RouteConfig.cs의 RouteConfig에 설정된 .MapRoute()중 matching되는 패턴을 찾아서 해당 URL로 rendering됩니다. 1.2 다른 Controller 호출다른 Controller로 가려면 Html.ActionLink의 overloading된 다른 함수를 사용하면 됩니다. 1@Html.ActionLink(\"This is a outgoing URL\", \"ActionMethod\", \"ControllerName\") 1.3 추가값 전달Controller, Action Method 이외에 추가값을 전달할 경우 익명타입을 이용하여 전달합니다. 1@Html.ActionLink(\"This is a outgoing URL\", \"ActionMethod\", \"ControllerName\", new &#123; id = \"Luna\" ) 이 경우 다음과 같은 Link로 rendering 됩니다. 1&lt;a href=\"/ControllerName/ActionMethod?id=Luna\"&gt;This is a outgoing URL&lt;/a&gt; 물론 routes.MapRoute(null, &quot;{controller}/{action}/{id}&quot;, ...);로 URL pattern이 설정되어 있을 경우에는 &quot;/ControllerName/ActionMethod/Luna&quot; 로 생성합니다. 1.4 Html Attribute가 적용된 앵커(a) 생성익명타입의 추가값 다음 인자로 익명타입으로 전달하면 됩니다. 전달할 추가값이 없는 경우에는 추가값에 대한 익명타입란에 null을 넣어주면 됩니다. 12@Html.ActionLink(\"Home\", \"Index\", \"Home\", null, new &#123; id = \"anchorID\", @class = \"cssStyleClass\" &#125; ) 다음과 같이 rendering 됩니다. 1&lt;a href=\"/\" id = \"anchorID\", class = \"cssStyleClass\"&gt;Home&lt;/a&gt; @class를 좀 주의해야하는데, 아마도 C# keyword의 class와 중복이 되어서가 아닐까라 추측됩니다. 1.5 정규화된 URL 생성1234@Html.ActionLink(\"Home\", \"Index\", \"Home\", \"https\", \"mySite.com\", \"fragment\", new &#123; id = \"Luna\" &#125;, new &#123; id = \"anchorID\", @class = \"cssStyleClass\" &#125; ) Controller 다음에 새로 추가된 3개의 매개변수는 각각 Protocol, Server의 URL, FragmentName을 나타냅니다.그래서 다음과 같이 rendering 됩니다. 1&lt;a href=\"https://mySite.com?id=Luna#fragment\" id = \"anchorID\", class = \"cssStyleClass\"&gt;Home&lt;/a&gt; 1.6 링크(a)없이 URL만 생성하기Html.ActionLink() 대신 Html.Action()를 사용하면 &lt;a&gt;&lt;/a&gt;없는 URL만 Text로 생성합니다.말 그대로 Link를 빼면 Link없이 URL만 생성합니다.사용법은 Html.ActionLink()와 같습다만 처음의 text 인자와 html attribute 인자가 없습니다. 1@Html.Action(\"ActionMethod\", \"ControllerName\", new &#123; id = \"Luna\" ) 의 경우 /ControllerName/ActionMethod?id=Luna라는 문자열을 생성합니다.routes.MapRoute(null, &quot;{controller}/{action}/{id}&quot;, ...);로 URL pattern이 설정되어 있을 경우에는 /ControllerName/ActionMethod/Luna 로 생성합니다. 2. Action Method에서 outgoing URL 생성하기2.1 View에서 사용한 helper method 그대로 사용하여 URL생성1234567public ViewResult MyActionMethod()&#123; string url = Url.Action(\"Index\", new &#123; id = \"Luna\"&#125;); // /Home/Index?id=Luna or /Home/Index/Luna string url2 = Url.RouteUrl(new &#123; controller = \"Home\", action = \"Index\"&#125;); // /Home/Index or / ... return View();&#125; 2.2 다른 URL로 재전송2.2.1 다른 Action Method 호출1234public RedirectToRouteResult MyActionMethod()&#123; return RedirectToAction(\"Index\");&#125; 다른 Controller 호출 및 segement 전달 가능한 overload된 함수들이 존재합니다. 2.2.2 URL을 생성하여 재전송1234public RedirectToRouteResult MyActionMethod()&#123; return RedirectToRoute(new &#123; controller = \"Home\", action = \"Index\", id = \"Luna\"&#125;);&#125; 3. 특정 Route를 선택적으로 사용하기이제껏 Routing system이 URL, Link를 Rule에 따라서 생성하였습니다.우리가 직접 Route를 선택하는 방법도 있습니다.(routes.MapRoute()의 첫번째 인자로 명칭을 입력했는데 그것을 명시적으로 사용하면 됩니다.) 12routes.MapRoute(\"Route1\", \"&#123;controller&#125;/&#123;action&#125;\");routes.MapRoute(\"Route2\", \"App/&#123;action&#125;\", new &#123; controller = \"Home\" &#125;); 위와 같이 설정된 경우 1@Html.ActionLink(\"Customer Infomation\", \"Index\", \"Customer\") 는 항상 다음의 Link로 생성됩니다. 1&lt;a href=\"/Customer/Index\"&gt;Customer Information&lt;/a&gt; 3.1 View에서 특정 Route 사용하기만약 Route2를 이용한 Link의 생성을 원할 경우 다음과 같이 명시적으로 Route Name을 선택 할 수 있습니다. 1@Html.ActionLink(\"Customer Infomation\", \"Route2\", \"Index\", \"Customer\") 1&lt;a href=\"/Home/Index?Length=5\" Length=\"8\"&gt;Customer Information&lt;/a&gt; 사용자가 Customer라는 Controller를 사용하라고 했지만, 해당 Route Pattern에 의해서 HomeController로 연결이 됩니다. 3.2 Route Attribute에서 특정 Route를 지정12345[Route(\"Add/&#123;user&#125;/&#123;id:int&#125;\", Name=\"AddRoute\")]public string Add(string user, int id)&#123; return $\"Add User - Name : &#123;user&#125; , ID : &#123;id&#125;\";&#125; 4. AreaProject에서 Area를 추가 할 수 있습니다.각 영역(Area)별로 다른 Controller, Model, View 및 다른 Route 규칙 등을 가집니다.Area의 특징은 다음과 같습니다. Area별로 다른 Folder안에 MVC Project의 구조들을 그대로 가지고 있습니다. Area내의 (Area명칭)AreaRegistration.cs 내에 Route 규칙을 정의합니다. Project의 Global.asax.cs내에 AreaRegistration.RegisterAllAreas();를 호출하는 부분이 추가됩니다. Attribute로 Routing하는 경우 [RouteArea(&quot;Area명칭&quot;)]으로 적용이 가능합니다. Html.ActionLink()에서 Area를 명시할 경우에는 추가정보를 적는 무명 타입란에 area를 지정하면 됩니다. 1@Html.ActionLink(\"Go to Another Area\", \"Index\", new &#123; area = \"Admin\" &#125;) 5. Disk file에 대한 요청정적 파일 (Image, html, JavaScript 등…)에 대한 접근은 그냥 해당 주소를 그대로 적어주면 접근이 됩니다.Routing system은 전달받은 URL이 disk상의 file과 매칭될 경우 Routing pattern과는 상관없이 해당 file을 전달해 줍니다.단, RouteConfig.cs에서 routes.RouteExistingFiles = true;로 설정할 경우 file을 찾기전에 Routing pattern을 먼저 적용합니다.이렇게 설정한 경우 특정 패턴에 대해서는 file로 접근을 먼저 시키고자 할때는 routes.IgnoreRoute(&quot;Content/{filename}.html&quot;)과 같은 형식으로 적용이 가능합니다.","categories":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/categories/C/"},{"name":"ASP.NET","slug":"C/ASP-NET","permalink":"http://DevStarSJ.github.io/categories/C/ASP-NET/"}],"tags":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/tags/C/"},{"name":"ASP.NET","slug":"ASP-NET","permalink":"http://DevStarSJ.github.io/tags/ASP-NET/"}]},{"title":"ASP.NET MVC 02. URL Routing","slug":"CSharp.Aspnet.02.Route","date":"2016-05-06T16:00:00.000Z","updated":"2017-05-24T03:25:11.000Z","comments":true,"path":"2016/05/07/CSharp.Aspnet.02.Route/","link":"","permalink":"http://DevStarSJ.github.io/2016/05/07/CSharp.Aspnet.02.Route/","excerpt":"","text":"ASP.NET MVC URL Routing1. URL Routing이란ASP.NET MVC로 생성된 Web Application의 경우 아래와 같은 형식으로 접근이 가능합니다. 1http://mySite.com/Home/Index 기본 URL Routing 형식으로 해석을 할 경우 mySite.com : Web Application의 주소 Home : Controller 명칭 Index : Action method 명칭 으로 동작합니다. 2. RouteConfig.cs2.1 Global.asax.cs 를 보면 아래와 같이 Route를 설정하는 Code가 있습니다.1RouteConfig.RegisterRoutes(RouteTable.Routes); 2.2 \\App_Start\\RouteConfig.cs 파일에 RouteConfig.RegisterRoute라는 static method가 있습니다.매개변수로 전달받은 RouteCollection route에 .MapRoute()로 Routing 규칙들을 추가하는 Code들이 있습니다. 3. .MapRoute() parameters3.1 nameMapping할 Routing 명칭입니다. 별 의미가 없으므로 null로 입력해도 됩니다. 3.2 urlURL 패턴을 지정합니다.Web Application 주소/ 다음부터의 패턴을 지정 할 수 있습니다. Static URL Segment : url안에 일반 문자열로 입력이 가능합니다. Dynamic URL Segment : 중괄호{ }내에 변수명을 입력하면 해당 ActionMethod에서 RouteData.Vaues[&quot;변수명&quot;]으로 읽을 수 있습니다. ex) url: &quot;Page{page}&quot;로 설정할 경우 http://mySite.com/Page3으로 접근하면 해당 Route로 mapping되며 {page}에 3의 값이 전달됩니다. 아래의 3가지 명칭은 변수명으로 지정이 불가능 합니다. controller : Controller 이름을 지정합니다. action : Action Method 이름을 지정합니다. area : Area를 지정합니다. 만약 해당 Controller의 Action Method의 argument와 같은 변수명으로 Mapping하게되면 Action Method의 argument로 그 값을 전달합니다. ex) url : &quot;{controller}/{action}/{id}로 설정하였을 경우,http://mySite.com/Product/Index/Luna란 주소로 접근할 경우ProductController에 Index(string id)라는 Action Method가 있으면 id라는 argument를 Luna로 전달하게 됩니다. 가변길이 parameter{controller}/{action}/{*all} 이라고 정의한 경우 segment가 3개 이상인 경우 모두 all변수에 할당되어서 Matching됩니다. 3.3 defaults기본값 설정이 가능합니다. 1defaults : new &#123; controller = \"Product\", action = \"Index\", id = \"Luna\" &#125; 와 같은 형식으로 지정이 가능합니다.해당 URL와 매칭되는 경우 URL 패턴의 변수명과 같은 곳에 아무런 값도 안 넣은 경우 default로 설정된 값이 사용되며,URL 패턴에 없는 변수명을 default로 설정한 경우 해당 변수명(또는 controller, action)에 대해서는 default로 설정된 값으로 동작합니다. Optinal로 설정될 경우 id = UrlParameter.Optional 해당 segment는 입력되지 않아도 Matching 된 것으로 간주됩니다. 3.4 constratinsURL parameter에 제약사항을 설정합니다. 3.4.1 Regular Expression (정규표현식)을 이용하여 검사1constraints: new &#123; page = @\"\\d+\" &#125; 위의 경우 page의 값은 숫자형식만 가능하게 됩니다. 3.4.2 여러 개의 값을 지정하여 검사1constraints: new &#123; page = @\"\\d+\", action=\"^Index$|^About$\"&#125; 위의 경우 추가로 action segment가 Index 나 About인 URL만 Matching합니다. 3.4.3 HTTP Method를 사용하여 검사12constraints: new &#123; page = @\"\\d+\", action=\"^Index$|^About$\", httpMethod = new HttpMethodConstarint(\"GET\", \"POST\")&#125; 위의 경우 추가로 GET, POST 요청만 처리하도록 제한합니다. 3.4.4 형식,범위 등의 제약조건123constraints: new &#123; page = @\"\\d+\", action=\"^Index$|^About$\", httpMethod = new HttpMethodConstarint(\"GET\", \"POST\"), id = new RangeRouteConstraint(10, 20) &#125; 위의 경우 추가로 id값이 10에서 20 사이에 경우에만 허용합니다. 1using System.Web.Mvc.Routing.Constarints; 위 namespace에 제약조건 class들이 정의되어 있으며 목록은 아래 link에서 확인이 가능합니다. https://msdn.microsoft.com/ko-kr/library/system.web.mvc.routing.constraints(v=vs.118).aspx 3.5 namespacesstring[] 타입으로 여러개의 namespace 값을 전달 받습니다.해당 값을 전달받은 경우 먼저 전달받은 namespace내의 controller부터 찾게 됩니다.배열로 전달받은 namespace들은 모두 동일한 우선순위를 가지게 됩니다.만약 특정 namespace에 우선순의를 두고자 할 경우 MapRoute()를 따로 설정하여야 합니다. 4. Segment Matching 규칙 위에 설정한 규칙부터 차례대로 적용합니다. 그러므로 동일한 segment를 가지는 Route를 여러개 설정할 경우 좀 더 특수한 경우를 먼저 선언해야 적용됩니다. ex) 123456789routes.MapRoute( name: null, url: \"Luna&#123;controller&#125;/&#123;action&#125;\");routes.MapRoute( name: null, url: \"&#123;controller&#125;/&#123;action&#125;\"); 위와 같이 설정했을 경우에는 http://mySite.com/LunaProduct/Index로 접근할 경우 Product controller의 Index Action Method를 실행하게 되며, http://mySite.com/Product/Index로 접근할 경우에도 Product controller의 Index Action Method를 실행하게 됩니다. 123456789routes.MapRoute( name: null, url: \"&#123;controller&#125;/&#123;action&#125;\");routes.MapRoute( name: null, url: \"Luna&#123;controller&#125;/&#123;action&#125;\"); 위와 같이 설정되었을 경우 segment가 2개인 경우 무조건 위에 것만 처리되며 아래에 설정된 URL패턴으로는 검사하지 않습니다.즉, http://mySite.com/LunaProduct/Index로 접근할 경우 LunaProduct controller의 Index Action Method를 실행하게 되며, (없으면 404 오류) http://mySite.com/Product/Index로 접근할 경우에도 Product controller의 Index Action Method를 실행하게 됩니다. 5. Attribute Routing위에 살펴본 것은 Rule-based Routing (규칙기반 라우팅)이었습니다.각각의 Action Method에 Attribute를 이용하여 적용하는 방법도 있습니다. 5.1 Attribute Route가 동작하도록 설정RouteConfig.cs의 RegisterRoutes(RouteCollection routes)함수 내에 routes.MapMvcAttributeRoutes();를 호출하면 Attribute 기반의 Route 기능을 활성화합ㄴ다. 5.2 Attribute Route 설정12345678public class CustomerController : Controller&#123; [Route(\"Test\")] public ActionResult Index() &#123; ... &#125;&#125; 와 같이 경우 http://mySite.com/Test로 접근할 경우 Customer Controller의 Index Action method가 실행됩니다. 12[Route(\"User/Add/&#123;user&#125;/&#123;id&#125;\"]public string Create(string user, int id) &#123; ... &#125; user와 id가 인자로 전달됩니다.각각의 인자에 제약조건 설정도 가능합니다. {id:int} : id는 int 값으로전달이 가능합니다. {password:alpha:length(6)} : password에 alpha와 length 2가지 제약조건을 설정합니다. 5.3 Prefix(접두어) 사용123456789[RoutePrefix(\"User\")]public class UserController : Controller&#123; [Route(\"~/Test\")] public ActionResult Index() &#123; ... &#125; [Route(\"Add/&#123;user&#125;\")] public ActionResult Create(string user) &#123; ... &#125;&#125; http://mySite.com/User/Add/Luna로 접근할 경우 Create Action method가 실행됩니다. http://mySite.com/Test로 접근할 경우 Index가 실행됩니다. 즉, ~/로 설정할 경우 Prefix가 무시됩니다.","categories":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/categories/C/"},{"name":"ASP.NET","slug":"C/ASP-NET","permalink":"http://DevStarSJ.github.io/categories/C/ASP-NET/"}],"tags":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/tags/C/"},{"name":"ASP.NET","slug":"ASP-NET","permalink":"http://DevStarSJ.github.io/tags/ASP-NET/"}]},{"title":"Using the gesture function with a common mouse in macOS","slug":"macOS.set.mouse","date":"2016-05-06T15:00:00.000Z","updated":"2017-04-23T10:42:10.000Z","comments":true,"path":"2016/05/07/macOS.set.mouse/","link":"","permalink":"http://DevStarSJ.github.io/2016/05/07/macOS.set.mouse/","excerpt":"","text":"macOS(OSX)에서 일반 마우스로 매직마우스의 제스쳐(gesture) 기능 사용하기맥북프로나 맥북에어의 경우 마우스없이 매직패드만으로도 사용이 편리하다는 분들이 많긴하지만,그래도 마우스를 사용하는게 익숙하신 분들은 마우스 사용을 선호합니다. 이 경우 매직패드에서 제스쳐로 제공하는 기능이 편리하기 때문에 해당 기능을 사용하기 위해서 매직마우스를 구입하는 경우가 많습니다.하지만 매직마우스 가격이 좀 후덜덜하죠. (99,000원)오픈마켓에서 조금 저렴하게 구입하더라도 8만원이 넘습니다. 키보드 단축키 확인 및 재할당사실 매직마우스에서 주로 사용하는 제스쳐 중 Mission Control, 왼쪽 Space, 오른쪽 Space 이 3가지만 사용하더라도 작업이 편리해 집니다. 기본적으로 이 기능을 굳이 매직마우스를 사용하지 않고 키보드 단축키를 사용하는 것도 가능합니다. ^는 control키를 뜻합니다.control키와 방향키 4개를 이용해서 해당 기능들이 기본으로 할당되어 있습니다. Mission Control 기능을 마우스에 할당이 기능들을 마우스 버튼에 할당하려면 시스템 환경설정 에서 Mission Control에서 가능합니다. 아래쪽에보면 키보드로는 기본 단축키들이 할당되어 있습니다. 그 오른쪽을 클릭하면 마우스버튼 또는 마우스 버튼 + 특수키(control , alt, command, shift) 조합을 이용해서도 가능합니다. 여기에서 마우스버튼을 할당하려고 눌러보면 마우스 버튼이 32번까지 할당이 가능합니다.하지만, 일반 마우스의 경우 마우스 버튼을 macOS 에서 인식하기 위해서는 전용 드라이버를 설치하거나, 별도의 프로그램을 사용해야 합니다.그리고 결정적으로 여기에서는 Space 간 이용에 대해서는 할당이 안됩니다. BetterTouchTool예전에는 무료 프로그램도 많았지만 요즘 대부분 유료화 되었으며 그래도 그 중 가장 기능이 많고 사용하기 편한 것으로는 BetterTouchTool가 있습니다.https://www.boastr.net/downloads에서 45일 Trial 로 사용이 가능하며 4,500원에서 50,000원 정도의 가격으로 구매가 가능합니다.제작사는 7,000원 정도의 가격으로 구매해주기를 추천한다고 되어 있습니다.가격별로 기능적 차이는 없습니다.그냥 donation 적인 측면이라 생각하시면 될 것입니다. BetterTouchTool 의 원래 목적은 macOS 및 개별 Application 별로 키보드, 매직마우스, 일반마우스 의 특정 버튼 및 제스쳐에 기능들을 할당하는 것이므로 매직마우스 사용자라도 구매하시면 편리하게 사용이 가능합니다. 일반마우스 사용자는 이 툴을 이용해서 기본적으로 macOS 에서 할당되지 않은 버튼이나 버튼 + 특수키(control , alt, command, shift)의 조합으로 Mission Control, 왼쪽 Space, 오른쪽 Space 등의 기능을 할당 할 수 있습니다. 제조사 제공 마우스 드라이버필자는 Logitech 사의 MX Anywhere 2 마우스를 사용중인데, 제조사에서 macOS 용 드라이버를 따로 제공해 줍니다.이렇게 별도의 드라이버를 제공하는 마우스의 경우에는 거기서 설정이 가능한 경우가 많습니다. MX Anywhere 2는 가운데 버튼에 Mission Control, 왼쪽 Space, 오른쪽 Space 이 기본적으로 할당되어 있습니다. Mission Control : 가운데 버튼 클릭 또는 누른체 위로 이동 왼쪽 Space : 가운데 버튼 누른체 좌로 이동 오른쪽 Space : 가운데 버튼 누른체 우로 이동 응용 프로그램 윈도우 : 가운데 버튼 누른체 아래로 이동 Space 이동의 경우는 비교적 자주 사용하는 기능이므로 좀 더 빨리 사용하기 위해 마우스 휠을 좌, 우로 클릭하는 것이 더 편리할 것으로 판단되어 그렇게 할당을 하였습니다. 마치며…해당 제품이 아닌 다른 마우스를 구입할 경우 제조사에서 드라이버를 제공해주지 않는다 하더라도 BetterTouchTool 툴을 이용해서 할당이 가능합니다.단, 마우스의 별도 버튼이 있거나, 휠을 좌,우 클릭으로 누르는게 가능한 마우스를 구매하셔야 좀 더 편리하게 사용이 가능하리라 생각됩니다. 조금 저렴한 버튼이 많은 마우스(휠 좌,우 클릭 지원)와 BetterTouchTool 구매를 하더라도 매직마우스 보다는 확실히 더 저렴하니깐요. 매직마우스 + BetterTouchTool 의 조합의 경우는 더 많은 작업이 가능하겠지만요.세손가락 클릭, 네손가락 클릭 등 매직마우스 상의 제스쳐를 이용해서 벼나별 기능의 할당이 가능합니다.","categories":[{"name":"Tips","slug":"Tips","permalink":"http://DevStarSJ.github.io/categories/Tips/"},{"name":"macOS","slug":"Tips/macOS","permalink":"http://DevStarSJ.github.io/categories/Tips/macOS/"}],"tags":[{"name":"macOS","slug":"macOS","permalink":"http://DevStarSJ.github.io/tags/macOS/"}]},{"title":"ASP.NET MVC 01. Project","slug":"CSharp.Aspnet.01.MVC.Project","date":"2016-05-06T15:00:00.000Z","updated":"2017-04-23T10:33:21.000Z","comments":true,"path":"2016/05/07/CSharp.Aspnet.01.MVC.Project/","link":"","permalink":"http://DevStarSJ.github.io/2016/05/07/CSharp.Aspnet.01.MVC.Project/","excerpt":"","text":"MVC Project 항목요약 /App_Data : File기반 저장소의 데이터 파일,XML 파일 등을 저장 /App_Start : Route, Filter, Contents 등에 대한 정의 같은 Project에 대한 주요 구성 설정들 /RouteConfig.cs : Route 정보 /Areas : 큰 Application을 작은 Area로 나누는 방법 /bin : compile된 어셈블리 및 기타 어셈블리들이 위치, 소스 제어에 포함시켜서는 안됨 /Content : css, Image 등 static contents들 /Controllers : Controller classes /Models : VewModel, Domain Model 들. 별도 Project에 Domain Model을 정의하는 방법을 더 많이 선호 /Scripts : JavaScript Library /Views : View, PartialView /Web.config : View가 동작하는데 필요한 구성, ISS에 의해 View 파일 자체가 서비스되지 않도록 제한하는데 필요한 구성, View에 import하는 namespace에 대한 정보 등… /Share : 특정 Controller에 종속되지 않는 Layout, View /Global.asax : 전역 ASP.NET Application class. /Web.config : Application을 위한 구성 파일 MVC 규약 Controller /Controllers/명칭Controller.cs 란 이름으로 저장 HTML helper method에서 명칭만 입력하면 명칭Controller class를 자동으로 찾아줌 View /Views/명칭 폴더안에 저장 해당 Controller의 Action method 명칭으로 View이름을 정함 : return View(); ex) ProductController의 Index에 대한 View는 /View/Product/Index.cshtml 이란 이름으로 작성 다른 View 이름을 명시적으로 사용도 가능함 : return View(&quot;View명칭&quot;); Controller 명칭의 폴더에서 View를 먼저 찾은 후 /Views/Shared 폴더에서 찾는다. Layout _(언더바)로 시작 기본적으로 /Views/_ViewStart.cshtml을 모든 View에 적용 특정 Layout을 지정하면 _ViewStart.cshtml을 적용하지 않음 : Layout = &quot;~/Views/Shared/_MyLayout.cshtml&quot;; 아무런 Layout도 참조하지 않으려면 null값을 대입 : Layout = null;","categories":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/categories/C/"},{"name":"ASP.NET","slug":"C/ASP-NET","permalink":"http://DevStarSJ.github.io/categories/C/ASP-NET/"}],"tags":[{"name":"C#","slug":"C","permalink":"http://DevStarSJ.github.io/tags/C/"},{"name":"ASP.NET","slug":"ASP-NET","permalink":"http://DevStarSJ.github.io/tags/ASP-NET/"}]},{"title":"Make Symbol Repository for Visual Studio","slug":"Devops.SymbolRepository","date":"2016-04-03T15:00:00.000Z","updated":"2017-04-23T09:56:54.000Z","comments":true,"path":"2016/04/04/Devops.SymbolRepository/","link":"","permalink":"http://DevStarSJ.github.io/2016/04/04/Devops.SymbolRepository/","excerpt":"","text":"Make Symbol Repository for Visual Studio1. Debugging Tools for Windows 설치https://msdn.microsoft.com/en-us/library/windows/hardware/ff551063(v=vs.85).aspx 2. Symbol 등록1call svnindex.cmd -source=&quot;&#123;SolutionFolder&#125;&quot; -symbols=&quot;&#123;SolutionFolder&#125;\\bin\\Unicode Release&quot; 1symstore.exe add /r /f &quot;&#123;SolutionFolder&#125;\\bin\\Unicode Release\\*.*&quot; /s &quot;&#123;SymbolRepository&#125;&quot; /t &quot;&#123;Name&#125;&quot; /compress e.g.call svnindex.cmd -source=”d:\\svn\\trunk” -symbol=”d:\\svn\\trunk\\bin\\Unicode Release”symstore add /r /f “d:\\svn\\trunk\\bin\\Unicode Release*.*” /s “d:\\symbol” /t “MyApp” /compress 통상적으로 symstore.exe는 아래 폴더에 위치합니다. 1C:\\Program Files\\Debugging Tools for Windows (x64) svnindex.cmd는 설치된 Debugging Tools for Windows 폴더 아래 srcsrv 폴더 내에 있으며 다른 CI 제품들의 cmd 파일들도 존재합니다. 3. 저장된 Symbol 확인 {SymbolRepository}\\000Admin\\server.txt에서 확인 각 ID별 Build일시. 이름 (/t 옵션 뒤에 이름) 확인이 가능 4. Symbol 삭제1symstore del /i ID /s &quot;&#123;SymbolRepository&#125;&quot; e.g.symstore del /i 142 /s “d:\\symbol” symstore 사용법 (Symbol 삭제 포함)https://msdn.microsoft.com/en-us/library/windows/desktop/ms681378(v=vs.85).aspx","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://DevStarSJ.github.io/categories/DevOps/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://DevStarSJ.github.io/tags/DevOps/"},{"name":"CI/CD","slug":"CI-CD","permalink":"http://DevStarSJ.github.io/tags/CI-CD/"}]},{"title":"소프트스킬 평범한 개발자의 비범한 인생 전략 71가지","slug":"softskill","date":"2016-03-11T15:00:00.000Z","updated":"2017-04-30T03:46:52.000Z","comments":true,"path":"2016/03/12/softskill/","link":"","permalink":"http://DevStarSJ.github.io/2016/03/12/softskill/","excerpt":"","text":"소프트스킬 : 평범한 개발자의 비범한 인생 전략 71가지 길벗 존 손메즈 지음 / 이미령, 김태곤 옮김 책소개 Link : http://www.gilbut.co.kr/book/bookView.aspx?bookcode=BN001351&amp;page=1&amp;TF=T 안녕하세요. 이번에 소개해 드릴 책은 나는 프로그래머다에서 정개발님이 추천해주신 소프트스킬이라는 책입니다.이전에 읽은 훌륭한 프로그래머가 되는 법 : 프로젝트와 팀을 성공으로 이끄는 선배 개발자의 노하우와는 또 완전히 다른 느낌의 책이었습니다.훌륭한 프로그래머가 되는 법은 뭔가 율법서 같이 딱딱하면서 실제 업무를 훌륭하게 하는 방법에 대해서 레퍼런스 식으로 소개하는 책이라면 소프트스킬은 개발 이외의 개발자의 삶에 대해서 저자가 조곤조곤 조언해 주는 내용으로 부드러운 대화같은 책입니다. 여기서의 소프트스킬은 Software의 소프트가 아니라 Hard Skill : 업무적으로 필요한 기술들 Soft Skill : 업무이외의 필요한 기술들로 구분했을 때의 소프트스킬입니다. 책표지의 작은 글씨로 흔한 개발자. 나는 어떻게 살아야 하나 ? 란 문구가 참 짠~하게 와닿더라구요.총 7개의 큰 부분으로 나뉘어져 있습니다. 1부 경력스타트업, 중소기업, 대기업 별 근무환경 및 특징에 대한 간략한 소개와개발회사와 비개발회사에서의 개발자의 처우 등… 부터해서승진, 면접, 이력서 등 다양한 내용들을 다루고 있습니다. 기술을 너무 신봉하지 말라는 말과 3년이 지난 기술 중 많은 부분은 더 이상 쓸모없는 기술이다 라는 말이 가장 기억에 남네요. 2부 셀프마케팅블로그, SNS, 외부강연 등을 통해서 자신을 마케팅하는 방법을 소개하고 있습니다. 3부 학습개발자의 공부법을 소개해주고 있습니다. 우리는 한번도 독학하는 법을 배워본적이 없는데 개발자로서 공부할 때 가장 필요한 것은 독학을 하는 방법이라는 말로 시작하여, 새로운 기술을 익이는 10단계 학습법은 주니어 개발자들에겐 반드시 알려줘야 할 내용이라 생각됩니다. 남을 가르치는 과정에서 자신이 얼마나 더 많이 배울 수 있는가에 대한 얘기는 참 많이 공감이 갔습니다. 필자도 블로그에 뭔가를 정리하는 이유가 책을 읽는 것은 그냥 그 당시에만 머리에 남고 시간이 조금만 지나도 잊혀지게 되며, 그것을 직접 실습해보면 조금 더 그 기억이 오래가며, 해당 기술에 대한 두려움이 있었던 경우에는 그 두려움을 없에주는데 도움이 되며, 블로그에서 글로 정리를 하다보면 어떤 순서로 쓸것인지를 생각하면서 그 동안 머리속에 뒤죽박죽으로 있던 지식을 체계적으로 모아서 분류하는 과정이 일어나서 큰 도움이 되었습니다. 하지만, 아직도 늘 누군가가 책, 강연 이런 얘기를 하면… 책은 읽는 것이지 쓰는게 아니다.강연은 듣는 것이지 하는게 아니다. 라고 발뺌을 하고 있습니다. ;;; 4부 생산성집중력을 높여서 작업의 생산성을 높이는 방법에 대해서 소개해 주고 있습니다. 뽀모도로 기법(https://ko.wikipedia.org/wiki/뽀모도로_기법)에 대해 소개해 주고 있어서 한번 날잡고 해봤습니다.정말로 한 2,3일 정도 걸릴 것이라 생각했던 작업이 하루만에 끝나는걸 보고 스스로 놀랐습니다. 하지만, 그때 했던 작업이 뭔가를 구현하기 위해서 개발하는 과정이라서 가능했던 것이지, 회사의 모든 업무에서 완벽하게 25분간 주위의 방해를 받지 않고 집중하는 것은 무리가 있어 보이며, TDD가 되지 않는 개발환경에서 UI를 손으로 직접 조작해가면서, 일정 시간 이상 조작하며 테스트 하며 디버깅 하기에는 25분의 집중이라는게 큰 의미가 없어 보였습니다. 자택근무나 카페 같은데서 모각코(모여서 각자 코딩)하는 경우에는 상당히 효과적인 방법으로 보입니다. 5부 재무관리월급을 어떻게 효율적으로 관리를 하는 방법과 부동산투자, 옵션투자에 대해 소개하고 있습니다. 6부 건강음식, 수면, 운동의 중요성과 효율적인 방법에 대해 소개하고 있습니다. ###7부 영혼 정신이 신체를 지배한다는 사실과 긍정적 사고의 중요성, 심지어 연애문제까지도 짧게나다 다루고 있습니다. 총평개발자를 위한 자기개발서가 몇년전만 하더라도 많이 없었는데, 요즘은 많아 졌습니다.이책은 다른 책과는 다르게 개발자를 위한 자기개발서이지만, 기술적인 내용이 아니라 기술 이외의 자기관리를 하는 방법에 대해서 총괄적으로 다룬 책입니다.모두들 한번씩은 꼭 읽어보셨으면 합니다.이 책의 저자는 33세에 이미 은퇴를 한 성공한 개발자입니다.이 책 한권에 모든 내용이 다 들어있지 않습니다. 저자가 이 책에서 소개한 내용중 더 자세한 것을 알고 싶을 경우 보면 좋은 책에 대해서도 소개해 주고 있습니다.물론 한국과 미국과는 여러가지 상황이 다르긴 하겠지만 그걸 감안하고 보더라도 이책을 보기 전의 나와 보고난 후의 내가 확실히 달라졌고, 앞으로도 계속 달라져야 할 것이다라고 느끼고 있습니다.","categories":[{"name":"Book","slug":"Book","permalink":"http://DevStarSJ.github.io/categories/Book/"},{"name":"Review","slug":"Book/Review","permalink":"http://DevStarSJ.github.io/categories/Book/Review/"}],"tags":[{"name":"Book","slug":"Book","permalink":"http://DevStarSJ.github.io/tags/Book/"},{"name":"Review","slug":"Review","permalink":"http://DevStarSJ.github.io/tags/Review/"}]},{"title":"Oracle hint","slug":"Oracle.hint","date":"2016-02-25T17:00:00.000Z","updated":"2017-04-24T00:20:38.000Z","comments":true,"path":"2016/02/26/Oracle.hint/","link":"","permalink":"http://DevStarSJ.github.io/2016/02/26/Oracle.hint/","excerpt":"","text":"LEADING(테이블) : 해당 Table 부터 읽음 QB_NAME(이름) : 해당 query block에 이름을 지어준다. 그래서 다른 곳에서 이름@테이블명 으로 해당 테이블을 지정 할 수 있다. JOIN 방법 USE_NL(테이블) : outer table을 테이블(inner table)과 Nested Loop Join 방식으로 JOIN을 시도 Semi Join : 1 row만 JOIN에 성공하면 더이상 inner쪽을 보지 않고 outer의 다음 row를 찾음 NL_SJ, HASH_SJ, MERGE_SJ Anti Join : 일치하지 않는 data를 추출 (NOT IN, NOT EXISTS, MINUS) NL_AJ, HASH_AJ, MERGE_AJ Subquery Unnesting 관련 UNNEST : 풀어서 JOIN 방식으로 유도 NO_UNNEST : 풀지말고 Filter 방식으로 최적화 유도 View Merging NO_MERGE(테이블) : main query 와 inline view를 JOIN으로 풀지말고 inline view를 먼저 실행 MERGE(테이블) : main query와 inline view를 JOIN으로 풀어서 최적화를 시도 PUSH_PRED(인라인뷰) : (Push Predicate, 조건절 Push) main query에서 먼저 filtering하여 그 결과를 inline view의 filter 조건으로 넣어라. PUSH_SUBQ : (Push Subquery) 실행계획상 가능한 앞 단계에서 subquery filtering을 하여 main query의 범위를 줄이고자 할때, NO_UNNEST와 같이 사용되어야 함 Concatenation (주로 OR절 처리) USE_CONCAT : UNION ALL로 표현 NO_EXPAND : 나누지 말고 그대로 실행 FULL(테이블) : 해당 테이블을 full scan 한다. PARALLEL(테이블 프로세스수) : 해당 테이블을 명시한 프로레스수 만큼 병렬로 처리한다. APPEND : INSERT를 APPEND 모드로 수행","categories":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/categories/Database/"},{"name":"Oracle","slug":"Database/Oracle","permalink":"http://DevStarSJ.github.io/categories/Database/Oracle/"}],"tags":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/tags/Database/"},{"name":"Oracle","slug":"Oracle","permalink":"http://DevStarSJ.github.io/tags/Oracle/"},{"name":"SQLP","slug":"SQLP","permalink":"http://DevStarSJ.github.io/tags/SQLP/"}]},{"title":"Codejock Xtreme ToolkitPro Chart Object Diagram","slug":"xtp.chart.diagram","date":"2016-02-23T06:28:00.000Z","updated":"2017-05-30T00:07:37.000Z","comments":true,"path":"2016/02/23/xtp.chart.diagram/","link":"","permalink":"http://DevStarSJ.github.io/2016/02/23/xtp.chart.diagram/","excerpt":"","text":"Xtreame Toolkip Pro의 Chart Control인 CXTPChartControl 사용시 알아야 할 class들 간의 상관관계를 Diagram으로 표시하였습니다. XTPChart를 조금 사용해 본 소감은…만들다 말았다는 느낌 ??? Mouse Click 이벤트 처리 같은거 ???NM_CLICK만 처리가 됩니다.ButtonDown, ButtonUp 같은거 처리 안됩니다.그냥 상속받아서 처리하세요.아래 글 참조하시면 됩니다. http://devluna.blogspot.kr/2016/02/mfc-control-message.html 분명 X-Argument로 날짜형식을 넣게는 되어 있는데,AxisRange를 이용해서 SetViewMin/MaxValue로 범위를 지정하면….제대로 안됩니다. double이나 CString 형으로는 잘 됩니다.굳이 날짜형식으로 쓸려면 Series가 바뀔때마다 GetMin/MaxValue로 값을 얻어와서그 값으로 계산을 해서 다시 SetViewMin/MaxValue로 값을 넣어야 합니다.자동으로 수정이 안됩니다. ;;; 자세한 설명은 생략하겠습니다. 혹시나 Chart를 많이 안써보신 분들이 있을 수 있으니 대략적인 용어 및 뜻만 표기하겠습니다. Title Chart에 표시되는 명칭입니다. Series Chart에서 값을 나타내는 선을 나타냅니다. 각 Point 들이 모여서 그 추이를 선으로 연결한 것입니다. 각 Point는 X, Y 값의 2차원 값을 나타냅니다. X 쪽을 Argument 라고 하며, Y 쪽을 Value 라고 합니다. Marker Series 에 보면 각각의 Point를 눈에 띄게 좀 큰 점으로 표현한 것을 Marker라고 합니다. Axis X, Y 축 입니다. Legend 각 Series 들이 어떤 값을 나타내는지 Chart 한쪽에 색깔 별로 소개해 놓은 범주를 의미합니다. ConstantLine Chart 상의 특정 지점에 기준 선을 그어 놓는 경우가 있습니다. 통계 관련 Chart의 경우 Y-Axis 상에 +- 1 sigma에 점선을 가로로 그어 놓는다던지 … X-Axis 상의 특정 시간안에 값들에 대해서 표시하기 위해서 세로로 그어 놓는 등… 위 그림은 Posting 목적으로 해상도를 줄여 놓았습니다.원래 크기대로 보실려면 아래 Link를 눌러주세요. https://github.com/DevStarSJ/Study/blob/master/Blog/CPP/MFC/image/XTP.diagram.png?raw=true","categories":[{"name":"CPP","slug":"CPP","permalink":"http://DevStarSJ.github.io/categories/CPP/"},{"name":"MFC","slug":"CPP/MFC","permalink":"http://DevStarSJ.github.io/categories/CPP/MFC/"}],"tags":[{"name":"CPP","slug":"CPP","permalink":"http://DevStarSJ.github.io/tags/CPP/"},{"name":"MFC","slug":"MFC","permalink":"http://DevStarSJ.github.io/tags/MFC/"},{"name":"ToolkitPro","slug":"ToolkitPro","permalink":"http://DevStarSJ.github.io/tags/ToolkitPro/"}]},{"title":"Oracle Plan,Trace","slug":"Oracle.read.plan.trace","date":"2016-02-19T17:00:00.000Z","updated":"2017-04-24T00:25:31.000Z","comments":true,"path":"2016/02/20/Oracle.read.plan.trace/","link":"","permalink":"http://DevStarSJ.github.io/2016/02/20/Oracle.read.plan.trace/","excerpt":"","text":"Oracle Plan, Trace 읽는 법SQL Tuning을 하기 위해서 가장 기본으로 알아야 하는 것이 Plan과 Trce를 읽는 방법입니다.그래야 어느 곳이 비효율적인지를 알아내서 그 부분을 중심으로 Tuning 전략을 세울 수 있습니다. 아래 내용중 SELECT Tuning시 중요하게 봐야할 사항은 다음과 같습니다. 실행 순서 : Plan, Trace 동일 Trace 결과 : Row Source Operation의 각 수치들의 의미 (rows, cr만 알아도 됩니다.) 1. Plan 읽는 법 Plan은 SQL을 실행하기 전에 Optimizer에 의해 선택된 최적의 실행 경로 및 계산되어진 예상 Cost를 보여줍니다. 1234567891011121314151617181920212223242526*************************[Explain Plan Time: 2016/02/21 14:01:15]*************************Execution Plan----------------------------------------------------------- 0 SELECT STATEMENT Optimizer=ALL_ROWS (Cost=5 Card=5 Bytes=325) 1 0 SORT (ORDER BY) (Cost=9 Card=5 Bytes=325) 2 1 UNION-ALL 3 2 COUNT (STOPKEY) 4 3 VIEW (Cost=5 Card=1 Bytes=65) 5 4 SORT (ORDER BY STOPKEY) (Card=1 Bytes=14) 6 5 FILTER 7 6 TABLE ACCESS (FULL) OF 'BBS' (TABLE) (Cost=3 Card=10 Bytes=140) 8 2 VIEW (Cost=4 Card=4 Bytes=260) 9 8 SORT (ORDER BY) (Cost=4 Card=4 Bytes=56) 10 9 COUNT (STOPKEY) 11 10 TABLE ACCESS (FULL) OF 'BBS' (TABLE) (Cost=3 Card=5 Bytes=70)-----------------------------------------------------------Predicate information (identified by operation id):----------------------------------------------------------- 3 - filter(ROWNUM&lt;=4) 5 - filter(ROWNUM&lt;=4) 6 - filter(NULL IS NOT NULL) 7 - filter(\"NUM\"&lt;10) 10 - filter(ROWNUM&lt;=4) 11 - filter(\"NUM\"&gt;10)----------------------------------------------------------- 1.1 실행순서 (access path) sibling 사이에서는 먼저 나온 것을 먼저 처리 child가 있는 경우 child부터 다 처리하고 parent 처리하기 이 두가지만 기억하면 됩니다. 위 Plan을 기준으로 처리 순서는 다음과 같습니다.(0 ~ 11까지 있는 왼쪽의 Index를 사용하겠습니다.) 17 -&gt; 6 -&gt; 5 -&gt; 4 -&gt; 3 -&gt; 11 -&gt; 10 -&gt; 9 -&gt; 8 -&gt; 2 -&gt; 1 -&gt; 0 (4) UNION-ALL 아래에 2개의 child(3,8)가 있습니다. 이 둘중 위에 있는 (3)부터 처리를 해야하는데 (3)은 child가 있으므로 가장 안쪽부터 처리합니다. (3)의 child를 다 처리한 후에 자신의 sibling인 (8)을 처리해야하는데, (8)도 child가 있으므로 안쪽부터 처리합니다. (3, 8)이 모두 처리된 후에 (2)부터 쭉 처리하면 됩니다. 1.2 예상 성능지표 (Cost-based Optimizer Mode에서만 표시) Cost : Cost 예상 지수. 클수록 성능상 (CPU 점유, Disk I/O, 수행시간 등…) 안좋다는 의미입니다. Card : (Computed Cardinality) : CBO상 계산된 예상되는 return row 입니다. Bytes : return row의 byte수 입니다. 1.3 Predicate information각 단계별 filter 조건이 어떻게 적용되었다는 정보를 보여줍니다. 2. Trace 읽는 법 Trace는 실제 실행된 경로와 그 성능상 중요 수치들을 보여줍니다. 123456789101112131415161718192021222324Compile Time : 2015/07/09 13:31:22Trace File : c:\\oracle\\diag\\rdbms\\orcl\\orcl\\trace\\orcl_ora_11048.trcTrace Version : 11.2.0.1.0********************************************************************************SELECT * FROM SCOTT.EMP WHERE DEPTNO = :\"SYS_B_0\"Call Count CPU Time Elapsed Time Disk Query Current Rows------- ------ -------- ------------ ---------- ---------- ---------- ----------Parse 1 0.000 0.000 0 0 0 0Execute 1 0.000 0.001 0 0 0 0Fetch 1 0.000 0.000 0 3 0 0------- ------ -------- ------------ ---------- ---------- ---------- ----------Total 3 0.000 0.001 0 3 0 0Misses in library cache during parse : 1Optimizer Goal : ALL_ROWSParsing user : SYS (ID=0)Rows Row Source Operation------- ----------------------------------------------------------------------- 0 TABLE ACCESS FULL EMP (cr=3 pr=0 pw=0 time=0 us cost=2 size=190 card=5 2.1 Row Source Operation 읽는법상대적으로 중요한 Row Source Operation 읽는 법부터 소개해드리겠습니다.Plan과 같은 형식으로 실행 경로를 보여 줍니다.읽는 법은 Plan과 같으며 괄호 안에 나오는 성능지표 값을 해석하는 것이 중요합니다. Rows (왼쪽) : return row 수 입니다. 해당 단계에서 몇건의 row가 결과로 return 되었는지 알려줍니다. cr : (Consistent Mode Block Read) 총 읽은 block수 입니다. 의미상은 DB Buffer Cache에서 읽은 block수 이지만, disk상에서 읽은 경우에도 buffer로 먼저 올린 후에 읽어야 하므로 사실상 disk + cache에서 읽은 총 수라고 해석하면 됩니다. pr : (Physical Disk Block Read) disk에서 읽은 block수 입니다. pw : (Physical Disk Block Write) disk에 저장한 block수 입니다. time : 소요시간 (microsecond 단위) cost : cost (성능상) size : data size card : (cardinality) 2.2 Call TableTunning시 사실상 크게 볼 필요 없습니다. Call Parse : Cursor를 Parsing하고 Execution Plan을 생성하는 단계 Execute : Cursor를 실행하는 단계 Fetch : 결과 Record를 Fetch하는 단계 Count : 수행 회수 CPU : CPU 사용시간 Elapsed : 수행시간 ( CPU time + Wait time ) Disk : Disk에서 읽은 Block수 Query : Consistent Mode에서 읽은 Block수 (Query 수행 시점에 읽은 읽기 전용 Block) Current : Current Mode에서 읽은 Block수 (Table을 액세스하는 시점에 읽은 수정할 Block) Rows : 읽거나 갱신한 처리 건수 참조 Slide좀 더 자세한 사항을 알고 싶으시면 아래 Slide를 참고해주세요. [Oracle Architecture][2015 04-17] Consistent vs Current : http://www.slideshare.net/seokjoonyun9/oracle-architecture2015-0417-consistent-vs-current [2015-06-12] Oracle 성능 최적화 및 품질 고도화 1 : http://www.slideshare.net/seokjoonyun9/20150612-oracle-1 [2015-07-10-윤석준] Oracle 성능 관리 &amp; v$sysstat : http://www.slideshare.net/seokjoonyun9/20150710-oracle-vsysstat","categories":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/categories/Database/"},{"name":"Oracle","slug":"Database/Oracle","permalink":"http://DevStarSJ.github.io/categories/Database/Oracle/"}],"tags":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/tags/Database/"},{"name":"Oracle","slug":"Oracle","permalink":"http://DevStarSJ.github.io/tags/Oracle/"},{"name":"SQLP","slug":"SQLP","permalink":"http://DevStarSJ.github.io/tags/SQLP/"}]},{"title":"사용자 정의 MFC Control의 Message 처리","slug":"mfc.wnd.message","date":"2016-02-16T06:28:00.000Z","updated":"2017-05-29T23:33:39.000Z","comments":true,"path":"2016/02/16/mfc.wnd.message/","link":"","permalink":"http://DevStarSJ.github.io/2016/02/16/mfc.wnd.message/","excerpt":"","text":"사용자 정의 MFC Control의 Message 처리CWnd를 상속받아서 사용자가 작성한 MFC Control의 메세지 처리하는 방법을 소개해드리겠습니다. 통상적으로 Dialog, View, FormView (앞으로 편의상 Dialog라 칭함)에 Control을 올려서 사용하는데,그 구현자체를 Control안에서 하는 경우도 있지만,해당 Control을 사용하고 있는 Dialog에서 구현을 해야하는 경우도 있습니다.2개 이상의 Control을 같이 활용하려면 그렇게 해야 하죠. 12Textbox에 숫자를 적어두고 Button을 눌렀을 경우 해당 숫자를 화면에 AfxMessageBox로 출력하는 경우 해당 처리는 Button에서 하는게 아니라 Textbox와 Button을 가지고 있는 Dialog에서 하는게 편합니다. 3가지 방법이 있습니다. Message로 처리 Command로 처리 Notify로 처리 각각에 대해서 소개해 드리겠습니다. 준비사항먼저 간단하게 Dialog 기반으로 MFC Application Project를 생성해주세요. 그런 다음 아래의 2개의 File을 추가합니다. UserWnd.h1234567891011121314#pragma once#include \"afxwin.h\"#define WM_USER_WND WM_USER + 10001 // User-defined Message (#1)class CUserWnd : public CWnd&#123;public: HWND m_hwndDlg = nullptr; // HWND of Parent Dialog (#2)protected: DECLARE_MESSAGE_MAP() // Message Map Macro (#3) afx_msg void OnLButtonDown(UINT nFlags, CPoint point); // Mouse left button click event (#4)&#125;; #1 : 사용자 정의 메세지 입니다. #2 : 메세지를 보낼려면 해당 메세지를 받을 Dialog의 pointer나 HWND값이 필요합니다. HWND를 알고 있는 경우 : ::SendMessage(m_hwndDlg, 메세지, WPARAM, LPARAM); Dialog의 pointer를 알고 있는 경우 : pointer-&gt;SendMessage(메세지, WPARAM, LPARAM); #3 : Message Map을 사용할려면 헤더파일에 선언해줘야할 매크로 입니다. #4 : 예제로 마우스 왼쪽 버튼을 눌렀을 경우 Dialog로 Message를 전달하기 위하여 해당 메세지를 사용했습니다. UserWnd.cpp1234567891011121314151617181920212223#include \"stdafx.h\"#include \"UserWnd.h\"BEGIN_MESSAGE_MAP(CUserWnd, CWnd) // Message Map (#1) ON_WM_LBUTTONDOWN() // Mouse left button click event (#2)END_MESSAGE_MAP()void CUserWnd::OnLButtonDown(UINT nFlags, CPoint point) // Mouse left button click event (#3)&#123; HWND hWnd = GetSafeHwnd(); if (hWnd == NULL) return; if (!::IsWindow(hWnd)) return; int nID = GetDlgCtrlID(); if (m_hwndDlg != nullptr) &#123; &#125; CWnd::OnLButtonDown(nFlags, point); // Call Parent Function (#4)&#125; #1 : Message Map 정의 부분입니다. 첫번째 인자 : 해당 class를 적어줍니다. 두번째 인자 : 부모 class를 적어줍니다. 해당 class 내에 적어주지 않은 메세지에 대해서는 부모 class에서 처리하게 됩니다. 만약 CXTPChartControl을 상속받아서 만든 사용자 정의 Control일 경우 두번째 인자에 CXTPChartControl을 적어줘야 합니다. #2 : MFC에서 미리 정의해놓은 것으로 마우스 왼쪽 버튼 눌렀을때 OnLButtonDown()을 실행하게 됩니다. #3 : 사용자 정의 메세지를 보내기위해 필요한 값들 HWND, ControlID를 가지고 있습니다. if 구문 안에서 각각의 메세지 타입에 따른 구현이 달라집니다. #4 : 부모 class에서 해당 메세지에 대한 동작을 계속 하도록 호출해 줍니다. 부모 class의 작업이 필요없다면 이 줄은 삭제하면 됩니다. Resource.h UserWnd의 Control ID를 생성해줍니다. 1#define IDC_USER_WND 10001 Dialog Header file (필자의 경우 UserCtrlMsgDlg.h) UserWnd.h를 추가해 주세요. 1#include \"UserWnd.h\" CUserWnd 타입의 멤버를 선언해 주세요. 1CUserWnd m_wndUser; Dialog cpp file (필자의 경우 UserCtrlMsgDlg.cpp) OnInitDialog() 에서 UserWnd를 생성해 줍니다. 123// TODO: Add extra initialization herem_wndUser.m_hwndDlg = GetSafeHwnd();m_wndUser.Create(NULL, _T(\"\"), WS_VISIBLE | WS_BORDER, CRect(0, 0, 100, 100), this, IDC_USER_WND); 이로서 준비는 끝났습니다.위에서 언급한 3가지 방법 (Message, Notify, Command)에 대해서 어떤 방법으로 구현을 하더라도 이 준비과정은 똑같습니다. 1. Message 방식 Dialog에 해당 User Control을 1개만 사용할 경우 유용합니다. Dialog에 Message로 전달하는 방식입니다. return값을 받을수 있기 때문에 User Control에서 그 값에 따라 처리가 가능합니다. 대신 Message 전달 이후 return값을 받아야 하므로 해당 처리가 끝날때까지 대기하게 됩니다. Dialog에 같은 User Control이 여러 개 있을 경우 모두 같은 Message로 전달되므로, Parameter로 Control ID를 보내는 등의 방법을 사용하여 Dialog에서 처리하는 함수 내부에서 구분하여 사용해야 합니다. UserWnd.cppOnLButtonDown 함수 내부에 아래와 같이 1줄을 추가 12345678910111213141516void CUserWnd::OnLButtonDown(UINT nFlags, CPoint point)&#123; HWND hWnd = GetSafeHwnd(); if (hWnd == NULL) return; if (!::IsWindow(hWnd)) return; int nID = GetDlgCtrlID(); if (m_hwndDlg != nullptr) &#123; ::SendMessage(m_hwndDlg, WM_USER_WND, nID, NULL); &#125; CWnd::OnLButtonDown(nFlags, point);&#125; Dialog Header file (필자의 경우 UserCtrlMsgDlg.h)Message를 처리할 함수를 선언해주세요. 1afx_msg LRESULT OnUserWnd(WPARAM wParam, LPARAM lPraram); Dialog cpp file (필자의 경우 UserCtrlMsgDlg.cpp)Message Map에 아래 1줄을 추가해주세요. 1ON_MESSAGE(WM_USER_WND, OnUserWnd) ON_MESSAGE 경우 Message번호 와 실행할 함수를 인자로 설정해줍니다. Command를 처리할 함수를 구현합니다. 12345678LRESULT CUserCtrlMsgDlg::OnUserWnd(WPARAM wParam, LPARAM lPraram)&#123; int nID = (int)wParam; // 해당 ID를 비교해서 Control 구분 가능 AfxMessageBox(_T(\"ON MESSAGE\")); return TRUE;&#125; 이제 실행 후 왼쪽 상단의 검은색 선 안을 누르면 해당 메세지가 출력되는 것을 확인 할 수 있습니다. 2. Notify 방식 Dialog에 해당 User Control이 여러개 있고, 전달한 메세지 종류가 2가지 이상인 경우 유용합니다. Dialog에 Notify로 알려주고 User Control은 계속 남은 처리를 진행합니다. UserWnd.cppOnLButtonDown 함수 내부에 아래와 같이 NMHDR 선언과 SendMessage를 추가 1234567891011121314151617181920void CUserWnd::OnLButtonDown(UINT nFlags, CPoint point)&#123; HWND hWnd = GetSafeHwnd(); if (hWnd == NULL) return; if (!::IsWindow(hWnd)) return; int nID = GetDlgCtrlID(); if (m_hwndDlg != nullptr) &#123; NMHDR nmhdr; nmhdr.code = WM_USER_WND; nmhdr.idFrom = nID; nmhdr.hwndFrom = hWnd; ::SendMessage(m_hwndDlg, WM_NOTIFY, nID, (LPARAM)&amp;nmhdr); &#125; CWnd::OnLButtonDown(nFlags, point);&#125; Dialog Header file (필자의 경우 UserCtrlMsgDlg.h)Message를 처리할 함수를 선언해주세요. 1afx_msg void OnNotyfyUserWnd(NMHDR* pNMHDR, LRESULT* pResult); Dialog cpp file (필자의 경우 UserCtrlMsgDlg.cpp)Message Map에 아래 1줄을 추가해주세요. 1ON_NOTIFY(WM_USER_WND, IDC_USER_WND, OnNotyfyUserWnd) ON_NOTIFY 경우 Message번호, Contril ID와 실행할 함수를 인자로 설정해줍니다. Command를 처리할 함수를 구현합니다. 1234void CUserCtrlMsgDlg::OnNotyfyUserWnd(NMHDR* pNMHDR, LRESULT* pResult)&#123; AfxMessageBox(_T(\"ON NOTIFY\"));&#125; 3. Command 방식 Dialog에 해당 User Control 별로 전달할 메세지가 1가지 밖에 없을 경우 유용합니다. e.g. button의 경우 눌렀을 경우에만 메세지를 전달하면 되고, 나머지 경우는 전달하지 않아도 될 경우 유용합니다. UserWnd.cppOnLButtonDown 함수 내부에 아래와 같이 1줄을 추가 12345678910111213141516void CUserWnd::OnLButtonDown(UINT nFlags, CPoint point)&#123; HWND hWnd = GetSafeHwnd(); if (hWnd == NULL) return; if (!::IsWindow(hWnd)) return; int nID = GetDlgCtrlID(); if (m_hwndDlg != nullptr) &#123; ::SendMessage(m_hwndDlg, WM_COMMAND, nID, NULL); &#125; CWnd::OnLButtonDown(nFlags, point);&#125; Dialog Header file (필자의 경우 UserCtrlMsgDlg.h)Command를 처리할 함수를 선언해주세요. 1afx_msg void OnCommandUserWnd(); Dialog cpp file (필자의 경우 UserCtrlMsgDlg.cpp)Message Map에 아래 1줄을 추가해주세요. 1ON_COMMAND(IDC_USER_WND, OnCommandUserWnd) ON_COMMAND의 경우 Control ID 와 실행할 함수를 인자로 설정해줍니다. Command를 처리할 함수를 구현합니다. 1234void CUserCtrlMsgDlg::OnCommandUserWnd()&#123; AfxMessageBox(_T(\"ON COMMAND\"));&#125; 이제 실행 후 왼쪽 상단의 검은색 선 안을 누르면 해당 메세지가 출력되는 것을 확인 할 수 있습니다.","categories":[{"name":"CPP","slug":"CPP","permalink":"http://DevStarSJ.github.io/categories/CPP/"},{"name":"MFC","slug":"CPP/MFC","permalink":"http://DevStarSJ.github.io/categories/CPP/MFC/"}],"tags":[{"name":"CPP","slug":"CPP","permalink":"http://DevStarSJ.github.io/tags/CPP/"},{"name":"MFC","slug":"MFC","permalink":"http://DevStarSJ.github.io/tags/MFC/"}]},{"title":"SQLP etc-1 외워야 할 SQL 문법","slug":"05.01.sql","date":"2016-02-12T17:00:00.000Z","updated":"2017-04-24T00:18:34.000Z","comments":true,"path":"2016/02/13/05.01.sql/","link":"","permalink":"http://DevStarSJ.github.io/2016/02/13/05.01.sql/","excerpt":"","text":"핵심정리5. 외워야 할 SQL 문법1. Hirarchical SQL (계층형 질의)root에서 시작해서 주어진 조건에 맞게 전개하는 방식으로 Query 123456SELECT ... FROM table_name WHERE ... START WITH (root condition) CONNECT BY [NOCYCLE] PRIOR (root id) = (child's root id) [ORDER SIBLINGS BY (columns...)] 가상 Coluns LEVEL : root = 1, leaf 방향으로 1씩 증가 CONNECT_BY_ISLEAF : leaf면 1 (자식이 있으면 0, 없으면 1) CONNECT_BY_ISCYCLE : leaf가 아니면서 조상 중에 자기자신이 있으면 1 (cycle에 속해 있으면 1, 아니면 0) 전용 함수 SYS_CONNECT_BY_PATH(column, separator) : root부터 현재까지 경로 CONNECT_BY_ROOT column : root 데이터의 컬럼을 표시 Oracle SCOTT.EMP Table에서 MANAGER = NULL부터 전개 123456789SELECT EMP.*, LPAD(' ',LEVEL - 1) || LEVEL \"LEVEL\", CONNECT_BY_ISLEAF ISLEAF, SUBSTR(SYS_CONNECT_BY_PATH(ENAME,'-'),2) PATH, CONNECT_BY_ROOT ENAME ROOT FROM EMP START WITH MGR IS NULL CONNECT BY PRIOR EMPNO = MGR ORDER SIBLINGS BY HIREDATE; 반대로 MILLER(7934)로 부터 직속상관들을 전개1234567SELECT EMP.*, LPAD(' ', LEVEL - 1) || LEVEL \"LEVEL\", SUBSTR(SYS_CONNECT_BY_PATH(ENAME, '-'),2) NAME_PATH, SUBSTR(SYS_CONNECT_BY_PATH(JOB,'-'),2) JOB_PATH FROM EMP START WITH EMPNO = 7934 CONNECT BY PRIOR MGR = EMPNO 2. ROLLUP (Group Function)각 단계별 소계를 계산 123SELECT ... FROM ... WHERE ...GROUP BY (소계를 적용하지 않을 column...), ROLLUP (소계 적용할 columns...)-- ROLLUP 안에서 column들을 괄호로 묶을시 계층구조가 아닌 같은 level로 소계를 구분 GROUPING(column) 함수 : 해당 소계에 속한 column에 대해서 1을 출력 1234567SELECT DECODE(GROUPING(DNAME), 1,'Total DEPT', DNAME) DNAME, DECODE(GROUPING(JOB), 1,'Toal JOB', JOB) JOB, COUNT(*) TOTAL_EMP, SUM(SAL) TOTAL_SAL FROM EMP e, DEPT d WHERE e.DEPTNO = d.DEPTNO GROUP BY ROLLUP (DNAME, JOB);","categories":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/categories/Database/"},{"name":"SQLP","slug":"Database/SQLP","permalink":"http://DevStarSJ.github.io/categories/Database/SQLP/"}],"tags":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/tags/Database/"},{"name":"Oracle","slug":"Oracle","permalink":"http://DevStarSJ.github.io/tags/Oracle/"},{"name":"SQLP","slug":"SQLP","permalink":"http://DevStarSJ.github.io/tags/SQLP/"}]},{"title":"SQLP 3-5-4 Partition, Batch Job","slug":"04.04.partition","date":"2016-02-10T17:00:00.000Z","updated":"2017-04-24T00:17:31.000Z","comments":true,"path":"2016/02/11/04.04.partition/","link":"","permalink":"http://DevStarSJ.github.io/2016/02/11/04.04.partition/","excerpt":"","text":"3과목 SQL 고급 활용 및 Tuning5장 고급 SQL Tuning5.4 Partition 활용 Partitioning 이란 ? Table, Index를 Partition 단위로 나누어 저장 Partition Key에 따라 물리적으로 별도의 Segment에 저장 Partition 장점 관리적 측면 : Partition 단위 백업, 추가, 삭제, 변경이 편리 성능적 측면 : Partition 단위로 Query, DML이 수행되어서 Transaction 경합 및 부하 분산 5.4.1 Partition 유형1. Range Partition Partition Key 값의 범위(Range)로 분할 가장 일반적인 형태 e.g. 날짜 칼럼 기준으로 판매데이터를 월별로 분할 1234567891011CREATE TABLE 주문( ...)PARTITION BY RANGE(주문일자)( PARTITION P2009_Q1 VALUES LESS THAN ('20090401'), PARTITION P2009_Q2 VALUES LESS THAN ('20090701'), ... PARTITION P9999_MX VALUES LESS THAN (MAXVALUE))' 2. Hash Partition Partition Key 값의 Hash 함수를 적용하여 그 값으로 Mapping 고르게 분산되는 대신 각 Row의 저장위치 예측이 불가 병렬처리 시 성능효과 극대화 DML 경합 분산에 효과적 e.g. 고객번호, 주문일련번호 3. List Partition 불연속적인 값의 목록을 각 Partition에 지정 e.g. 판매 데이터를 지역별로 분할 4. Composite Partition 2개 이상의 Partition 구성 (단, 맨 처음에 Hash가 올 순 없음) Range나 List Partition에 Range, Hash, List를 Sub-partition으로 구성 e.g. Range + Hash로 구성123456789101112CREATE TABLE 주문( ...)PARTITION BY RANGE(주문일자)SUBPARTITION BY HASH(고객ID) SUBPARTITIONS 8( PARTITION P2009_Q1 VALUES LESS THAN ('20090401'), PARTITION P2009_Q2 VALUES LESS THAN ('20090701'), ... PARTITION P9999_MX VALUES LESS THAN (MAXVALUE) ); 5.4.2 Partition Pruning Optimizer가 SQL의 대상 Table과 조건을 분석하여 불필요한 Partition을액세스 대상에서 제외하는 기능 Static Partition Pruning 액세스할 Partition을 Compile-Time에 미리 결정 상수 조건으로 조회할 경우 작동 Dynamic Partition Pruning 액세스할 Partition을 Run-Time에 결정 Bind Variable로 조회하는 경우 NL Join시 Inner Table이 Join 칼럼 기준으로 Partition 되 있는 경우 5.4.3 Index Partitioning Local vs Global Local Partition Index Table Partition과 1:1 대응하도록 Index Partitioning Index Partition Key를 사용자가 따로 지정하지 않고, DBMS가 자동으로 관리 Global Partition Index Table Partition과는 독립적으로 구성 Prefixed vs NonPrefixed Prefixed Partition Index : Partition Key Column이 Index의 왼쪽 선두에 위치 NonPrefixed Partition Index : Partition Key Column이 Index의 왼쪽 선두에 있지 않거나, 아에 속하지 않을 경우 위 조합중 Global NonPrefixed Partition Index는 Oracle에서 지원하지 않음 Index Partitioning Guide NonPartitioned Index (일반 Index) Partition Key Column이 조건절에 누락되면 여러 Index Partition을 액세스해야 하므로 비효율적 특히 OLTP환경에서는 성능에 미치는 영향이 크므로 NonPartitioned 전략이 유용할 수 있음 NL Join에서 Partition Key에 대한 넓은 범위검색 조건을 가지고 Inner Table에 Partitioned Index로 액세스하면 비효율적 -&gt; NonPartitioned Index 사용을 고려 Partition Index를 이용하면 SORT ORDER BY 대체 효과 상실 -&gt; Sort 연산을 대체함으로 부분범위 처리를 활용하고자 할 경우 NonPartitioned Index가 유리함 Table Partition 이동,삭제 등 작업시 unsuable 되므로 적용 시 주의 Global Prefixed Index 경합 분산에 효과적 여러 Local Index Partition을 액세스하는 것이 비효율적일 경우 대안으로 활용 Table Partition 이동,삭제 등 작업시 unsuable 되므로 적용 시 주의 Local Prefixed 관리적 측면에서 유용 : Table Partition에 대한 추가, 삭제 등의 작업이 빈번할 때 이력성 데이터를 주로 관리하는 DB 환경에 효과적 Partition Key Column이 = 조건으로 사용될 때 유용 Partition Key Column에 대한 검색 조건이 없으면 정상적 사용이 불가 (Index Full Scan으로는 선택가능) Partition Key Column이 범위검색 (LIKE, BETWEEN, 부등호) 일 경우 불리 Local NonPrefixed Local Prefixed와 거의 같은 특징이긴하나 범위검색이 주로 사용될 경우 NonPrefixed가 더 유리 (단, 좁은 범위검색이어야 함) 5.5 Batch Program Tuning Batch Program이란 ? User와의 상호작용(Interface)없이 대량의 데이터를 처리하는 일련의 작업들을 묶어 정기적으로 반복 수행하거나 (정기 배치) 정해진 규칙에 따라 (이벤트 배치) 자동으로 수행 (수동으로 On-Demand 배치로도 수행가능) Batch 환경의 변화 과거 : 일, 월 단위로 주로 야간에 수행되었으며, Online과 Batch가 명확하게 구분되어서 사용되었지만, 현재 : 시간, 분 단위의 짧은 시간에 수행되는 경우가 많으며 On-Demand Batch도 제한적이나마 허용되어야 한다. 성능개선 목표 설정 전체 Batch Program 들의 최종 수행시간 단축 Batch Window를 보고 Batch Program 간의 선후 관계를 따져가면서 전체적으로 고려 System 부하도 고려해야 함 병렬도 (DOP : Degree of Parallelism)를 32로 하여 5분에 수행되는것보다는 병렬처리 없이 10분 소요되는게 더 나을 수 있다. 경합을 최소화 CPU 자원 대량 사용 및 동일한 자원(데이터)에 접근하는 Batch Program을 분산 Batch Program 구현 Pattern과 Tuning 방안 절차형으로 작성된 Program Application Cursor를 열고, Loop 내에서 다른 SQL이나 Sub Procedure를 호출하면서 반복처리 (One SQL 보다) 구현이 쉽다. 아무리 Tuning을 잘해도 다음과 같은 최적화 한계가 있음 반복적인 DB Call 발생 Random I/O 위주 동일한 데이터 중복 액세스 Tuning Guide 병목을 일으키는 SQL을 찾아 I/O Tuning : Index 재구성 및 액세스 경로 최적화 Program Parallel 활용 : SQL이 읽는 데이터 범위를 달리하여 여러 Program이 동시에 수행 Array Processing 활용 One SQL로 다시 구현;;; One SQL One SQL로 구현하거나, 집합적으로 정의된 여러 SQL을 단계적으로 실행 구현하기 어렵고, 업무가 복잡할 경우 여러 SQL들을 통합했다가 결과가 틀려질 수 있음 Tuning Guide 병목을 일으키는 오퍼레이션을 찾아 I/O Tuning Index Scan 대신 Full Table Scan으로 NL Join 보다 Hash Join으로 임시 Table 활용 Partition 활용 병렬처리 활용 병렬 처리 활용 SELECT /*+ full(T) parallel(T, 4) */ ... : T Table을 Full Scan으로 4개로 병렬처리 SELECT /*+ index_ffs(T t_idx) parallel(T, t_idx, 4) */ ... : T Table의 t_idx Index를 Fast Full Scan으로 4개로 병렬처리 QC (Query Cordinator) 병렬 SQL문을 발행한 Session 병렬로 처리되지 않는 Table은 QC가 직접처리 각 병렬 Server로부터의 산출물을 통합하는 작업 수행 최종 결과 집합을 User에게 전송 Parallel Server Process 병렬 SQL을 실제로 수행하는 개별 Session Operation Parallelism Intra-Opertarion Parallelism 서로 배타적인 범위를 독립적으로 처리 각각의 데이터를 Process별로 읽는 작업 전달받은 데이터를 각각의 Process에서 처리 Inter-Operation Parallelism 다른 서버 집합으로 분배하거나 정렬된 결과를 QC에게 전송하는 작업을 병렬로 동시에 진행 Process간의 통신이 발생","categories":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/categories/Database/"},{"name":"SQLP","slug":"Database/SQLP","permalink":"http://DevStarSJ.github.io/categories/Database/SQLP/"}],"tags":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/tags/Database/"},{"name":"Oracle","slug":"Oracle","permalink":"http://DevStarSJ.github.io/tags/Oracle/"},{"name":"SQLP","slug":"SQLP","permalink":"http://DevStarSJ.github.io/tags/SQLP/"}]},{"title":"SQLP 3-5-3 DML Tuning","slug":"04.03.dml","date":"2016-02-10T16:00:00.000Z","updated":"2017-04-24T00:16:41.000Z","comments":true,"path":"2016/02/11/04.03.dml/","link":"","permalink":"http://DevStarSJ.github.io/2016/02/11/04.03.dml/","excerpt":"","text":"3과목 SQL 고급 활용 및 Tuning5장 고급 SQL Tuning5.3 DML Tuning DML 수행시 Table 변경 Index 변경 : Update 수행시 Index는 Delete &amp; Insert 수행 Redo, Undo 생성 5.3.1 Insert Tuning Direct Path Insert Freelist 조회없이, Buffer Cache를 거치지 않고 datafile에 바로 입력하는 방식 INSERT SELECT 문장에 /*+ append */ Hint 사용 Parallel Mode로 INSERT direct 옵션을 지정하고 SQL#Loader(sqlldr)로 데이터 로드 CTAS (CREATE TABLE … AS SELECT) 문장을 수행 nologging 모드 Insert ALTER TABLE 테이블명 NOLOGGING; Redo Log까지 최소화 (DPI에서는 Freelist 조회X, Buffer Cache X) Direct Path Insert 시에만 작동 단 Exclusive Mode Table Lock이 걸리므로 다른 Transaction이 해당 Table에 DML 수행을 차단 nologging 상태에서 입력한 데이터는 장애 발생시 복구가 불가능 입력후 바로 Backup을 해야 함 언제든 재생 가능한 데이터라면 상관없음 e.g. 배치 프로그램에서 중간 단계 임시 Table 5.3.2 Update Tuning1. Truncate &amp; Insert 방식1UPDATE contract SET status = '9999' WHERE ord_date &lt; _TO_DATE('20000101', 'yyyymmdd); 대량의 데이터를 UPDATE하면 상당히 오랜시간이 걸린다. UPDATE 자체 작업 Index Delete &amp; Insert Datafile을 Buffer Cache로 load한 후에 갱신 Redo, Undo 정보 생성 Block에 빈 공간이 없는 경우 새 블록 할당 -&gt; Row Migration 그래서 차라리 Table을 새로 생성하여서 작업을 한 후에 Index를 생성하는 것이 더 효율적일 수 있다. 12345678910111213141516CREATE TABLE tmp_cont AS SELECT * FROM contract; -- 임시 Table로 데이터 복사ALTER TABLE DROP CONSTRAINT cont_pk; -- INDEX 삭제DROP INDEX contract.cont_idx;TRUNCATE TABLE contract; -- Table 데이터 삭제 (No Undo)INSERT INTO contract (ord_no, ord_date, status) -- UPDATE 문에 대응하는 INSERT INTO SELECT 문SELECT ord_no, ord_date, CASE WHEN ord_date &gt;= TO_DATE('20000101', 'yyyymmdd') then '9999' ELSE status END FROM tmp_cont;ALTER TABLE contract ADD CONSTRAINT cont_pk PRIMARY KEY (ord_no, ord_date); -- INDEX 다시 생성CREATE INDEX cont_idx ON contract(ord_date, status);DROP TABLE tmp_cont; -- 임시 Table 삭제 이 작업은 UPDATE 뿐만 아니라 DELETE 에도 적용이 가능하다. 1DELETE contract WHERE ord_date &lt; TO_DATE('20010101','yyyymmdd'); 위 문장을 수행하는 것보다 아래가 더 효율적일 수 있다.1234567891011121314151617CREATE TABLE tmp_cont -- DELETE 문에 대응하는 CTASASSELECT * FROM contract WHERE ord_date &gt;= TO_DATE('20010101','yyyymmdd');ALTER TABLE DROP CONSTRAINT cont_pk;DROP INDEX contract.cont_pk;TRUNCATE TABLE contract;INSERT INTO contractSELECT * FROM tmp_cont;ALTER TABLE ADD CONSTRAINT cont_pk PRIMARY KEY (ord_no, ord_date);CREATE INDEX cont_idx ON contract(ord_date, status);DROP TABLE tmp_cont; 2. Join을 내포한 Update Tuning UPDATE 자체 성능보다는 Join 과정의 비효율 때문에 성능이 느려지는 경우가 더 많다. 최근 1달안에 거래내역이 있는 고객의 최종거래일시와 1달간의 거래금액을 UPDATE하는 문장에 대한 예제이다. 12345678UPDATE 고객 SET (최종거래일시, 최근거래금액) = (SELECT MAX(거래일시), SUM(거래금액) FROM 거래 WHERE 고객번호 = 고객.고객번호 AND 거래일시 &gt;= TRUNC(ADD_MONTHS(SYSDATE, -1))) WHERE EXISTS (SELECT 1 FROM 거래 WHERE 고객번호 = 고객.고객번호 AND 거래일시 &gt;= TRUNC(ADD_MONTHS(SYSDATE, -1))); 문제점 거래 Table을 2번 참조했다. [고객번호 + 거래일시] Index가 필요하다. Index에 데이터가 많으면 Random 액세스로 Join을 수행하기 때문에 비효율적이다. 해결방안1 Sub-query에서 unnest 와 hash_sj Hint를 이용해서 Semi Join 방법을 유도 그래도 여전히 Table을 2번 참조하긴 해야 한다. 123456789UPDATE 고객 SET (최종거래일시, 최근거래금액) = (SELECT MAX(거래일시), SUM(거래금액) FROM 거래 WHERE 고객번호 = 고객.고객번호 AND 거래일시 &gt;= TRUNC(ADD_MONTHS(SYSDATE, -1))) WHERE EXISTS (SELECT /*+ unnest hash_sj */ 1 FROM 거래 WHERE 고객번호 = 고객.고객번호 AND 거래일시 &gt;= TRUNC(ADD_MONTH(SYSDATE, -1))); 해결방안2 수정가능 조인뷰 (Updatable Join View) 활용 12345678910UPDATE /*+ bypass_ujvc */ (SELECT c.최종거래일시, c.최근거래금액, t.거래일시, t.거래금액 FROM (SELECT 고객번호, MAX(거래일시) 거래일시, SUM(거래금액) 거래금액 FROM 거래 WHERE 거래일시 &gt;= TRUNC(ADD_MONTH(SYSDATE, -1)) GROUP BY 고객번호) t, 고객 c WHERE c.고객번호 = t.고객번호) SET 최종거래일시 = 거래일시, 최근거래금액 = 거래금액; Updatable Join View 란 ? Join View : FROM 절에 2 개의 Table을 가진 View Unique Index가 있는 Table 쪽의 Unique 한 경우에만 UPDATE가 가능 GROUP BY를 통하면 결과가 무조건 Unique한데도 불구하고 Unique Index가 없으면 수정 불가 Oracle MERGE문 활용 12345MERGE INTO 대상테이블 t using 소스테이블 s ON (t.id = s.id) -- 조건WHEN MATCHED THEN UPDATE SET t.a = s.a, ...WHEN NOT MATCHED THEN INSERT (t.컬렴list) VALUES (s.컬럼list); Oracle 9i, MS-SQL 2008부터 지원 Oracle 10g부터는 UPDATE, INSERT 를 선택적으로 따로 처리가 가능 MERGE문으로 앞에서 본 Updatable Join View를 대체 할 수 있다. 123456789MERGE INTO 고객 c USING (SELECT 고객번호, MAX(거래일시) 거래일시, SUM(거래금액) 거래금액 FROM 거래 WHERE 거래일시 &gt;= TRUNC(ADD_MONTHS(SYSDATE,-1)) GROUP BY 고객번호) t ON (c.고객번호 = t.고객번호)WHEN MATCHED THEN UPDATE SET c.최종거래일시 = t.거래일시, c.최근거래금액 = t.거래금액","categories":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/categories/Database/"},{"name":"SQLP","slug":"Database/SQLP","permalink":"http://DevStarSJ.github.io/categories/Database/SQLP/"}],"tags":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/tags/Database/"},{"name":"Oracle","slug":"Oracle","permalink":"http://DevStarSJ.github.io/tags/Oracle/"},{"name":"SQLP","slug":"SQLP","permalink":"http://DevStarSJ.github.io/tags/SQLP/"}]},{"title":"SQLP 3-5-2 Sort Tuning","slug":"04.02.sort","date":"2016-02-08T16:00:00.000Z","updated":"2017-04-24T00:16:03.000Z","comments":true,"path":"2016/02/09/04.02.sort/","link":"","permalink":"http://DevStarSJ.github.io/2016/02/09/04.02.sort/","excerpt":"","text":"3과목 SQL 고급 활용 및 Tuning5장 고급 SQL Tuning5.2 Sort Tuning5.2.1 Sort Tuning 전략 Data Modeling 측면에서 검토 GROUP BY, DISTINCT, UNION 연산이 자주 일어난다면 정규화를 잘하면 많이 해소된다. M:M 관계에서 조회하려면 Sort 연산이 많이 일어난다. Sort 발생하지 않도록 SQL 작성 UNION -&gt; UNION ALL DISTINCT -&gt; EXISTS 불필요한 COUNT 연산 제거 Index를 이용한 Sort 연산 대체 Sort Order By, Sort Group By, Min, Max 등… Sort Area를 적게 사용하도록 SQL 작성 Sort 완료 후 데이터 가공 || 연산으로 붙인 후 Sort하지 말고 먼저 Sort한 것을 Inline View로 구한 뒤 결합하자. Top-N Query Sort 영역 크기 조정12ALTER SESSION SET WORKAREA_SIZE_POLICY = MANUAL;ALTER SESSION SET SORT_AREA_SIZE = N; 5.2.2 Memory Sort vs Disk Sort Memory Sort 전체 정렬 작업을 할당받은 Sort Area (PGA) 내에서 완료 Internal Sort, Optimal Sort 라고도 함 Disk Sort 할당받은 Sort Area 안에서 완료못해서 Disk까지 사용 External Sort 라고도 함 Onepass Sort : disk에 한 번만 기록 Multipass Sort : disk에 여러 번 기록 5.2.3 Sort Operation1. Sort Aggregate 집계 함수 수행. (실제로 Sort가 발생하진 않음) 12345SELECT SUM(SAL), MAX(SAL), MIN(SAL) FROM EMP;SELECT STATEMENT OPTIMIZER=ALL_ROWS SORT (AGGREGATE) TABLE ACCESS (FULL) OF `EMP` (TABLE) 2. Sort Order By ORDER BY (Index가 있는 컬럼에 대해서는 발생하지 않음)12345SELECT * FROM EMP ORDER BY SAL;SELECT STATEMENT OPTIMIZER=ALL_ROWS SORT (ORDER BY) TABLE ACCESS (FULL) OF 'EMP' (TABLE) 12345SELECT * FROM EMP ORDER BY EMPNO;SELECT STATEMENT OPTIMIZER=ALL_ROWS TABLE ACCESS (BY INDEX ROWID) OF `EMP` (TABLE) INDEX (FULL SCAN) OF 'PK_EMP' (INDEX (UNIQUE)) 3. Sort Group By GROUP BY 예전에는 GROUP BY가 Sort된 형태의 결과를 보장했지만, 요즘은 Optimizer가 대신 Hash를 사용 할 수도 있기 때문에 순서를 보장하지 않음 따로 ORDER BY를 붙여줘야지만 순서를 보장함12345SELECT JOB, SUM(SAL) FROM EMP GROUP BY JOB ORDER BY JOB;SELECT STATEMENT OPTIMIZER=ALL_ROWS SORT (GROUP BY) TABLE ACCESS (FULL) OF 'EMP' (TABLE) 12345SELECT JOB, SUM(SAL) FROM EMP GROUP BY JOB;SELECT STATEMENT OPTIMIZER=ALL_ROWS HASH (GROUP BY) TABLE ACCESS (FULL) OF 'EMP' (TABLE) 4. Sort Unique UNION, DISTINCT 연산자 사용시 GROUP BY 같이 Sort를 보장해주지 않으므로 ORDER BY를 안붙여주면 Optimizer가 Hash로 실행할 가능성이 높음 12345SELECT DISTINCT DEPTNO FROM EMP ORDER BY DEPTNO;SELECT STATEMENT OPTIMIZER=ALL_ROWS SORT (UNIQUE) TABLE ACCESS (FULL) OF 'EMP' (TABLE) 12345SELECT DISTINCT DEPTNO FROM EMP;SELECT STATEMENT OPTIMIZER=ALL_ROWS HASH (UNIQUE) TABLE ACCESS (FULL) OF `EMP` (TABLE) 12345678910SELECT ENAME FROM EMP WHERE SAL &lt;= 1500 UNIONSELECT DNAME FROM DEPT;SELECT STATEMENT OPTIMIZER=ALL_ROWS SORT (UNIQUE) UNION-ALL TABLE ACCESS (BY INDEX ROWID) OF 'EMP' (TABLE) INDEX (RANGE SCAN) OF 'EMP_SAL_IDX' (INDEX) TABLE ACCESS (FULL) OF 'DEPT' (TABLE) 5. Sort Join Sort Merge Join 수행시 (Index 사용할 경우에는 발생하지 않을 수 있음)12345678SELECT /*+ ordered use_merge(d) */ * FROM EMP e, DEPT d WHERE e.DEPTNO = d.DEPTNO;SELECT STATEMENT OPTIMIZER=ALL_ROWS MERGE JOIN TABLE ACCESS (BY INDEX ROWID) OF 'EMP' (TABLE) INDEX (FULL SCAN) OF 'EMP_DEPT_IDX' (INDEX) SORT (JOIN) TABLE ACCESS (FULL) OF 'EMP' (TABLE) 6. Window Sort Window 함수에서 ORDER BY 수행시12345SELECT EMPNO, ROW_NUMBER() OVER (ORDER BY HIREDATE) FROM EMP;SELETE STATEMENT OPTIMIZER=ALL_ROWS WINDOW (SORT) TABLE ACCESS (FULL) OF 'EMP' (TABLE) 5.2.4 Sort가 발생하지 않도록 SQL 작성1. UNION을 UNION ALL로 대체 UNION : 중복 제거를 위해 SORT UNIQUE 연산을 수행한다. UNION ALL : 중복을 허용하고 두 집합을 단순히 결합한다. 두 연산의 결과가 같다는게 보장된다면 UNION보다는 UNION ALL을 사용하는게 성능상 도움이 된다. 1234567891011SELECT * FROM EMP WHERE DEPTNO = 10 UNIONSELECT * FROM EMP WHERE DEPTNO = 20;SELETE STATEMENT OPTIMIZER=ALL_ROWS SORT (UNIQUE) UNION-ALL TABLE ACCESS (BY INDEX ROWID) OF 'EMP' (TABLE) INDEX (RANGE SCAN) OF 'EMP_DEPT_IDX' (INDEX) TABLE ACCESS (BY INDEX ROWID) OF 'EMP' (TABLE) INDEX (RANGE SCAN) OF 'EMP_DEPT_IDX' (INDEX) 12345678910SELECT * FROM EMP WHERE DEPTNO = 10 UNION ALLSELECT * FROM EMP WHERE DEPTNO = 20;SELETE STATEMENT OPTIMIZER=ALL_ROWS UNION-ALL TABLE ACCESS (BY INDEX ROWID) OF 'EMP' (TABLE) INDEX (RANGE SCAN) OF 'EMP_DEPT_IDX' (INDEX) TABLE ACCESS (BY INDEX ROWID) OF 'EMP' (TABLE) INDEX (RANGE SCAN) OF 'EMP_DEPT_IDX' (INDEX) 실행계획을 보면 나머진 똑같은데 SORT (UNIQUE) 연산이 빠졌다. 2. DISTINCT를 EXISTS Sub-query로 대체 중복제거를 위해 DISTINCT를 사용하는게 대표적인데, EXISTS로 대체가 가능하다. EXISTS의 경우에는 조건에 맞는 것 1개만 찾으면 바로 다음으로 넘어가버리기 때문에 성능상 유리하다. 이럴 경우 DISTINCT한 값들이 들어가 있는 Table (주로 Master Table)이 필수적으로 필요하다. Master Table이 없는 경우 별도로 생성하는 경우도 있다. (e.g. 연월 Table) 12345SELECT DISTINCT DEPTNO FROM EMP ORDER BY DEPTNO;SELECT STATEMENT OPTIMIZER=ALL_ROWS SORT (UNIQUE) TABLE ACCESS (FULL) OF 'EMP' (TABLE) 123456SELECT DEPTNO FROM DEPT WHERE EXISTS (SELECT 1 FROM EMP WHERE DEPTNO = DEPT.DEPTNO) ORDER BY DEPTNO;SELECT STATEMENT OPTIMIZER=ALL_ROWS NESTED LOOPS (SEMI) INDEX (FULL SCAN) OF 'PK_DEPT' (INDEX (UNIQUE)) INDEX (RANGE SCAN) OF 'EMP_DEPT_IDX' (INDEX) Semi Join Subquery unnesting의 대표적인 결과 Join 조건에 만족하는 것이 하나라도 있으면 다음으로 넘어감 3. 불필요한 COUNT 연산 제거이건 근본적으로 잘못 짜여진 SQL에서 비롯된 문제이다.해당 데이터가 있는지 그 여부를 알기 위해서 COUNT(*)를 사용하면 : SORT AGGREGATE 가 발생하고 ROWNUM &lt;= 1 조건을 사용하면 : COUNT STOPKEY가 발생한다.","categories":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/categories/Database/"},{"name":"SQLP","slug":"Database/SQLP","permalink":"http://DevStarSJ.github.io/categories/Database/SQLP/"}],"tags":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/tags/Database/"},{"name":"Oracle","slug":"Oracle","permalink":"http://DevStarSJ.github.io/tags/Oracle/"},{"name":"SQLP","slug":"SQLP","permalink":"http://DevStarSJ.github.io/tags/SQLP/"}]},{"title":"SQLP 3-5-1 One SQL","slug":"04.01.onesql","date":"2016-02-08T15:00:00.000Z","updated":"2017-04-24T00:15:16.000Z","comments":true,"path":"2016/02/09/04.01.onesql/","link":"","permalink":"http://DevStarSJ.github.io/2016/02/09/04.01.onesql/","excerpt":"","text":"3과목 SQL 고급 활용 및 Tuning5장 고급 SQL Tuning5.1 One SQL 구현 기법5.1.1 CASE(DECODE) 활용One SQL 기법중 가장 기본인 CASE를 이용하여 record로 나눠져 있는 데이터를 한 row에 표현하는 방법이다. 12345월별납입방법별집계# 고객번호# 납입월# 납입방법코드* 납입금액 위 Table을 읽어서 아래 형식으로 가공하고자 할 경우 12345678월별요금납부실적# 고객번호# 납입월* 지로 금액* 자동이체 금액* 신용카드 금액* 핸드폰 금액* 인터넷 금액 CASE를 이용한 One SQL로 구현해보자. (이건 너무 자주 나온 방법이라… 별 다른 설명이 필요없을듯 하다.) 12345678SELECT 고객번호, 납입월, NVL(SUM(DECODE(납입방법코드, '지로', 납입금액))) 지로, NVL(SUM(DECODE(납입방법코드, '자동이체', 납입금액))) 자동이체, NVL(SUM(DECODE(납입방법코드, '신용카드', 납입금액))) 신용카드, NVL(SUM(DECODE(납입방법코드, '인터넷', 납입금액))) 인터넷, NVL(SUM(DECODE(납입방법코드, '핸드폰', 납입금액))) 핸드폰 FROM 월별납입방법별집계 GROUP BY 고객번호, 납입월; 5.1.2 Table 복제 기법Data를 복제를 해서 활용을 해야하는 경우 예전에는 복제용 Table을 생성해 두고 묻지마 JOIN을 활용하여 복제하였다. 1234567CREATE TABLE COPY_T (no NUMBER); -- 복사용 Table을 생성해 두고,INSERT INTO COPY_TSELECT ROWNUM FROM EMP WHERE ROWNUM &lt;= 10; -- 1 ~ 10의 값을 넣어두고 (최대 10배까지 복사)SELECT * FROM EMP, COPY_T -- 복사할 값에 대해서 묻지마 JOIN WHERE COPY_T.NO &lt;= 2; -- no에 대한 조건으로 복사건수 입력 Oracle 9i부터는 dual Table에 start with 없는 connect by 구문으로 inline view로 활용이 가능하다. 123SELECT ROWNUM FROM dual CONNECT BY LEVEL &lt;= 2; -- 2개의 값을 가진 임시 복제 TableSELECT * FROM EMP, (SELECT ROWNUM FROM dual CONNECT BY LEVEL &lt;= 2); -- 2개로 복제 그럼 복사를 이용해서 emp Table을 1번만 읽고 JOB별 SAL의 합계와 전체 합계를 구해보자. 123456SELECT DECODE(no, 1, job, 'Total') as JOB, SUM(sal) as SAL FROM (SELECT job, no, sal FROM EMP, (SELECT ROWNUM no FROM dual CONNECT BY LEVEL &lt;= 2)) GROUP BY no, DECODE(no, 1, job, 'Total') ORDER BY job, no; 사실 위 방식도 옜날 방식이긴하다.그냥 ROLLUP을 이용하면 쉽게 가능하다. 12345SELECR DECODE(GROUPING(job), 0, job, 'Total') JOB, SUM(sal) SAL FROM emp GROUP BY ROLLUP(job) ORDER BY job; ROLLUP을 이용한게 메모리도 훨씬 더 적게 사용한다. dual을 이용한 복제 Table 방식의 Execute Plan123456789SELECT STATEMENT OPTIMIZER=ALL_ROWS SORT (GROUP BY) (Bytes=125) MERGE JOIN (CARTESIAN) (Bytes=350) VIEW COUNT CONNECT BY (WITHOUT FILTERING) FAST DUAL BUFFER (SORT) (Bytes=168) TABLE ACCESS (FULL) OF &apos;EMP&apos; (TABLE) (Bytes=168) 위 경우에는 MERGE JOIN 단계에서 Table 크기의 2배만큼의 메모리를 사용한다. ROLLUP을 이용한 Execute Plan1234SELECT STATEMENT OPTIMIZER=ALL_ROWS SORT (ORDER BY) (Bytes=60) SORT (GROUP BY) (Bytes=60) TABLE ACCESS (FULL) OF &apos;EMP&apos; (TABLE) (Bytes=168) 5.1.3 UNION ALL을 활용한 M:M JoinM:M 관계 Join이나 Full Outer Join을 대신해서 UNION ALL을 활용할 수 있다. 12345부서별판매계획 채널별판매실적# 상품 # 상품# 계획연월 # 판매연월# 판매부서 # 판매채널* 계획수량 * 판매수량 위와 같은 2개의 Table을 이용하여 월별로 각 상품의 계획 대비 판매 실적을 집계할려면 M:M 관계로 Join을 해야한다.하지만 아래와 같이 무턱대로 Full Outer Join을 하면 잘못된 결과가 출력된다. 123456789SELECT NVL(a.상품, b.상품) 상품, NVL(a.계획연월, b.판매연월) 연월, SUM(계획수량) 계획, SUM(판매수량) 판매 FROM 부서별판매계획 a FULL OUTER JOIN 채널별판매실적 b ON a.상품 = b.상품 AND a.계획연월 = b.판매연월 GROUP BY NVL(a.상품, b.상품) , NVL(a.계획연월, b.판매연월) ORDER BY NVL(a.상품, b.상품) , NVL(a.계획연월, b.판매연월); 어떤 잘못된 결과가 나오는지 SQL만 보고 판단이 가능한가 ?예를 들어서 상품A, 201501 대해서 계획에서는 1개의 record가 있고, 판매에는 2개의 record가 있다면 SUM(계획수량)에는 계획수량 X 2 개의 값이 나온다.만약 Join 조건에 판매부서, 판매채널도 포함시킨다면 위와 같은 문제없이 정상적으로 활용이 가능하다. 그럼 판매부서를 Join조건에서 뺀 상태에서 동일 데이터가 2번 집계되지 않도록 하려면 어떻게 해야 할까 ?그렇다면 미리 [상품 + 연월] 별로 GROUP BY 한 결과들로 Full Outer Join을 하면 된다. 12345678910111213SELECT NVL(a.상품, b.상품) 상품, NVL(a.연월, b.연월) 연월, SUM(계획) 계획, SUM(판매) 판매 FROM (SELECT 상품, 계획연월 연월, SUM(계획수량) 계획 FROM 부서별판매계획 GROUP BY 상품, 계획연월) a FULL OUTER JOIN (SELECT 상품, 판매연월 연월, SUM(판매수량) 판매 FROM 채널별판매실적 GROUP BY 상품, 판매연월) b ON a.상품 = b.상품 AND a.연월 = b.연월 GROUP BY NVL(a.상품, b.상품), NVL(a.연월, b.연월) ORDER BY NVL(a.상품, b.상품), NVL(a.연월, b.연월); 원하는대로 출력된다.책에는 Execute Plan이 비효율적이라고 나왔다는데, Oracle 11g에서는 별로 비효율적이지 않았다. 12345678910SELECT STATEMENT OPTIMZER=ALL_ROWS SORT (GROUP BY) VIEW OF &apos;임시&apos; (VIEW) HASH JOIN (FULL OUTER) VIEW HASH TABLE ACCESS (FULL) OF &apos;채널별판매실적&apos; (TABLE) VIEW HASH TABLE ACCESS (FULL) OF &apos;부서별판매계획&apos; (TABLE) 전형적인 Hash Join의 Execute Plan이다.위와 같은 SQL문 보다는 UNION ALL일 이용하면 더 간단히 구현이 가능하다. 12345678SELECT 상품, 연월, SUM(계획) 계획, SUM(판매) 판매 FROM (SELECT 상품, 계획연월 연월, SUM(계획수량) 계획, NULL 판매 FROM 부서별판매계획 GROUP BY 상품, 계획연월 UNION ALL SELECT 상품, 판매연월, NULL, SUM(판매수량) FROM 채널별판매실적 GROUP BY 상품, 판매연월) GROUP BY 상품, 연월 ORDER BY 상품, 연월; 실행계획도 보면 Hash Join이 아닌 UNION ALL로 바뀌었다.12345678SELECT STATEMENT OPTIMIZER=ALL_ROWS SORT (GROUP BY) VIEW UNION-ALL HASH (GROUP BY) TABLE ACCESS (FULL) OF &apos;부서별판매계획&apos; (TABLE) HASH (GROUP BY) TABLE ACCESS (FULL) OF &apos;채널별판매실적&apos; (TABLE) 5.1.4 Paging 처리Webpage에서 게시판을 보여줄 경우 한번에 모든 목록을 다 보여주지않고, Page 단위로 끊어서 목록을 보여준다.이럴 경우 Paging 처리를 해주지 않고, 무조건적으로 읽은 다음 FETCH로 넘기디가 필요한 만큼만 보여주고 끝내는 방식으로 구현했다가는 DB에 엄청난 부하가 걸린다. 1234567BBS# Catalog# num* RegDate* Title* Description* Writer 위와 같이 게시판을 관리하는 Table이 있는 경우 Paging 처리는 다음과 같이 하면 된다. 12345678910SELECT * FROM (SELECT ROWNUM no, num, title, COUNT(*) OVER () CNT -- #1 FROM (SELECT num, title FROM bbs WHERE RegDate &gt;= :dt AND Catalog = :cat ORDER BY num DESC) WHERE ROWNUM &lt;= :page * :pageSize + 1) -- #2 WHERE no BETWEEN (:page - 1) * :pagesize + 1 AND :pageSize * :page; -- #3 1234567SELECT STATEMENT Optimizer=ALL_ROWS VIEW WINDOW (BUFFER) COUNT (STOPKEY) VIEW TABLE ACCESS (BY INDEX ROWID) OF &apos;BBS&apos; (TABLE) INDEX (RANGE SCAN) OF &apos;BBS_PK&apos; (INDEX (UNIQUE)) #1 : 다음 page에 데이터가 있는지 확인할 용도이다. 가장 안쪽 Inline View의 record 수가 return 된다. 이 값을 no값과 비교해서 더 크다면 다음 page에 출력할 값이 있다고 판단 할 수 있다. #2 : List의 첫 page 부터 현재 page까지의 데이터를 출력한다. 사실 비효율적이긴 하다. (index + first_rows(n)을 활용해서 부분범위 처리해야 한다.) #3 : 현재 page에 보여줄 내용만 걸러낸다. 성능과 I/O효율을 위해서는 num의 index가 필요하다. 그러면 sort 작업을 수행하지 않아도 되며, first_rows(N) Hint를 활용해서 부분범위 처리를 유도할수도 있다. 위 예제는 1 page만 볼때는 괜찮은데, 다음 page 조회를 자주 할 경우에는 비효율적이다.매번 보여줄 필요가 없는 앞 page들의 데이터를 다 읽어와야 한다.다음 page 버튼을 눌렀을때의 SQL문은 간단히 구현이 가능하다. 123456SELECT num, title FROM bbs WHERE Catalog = :cat AND num &lt; :no -- 현재 page의 마지막 num값 AND rownum &lt;= :pageSize ORDER BY num DESC; 위 SQL이 맞게 보일수도 있다. 더군다가 읽은 데이터도 딱 한 page에 보여줄 만큼만 읽었다.하지만, Index가 어떻게 설정되어 있냐에 따라 다른 값이 나올 수 있다.이 경우에는 성능보다는 어떤 상황에서도 정확한 값이 나오는게 더 중요하기 때문에 아래와 같이 Inline View로 처리를 해주어야 안전하다. 1234567SELECT * FROM (SELECT num, title FROM bbs WHERE Catalog = :cat AND num &lt; :no -- 현재 page의 마지막 num값 ORDER BY num DESC) WHERE rownum &lt;= :pageSize 12345SELECT STATEMENT Optimzer=ALL_ROWS COUNT (STOPKEY) VIEW TABLE ACCESS (BY INDEX ROWID) OF &apos;BBS&apos; (TABLE) INDEX (RANGE SCAN DESCENDING) OF &apos;BBS_PK&apos; (INDEX (UNIQUE)) 그럼 이전 page는 ??? 12345678SELECT * FROM (SELECT num, title FROM bbs WHERE Catalog = :cat AND num &gt; :no -- 현재 page의 첫번째 num값 AND rownum &lt;= :pageSize ORDER BY num) ORDER BY num DESC; 이 경우에는 rownum 비교를 Inline View 안으로 넣어서 읽는 데이터 수를 줄였다.이건 index 구성과 화면에 보여주는 data의 순서를 생각해서 다음 page, 이전 page 둘 중 하나는 안에 넣는게 가능하다.다음 page의 SQL문 같이 밖으로 빼도 결과는 똑같다. 그럼 다음 page 와 이전 page를 하나의 SQL문으로 묶을순 없을까 ?UNION ALL을 이용하면 된다.어느 버튼을 눌렀는지에 대한 조건만 추가를 해주면 된다.만약 다음 page를 눌렀을때 ‘N’을 전달하고, 이전 page를 눌렀을때 ‘P’를 전달하다고 하면 다음과 같이 작성이 가능하다. 123456789101112131415161718SELECT num, title FROM (SELECT num, title FROM bbs WHERE 'N' = :btn AND Catalog = :cat AND num &lt; :no ORDER BY num DESC) WHERE rownum &lt;= :pageSize UNION ALL SELECT num, title FROM (SELECT num, title FROM bbs WHERE 'P' = :btn AND Catalog = :cat AND num &gt; :no AND rownum &lt;= :pageSize ORDER BY num) ORDER BY num DESC; 얼핏 생각하면 아래,위의 Inline View를 UNION ALL로 하고 겉에 SELECT로 씌우는게 가능할것 같지만, 안된다.겉의 SELECT까지 해야 원하는 데이터가 순서래도 출력되기 때문이다. 5.1.5 Window 함수 활용 왼쪽 그럼과 같이 저장되어 있는 Table에서 오른쪽과 같은 형태로 출력하고 싶을 때 Query를 어떻게 만들어야 할까 ? 먼저 STATUS 값이 NULL이면 자신보다 이전 값중에 NULL이 아닌 최근값을 찾아야 하는데… (이 부분에서 Sub-query로 한겹) 그러기 위해서는 STATUS가 NULL이 아닌 최근값의 SN을 구해야 한다. (이 부분에서 다시 Sub-query) 즉 다음과 같은 Query를 작성해야 한다. 123456789SELECT a.SN, NVL(a.STATUS, (SELECT b.STATUS FROM EQ_MES b WHERE b.SN = (SELECT MAX(SN) FROM EQ_MES c WHERE c.SN &lt; a.SN AND c.STATUS IS NOT NULL))) STATUS, a.VALUE FROM EQ_MES a; SN에 PK가 설정되어 있다는 가정하에서 생각해보면, 가장 안쪽의 Sub-query에서 MAX(SN)을 구하기 위해서 INDEX RANGE SCAN 해당 SN값으로 b.STATUS값을 구하기 위해서 INDEX UNIQUE SCAN 위 1,2 과정을 모든 레코드 별로 1번씩 수행. 필터링 캐시 ? 입력값이 늘 다르므로 의미없음 1234567SELECT STATEMENT OPTIMIZER=ALL_ROWS TABLE ACCESS (BY INDEX ROWID) OF 'EQ_MES' (TABLE) INDEX (UNIQUE SCAN) OF 'EQ_MES_PK' (INDEX (UNIQUE)) SORT (AGGREGATE) TABLE ACCESS (BY INDEX ROWID) OF `EQ_MES` (TABLE) INDEX (RANGE SCAN) OF `EQ_MES_PK` (INDEX (UNIQUE)) TABLE ACCESS (FULL) OF `EQ_MES` (TABLE) SN에 PK가 설정되어 있으면 그냥 간단하게 index를 활용하여 NULL이 아닌 첫번째 값을 가져오게끔도 가능하다. 12345678SELECT a.SN, NVL(a.STATUS, (SELECT /*+ index_desc(b EQ_MES_PK) */ b.STATUS FROM EQ_MES b WHERE b.SN &lt; a.SN AND b.STATUS IS NOT NULL AND ROWNUM &lt;= 1)) STATUS, a.VALUE FROM EQ_MES a; 12345SELECT STATEMENT OPTIMIZER=ALL_ROWS COUNT (STOPKEY) TABLE ACCESS (BY INDEX ROWID) OF `EQ_MES` (TABLE) INDEX (RANGE SCAN DESCENDING) OF EQ_MES_PK` (INDEX (UNIQUE)) TABLE ACCESS (FULL) OF `EQ_MES` (TABLE) 앞에서 배운 Window 함수를 이용하면 쉽게 해결이 가능하다. LAST_VALUE : Partition 내에서 가장 마지막 값을 출력 IGNORE NULLS 옵션을 사용해서 바로 가져 올 수가 있다. 123456SELECT SN, LAST_VALUE(STATUS IGNORE NULLS) OVER (ORDER BY SN ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) STATUS, VALUE FROM EQ_MES ORDER BY SN; IGNORE NULLS : NULL값은 무시하고 마지막값을 가져옴 PARTITION 은 여기서 지정하지 않았음 ORDER BY SN : SN 순으로 정렬 BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW : 검색 RANGE를 이전의 모든 데이터에서 현재까지 123SELECT STATEMENT OPTIMIZER=ALL_ROWS WINDOW(SORT) TABLE ACCESS (FULL) OF `EQ_MES` (TABLE) 5.1.6 WITH 활용PL/SQL 에서 내부적으로 임시 테이블을 생성하여 재활용이 가능하다. 123WITH 임시테이블명AS(SELECT ... ) 로 선언을 해두고 재활용이 가능하다.하지만 이것을 활용한 성능향상은 Oracle (9i이후)만 가능하다.MS-SQL은 Inline 방식으로 항상 해당 Query를 새로 실행한다.Oracle은 materialize, inline Hint를 활용하여 임시 테이블로 결과를 저장하고 재사용할 것인지, View같이 항상 새로 실행한 것인지의 선택이 가능하다.","categories":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/categories/Database/"},{"name":"SQLP","slug":"Database/SQLP","permalink":"http://DevStarSJ.github.io/categories/Database/SQLP/"}],"tags":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/tags/Database/"},{"name":"Oracle","slug":"Oracle","permalink":"http://DevStarSJ.github.io/tags/Oracle/"},{"name":"SQLP","slug":"SQLP","permalink":"http://DevStarSJ.github.io/tags/SQLP/"}]},{"title":"SQLP 3-4-3 고급 Join 기법","slug":"03.07.join.adv","date":"2016-02-06T15:00:00.000Z","updated":"2017-04-24T00:14:22.000Z","comments":true,"path":"2016/02/07/03.07.join.adv/","link":"","permalink":"http://DevStarSJ.github.io/2016/02/07/03.07.join.adv/","excerpt":"","text":"3과목 SQL 고급 활용 및 Tuning4장 Index와 Join4.4 고급 Join 기법Inline View 활용대부분의 JOIN은 1:M 관계이다.M쪽 집합을 1쪽 집합 단위로 Grouping해야 한다면 미리 Grouping한 뒤 JOIN하는 것이 유리하다. 12345SELECT MIN(b.상품명) 상품명, SUM(a.판매수량) 판매수량, SUM(a.판매금액) 판매금액 FROM 일병상품판매 a, 상품 b WHERE a.상품코드 = b.상품코드 AND a.판매일자 BETWEEN '20090101' AND '20091231' GROUP BY b.상품코드; 123456SELECT STATEMENT OPTIMIZER=ALL_ROWS SORT GROUP BY NESTED LOOPS TABLE ACCESS FULL 일별상품판매 (Table) TABLE ACCESS BY INDEX ROWID 상품 (Table) INDEX UNIQUE SCAN 상품_PK (Index) 위 상황에서 일별상품판매에서 조건에 맞는 모든 record에 대해서 상품 과 JOIN을 수행한 후에 마지막에 SORT GROUP BY를 수행하였다.미리 상품코드 별로 GROUP BY를 한 후에 JOIN을 하는 것으로 수정해 보자. 123456SELECT b.상품명, a.판매수량, a.판매금액 FROM (SELECT 상품코드, SUM(판매수량) 판매수량, SUM(판매금액) 판매금액 FROM 일별상품판매 WHERE 판매일자 BETWEEN '20090101' AND '20091231' GROUP BY 상품코드) a, 상품 b WHERE a.상품코드 = b.상품코드; 1234567SELECT STATEMENT OPTIMIZER=ALL_ROWS NESTED LOOPS VIEW SORT GROUP BY TABLE ACCESS FULL 일별상품판매 (Table) TABLE ACCESS BY INDEX ROWID 상품 (Table) INDEX UNIQUE SCAN 상품_PK (Index) 베타적 관계의 JOIN 상호배타적 관계란 ? 어떤 엔터티가 두 개 이상의 다른 엔터티의 합집합과 관계를 갖는 것 e.g. 작업지시 Table의 작업일련번호 가 개통신청 Table의 개통신청번호 와도 관계를 가지고, 장애접수 Table의 장애접수번호 와도 관계를 가지는 경우 이 경우 3가지로 구현이 가능하다. 작업일련번호 1개의 컬럼으로 2개의 Table로 연결하여 관련있는 레코드만 각 테이블에 입력 (#1) 개통신청번호, 장애접수번호 두 칼럼을 따로 두고 각 레코드별로 둘 중 하나에만 값을 입력 (#2) 접수번호 와 작업구분 칼럽을 두고 작업구분의 값으로 개통신청, 장애접수를 구분 (#3) 예제 SQL (#1) 12345678SELECT /*+ ordered use_nl(b) use_nl(c) */ a.작업일련번호, a.작업자ID, NVL(b.고객번호, c.고객번호) 고객번호, NVL(b.주소, c.주소) 주소 FROM 작업지시 a, 개통신청 b, 장애접수 c WHERE a.작업일련번호 = b.작업지시번호(+) AND a.작업일련번호 = c.장애접수번호(+) AND a.접수일자 BETWEEN :fromDate AND :toDate; 예제 SQL (#2) 12345678910111213141516171819202122232425SELECT /*+ ordered use_nl(b) use_nl(c) */ NVL(a.개통신청번호, b.장애접수번호) 작업일련번호, a.작업자ID, DECODE(a.개통신청번호, NULL, c.고객번호, b.고객번호) 고객번호, DECODE(a.개통신청번호, NULL, c.주소, b.주소) 주소 FROM 작업지시 a, 개통신청 b, 장애접수 c WHERE a.개통신청번호 = b.개통신청번호(+) AND a.장애접수번호 = c.장애접수번호(+) AND a.접수일자 BETWEEN :fromDate AND :toDate;-- 위의 경우 필요없는 JOIN 시도 횟수가 많아지기 때문에 2가지 경우를 나누어서 UNION ALL하는게 효율이 좋다.SELECT a.개통신청번호 작업일련번호, a.작업자ID, b.고객번호, b.주소 FROM 작업지시 a, 개통신청 b WHERE a.개통신청번호 = b.개통신청번호 AND a.개통신청번호 IS NOT NULL AND a.접수일자 BETWEEN :fromDate AND :toDate UNION ALLSELECT a.장애접수번호 작업일련번호, a.작업자ID, b.고객번호, b.주소 FROM 작업지시 a, 장애접수 b WHERE a.장애접수번호 = b.장애접수번호 AND a.장애접수번호 IS NOT NULL AND a.접수일자 BETWEEN :fromDate AND :toDate 예제 SQL (#3) 12345678910111213SELECT a.작업일련번호, a.작업자ID, b.고객번호, b.주소 FROM 작업지시 a, 개통신청 b WHERE a.작업일련번호 = b.개통신청번호 AND a.작업구분 = 1 AND a.접수일자 BETWEEN :fromDate AND :toDate UNION ALLSELECT a.작업일련번호, a.작업자ID, b.고객번호, b.주소 FROM 작업지시 a, 장애접수 b WHERE a.작업일련번호 = b.장애접수번호 AND a.작업구분 = 2 AND a.접수일자 BETWEEN :fromDate AND :toDate 마지막 예제의 경우 Index가 [작업구분 + 접수일자]로 구성되었다면 읽는 범위의 중복이 없겠지만,[접수일자 + 작업구분]일 경우 중복해서 읽어야 하며,[접수일자]만으로 구성된 Index를 사용한다면 작업구분을 필터링하기위해 Random 액세스까지 중복으로 발생한다.그럴 경우 아래와 같이 수정을 하면 중복 액세스의 비효율을 해소할 수 있다. 12345678SELECT /*+ ordered use_nl(b) use_nl(c) */ a.작업일련번호, a.작업자ID, NVL(b.고객번호, c.고객번호) 고객번호, NVL(b.주소, c.주소) 주소 FROM 작업지시 a, 개통신청 b, 장애접수 c WHERE b.개통신청번호(+) = DECODE(a.작업구분, 1,a.작업일련번호) AND c.장애접수번호(+) = DECODE(a.작업구분, 2,a.작업일련번호) AND a.접수일자 BETWEEN :fromDate AND :toDate; 부등호 JOIN‘=’ 조건이 아닌 BETWEEN, LIKE 등과 같은 부등호 연산과 JOIN해야 할 때도 있다. 아래 그림의 왼쪽 그림과 같은 월별지점매출 Table을 이용하여 오른쪽 그림의 누적매출을 구해보자. Oracle의 Window 함수를 이용하면 간단하다.12345SELECT 지점, 판매월, 매출, SUM(매출) OVER (PARTITION BY 지점 ORDER BY 판매월 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) 누적매출 FROM 월별지점매출 Window 함수를 사용하지 않고 BETWEEN을 JOIN조건으로 넣어서도 가능하다.123456SELECT a.지점, a.판매월, MIN(a.매출) 매출, SUM(b.매출) 누적매출 FROM 월별지점매출 a, 월별지점매출 b WHERE a.지점 = b.지점 AND a.판매월 &gt;= b.판매월 GROUP BY a.지점, a.판매월 ORDER BY a.지점, a.판매월 BETWEEN JOIN 이력관리 방식 선분이력 시작일자, 종료일자 형식으로 2개의 일자 컬럼으로 이력을 관리 특정시점 이력을 조회할때 BETWEEN 조건으로 간편하게 가능 :dt BETWEEN 시작일자 AND 종료일자 현재시점 : 종료일자 = &#39;99991231&#39; PK값 변경이 자주 발생함 PK를 [Master Key + 시작일자 + 종료일자]로 관리해야 하는데, 새로운 이력이 들어오면 기존의 마지막 종료일자가 변경되어야 함 점이력 주로 시작일자만을 저장하여 관리 특정시점 이력을 조회할때 Subquery를 이용하여 그 시점의 마지막 이력일자를 먼저 구한뒤에 조회 1234567891011121314151617181920212223242526-- 선분이력으로 관리할때의 특정시점 조회SELECT 고객번호, 연체금액, 연체기간 FROM 고객별연체금액 WHERE 고객번호 = :no AND :date BETWEEN 시작일자 AND 종료일자;-- 점이력SELECT a.고객번호, a.연체금액, a.연체기간 FROM 고객별연체금액 a, (SELECT 고객번호, MAX(a.시작일자) 시작일자 FROM 고객별연체금액 WHERE 고객번호 = :no AND 시작일자 &lt;= :date) b WHERE a.고객번호 = b.고객번호 AND a.시작일자 = b.시작일자;-- 또는 체크조건으로SELECT a.고객번호, a.연체금액, a.연체기간 FROM 고객별연체금액 a WHERE a.고객번호 = :no AND a.시작일자 = (SELECT MAX(b.시작일자) FROM 고객별연체금액 b WHERE a.고객번호 = b.고객번호 AND b.시작일자 &lt;= :date); 선분이력 JOIN 고객 Table, 등급변경이력 Table, 전화번호변경이력 Table이 있고, 각각의 이력Table에서 선분이력으로 관리하고 있는 경우 특정시점의 등급과 전화번호를 조회할 경우 1234567SELECT a.고객명, b.등급, c.전화번호 FROM 고객 a, 등급변경이력 b, 전화번호이력 c WHERE a.고객ID = :id AND a.고객ID = b.고객ID AND a.고객ID = c.고객ID AND :dt BETWEEN b.시작일자 AND b.종료일자 AND :dt BETWEEN c.시작일자 AND c.종료일자; 점이력관리에서 ROWID 이용 앞서 살펴본 점이력관리의 경우 동일한 Table을 2번 액세스해야 한다.-123456SELECT a.고객번호, a.연체금액, a.연체기간 FROM 고객별연체금액 a WHERE a.고객번호 = :no AND a.시작일자 = (SELECT MAX(b.시작일자) FROM 고객별연체금액 b WHERE a.고객번호 = b.고객번호 AND b.시작일자 &lt;= :date); 1234567SELECT STATEMENT OPTIMIZER=ALL_ROWS NESTED LOOPS TABLE ACCESS (BY INDEX ROWID) OF &apos;고객별연체금액&apos; INDEX (RANGE SCAN) OF &apos;IDX_고객별연체금액_고객_일자&apos; (NON-UNIQUE) SORT FIRST ROW INDEX (RANGE SCAN (MIN/MAX) OF &apos;IDX_고객별연체금액_고객_일자&apos; (NON-UNIQUE) 이 경우 Subquery에서 rowid를 구해서 Main Query로 전달해주면 조금 더 성능을 향상 시킬 수 있다. 12345678SELECT a.고객번호, a.연체금액, a.연체기간 FROM 고객별연체금액 a WHERE a.고객번호 = :no AND a.rowid = (SELECT /*+ index_desc(b IDX_고객별연체금액_고객_일자) */ rowid FROM 고객별연체금액 b WHERE a.고객번호 = b.고객번호 AND b.시작일자 &lt;= :date AND rownum &lt;= 1); 1234567SELECT STATEMENT OPTIMZER=ALL_ROWS NESTED LOOPS TABLE ACCESS (BY INDEX ROWID) OF &apos;고객별연체금액&apos; INDEX (RANGE SCAN) OF &apos;IDX_고객별연체금액_고객_일자&apos; (NON-UNIQUE) TABLE ACCESS (BY USER ROWID) OF &apos;고객별연체금액&apos; COUNT (STOPKEY) INDEX (RANGE SCAN) OF &apos;IDX_고객별연체금액_고객_일자&apos; (NON-UNIQUE)","categories":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/categories/Database/"},{"name":"SQLP","slug":"Database/SQLP","permalink":"http://DevStarSJ.github.io/categories/Database/SQLP/"}],"tags":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/tags/Database/"},{"name":"Oracle","slug":"Oracle","permalink":"http://DevStarSJ.github.io/tags/Oracle/"},{"name":"SQLP","slug":"SQLP","permalink":"http://DevStarSJ.github.io/tags/SQLP/"}]},{"title":"SQLP 3-4-2 Join","slug":"03.06.join","date":"2016-02-05T15:00:00.000Z","updated":"2017-04-24T00:14:01.000Z","comments":true,"path":"2016/02/06/03.06.join/","link":"","permalink":"http://DevStarSJ.github.io/2016/02/06/03.06.join/","excerpt":"","text":"3과목 SQL 고급 활용 및 Tuning4장 Index와 Join4.3 JOINNested Loop Join Index 상황 12345* PK_DELP : DEPT.DEPTNO* DEPT_LOC_IDX : DEPT.LOC* PK_EMP : EMP.EMPNO* EMP_DEPTNO_IDX : EMP.DEPTNO* EMP_SAL_IDX : EMP.SAL Query 123456SELECT /*+ ORDERED USE_NL(e) */ E.EMPNO, E.ENAME, D.DNAME, E.JOB, E.SAL FROM DEPT d, EMP e WHERE e.DEPTNO = d.DEPTNO -- #1 AND d.LOC = 'DALLAS' -- #2 AND e.SAL &gt;= 1500 -- #3 ORDER BY SAL DESC 위의 경우 실행계획은 다음과 같다. Execution Plan 12345678SELECT STATEMENT OPTIMIZER = ALL_ROWS SORT (ORDER BY) NESTED LOOPS NESTED LOOPS TABLE ACCESS (BY INDEX ROWID) OF &apos;DEPT&apos; (TABLE) INDEX (RANGE SCAN) OF &apos;DEPT_LOC_IDX&apos; (INDEX) INDEX (RANGE SCAN) OF &apos;EMP_DEPT_INDEX&apos; (INDEX) TABLE ACCESS (BY INDEX ROWID) OF &apos;EMP&apos; (TABLE) 순서를 살펴보면 다음과 같다. DEPT_LOC_IDX Index를 이용하여 LOC = &#39;DALLAS&#39; 조건에 맞는 ROWID를 찾아낸다. 해당 ROWID를 이용하여 DEPT Table에서 record를 찾는다. 위 조건에 만족하는 Table의 DEPTNO 칼럼과 EMP_DEPT_INDEX Index의 DEPTNO 칼럼을 NL Join한다. NL Join 결과에서의 EMP_DEPT_INDEX의 ROWID로 EMP Table을 액세스 해서 SAL &gt;= 1500 조건에 만족하는 record를 찾는다. 2번과 5번의 record를 NL Join 한다. 그 결과를 SAL DESC 기준으로 정렬한다. NL Join의 특징 DBMS는 Block단위 I/O를 수행하는데, Random 액세스 하므로 아무리 Index 구성이 완벽해도 대량의 데이터를 JOIN하면 매우 비효율적이다. record 단위로 순차적으로 JOIN을 수행하므로 대용량 데이터 처리시 매우 치명적이다. 하지만, 부분범위처리가 가능한 상황에서 최초의 응답시간은 매우 짧다. 순차적으로 처리되는 특징때문에 Driving Table의 처리 범위에 의해 전체 일량이 결정된다. Index 구성 전략이 중요하다. 소량 데이터를 주로 처리하거나 부분범위처리가 가능한 온라인 트랜잭션 환경에 적합하다. Sort Merge Join 진행 단계 Sort : 양쪽 집합을 JOIN 컬럼 기준으로 정렬 (단, Oracle의 경우 Outer Table에 해당 컬럼에 대한 Index가 있다면 생략 가능) Merge : 정렬된 양쪽 집합을 Merge SQL 123SELECT /*+ ORDERED USE_MERGE(e) */ d.deptno, d.name, e.empno, e.ename FROM dept d, emp e WHERE d.deptno = e.deptno Execute Plan 123456SELECT STATEMENT OPTIMIZER = ALL_ROWS MERGE JOIN TABLE ACCESS (BY INDEX ROWID) OF &apos;DEPT&apos; (TABLE) INDEX (FULL SCAN) OF &apos;PK_DEPT&apos; (INDEX (UNIQUE)) SORT (JOIN) TABLE ACCESS (FULL) OF &apos;EMP&apos; (TABLE) 특징 JOIN하기 전에 양쪽 집합을 정렬한다. 대용량 Table의 경우 Sort자체가 큰 비용을 수반하기 때문에 비효율적일 수 있다. 하지만, Cluster나 Index처럼 미리 정렬된 오브젝트를 이용하면 효과적이다. 부분적으로 부분범위 처리가 가능하다. Outer 집합이 미리 정렬된 상태에서 일부만 Fet하다 멈춘다면 Outer 집합은 끝까지 읽을 필요가 없다. Table별 검색 조건에 의해 전체 일량이 결정 NL Join의 경우 Outer 집합에서 조인 대상이 되는 건수에 의해 좌우된다. Sort Merge Join의 경우 각 집합의 크기, 즉 각 테이블별 검색 조건에 의해 좌우된다. Inner Table을 반복 액세스하지 않는다. Hash Join 진행 단계 둘 중 작은 집합(Build input)을 읽어 Hash Area에 Hash Map을 생성 (Hash Bucket으로 구성된 배열) 큰 집합(Probe Input)을 읽어 Hash Map을 탐색하면서 JOIN SQL 123SELECT /*+ ORDERED USE_HASH(e) */ d.deptno, d.dname, e.empno, e.ename FROM dept d, emp e WHERE d.deptno = e.deptno Execute Plan 1234SELECT STATEMENT OPTIMIZER = ALL_ROWS HASH JOIN TABLE ACCESS (FULL) OF &apos;DEPT&apos; (TABLE) TABLE ACCESS (FULL) OF &apos;EMP&apos; (TABLE) 특징 NL Join처럼 Random 액세스 부하도 없으며, Sort Merge Join 처럼 Sort에 대한 부하도 없다. Build Input의 크기가 작아야 효과적이다. Hash Join 자체는 전체 Table을 다 읽어야 하지만, Probe Input을 Scan하는 단계는 NL Join처럼 부분범위처리가 가능하다. Build Input이 Memory 공간을 초과하는 경우 Partition 단계 : 양쪽 테이블 모두 Hash값에 따라 동적으로 파티셔닝 Join 단계 : 각 파티션별로 크기가 작은 쪽을 Build Input으로 큰 쪽을 Probe Input으로 해서 Hash Join 수행 Join 하기위해서는 Memory로 Load해야 하는데 그 과정에서 가용 Memory를 초과하면 계속해서 Recursive 하게 Partition 단계를 수행한다. Build Input의 Hash Key 중복이 많을 경우 비효율적이게 된다. Hash Bucket에서는 Sequential Scan을 해야 하므로 엔트리가 많아지면 그만큼 비효율적이다. Hash Join 전략 가장 극적으로 효과가 좋기 위한 조건 한 쪽 Table이 가용 Memory에 담길 정도로 충분히 작아야 함 Build Input HashKey 칼럼의 중복 값이 거의 없어야 함 다음과 같은 경우 Hash Join의 사용을 고려해 보아야 한다. Join 칼럼에 적당한 Index가 없어 NL Join이 비효율적일 때 Index가 있더라도 Driving 집합에서 Inner 쪽으로 Join 액세스가 많아 Random 액세스 부하가 심할 때 Sort Merge Join을 하기에 두 테이블이 너무 커 Sort 부하가 심할 때 수행빈도가 낮고 수행 시간이 오래 걸리는 대용량 Table Join 시 Hash 결과는 일회용이다. (재사용이 안된다.) 수행빈도가 높은 작업을 Hash로 하면 메모리 확보를 위해 Latch 경합이 발생해 시스템 동시성을 떨어뜨릴 수 있다. Scalar Subquery Scalar Subquery : 1개의 data (1 row 1 column)만 반환. SQL문 중 column이 위치할 수 있는 대부분의 곳에 사용 가능 대부분의 Scalar Subquery는 Outer Join문으로 변경이 가능하다. 123456789SELECT empno, ename, sal, hiredate, (SELECT d.dname FROM dept d WHERE d.deptno = e.deptno) dname FROM EMP e WHERE sal &gt;= 2000; SELECT empno, ename, sal, hiredate, dname FROM emp e, dept d WHERE e.deptno(+) = d.deptno AND sal &gt;= 2000; 결과만 100% 같을 뿐 아니라 처리 경로도 동일하다.하지만 Scarlar Subquery는 내부적으로 Caching 기법이 작용한다. Scarlar Subquery Cache Subquery의 입력값과 출력값을 Cache에 저장 Main Query에서 같은 입력값이 들어오면 캐시된 출력값을 리턴 Hash 알고리즘을 이용하여 찾기 때문에 입력값의 종류가 소수일 경우 더욱 효과적 2개 이상의 값을 return하고 싶을 땐 값을 결합하여 1개로 만들어서 return하고 밖에서 SUBSTR로 분리하는 방법을 사용 12345SELECT d.deptno, d.dname, avg_sal, min_sal, max_sal FROM dept d, (SELECT deptno, AVG(sal) avg_sal, MIN(sal) min_sal, MAX(sal) max_sal FROM emp GROUP BY deptno) e WHERE d.deptno = e.deptno(+) AND d.loc = 'CHICAGO'; 위의 경우에는 일단 Inline View를 만들기 위해 emp 테이블 전체를 읽어야 한다. 123456SELECT d.deptno, d.dname, (SELECT AVG(sal) FROM emp WHERE emp.deptno = d.deptno) avg_sal, (SELECT MIN(sal) FROM emp WHERE emp.deptno = d.deptno) min_sal, (SELECT MAX(sal) FROM emp WHERE emp.deptno = d.deptno) max_sal FROM dept d WHERE d.loc = 'CHICAGO'; 위의 경우에는 emp를 3번 호출하였다. 123456789SELECT deptno, dname, TO_NUMBER(SUBSTR(ret,1,5)) avg_sal, TO_NUMBER(SUBSTR(ret,6,5)) min_sal, TO_NUMBER(SUBSTR(ret,11,5)) max_sal FROM (SELECT d.deptno, d.dname, (SELECT LPAD(AVG(sal),5) || LPAD(MIN(sal),5) || LPAD(MAX(sal),5) FROM emp WHERE emp.deptno = d.deptno) ret FROM dept d WHERE d.loc = 'CHICAGO'); 다소 Query가 좀 복잡해 졌지만, emp 테이블을 1번만 읽고도 같은 결과를 출력하였다.","categories":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/categories/Database/"},{"name":"SQLP","slug":"Database/SQLP","permalink":"http://DevStarSJ.github.io/categories/Database/SQLP/"}],"tags":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/tags/Database/"},{"name":"Oracle","slug":"Oracle","permalink":"http://DevStarSJ.github.io/tags/Oracle/"},{"name":"SQLP","slug":"SQLP","permalink":"http://DevStarSJ.github.io/tags/SQLP/"}]},{"title":"SQLP 3-4-1 Index","slug":"03.05.index","date":"2016-02-04T15:00:00.000Z","updated":"2017-04-24T00:07:47.000Z","comments":true,"path":"2016/02/05/03.05.index/","link":"","permalink":"http://DevStarSJ.github.io/2016/02/05/03.05.index/","excerpt":"","text":"3과목 SQL 고급 활용 및 Tuning4장 Index와 Join4.1 IndexIndex의 NULL값 Oracle : 모두 NULL인 값은 저장하지 않음. NULL은 맨 뒤에 저장 MS-SQL : 모두 NULL인 값도 저장. NULL은 맨 앞에 저장 Index 탐색 수직 탐색 수평적 탐색을 위한 시작점을 찾는 과정 Root Node에서 Leaf Node까지의 검색 Index 조건에 맞는 첫번째 값을 찾아가는 연산 수평 탐색 Leaf Node끼리 연결된 Link를 통해서 범위 검색 Index Scan 방식1. Index Range Scan1INDEX (RANGE SCAN) OF &apos;인덱스명&apos; (INDEX) 수직 탐색 후 Leaf Block을 필요한 범위만 Scan B*Tree Index의 가장 일반적이고 정상적인 형태 Index 구성 칼럼 중 선두 컬럼이 조건절에 사용되어야만 가능 생성된 결과집합은 Index 컬럼 순대로 정렬된 상태 (ORDER BY, MIN, MAX 처리 가능) 2. Index Full Scan1INDEX (FULL SCAN) OF &apos;인덱스명&apos; (INDEX) 수직 탐색 없이 Leaf Block을 처음부터 끝까지 수평적으로 Scan 대개의 경우 Index의 선두 컬럼이 조건절에 없으면 Optimizer는 Table Full Scan을 고려한다. 하지만 다음 경우에는 Optimzer가 전략적으로 Index Full Scan을 고려한다. Table이 대용량이거나, Index의 나머지 칼럼으로 대부분의 record를 filtering하고 일부에 대해서만 Table 액세스가 발생하는 경우 ORDER BY 연산을 해야하는데 first_rows Hint를 이용하여 부분범위 처리를 할 경우. 하지만 이 경우 사용자가 FETCH를 끝까지 다 할 경우 Table Full Scan보다 더 비효율적이게 된다. 3. Index Unique Scan1INDEX (UNIQUE SCAN) OF &apos;PK 또는 Unique Index명` (UNIQUE) 수직 탐색만으로 Scan Unique Index를 = 조건으로 검색할 경우에만 작동 4. Index Skip Scan1INDEX (SKIP SCAN) OF &apos;인덱스명&apos; (INDEX) INDEX의 선두컬럼이 조건절에 빠졌을 경우 대부분 Table Full Scan을 사용하지만 9i에서 새로 생긴 방식 선두 컬럼의 DISTICT 수가 적고, 후행 컬럼의 DISTINCT 수가 많을 경우 효과적 5. Index Fast Full Scan Index에 포함된 컬럼만으로 조회가 가능한 경우 Index Tree구조를 무시하고 Segment 전체를 Multiblock Read 방식으로 Scan 결과집합 순서가 보장 안됨 Parallel Scan 가능 6. Index Range Scan Descending1INDEX (RANGE SCAN DESCENDING) OF &apos;인덱스명&apos; (INDEX) Index Range Scan과 동일한 방법이나 뒤에서 앞으로 Scan Index에 저장된 순서와는 반대로 정렬된 결과집합을 출력 MIN / MAX 값을 구할 경우 1건만 읽고 멈추는 실행계획으로 유도할 경우에 좋음 1INDEX (RANGE SCAN (MIN/MAX)) OF &apos;인덱스명&apos; (INDEX) Index 종류1. B*Tree Index 가장 기본적인 Index 형식 최적의 성능을 위해서는 Index Fragmentation을 고려해야 함 Unbalnaced Index Root에서 Leaf Node까지의 Height가 다른 경우 BTree에서는 이런 현상이 발생하지 않음 (BalancedTree에서 Unbalanced 현상이 생기는건 말이 안됨) Index Skew Index Enrty가 한쪽으로 치우치는 현상 대량의 delete 작업 후에는 한쪽의 Leaf Node들이 empty 상태가 됨 empty Node들은 언제든 재사용 가능하지만, 다시 채워질 때까지는 Index Scan 효율이 떨어짐 MS-SQL은 주기적으로 Index를 정리해주므로 이런 현상이 나타나지 않음 Index Sparse Index Block 내의 밀도(density)가 떨어지는 현상 아래와 같은 현상이 일어나면 Index Sparse라 판단 Index 내의 record는 많이 삭제했지만, Index Scan Block 수는 변화가 없음 Index record수는 일정한데, Index 사용 공간이 점점 커짐 Index 재생성 위와 같은 Fragmentation 현상을 제거하기 위해 Index를 삭제 후 재생성 재생성은 수행시간과 부하가 큰 작업이므로 아래와 같이 예상효과가 확실할 때만 시행하는게 바람직함 Index 분할에 의한 경합이 현저히 높을 때 자주 사용되는 Index Scan 효율을 높이고자 할 때. 특히 NL Join에서 반복 액세스 되는 경우 대량의 delete 작업 이후 새로운 record가 입력될 때까지 오랜 시간이 걸릴 때 총 record수가 일정한데도 Index가 계속 커질 때 2 Bitmap Index Column이 가질수 있는 값의 DISTINCT 수만큼의 BIT(0,1)를 2차원 배열로 표현 여러 INDEX를 동시에 활용할 수 있어서, 정형화되지 않은 ad-hoc query가 많은 환경에 효과적 DISTICT수가 적을 경우에는 B*Tree Index보다 적은 공간을 차지하지만, DISTINCT수가 많으면 더 큰 공간을 차지할 수도 있다. 등치(=), 부정(&lt;&gt;), NULL 조건을 찾는데 효과적이다. 하나의 record만 변경되더라도 전체에 Lock이 걸리므로 OLTP환경에서는 쓸수 없음 대용량의 DW(OLAP) 환경에 적합 3. FBI (Function Based Index) 컬럼값 자체가 아닌 함수결과값으로 B*Tree Index를 생성 Index 컬럼 자체를 가공하면 정상적인 Index 사용이 불가능한데, 이 경우 효과적으로 Scan 가능 123CREATE INDEX EMP_NVL_COMM ON EMP(NVL(COMM,0)); -- 상여금이 없는 경우 0CREATE INDEX EMP_UPPER_ENAME ON EMP(UPPER(ENAME)); -- 이름을 대소문자 구분없이 검색해야 할 경우 4. Reverse Key Index Key 값을 Reverse() 함수를 거쳐서 저장 한쪽으로만 치우치는 형태의 값을 분산적으로 저장하고자 할 경우 효과적 주문일시의 경우 항상 증가된 값이 들어오르모 오른쪽 Leaf Block에만 데이터가 쌓인다. (Right Growing Index) 이럴 경우 주문일자를 거꾸로 입력하면 Leaf 전체에 고르게 저장되므로 Transaction을 분산시키는 효과를 얻을 수 있다. 하지만, 등치(=) 조건으로만 검색이 가능 (부등호, BETWEEN, LIKE로의 검색은 불가능) 1CREATE INDEX IDX_주문_주문일시 ON 주문(REVERSE(주문일시)); 5. Cluster Index12CREATE CLUSTER C_DEPTNO (DEPTNO NUMBER(2)) INDEX;CREATE INDEX I_DEPTNO ON CLUSTER C_DEPTNO; Oracel Clusterd Table : 값은 Key값을 가진 record를 한 block에 저장 (1 block의 크기가 넘으면 cluster chain으로 연결) CLUSTER에 대한 Index를 생성 Index Key값은 Unique Index Key : Table Record가 1:M 관계 (일반 Index는 1:1) Index Key에서 Random Scan, Cluster 내에서는 Sqeuential Scan 다음과 같은 경우 유리 Scan 범위가 넓을 경우 크기가 작고 NL Join으로 반복 Lookup하는 Table Column 수가 적고 rocord가 많은 Table 데이터 입력 패턴과 조회 패턴이 서로 다른 Table ex. 실적등록 및 조회의 경우 입력은 일자별로 진행되지만, 조회는 사원별로 하는 경우 일반 Table의 경우 사원마다 365일의 데이터 페이지를 Random 액세스 해야함 사번을 기준으로 CLUSTER를 생성하면 효과적 4.2 Index TuningIndex Tuning 기초 Index 선두 컬럼이 조건절에 사용되더라도 Index Range Scan이 불가능하거나 Index를 사용못하는 경우 칼럼 가공 : SUBSTR(DNAME, 1, 2) = &#39;영업&#39; 부정 비교 : DNAME &lt;&gt; &#39;영업부&#39; NOT NULL 조건 : COMM IS NOT NULL (당연히 INDEX에는 NULL이 없으므로, 그냥 Index Full Scan과 같다.) Index 컬럼 가공에 대한 Tuning SUBSTR(DNAME, 1, 2) = &#39;영업&#39; -&gt; DNAME LIKE &#39;영업%&#39; SAL * 12 &gt; 3000 -&gt; SAL &gt; 3000 / 12 TO_CHAR(일시,&#39;yyyymmdd&#39;) = :dt -&gt; 일시 &gt;= TO_DATE(:dt,&#39;yyyymmdd&#39;) AND 일시 &lt; TO_DATE(:dt,&#39;yyyymmdd&#39;) + 1 연령 || 직업 = &#39;30공무원&#39; -&gt; 연령 = 30 AND 직업 = &#39;공무원&#39; 회원번호 || 지점번호 = :str -&gt; 회원번호 = SUBSTR(:str,1,2) AND 지점번호 = SUBSTR(:str,3,4) Implicit Conversion (묵시적 형변환) 컬럼 타입과 비교값 타입이 다를 경우 묵시적 형변환이 발생 문자형과 숫자형 : 문자형을 숫자형으로 변환 문자형과 날짜형 : 문자형을 날짜형으로 변환 변환되는게 컬럼쪽이라면 Index를 사용하지 못하고 Table Full Scan 발생 이런 변환의 우선순위를 외우기 보다는 그냥 비교값을 컬럼 타입으로 변환해주는게 좋음 Table Random 액세스 최소화 Index rowid에 의한 Table 액세스1TABLE ACCESS (BY INDEX ROWID) OF &apos;컬럼&apos; (TABLE) rowid는 disk 상의 위치정보이다. DB Buffer Cache에서의 해당 Block의 위치는 rowid의 hash값을 이용하여 bucket list로 찾아간다. bucket list 상에서 값을 찾는 과정에서도 Latch, 버퍼 Lock등을 이용해서 찾는다. Clustering Factor Index상 같은 Block에 있는 record들라도 Table상에서는 다른 Block들에 있을 수 있다. Index와 Table의 Record정렬 순서가 비교적 같은 경우에는 Clustering Factor가 좋아서 Index Scan 효율이 좋다. Index 손익분기점 Index Range Scan에 의한 비용이 Table Full Scan보다 느려지는 지점 일반적으로 5 ~ 20% 정도지만 Clustering Factor가 나쁘면 5% 미만이 될수도 있고, 아주 좋을 땐 90%까지 올라가기도 한다. Index rowid에 의한 Table 액세스 : Random 액세스, Single Block Read Full Table Scan : Sequential 액세스, Multiblock Read 손익분기점 극복하기 Clustering Index, IOT : Table을 Index구조로 생성함으로써 항상 정렬된 상태를 유지 Index Key 이외의 미리 지정된 칼럼을 Leaf Level에 모두 저장 (MS-SQL의 Include index) Oracle의 Clusterd Table : Key값이 같은 record를 같은 Block에 저장함으로 Random 액세스는 Key값당 1번 Partitioning : 자주 사용하는 컬럼 기준으로 파티셔닝을 하면 Full Table Scan이더라도 일부 파티션만 읽고 멈출 수 있음 Table Random 액세스 최소화 Tuning1. Index 컬럼 추가 기존 Index의 구성이나 신규 추가는 실 운영 환경에서는 함부로 바꾸기가 쉽지 않다. 기존 Index에 조건절의 비교조건을 보고 뒤에 컬럼을 추가해줘서 최대한 조건비교를 Index 내에서 끝내고 Table 액세스를 최소화 한다. 123456CREATE INDEX I_EMP_01 ON EMP(DEPTNO, JOB);SELECT /*+ INDEX(I_EMP_01) */ ENAME, JOB, SAL FROM EMP WHERE DEPTNO = 30 AND SAL &gt;= 2000; 위의 상황에서는 DEPTNO = 30인 조건에 맞는 record들에 대해서 Table에서 record들을 가져와야 한다.아래와 같이 기존 Index를 그대로 두고 컬럼만 추가해 줄 경우 Index의 액세스는 줄일 수 없지만, Table 액세스는 줄일 수 있다. 1CREATE INDEX I_EMP_01 ON EMP(DEPTNO, JOB, SAL); 만약 Index의 칼럼만으로도 조회가 가능하다면 Table 액세스 자체를 안해도 될 수 있다. MS-SQL에서는 이 경우를 Covered Index, Covered Query 라 부른다. Include Index : MS-SQL에서는 Index에 Key가 아닌 일반 컬럼 추가가 가능하다. CREATE INDEX EMP_01 ON EMP (DEPTNO) INCLUDE (SAL); 2. IOT, Cluster 활용 Index Key를 이용해서 한번만에 찾아가서 Sequential로 찾음 Index Key의 Hash값으로 찾아가므로 = 조건으로만 검색되는 칼럼을 Key로 해야한다. 3. 수동으로 Clustering Factor 높이기 자주 이용되는 Index를 기준으로 Table을 재생성 한 Table에 Index가 여러 개인 경우 그 중 1개에 대해서만 Clustering Factor가 좋게 할 수 있다. Index Scan 범위 최소화 일반적으로 Random 액세스 발생량을 줄이고, Sequential 액세스에 의한 선택 배중을 높이면 성능이 좋아진다. 1. Index 선행 칼럼이 범위조건일 경우 범위 조건 이후의 칼럼들에 대해서는 Range Scan을 해야 하므로 읽어야 할 범위가 넓어진다. 이럴 경우에는 Index 컬럼 순서를 바꿔주는게 효과적이다. 2. 범위조건을 In-List로 전환 범위조건으로 검색하는 컬럼의 순서를 바꾸기가 힘든 경우에는 BETWEEN 조건을 IN-List로 바꿔주면 효과적이다. 실행계획상에 INLIST ITERATOR로 처리되므로 Scan 범위를 줄일 수 있다. IN-List는 UNION ALL로 따로 실행되는 거랑 같다. IN-List의 개수가 적을 경우 효과적이다. 많다면 범위조건일 경우보다 비효율적일 수 있다. 1DEPTNO BETWEEN 10 AND 20 -&gt; DEPTNO IN (10, 20) 3. 범위조건이 2개 이상일 경우123456CREATE INDEX I_PROD ON PRODUCT(COMPANY, PTYPE, PNAME);SELECT * FROM PRODUCT WHERE COMPANY = :com AND PTYPE LIKE :ptype || '%' AND PNAME LIKE :pname || '%'; 첫번째 범위조건에 의해서 스캔 범위가 거의 결정나고, 두번째는 필터 조건 역할만 한다. 만약 이 경우 첫번째 범위조건이 입력되지 않을 수 있다면 SQL을 2개로 나누는게 효과적이다. 123456789101112SELECT * FROM PRODUCT WHERE :ptype IS NULL AND COMPANY = :com AND PNAME LIKE :pname || '%'; UNION ALL SELECT * FROM PRODUCT WHERE :ptype IS NOT NULL AND COMPANY = :com AND PTYPE = :ptype AND PNAME LIKE :pname || '%'; Index 설계 기본 공식 조건절에 항상 사용되거나, 자주 사용되는 컬럼을 선정 = 조건으로 자주 조회되는 칼럼을 앞으로 조건절에 사용되지 않더라도 Sort 연산 (ORDER BY, GROUP BY)를 대체할 목적으로 구성이 가능 선택도(Selectivy)가 충분히 낮지 않다면 Full Table Scan보다 느려지기 때문에 의미가 없음 추가 고려사항 Query 수행 빈도 업무상 중요도 Clustering Factor 데이터량 DML 부하 저장 공간 Index 관리 비용","categories":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/categories/Database/"},{"name":"SQLP","slug":"Database/SQLP","permalink":"http://DevStarSJ.github.io/categories/Database/SQLP/"}],"tags":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/tags/Database/"},{"name":"Oracle","slug":"Oracle","permalink":"http://DevStarSJ.github.io/tags/Oracle/"},{"name":"SQLP","slug":"SQLP","permalink":"http://DevStarSJ.github.io/tags/SQLP/"}]},{"title":"Codejock Xtreme ToolkitPro Chart Control Tutorial","slug":"Codejock.Xtreme ToolkitPro.Chart.Control.Tutorial","date":"2016-02-04T06:28:00.000Z","updated":"2017-05-30T00:07:06.000Z","comments":true,"path":"2016/02/04/Codejock.Xtreme ToolkitPro.Chart.Control.Tutorial/","link":"","permalink":"http://DevStarSJ.github.io/2016/02/04/Codejock.Xtreme ToolkitPro.Chart.Control.Tutorial/","excerpt":"","text":"Codejock Xtreme ToolkitPro Chart Control TutorialToolkitPro의 Chart Control 인 CXTPChartContorl의 간단한 사용법을 소개해 드리도록 하겠습니다.기본적으로 ToolkitPro를 설치하고 환경설정하는 방법은 생략하겠습니다.아래 Link를 참조해 주세요. 먼저 MFC Application Project를 생성하여 Dialog로 생성해 주세요. 물론 ToolkitPro를 사용하려면 stdafx.h에 ToolkitPro 헤더파일을 추가해 주세요.1#include &lt;XTToolkitPro.h&gt; 1.Resource File (.rc)에서 Dialog Design에 찾아서 아래와 같이 Control을 타이핑1CONTROL &quot;Chart&quot;, IDC_CHARTCONTROL, &quot;XTPChartControl&quot;, WS_TABSTOP, 7, 7, 245, 186 2. Resource.h에 추가1#define IDC_CHARTCONTROL 103 Resource View에서 마우스로 대충 크기 변환해주세요. 대충 아래와 같은 모양이 됩니다. 12345678910IDD_XTPCHARTSAMPLE_DIALOG DIALOGEX 0, 0, 427, 287STYLE DS_SETFONT | DS_MODALFRAME | DS_FIXEDSYS | WS_POPUP | WS_VISIBLE | WS_CAPTION | WS_SYSMENUEXSTYLE WS_EX_APPWINDOWCAPTION &quot;XTPChartSample&quot;FONT 8, &quot;MS Shell Dlg&quot;, 0, 0, 0x1BEGIN DEFPUSHBUTTON &quot;OK&quot;,IDOK,312,266,50,14 PUSHBUTTON &quot;Cancel&quot;,IDCANCEL,370,266,50,14 CONTROL &quot;Chart&quot;,IDC_CHARTCONTROL,&quot;XTPChartControl&quot;,WS_TABSTOP,7,7,413,255END 3. 컨트럴에 마우스 우 클릭 Add Variable 누른 뒤 그림대로 추가해주세요. 위와 같이 하지 않고 직접 코딩하여도 됩니다. XTPChartSampleDlg.h 12public: CXTPChartControl m_wndChartControl; XTPChartSampleDlg.cpp 12345void CXTPChartSampleDlg::DoDataExchange(CDataExchange* pDX)&#123; CDialogEx::DoDataExchange(pDX); DDX_Control(pDX, IDC_CHARTCONTROL, m_wndChartControl);&#125; 모든 구현은 void InitChart();를 추가하여 여기다가 하겠습니다. BOOL CXTPChartSampleDlg::OnInitDialog()에서 InitChart();를 호출하도록 해주세요. 4. 구현어떤 작업을 하던지 Content 객체를 가져와서 작업을 해야 합니다. 1CXTPChartContent* pContent = m_wndChartControl.GetContent(); Title 설정 1234// Title 설정CXTPChartTitleCollection* pTitles = pContent-&gt;GetTitles();CXTPChartTitle* pTitle = pTitles-&gt;Add(new CXTPChartTitle());pTitle-&gt;SetText(_T(\"My Chart\")); Series에 Point 추가 1234567891011// Series, Series Point 추가CXTPChartSeriesCollection* pCollection = pContent-&gt;GetSeries();CXTPChartSeries* pSeries = pCollection-&gt;Add(new CXTPChartSeries());pSeries-&gt;SetStyle(new CXTPChartLineSeriesStyle());CXTPChartSeriesPointCollection* pPoints = pSeries-&gt;GetPoints();pPoints-&gt;Add(new CXTPChartSeriesPoint(0, 3));pPoints-&gt;Add(new CXTPChartSeriesPoint(1, 1));pPoints-&gt;Add(new CXTPChartSeriesPoint(2, 2));pPoints-&gt;Add(new CXTPChartSeriesPoint(3, 0.5)); 실행시키면 다음과 같은 화면이 나옵니다. 여기에서 Series를 하나 더 추가해 보겠습니다. 12345678910CXTPChartSeries* pS2 = pCollection-&gt;Add(new CXTPChartSeries());pSeries-&gt;SetName(_T(\"Series2\"));pS2-&gt;SetStyle(new CXTPChartLineSeriesStyle());CXTPChartSeriesPointCollection* pPoints = pS2-&gt;GetPoints();pPoints-&gt;Add(new CXTPChartSeriesPoint(0, 2));pPoints-&gt;Add(new CXTPChartSeriesPoint(1, 0.5));pPoints-&gt;Add(new CXTPChartSeriesPoint(2, 3));pPoints-&gt;Add(new CXTPChartSeriesPoint(3, 1)); Series의 Label을 설정하려면 다음과 같이 하면 됩니다.소숫점 1자리까지 나오게 하는 예제 입니다. 1234567// SeriesLabel의 설정for (int i = 0; i &lt; pCollection-&gt;GetCount(); i++)&#123; CXTPChartSeriesLabel* pLabel = pCollection-&gt;GetAt(i)-&gt;GetStyle()-&gt;GetLabel(); pLabel-&gt;GetFormat()-&gt;SetCategory(xtpChartNumber); pLabel-&gt;GetFormat()-&gt;SetDecimalPlaces(1); // 소숫점 표시&#125; Point Label 자체를 안보이게 하려면 다음 문장을 추가하면 됩니다. 1pLabel-&gt;SetVisible(FALSE); 범주 보이게 하기 1pContent-&gt;GetLegend()-&gt;SetVisible(TRUE); Series의 통계값 계산 아래와 같은 함수들을 지원해줘서 통계값을 쉽게 계산할 수 있습니다. Min, Max등의 다양한 함수가 많습니다. 123double dArithmeticMean = pPoints-&gt;GetArithmeticMean(0);double dVariance = pPoints-&gt;GetVariance(0);double dStd = pPoints-&gt;GetStandardDeviation(0); 축(AXIS 설정) 123456789101112131415161718// Axis 설정//CXTPChartDiagram2D* pDiagram = DYNAMIC_DOWNCAST(CXTPChartDiagram2D, pCollection-&gt;GetAt(0)-&gt;GetDiagram());CXTPChartDiagram* pDiagram = pCollection-&gt;GetAt(0)-&gt;GetDiagram();CXTPChartDiagram2D* pD2D = DYNAMIC_DOWNCAST(CXTPChartDiagram2D, pDiagram);CXTPChartAxis *pAxisX = pD2D-&gt;GetAxisX();CXTPChartAxisTitle* pTitle = pAxisX-&gt;GetTitle();pTitle-&gt;SetText(_T(\"X-Argument\"));pTitle-&gt;SetVisible(TRUE);CXTPChartAxis *pAxisY = pD2D-&gt;GetAxisY();CXTPChartAxisTitle* pTitle2 = pAxisY-&gt;GetTitle();pTitle2-&gt;SetText(_T(\"Y-Value\"));pTitle2-&gt;SetVisible(TRUE); Series Marker 안보이게 하기 1234567for (int i = 0; i &lt; pCollection-&gt;GetCount(); i++)&#123; CXTPChartPointSeriesStyle* pStyle = (CXTPChartPointSeriesStyle*)pCollection-&gt;GetAt(i)-&gt;GetStyle(); pStyle-&gt;GetMarker()-&gt;SetVisible(FALSE); //pStyle-&gt;GetMarker()-&gt;SetSize(20); // Maeker Size 조정 //pStyle-&gt;GetMarker()-&gt;SetType(xtpChartMarkerCircle); // enum XTPChartMarkerType&#125; 마우스 휠을 이용한 Zoom 허용 및 Scroll 허용 12pD2D-&gt;SetAllowZoom(TRUE); // 마우스 휠을 이용한 Zoom 허용pD2D-&gt;SetAllowScroll(TRUE); // Scroll 허용 Chart Image 저장 1m_wndChartControl.SaveAsImage(_T(\"D:\\\\A.PNG\"),CSize(600,400)); 위 설명한 내용의 Full Source123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110void CXTPChartSampleDlg::InitChart()&#123; // Content를 이용해서 Chart의 Title, Series, Legends등의 설정이 가능 CXTPChartContent* pContent = m_wndChartControl.GetContent(); if (!pContent) return; pContent-&gt;GetLegend()-&gt;SetVisible(TRUE); // Title 설정 CXTPChartTitleCollection* pTitles = pContent-&gt;GetTitles(); if (pTitles) &#123; CXTPChartTitle* pTitle = pTitles-&gt;Add(new CXTPChartTitle()); if (pTitle) &#123; pTitle-&gt;SetText(_T(\"My Chart\")); &#125; &#125; // Series, Series Point 추가 CXTPChartSeriesCollection* pCollection = pContent-&gt;GetSeries(); if (pCollection) &#123; CXTPChartSeries* pSeries = pCollection-&gt;Add(new CXTPChartSeries()); if (pSeries) &#123; pSeries-&gt;SetName(_T(\"Series1\")); pSeries-&gt;SetStyle(new CXTPChartLineSeriesStyle()); CXTPChartSeriesPointCollection* pPoints = pSeries-&gt;GetPoints(); if (pPoints) &#123; pPoints-&gt;Add(new CXTPChartSeriesPoint(0, 3)); pPoints-&gt;Add(new CXTPChartSeriesPoint(1, 1)); pPoints-&gt;Add(new CXTPChartSeriesPoint(2, 2)); pPoints-&gt;Add(new CXTPChartSeriesPoint(3, 0.5)); double dArithmeticMean = pPoints-&gt;GetArithmeticMean(0); double dStd = pPoints-&gt;GetStandardDeviation(0); &#125; &#125; CXTPChartSeries* pS2 = pCollection-&gt;Add(new CXTPChartSeries()); if (pS2) &#123; pS2-&gt;SetName(_T(\"Series2\")); pS2-&gt;SetStyle(new CXTPChartLineSeriesStyle()); CXTPChartSeriesPointCollection* pPoints = pS2-&gt;GetPoints(); if (pPoints) &#123; pPoints-&gt;Add(new CXTPChartSeriesPoint(0, 2)); pPoints-&gt;Add(new CXTPChartSeriesPoint(1, 0.5)); pPoints-&gt;Add(new CXTPChartSeriesPoint(2, 3)); pPoints-&gt;Add(new CXTPChartSeriesPoint(3, 1)); &#125; &#125; // SeriesLabel의 설정 for (int i = 0; i &lt; pCollection-&gt;GetCount(); i++) &#123; CXTPChartSeriesLabel* pLabel = pCollection-&gt;GetAt(i)-&gt;GetStyle()-&gt;GetLabel(); pLabel-&gt;GetFormat()-&gt;SetCategory(xtpChartNumber); pLabel-&gt;GetFormat()-&gt;SetDecimalPlaces(1); // 소숫점 표시 pLabel-&gt;SetVisible(FALSE); &#125; // Axis 설정 //CXTPChartDiagram2D* pDiagram = DYNAMIC_DOWNCAST(CXTPChartDiagram2D, pCollection-&gt;GetAt(0)-&gt;GetDiagram()); CXTPChartDiagram* pDiagram = pCollection-&gt;GetAt(0)-&gt;GetDiagram(); CXTPChartDiagram2D* pD2D = DYNAMIC_DOWNCAST(CXTPChartDiagram2D, pDiagram); if (pD2D) &#123; CXTPChartAxis *pAxisX = pD2D-&gt;GetAxisX(); if (pAxisX) &#123; CXTPChartAxisTitle* pTitle = pAxisX-&gt;GetTitle(); if (pTitle) &#123; pTitle-&gt;SetText(_T(\"X-Argument\")); pTitle-&gt;SetVisible(TRUE); &#125; &#125; CXTPChartAxis *pAxisY = pD2D-&gt;GetAxisY(); if (pAxisX) &#123; CXTPChartAxisTitle* pTitle = pAxisY-&gt;GetTitle(); if (pTitle) &#123; pTitle-&gt;SetText(_T(\"Y-Value\")); pTitle-&gt;SetVisible(TRUE); &#125; &#125; &#125; // Marker 안보이게 하기 for (int i = 0; i &lt; pCollection-&gt;GetCount(); i++) &#123; CXTPChartPointSeriesStyle* pStyle = (CXTPChartPointSeriesStyle*)pCollection-&gt;GetAt(i)-&gt;GetStyle(); pStyle-&gt;GetMarker()-&gt;SetVisible(FALSE); //pStyle-&gt;GetMarker()-&gt;SetSize(20); // Maeker Size 조정 //pStyle-&gt;GetMarker()-&gt;SetType(xtpChartMarkerCircle); // enum XTPChartMarkerType &#125; pD2D-&gt;SetAllowZoom(TRUE); // 마우스 휠을 이용한 Zoom 허용 pD2D-&gt;SetAllowScroll(TRUE); // Scroll 허용 m_wndChartControl.SaveAsImage(_T(\"D:\\\\A.PNG\"),CSize(600,400)); &#125;&#125; 예제 소스https://github.com/DevStarSJ/Cpp/tree/master/MFC/XTPChartSample","categories":[{"name":"CPP","slug":"CPP","permalink":"http://DevStarSJ.github.io/categories/CPP/"},{"name":"MFC","slug":"CPP/MFC","permalink":"http://DevStarSJ.github.io/categories/CPP/MFC/"}],"tags":[{"name":"CPP","slug":"CPP","permalink":"http://DevStarSJ.github.io/tags/CPP/"},{"name":"MFC","slug":"MFC","permalink":"http://DevStarSJ.github.io/tags/MFC/"},{"name":"ToolkitPro","slug":"ToolkitPro","permalink":"http://DevStarSJ.github.io/tags/ToolkitPro/"}]},{"title":"SQLP 3-3 Optimizer","slug":"03.04.optimizer","date":"2016-02-03T15:00:00.000Z","updated":"2017-04-24T00:04:58.000Z","comments":true,"path":"2016/02/04/03.04.optimizer/","link":"","permalink":"http://DevStarSJ.github.io/2016/02/04/03.04.optimizer/","excerpt":"","text":"3과목 SQL 고급 활용 및 Tuning3장 Optimizer 원리3.1 OptimizerSQL을 가장 빠르고 효율적으로 수행할 최적(최저비용)의 처리경로를 생성해주는 DBMS 핵심엔진 Optimizer 종류 RBO (Rule-based Optimizer) : 규칙(우선 순위)를 가지고 실행계획 생성 CBO (Cost-based Optimizer) : 통계정보를 기반으로 여러가지 실행계획을 생성하여 그중 최저비용의 실행계획을 선택 최적화 과정 Parser : SQL Parsing. SQL의 문법(Syntax) , 의미 (Semantic)을 확인 Optimizer Query Transformer : Parsing된 SQL을 표준 형태로 변환 Estimator : 통계정보를 이용하여 선택도, 카디널리티 등으로 Execution Plan의 총 비용을 계산 Plan Generator : 후보군이 될만한 Execution Plan을 생성 Row-Source Generator : 최종 선택된 Execution Plan을 SQL 엔진이 실행할 수 있는 코드 생성 SQL Engine : SQL을 실행 최적화 목표 전체 처리속도 최적화 (all_rows) : 결과집합을 끝까지 읽는 것을 전제. 대부분 DBMS의 기본옵션 최초 응답속도 최적화 (first_rows) : 결과중 일부만 읽다가 멈추는 것을 전제.12SELECT /*+ ALL_ROWS */ ... ; -- 전체 처리속도 최적화SELECT /*+ FIRST_ROWS(10) */ ... ; -- 처음 10개의 row만 읽고 멈추는 것을 전제로 최적화 Optimizer 통계유형 Table : 전체 레코드 수, 총 블록 수, 빈 블록 수, 한 행당 평균 크기 등 Index : 높이, 리프 블록 수, 클러스터링 팩터, 인덱스 레코드 수 등 Column : 값의 수, MIN, MAX, 밀도, NULL값 개수, 히스토그램 등 System : CPU 속도, 평균 I/O 속도, 초당 I/O 처리량 등 통계정보를 이용한 비용계산 원리 선택도 (Selectivity) : 1 / Distinct Value 수 카디널리티 (Cardinality) : 총 Row 수 X 선택도 히스토그램 (Histogram) : Column의 분포도 도수분포 히스토그램 : 값별로 빈도수(Frequency Number)를 저장 높이균형 히스토그램 : 각 버킷의 높이를 같게 하고 빈도 수가 많은 값(popular value)는 여러 버킷에 할당. 컬럼이 가진 값의 수가 아주 많을 경우 효과적 비용 (Cost) I/O 비용 모델 : 예상되는 I/O 요청(Call) 횟수로 평가 CPU 비용 모델 : I/O비용 모델 + 시간 개념을 더해 비용 산정 Optimizer Hint Optimizer도 잘못된 판단을 할 수 있으므로, 개발자가 직접 실행방식을 원하는대로 유도하는 방법 Hint가 무시되는 경우 문법적으로 틀린 경우 의미적으로 틀린 경우 : RBO에서 CBO Hint (ex. first_rows_10), unnest 와 push_subq를 같이 쓴 경우 잘못된 참조 사용 : 없는 Table, Index, Alias 지정 논리적으로 불가능 : JOIN에 등치(=)조건 없이 Hash Join으로 유도, Nullable 칼럼에 대해 Index를 활용해 COUNT(*) 계산시도 Hint 종류는 별도로 정리할 예정 3.2 Query Transformation (쿼리 변환) Optimizer가 SQL을 분석하여 동일하지만 더 나은 성능의 SQL로 재작성 Query Transformer가 담당 Query 변환 방식 Heuristic Query 변환 : 결과만 보장된다면 무조건 수행. Rule-based 최적화 기법 Cost-based Query 변환 : 변환된 Query의 비용이 더 낮을 때만 그것을 사용 Subquery Unnesting Nested Subquery를 풀어서 Main-query와의 JOIN된 형태로 변환 Optimizer는 JOIN방식에 대해서 여러가지 최적화 기법을 시도 할 수 있다. 만약 Nested Subquery를 그대로 두고 최적화를 해야 한다면 각각의 Subquery, Main-query별로 최적화를 해야하는데, 이렇게 부분의 최적화가 전체 수행 성능의 최적화를 보장하진 못한다. 관련 Hint UNNEST : Unnesting 하여 JOIN방식으로 유도 NO_UNNEST : 그래도 둔 상태에서 Filter 방식으로 최적화 유도 123SELECT * FROM EMP WHERE DEPTNO IN (SELECT DEPTNO FROM DEPT); -- Main (M) : Sub (1) 관계에서는 Unnesting이 대부분 유리-- 변환SELECT EMP.* FROM DEPT, EMP WHERE EMP.DEPT = DEPT.DEPTNO; Subquery가 M쪽 집합이거나 Non-unique Index일 경우 예를 들어 SELECT * FROM DEPT WHERE DEPTNO IN (SELECT DEPTNO FROM EMP)와 같은 경우 위 방법과 같이 Unnesting하면 결과가 달라지게 된다. (EMP에는 같은 DEPTNO가 많다.) 이럴 경우 Optimizer는 2 가지 방법 중 하나를 선택한다. Sort Unique : Subquery쪽 Table이 1쪽임을 호가신할 수 없는 경우 먼저 Sort Unique를 수행한 후에 JOIN Semi Join : Driving Table의 한 row가 Inner Table의 한 row와 JOIN에 성공하면 Outer Table의 다음 row를 진행. Main-query 쪽 Table이 먼저 Driving될 경우 View Merging 일반 View, Inline View를 JOIN으로 풀어서 변환 사람 눈으로 볼땐 Query가 블록화 되어 보기 편하지만 Optimizer는 가급적 풀어서 JOIN형태로 변환한 뒤 최적화를 시도 단순한 View는 Merging하여도 성능이 나빠지지 않는다. 복잡한 연산을 포함하는 View는 Merging하면 성능이 나빠질 수 있다. Inline View Merging 예제 123456789101112SELECT A.* FROM (SELECT * FROM EMP WHERE JOB = 'SALESMAN') A, (SELECT * FROM DEPT WHERE LOC = 'CHICAGO') B WHERE A.DEPTNO = B.DEPTNO;-- 변환SELECT * FROM EMP A, DEPT B WHERE A.DEPTNO = B.DEPTNO AND A.JOB = 'SALESMAN' AND B.LOC = 'CHICAGO'; View Merging 예제 12345678910111213141516CREATE OR REPLACE VIEW EMP_SALESMANASSELECT * FROM EMP WHERE JOB = 'SALESMAN';SELECE E.* FROM EMP_SALESMAN E, DEPT D WHERE D.DEPTNO = E.DEPTNO AND E.SAL &gt;= 1500;-- 변환SELECT E.* FROM EMP E, DEPT D WHERE D.DEPTNO = E.DEPTNO AND E.JOB = 'SALESMAN' AND E.SAL &gt;= 1500; View Merging시 성능이 나빠질 수 있는 연산 GROUP BY 절 DISTINCT 연산 View Merging이 불가능한 연산 집합(SET) : UNION, UNION ALL, INTERSECT, MINUS CONNECT BY 절 ROWNUM pseudo 칼럼 집계 함수 (AVG, CONUT, MAX, MIN, SUM, …) 분석 함수 (Analytic Function) 관련 Hint : MERGE, NO_MERGE Predicate Pushing (조건절 푸싱) 조건절을 가능한 빨리 처리되도록 View 안으로 밀어넣어서 처리량을 최소화 하는 방식 종류 Predicate Pushdown : Query 블록 밖에 있는 조건절은 안으로 밀어 넣음 Predicate Pullup : Query 블록 안의 조건절을 밖으로 내오와서, 다른 Query 블록 안으로 Pushdown하는데 사용 Join Predicate Pushdown : NL Join 수행시 Driving Table에서 읽은 값을 Inner View Query 쪽으로 밀어 넣음 Predicate Pushdown 123SELECT DEPTNO, AVG_SAL FROM (SELECT DEPTNO, AVG(SAL) AVG_SAL FROM EMP GROUP BY DEPTNO) WHERE DEPTNO = 30; Inline View 안에서 DEPTNO에 대해서만 GROUP BY 하여 데이터량을 줄일 수 있다. Predicate Pullup1234SELECT * FROM (SELECT DEPTNO, AVG(SAL) FROM EMP WHERE DEPTNO = 10 GROUP BY DEPTNO) E1, (SELECT DEPTNO, MIN(SAL), MAX(SAL) FROM EMP GROUP BY DEPTNO) E2 WHERE E1.DEPTNO = E2.DEPTNO; E1의 조건을 Pullup하여 E2로 Pushdown하여 데이터량을 줄일 수 있다. Join Predicate Pushdown1234SELECT D.DEPTNO, D.DNAME, E.AVG_SAL FROM DEPT D, (SELECT DEPTNO, AVG(SAL) AVG_SAL FROM EMP GROUP BY DEPTNO) E WHERE E.DEPTNO(+) = D.DEPTNO; D에 존재하는 DEPTNO에 대해서만 E에서 수행하여 데이터량을 줄일 수 있다. 조건절 이행(Transitive Predicate Generation, Transitive Closure)1234SELECT * FROM DEPT D, EMP E WHERE E.JOB = 'MANAGER' AND E.DEPTNO = 10 AND D.DEPTNO = E.DEPTNO E의 DEPTNO = 10 조건을 D에서도 수행 불필요한 JOIN 제거 (Join Elimination)1SELECT E.* FROM DEPT D, EMP E WHERE D.DEPTNO = E.DEPTNO; D의 참조가 전혀 없으므로 제거 단, PK, FK의 제약조건이 있어야만 가능. PK가 없는 경우 Join Cardinality를 파악할 수 없으므로 결과가 달라 질 수 있음 FK가 설정되어 있다하더라도 EMP의 DEPTNO가 Nullable이면 결과가 달라질 수 있음 OR 조건을 UNION으로 변환 OR 조건을 그대로 둘 경우 Full Table Scan으로 처리되거나 각각의 Column별 Index를 활용하여 Bitmap 연산을 하는 Index Combine으로 작동할 경우가 있다. 관련 Hint USE_CONCAT : UNION ALL 표현 (OR-Expansion)을 유도 NO_EXPAND : 나누지 말고 그대로 실행 집합 연산을 JOIN 연산으로123SELECT JOB, MGR FROM EMPMINUSSELECT JOB, MGR FROM EMP WHERE DEPTNO = 10; 위 문장을 실행하면 Table Full Scan 후 Sort Unique 하는 연산을 2번 수행 후에 결과집합을 구하게 된다.이 경우 아래와 같은 형태로 Query 변환을 하여 실행을 한다. 12345SELECT DISTINCT JOB, MGR FROM EMP E WHERE NOT EXISTS (SELECT 'X' FROM EMP WHERE DEPTBO = 10 AND SYS_OP_MAP_NONNULL(JOB) = SYS_OP_MAP_NONNULL(E.JOB) AND SYS_OP_MAP_NONNULL(MGR) = SYS_OP_MAP_NONNULL(E.MGR) SYS_OP_MAP_NONNULL() : null끼리 비교시 true값을 반환하도록 처리 JOIN Column에 IS NOT NULL 조건 추가 어차피 NULL인 Column은 JOIN에 실패한다. 그러기 때문에 미리 NULL인 Column에 대해서 Filtering 하면 불필요한 액세스를 줄일 수 있다. (Oracle의 경우 해당 Column의 NULL값 비중이 5% 이상이면 내부적으로 추가해준다.) 123456SELECT EMPNO, DNAME FROM EMP E, DEPT D WHERE D.DEPTNO = E.DEPTNO AND SAL &lt;= 2900 AND E.DEPTNO IS NOT NULL -- Optimizer가 추가 AND D.DEPTNO IS NOT NULL -- Optimizer가 추가 Filter 조건 추가1SELECT * FROM EMP WHERE SAL BETERRN :MIN AND :MAX 위 Query에서 :MIN 이 :MAX보다 크면 당연히 결과는 공집합이다.이 경우 :MIN 값이 :MAX보다 작거나 같다는 Filter조건을 임의로 추가해서 실행해준다. WHERE 비교 순서WHERE 절에 비교할 컬럼이 많은 경우 그 중 작업량을 많이 줄여줄거라 판단한 조건부터 먼저 비교한다.","categories":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/categories/Database/"},{"name":"SQLP","slug":"Database/SQLP","permalink":"http://DevStarSJ.github.io/categories/Database/SQLP/"}],"tags":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/tags/Database/"},{"name":"Oracle","slug":"Oracle","permalink":"http://DevStarSJ.github.io/tags/Oracle/"},{"name":"SQLP","slug":"SQLP","permalink":"http://DevStarSJ.github.io/tags/SQLP/"}]},{"title":"SQLP 3-2 Lock과 Transaction 동시성 제어","slug":"03.03.lock","date":"2016-02-01T15:00:00.000Z","updated":"2017-04-24T00:03:45.000Z","comments":true,"path":"2016/02/02/03.03.lock/","link":"","permalink":"http://DevStarSJ.github.io/2016/02/02/03.03.lock/","excerpt":"","text":"3과목 SQL 고급 활용 및 Tuning2장 Lock과 Transaction 동시성 제어2.1 LockShared Lock vs. Exclusive Lock Shared Lock (공유 Lock) 데이터를 읽을 때 사용 다른 Shared Lock과는 호환되지만, Exclusive Lock과는 호환이 안됨 즉, Shared Lock이 걸려있는 상태에서 Exclusive Lock은 Blocking 됨 Exclusive Lock (베타적 Lock) 데이터를 변경할 때 사용 모든 종류의 Lock과 호환이 안됨 Blocking과 Deadlock Blocking Lock 경합이 발생하여 특정 세션이 작업을 진행하지 못하고 멈춘 상태 Blocking 상태를 해소하는 방법은 Commit or Rollback 뿐 Lock에 의한 성능 최소화 방안 Transaction의 원자성을 훼손하지 않는 선에서 최대한 짧게 정의 같은 데이터를 갱신하는 Transaction이 동시에 수행되지 않도록 설계 Transaction Isolation Level을 지나치게 상향 조정하지 않음 Transaction을 잘 설계하여 대기 현상을 피하도록 프로그래밍 주간의 대용량 갱신작업이 불가피하다면 timeout을 이용 12SELECT * FROM T WHERE ... FOR UPDATE NOWAIT -- 대기없이 Exception SELECT * FROM T WHERE ... FOR UPDATE WAIT 3 -- 3초 대기 후 Exception Deadlock (교착상태) 두 세션이 각각 Lock을 건 상태에서 서로의 Lock걸린 리소스를 액세스하려 할 경우 영원히 대기상태에 빠지는 것 유일한 해결 방법은 둘 중 한 세션에 에러를 발생시키는 것 테이블 접근 순서를 같게 처리하면 피할 수 있음 Oracle Lock Oracle에서는 어떠한 읽기 작업도 Lock에 영향을 받지 않는다. Undo 데이터를 활용한 다중버전 동시성 제어 메커니즘을 활용한다. 단, SELECT … FOR UPDATE 제외 Row Lock 항상 Exclusive Lock INSERT, UPDATE, DELETE, SELECT … FOR UPDATE를 수행한 Transaction에 의해 설정되며 해당 Transaction이 Commit 이나 Rollback할때까지 다른 Transaction은 해당 Row를 변경할 수 없다. Table Lock Row Lock을 얻는 순간, 해당 Table에 대한 Table Lock도 얻는다. 현재 Transaction이 갱신 중인 Table에 대해 호환되지 않는 DDL 수행을 방지한다. 5종류의 Lock이 있음 RS (Row Share) : X제외 모두 허용 RX (Row Exclusive) : RS, RX 허용 S (Share) : RS, S 허용 SRX (Share Row Exclusive) : RS 허용 X (Exclusive) : 모두 불허용 명시적으로 Lock Table 명령어를 사용 할 수도 있음 123LOCK TABLE emp IN ROW SHARE MODE;LOCK TABLE emp IN ROW EXCLUSIVE MODE;... 2.1 TransactionTransaction 특징 원자성 (Atomicity) : 업무상 최소단위 일관성 (Consistency) : 실행 전후 데이터베이스 상태가 모순되지 않아야 함 격리성 (Isolation) : 실행 중 다른 Transaction이 접근할 수 없음 영속성 (Durability) : 성공적으로 수행하면, 데이터베이스에 영속적으로 저장 낮은 Isolation Level에서의 현상 Dirty Read Commit하지 않은 데이터를 읽음. 이미 읽은 뒤 다시 Rollback 될 수 있음. Non-Repeatable Read 한 Transaction 내의 같은 Query에 대해서 값이 바뀌는 현상 처음 값을 읽은 뒤 다른 Transaction이 해당 값을 변경한 경우 Phantom Read 한 Transaction 내에 같은 Query에 대해서 처음에 없었던 값이 읽히는 현상 처음 값을 읽은 뒤 다른 Transaction이 새로운 값을 입력한 경우 Transaction Isolation Level Read Uncommitted : 다른 Transaction이 처리 중인 값을 읽는 것을 허용 (이걸 허용하는 DB는 거의 없음) Read Committed : Dirty Read 방지 Repeatable Read : Non-Repeatable Read 방지 Serializable Read : Phantom Read 방지1SET TRANSACTION ISOLATION LEVEL READ SERIALIZABLE; Transaction Isolation Level을 높일수록 Lock에 의존적이다보니 동시성이 저하된다. Oracle에서는 다중버전 동시성 제어(Multiversion Concurrency Control)을 사용한다. 동시성 제어 (Concurrency Control) 비관적 동시성 제어 (Pessimistic Concurrency Control) 같은 데이터를 동시에 수정할 것이라고 가정 먼저 Lock을 걸고 Transaction이 완료될때까지 유지123SELECT ... FOR UPDATE;UPDATE ...COMMIT; 낙관적 동시성 제어 (Optimistic Concurrency Control) 같은 데이터를 동시에 수정하지 않을 것이라고 가정 데이터 읽을 때 Lock을 걸지 않지만, 수정할때 변경되었는지 확인12SELECT ... INTO :a, :b, :c, :d ... ;UPDATE ... WHERE col1 = :a AND col2 = :b ...; 다중버전 동시성 제어 (Multiversion Concurrency Control) 데이터를 변경할 때마다 Undo 영역에 저장 Query (또는 Transaction) 시작 시점 이후 변경된 값에 대해서는 Undo 영역에 저장된 정보를 이용해서 일관성 있는 버전(CR Copy)를 생성하여 읽음 문장수준 읽기 일관성 (Statement-Level Read Consistency) 단일 SQL 내에서의 일관성 유지 Query 시작시점 이후 변경값에 대해서는 CR Copy 값을 읽음 트랜잭션 수준 읽기 인관성 (Transaction-Level Read Consistency) Transaction 시작시점 이후 변경값에 대해서는 CR Copy 값을 읽음 Snapshot too old Undo 영역의 정보가 다른 Transaction에 의해 재사용됨으로 CR Copy를 생성할 수 없을 경우 발생 줄일 수 있는 방법 Undo 영역 크기 증가 Commit을 자주하지 않음 fetch across commit 형태의 프로그램 작성을 피함 Transation이 몰리는 시간대에 오래 걸리는 Query 수행을 피함 큰 Table을 일정 범위로 나우어 일고 단계적으로 실행하도록 코딩 (단 일관성 문제는 없어야 함) 오랜 시간에 걸쳐 같은 Block을 여러 번 방문하는 NL JOIN 또는 Index를 경유한 Table 액세스를 체크하고 회피할수 있는 방법 찾음 (JOIN 방법 변경, Full Table Scan) ORDER BY를 강제로 삽입하여 Sort연산을 강제로 발생 대량 UPDATE후 바로 해당 Table 또는 Index를 Full Scan하도록 Query 수행 관련 내용 Slide Oracle Transaction Isolation Level : http://www.slideshare.net/seokjoonyun9/2015-0515-oracle-transaction-concurrency-control-read-consistency Oracle Concurrency Control : http://www.slideshare.net/seokjoonyun9/20150522-oracle-ways-of-concurrency-control Oracle Snapshot too Old : http://www.slideshare.net/seokjoonyun9/oracle-architecture2015-0424-bblock-cleanout-and-snapshottooold Oracle Consistency : http://www.slideshare.net/seokjoonyun9/2015-0409-consistency","categories":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/categories/Database/"},{"name":"SQLP","slug":"Database/SQLP","permalink":"http://DevStarSJ.github.io/categories/Database/SQLP/"}],"tags":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/tags/Database/"},{"name":"Oracle","slug":"Oracle","permalink":"http://DevStarSJ.github.io/tags/Oracle/"},{"name":"SQLP","slug":"SQLP","permalink":"http://DevStarSJ.github.io/tags/SQLP/"}]},{"title":"MFC UAC 관련 사항 정리","slug":"mfc.uac","date":"2016-02-01T06:28:00.000Z","updated":"2017-05-29T23:30:11.000Z","comments":true,"path":"2016/02/01/mfc.uac/","link":"","permalink":"http://DevStarSJ.github.io/2016/02/01/mfc.uac/","excerpt":"","text":"MFC UAC 관련 사항 정리Project의 UAC 설정Project -&gt; Properties -&gt; Linker -&gt; Manifest File -&gt; UAC Execution Level asInvoker : 응용 프로그램을 시작한 프로세스와 동일한 권한으로 응용 프로그램이 실행됩니다. 관리자 권한으로 실행을 선택하면 응용 프로그램의 권한 수준을 높일 수 있습니다. requireAdministrator: 응용 프로그램이 관리자 권한으로 실행됩니다. 응용 프로그램을 시작하는 사용자는 관리자 그룹의 멤버이어야 합니다. 응용 프로그램을 여는 프로세스가 관리자 권한으로 실행되고 있지 않은 경우 자격 증명을 입력하라는 메시지가 표시됩니다. highestAvailable: 최대한 높은 권한 수준으로 응용 프로그램이 실행됩니다. 응용 프로그램을 시작하는 사용자가 관리자 그룹의 멤버이면 이 옵션은 requireAdministrator와 같습니다. 사용 가능한 가장 높은 권한 수준이 응용 프로그램을 여는 프로세스의 수준보다 높으면 자격 증명을 입력하라는 메시지가 표시됩니다. MFC Manifest의 UAC 정보 : https://msdn.microsoft.com/library/bb384691(v=vs.110).aspx UAC Elevation (UAC Escalation)asInvoker 권한의 Application 에서 requireAdministrator를 호출하는 경우 권한 상승을 요구하는 창이 뜹니다.해당 창에서 Administrator권한을 가진 User로 인증을 하면 실행이 가능하게 됩니다. MFC에서 다른 Applicationd을 실행할때 CreateProcess()함수를 많이 사용하는데 이 함수로는 UAC 권한상승을 할 수 없습니다.ShellExecute() 라는 함수를 이용하면 가능합니다. ShellExecute : https://msdn.microsoft.com/ko-kr/library/windows/desktop/bb762153(v=vs.85).aspx UAC 관련 TroubleshootingProject를 asInvoker로 했는데도 계속 방패마크가 남아있으면서 Administrator 권한을 요구하는 경우1. Project -&gt; Propertise -&gt; Manifest Tool -&gt; Input and Oupput -&gt; Embed Manifest 항목을 Yes로 설정 이렇게 했을 경우 Compile시 아래와 같은 오류가 발생할 수 있습니다. CVTRES : fatal error CVT1100: duplicate resource. type:MANIFEST, name:1. language:0x0409LINK : fatal error LNK1123: COFF로 변환하는 동안 오류가 발생했습니다. 파일이 잘못되었거나 손상되었습니다. #####2 . 위 오류가 발생할 경우 해당 Project의 Resource View로 가서 MANIFEST 관련항목 삭제 UAC 권한 문제로 Application 간의 Drag&amp;Drop이 안 될 경우 해당 Link 참고 : http://devluna.blogspot.kr/2014/12/mfc-window7-file-drag-drop.html","categories":[{"name":"CPP","slug":"CPP","permalink":"http://DevStarSJ.github.io/categories/CPP/"},{"name":"MFC","slug":"CPP/MFC","permalink":"http://DevStarSJ.github.io/categories/CPP/MFC/"}],"tags":[{"name":"CPP","slug":"CPP","permalink":"http://DevStarSJ.github.io/tags/CPP/"},{"name":"MFC","slug":"MFC","permalink":"http://DevStarSJ.github.io/tags/MFC/"},{"name":"UAC","slug":"UAC","permalink":"http://DevStarSJ.github.io/tags/UAC/"}]},{"title":"SQLP 3-1-2 SQL Parsing, DB Call, Block I/O","slug":"03.02.sql.parsing","date":"2016-01-31T15:00:00.000Z","updated":"2017-04-24T00:03:00.000Z","comments":true,"path":"2016/02/01/03.02.sql.parsing/","link":"","permalink":"http://DevStarSJ.github.io/2016/02/01/03.02.sql.parsing/","excerpt":"","text":"3과목 SQL 고급 활용 및 Tuning1장 Architecture 기반 Tuning1.2 SQL ParsingSQL Parsing 과정 사용자 입력 SQL Semantic 검사 : 문법적 오류, 객체 존재 여부 Library Cache에서 검색 : Hash구조로 관리. SQL의 Hash값의 Bucket을 찾아봄 Soft Parsing : Cache에서 찾아서 바로 실행단계로 넘어감 Hard Parsing : Cache에서 찾지 못해서 최적화 과정을 거치고 실행단계로 넘어감 찾지 못했을 경우 최적화 수행 최적화 결과를 Library Cache의 Hash Bucket chain에 연결 해당 Execution Plan을 실행 Optimizer : 사용자 SQL을 가장 빠르고 효율적인 처리경로를 선택해 주는 DBMS의 핵심엔진 ####C aching 된 SQL 공유 공유조건 : 그냥 무조건 같은 SQL문이어야 한다. 공백, 줄바꿈이 다른 경우 : X 대소문자가 다른 경우 : X 주석이 다른 경우 : X OWNER명시 여부 (EMP 와 SCOTT.EMP) : X Optimizer Hint 여부 : X WHERE 절의 literal값이 다른 경우 : X 솔직히 1 ~ 5는 각 부서별 SQL표준을 정하면 되는데 6의 경우에는 Bind Variable을 사용할 수 밖에 없다.Bind Variable을 사용하면 SQL 재사용율이 좋아진다.하지만 Bind Variable을 사용하면 실행계획 생성시 통계정보를 활용하지 못한다.(당연한 얘기다. 어떤 값이 들어올지 모르기 때문에 그냥 균등하다고 생각하고 실행계획을 작성한다.) Bind Variable을 사용하지 않는게 좋은 경우 DW, OLAP 환경에서의 Long Running Query : Parsing 소유시간에 비해 Execution 시간이 훨씬 길며, Parsing도 자주 일어나지 않는다. WHERE절의 칼럼 Distinct 값이 적을 경우 : 그만큼 분포가 균일하지 않기 때문에 Histogram을 활용하는게 유리하다. Bind Variable Peeking (Sniffing) SQL이 처음 실행될때 Bind Variable 값을 살짝 훔쳐보고 Execution Plan을 작성 뒤에 어떻게 분포가 바뀔지 모르므로 상당히 위험한 기능 왠만해서는 해당 기능을 비활성화 하는게 좋음1ALTER SYSTEM SET \"_optim_peek_user_binds\" = FALSE; Static SQL, Dynamic SQL Static SQL : code 사이에 SQL문을 직접 기술 (Pro*C, Power Builder, SQLJ 등… ). Compile 단계에서 SQL 구문체크가 가능 Dynamic SQL : String 타입 변수에 SQL문을 저장 (현재 대부분의 경우) Application Cursor Caching SQL문을 한번 Parsing한 후 Bind Variable 값만 바꿔가면서 반복적으로 수행 Java에서 .setImplicitCachingEnabled(true)로 한다던지 Statement를 닫지 않고 재사용하는 방법 Parse Call 한번에 Execute Call이 여러번 일어남 (일반적인 경우는 Parse, Execute Call의 수가 같음) 1.3 Database Call과 네트워크 부하Call의 종류 SQL Cursor 작업 요청에 따른 구분 Parse Call : SQL Parsing을 요청 Execute Call : SQL 실행을 요청 Fetch Call : SELECT문의 결과 데이터 전송을 요청 Call 발생 위치에 따른 구분 User Call : DBMS외부로부터 요청 Recursive Call : DBMS내부에서 발생하는 Call SQL Parsing 과정에서 발생하는 데이터 딕셔너리 조회 사용자 정의 함수/프로시저 내에서의 SQL수행 User Call과 성능User Call은 시스템 확장성을 떨어뜨리는 가장 큰 요인 중 하나이므로 최소화 하려는 노력이 중요하다. 1. One SQL 구현 : Loop Query를 해소 1번의 Call로 해결되는 Query는 5번의 Call로 해결되는 Query에 비해 5배의 확장성을 갖는 것이다. 2. Array Processing : Array 단위 Fetch, Bulk Insert/Update/Delete INSERT 할때 Array에 계속 담다가 1,000건이 쌓일 때마다 executeBatch() 실행 (Java) SELECT 할때 .setFetchSize(1000)으로 1,000건 단위로 Fetch (Java) 3. 부분범위처리 원리 활용 SQL*Plus에서 set arraysize 100으로 할 경우 301번의 Fetch Call로 30,000 rows를 읽는 것을 Trace에서 확인이 가능하다. 만약 10개의 record를 담는 block이 3개 있는 경우 ArraySize를 3으로 할 경우 총 10번의 Fetch Call이 발생하지만, Block I/O는 12번이 된다. (왜냐면 4번째 Call의 경우 Block 1에서 1 record만 읽고, Block 2에서 2 record만 읽는다. 즉 2번의 Block I/O가 발생한 것이다.) 즉, ArraySize를 무작정 키운다고 좋은게 아니다. 4. 효과적인 화면 페이지 처리 Web에서 Page 단위로 게시물을 보여줄 경우 처음부터 다 읽어서 Fetch하면서 필요한 것만 보여주게 된다면 성능에 치명적이다. 필요한 Page부분만 읽도록 수정해야 한다. (뒤에서 자세히 다루겠다.) 5. 분산 Query원격에 있는 DB 간의 Table을 JOIN할 경우 성능을 높일 수 있는 방안은 ? 실행계획을 보고 다음의 Rows수를 확인한다. 실제 결과 데이터 각 Table 별로 필터 조건으로 걸러지는 데이터 REMOTE로 원격으로 전송된 데이터 /*+ driving_site(테이블명) */ Hint를 활용하여 어느 Server에서 JOIN을 수행하고 나머지 Server에서 원격으로 데이터를 전송하도록 조절한다. 결론적으로 네트워크를 통해 데이터 전송량을 줄이는게 핵심이다. 6. User-defined Function/Procedure Built-In Function/Procedure : Native code로 완전 compile된 형태이므로 엄청 빠르다. User-defined Function/Procedure : 실행할때마다 Virtual Machine에서 별도 실행 엔진을 통해 호출되므로 느리다. 특히나 내부적으로 또다른 Query가 있을 경우에는 Execute Call, Fetch Call이 재귀적으로 일어난다. 그러므로 다음의 경우에만 제한으로 사용할 것을 권장한다. 소량의 데이터를 조회할 경우 부분범위처리가 가능한 상황 가급적으로 One SQL로 구현하고자 노력하는게 좋다. (JOIN, Scalar-Subquery) 그 과정에서 별도의 Logic이 필요한 것을 따로 Table로 구현하는 방법도 있다. ex. 휴무일을 검사하는 Function 대신 업무일 Table을 생성해두고 EXISTS로 비교 1.4 DB I/O 원리Block I/O 모든 DBMS는 Block단위 I/O를 한다 1개의 record를 읽더라도 해당 Block 전체를 읽는다. Buffer Cache, Disk상의 Datafile 모두 Block 단위 I/O로 읽는다. Datafile -&gt; DB Buffer Cache로 Block을 적재할 때 Datafile에서 Block을 직접 읽고 쓸때 DB Buffer Cache에서 Block을 읽고 쓸때 DB Buffer Cache -&gt; Datafile로 다시 데이터를 쓸때 Buffer Cache Hit Ratio1BCHR = (버퍼 캐시에서 바로 찾은 Block수 / 총 읽은 Block수) X 100 Fetch Call 에서 disk : 18 , query : 822 일 경우 총 읽은 Block수는 822, 버퍼 캐시에서 읽은 수는 822 - 18 = 804 이므로 BCHR = 97.8%가 된다. Sequential I/O vs. Random I/O Sequential I/O : Index에서 Leaf Node를 따라 Scan하는 것과 Full Table Scan Random I/O : Index에서 한 건을 읽기 위해 한 Block씩 접근하는 방식 Sequential 액세스의 비중을 높이고 Random 액세스의 발생량을 줄이는게 I/O 튜닝의 핵심이다. Sequential 액세스의 효율을 높일려면 총 읽은 건수 중 결과집합으로 선택되는 비중을 높여야 한다. 즉 같은 결과를 얻기 위해 얼마나 적은 record를 읽느냐로 판단한다. Index의 컬럼 및 그 순서를 조정하는게 가장 좋은 방법이다. Single Block I/O vs. MultiBlock I/O Index : Single Block I/O (10g이후 Index Range Scan, Index Full Scan에서는 MultiBlock I/O로도 가능) Table : MultiBlock I/O 대량의 데이터를 읽을 땐 MultiBlock I/O가 I/O Call을 줄일 수 있기 때문에 유리하다. I/O 효율화 원리 필요한 최소 Block만 읽도록 SQL 작성 최적의 Optimizer 팩터 제공 전략적 Index 구성 DBMS가 제공하는 기능 활용 : Index, Partition, Cluster, Window 함수 필요하다면 Optimizer Hint를 활용하여 최적의 액세스 경로로 유도 전체처리 최적화, 최초 응답속도 최적화 및 그밖에 파라메터들 통계정보 제공","categories":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/categories/Database/"},{"name":"SQLP","slug":"Database/SQLP","permalink":"http://DevStarSJ.github.io/categories/Database/SQLP/"}],"tags":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/tags/Database/"},{"name":"Oracle","slug":"Oracle","permalink":"http://DevStarSJ.github.io/tags/Oracle/"},{"name":"SQLP","slug":"SQLP","permalink":"http://DevStarSJ.github.io/tags/SQLP/"}]},{"title":"MFC UAC 관련 사항 정리","slug":"stringConv","date":"2016-01-29T06:28:00.000Z","updated":"2017-05-29T23:31:17.000Z","comments":true,"path":"2016/01/29/stringConv/","link":"","permalink":"http://DevStarSJ.github.io/2016/01/29/stringConv/","excerpt":"","text":"MFC (C++) 에서 여러가지 라이브러리를 사용하다보면함수의 문자열을 받는 인자의 형식이 Unicode/Ansi , std::string, char*, LPCTSTR 등…각각 제멋대로입니다. 그래서 늘 해당 작업을 할때마다… 구글링…몇주 뒤에 또 이런 일이 있으면 또 구글링… 그래서 귀찮아서 정리해 봤습니다. 왠만한 조합은 다 있는듯 합니다.혹시 더 필요한 조합이나 아래 Code에 Error가 있으면 feedback 부탁드리겠습니다.(모든 조합을 다 Test해보진 않았습니다. ;;;) 처음엔 문제 많은 code였는데 feedback 주신분들이 친절히 가르쳐 주셔서 조금씩 보완하고 있는 중입니다.감사드립니다. ^_^ CString (CStringA, CStringW) to std::string12345678910std::string S2(CString&amp; CS)&#123;#ifdef _UNICODE USES_CONVERSION; std::string S = W2A(CS.GetBuffer());#else std::string S = CS.GetBuffer();#endif return S;&#125; std::string to CString (CStringA, CStringW)12345678910CString S2(std::string&amp; S)&#123;#ifdef _UNICODE USES_CONVERSION; CString CS = A2W(S.c_str());#else CString CS = S.c_str();#endif return CS;&#125; std::wstring to CString (CStringA, CStringW)12345678910CString S2(std::wstring&amp; WS)&#123;#ifdef _UNICODE CString CS = WS.c_str();#else USES_CONVERSION; CString CS = W2A(WS.c_str());#endif return CS;&#125; std::string to/from std::wstring1234567891011std::string S3(std::wstring&amp; WS)&#123; USES_CONVERSION; return std::string(WA2(WS.c_str()));&#125;std::wstring S3(std::string&amp; S)&#123; USES_CONVERSION; return std::wstring(A2W(S.c_str()));&#125; CStringA to/from CStringW123CStringA CACStringW CS(CA);CStringA _CA(CS); TCHAR (char\\, wchat_t*) to LPSTR, LPTSTR, LPCSTR, LPCTSTR1234567891011121314151617181920212223242526272829303132LPSTR S4_LPSTR(TCHAR * pChar)&#123;#ifdef _UNICODE return (LPSTR)S3(std::wstring(pChar)).c_str();#else return (LPSTR)pChar;#endif&#125;LPTSTR S4_LPTSTR(char * pChar)&#123; return (LPTSTR)S3(std::string(pChar)).c_str();&#125;LPTSTR S4_LPTSTR(wchar_t * pChar)&#123; return (LPTSTR)pChar;&#125;LPCSTR S4_LPCSTR(TCHAR * pChar)&#123; return (LPCSTR)S4_LPSTR(pChar);&#125;LPCTSTR S4_LPCTSTR(TCHAR * pChar)&#123;#ifdef _UNICODE return (LPCTSTR)pChar;#else return (LPCTSTR)S4_LPTSTR(pChar);#endif&#125; CString to char* buffer123456void SMEMCPY(char* destBuf, CString &amp; strSrc, int nSize)&#123; std::string str = CWVString::S2(strSrc); ZeroMemory(destBuf, nSize); memcpy(destBuf, &amp;str[0], min(str.size(), (size_t)(nSize - 1)));&#125; 전체 Codehttps://gist.github.com/DevStarSJ/c68e55449dc6e68d7376","categories":[{"name":"CPP","slug":"CPP","permalink":"http://DevStarSJ.github.io/categories/CPP/"},{"name":"MFC","slug":"CPP/MFC","permalink":"http://DevStarSJ.github.io/categories/CPP/MFC/"}],"tags":[{"name":"CPP","slug":"CPP","permalink":"http://DevStarSJ.github.io/tags/CPP/"},{"name":"MFC","slug":"MFC","permalink":"http://DevStarSJ.github.io/tags/MFC/"}]},{"title":"SQLP 3-1-1 Oracle Architecture","slug":"03.01.architecture","date":"2016-01-28T15:00:00.000Z","updated":"2017-04-24T00:01:39.000Z","comments":true,"path":"2016/01/29/03.01.architecture/","link":"","permalink":"http://DevStarSJ.github.io/2016/01/29/03.01.architecture/","excerpt":"","text":"3과목 SQL 고급 활용 및 Tuning1장 Architecture 기반 Tuning1.1 Oracle Architecture Database : Disk에 저장된 data 집합 Datafile Redo Log File Control File Instance : SGA(Shared Global Memory)와 이를 엑세스하는 process 집합 Memory PGA (Process Global Area) Process 혹은 Thread 의 개별적인 메모리 공간 사용자마다 개별적으로 사용하는 공간 Data Sort, Session, Cursor 정보 저장 SGA (System Global Area) Oracle Process 들이 접근하는 큰 공유 메모리 Serve Process와 Backgroung Process가 공용으로 사용 DB Buffer Cache, Shared Pool(Library Cache + Dictionay Cache), Log Buffer, Large Pool, Java Pool 직렬화 매커니즘 활용 (여러 Process가 동시에 사용) : Latch, Buffer Lock, Library Cache Lock/Pin Processes Server Process : 사용자의 명령어 처리 SQL Parsing 및 최적화 Cursor를 열어서 block을 read 읽은 data를 정렬해서 client가 요청한 결과집합을 생성하여 network로 전송 Background Process : User의 연결 유무와 상관없이 Background로 실행 SMON (System Monitor) : DBMS의 CEO (모든 작업 총관리), 임시 segment,extent 정리, dictionary 관리, 재시작시 Instance 복구 담당 PMON (Process Monitor) : Server Process 관리, 잘못된 Process 파괴 및 자원복구, 잘못된 Trasaction 문제 해결 DBWn (Databaser Writers) : Buffer Cache의 Dirty Block을 Datafile(disk)에 저장 LGWR (Log Writer) : Log Buffer Entry(승인된 transaction)를 Redo Logfile에 기록 ARCn (Archiver) : 꽉 찬 Redo Log가 덮어 쓰여지기 전에 Archive Log Directory로 Backup CKPT (Check Point) 이전 CP 이후 변경사항을 datafile에 기록하고록 트리거링 그 정보들을 control file/datafile의 header에 기록 (저장된 data를 일치시키는 작업) 장애 복구시 CP 이후 Log 데이터만 disk에 기록함 RECO (Recoverer Process) : 분산 시스템간의 Transaction을 맞춰주는 역할 예를 들어서 서울에 있는 은행과 부산에 있는 은행간에 이체 작업을 물리적으로 다른 DB Server 간의 two-phase commit(양쪽 모두 prepare-phase 한 뒤, 둘 다 commit 한 것이 확인되지 않으면 RECO가 rollback 시킴.) 1개의 Instance는 1개의 Database만 액세스 단, RAC(Real Application Cluster)에서는 여러 Instance가 하나의 Database 액세스 가능 1개의 Instance가 여러 Database를 액세스 할 수는 없음 1.2 DMBS 연결방식 전용 서버(Dedicated Server) 방식 Listener가 연결요청을 받으면 Server Process를 생성하여 사용자에게 제공 DBMS에 큰 부담을 주기 때문에 통상 Connectin Pooling 기법을 이용하여 반복 재사용함 공유 서버(Shared Server) 방식 Connection Pooling을 DBMS 내부에 구현 사용자는 Server Process에 직접 연결하는게 아니라 Dispatcher에 연결을 함 Dispatcher가 Request Queue에 등록하고, Response Queue에서 답변을 가져와서 사용자에게 전달 1.3 File 구조1. Datafile Block &gt; Extent &gt; Segment &gt; Tablespace &lt;-(1 : N)-&gt; Datafile Block Record의 집합 data I/O 단위 (Oracle은 2KB ~ 64KB, MS-SQL은 8KB) 하나의 record만 필요하더라도 disk에서 buffer로 block 단위로 읽음 Optimizer 가 Index/Table Scan을 결정하는 기준은 record수가 아닌 block수 Extent Block의 집합 Tablespace로부터 공간을 할당받는 단위 (Oracle 다양한 크기, MS-SQL 64KB) Uniform Extent : Oracle은 Extent내의 Block은 하나의 Object가 독점 Mixed Extent : MS-SQL은 여러 Object가 나누어 사용 Segemt Extent의 집합 Table, Index, Undo 등의 Object가 저장되는 공간 Object와 Segment는 1:1관계 이지만, Partition의 경우에는 1 : M 관계 1개의 Segment는 여러 datafile에 걸쳐 저장이 가능 (disk I/O 경합을 분산) Tablespace Segment를 담는 컨테이너, 여러 datafile로 구성 2. Temporary Tablespace (임시 데이터 파일) 대량의 Sort(ORDER BY, Sort Merge JOIN), Hash(Hash JOIN) 작업 중 메모리가 부족한 경우 중간 결과집합 저장 임시 데이터이므로 Redo 정보를 생성하지 않음. 복구가 안되고 백업도 필요없음. Oracle은 여러개 생성하여 사용자별로 할당이 가능 (MS-SQL은 1개의 tempdb를 전역으로 사용)12CREATE TEMPORARY TABLESPACE big_temp;ALTER USER scott TEMPORARY TABLESPACE big_temp; 3. Logfile Fast Commit 매커니즘 갱신작업 내용을 메모리상 Buffer Block에만 기록한체 disk에 기록되지 않았더라도 Redo Log를 믿고 빠르게 Commit 장애발생시 Logfile을 이용해서 언제든 복구가 가능 Online Redo Log (MS-SQL에서는 Transaction Log) 데이터 유실 대비용으로 수행했던 Transaction을 기록 사고 발생시 마지막 CP이후 작업 내용을 재현 (캐시 복구) 최소 2개 이상의 파일로 구성. 하나의 파일이 꽉 차면 다른 파일로 Log Switching. 모든 파일 꽉차면 첫번째 파일 재사용 (Round-robin) Archived(=Offline) Redo Log (MS-SQL에는 없음) Online Redo Log가 재사용되기 전 다른 위치로 백업해 둔 파일 4. Memory4.1 SGA (System Global Area) DB Buffer Cache Datafile에서 읽은 Block의 Cache Area Buffer Lock을 이용한 직렬화 Buffer 상태 Free Buffer : Clean 상태이거나 disk와 내용이 같아서 언제든지 덮어써도 무방 Dirty Buffer : 변경이 발생했지만 disk에 기록되기 전인 상태. 재사용하려면 disk에 기록하여 Free Buffer로 만들어야 함 Pinned Buffer : 현재 I/O가 진행중 Buffer 재사용 알고리즘 LRT (Least Recently Used) 알고리즘 사용 LRU 체인을 이용하여 사용빈도 순으로 위치를 옮김 Free Buffer가 필요할 때 LRU End 쪽 (가장 액세스 빈도가 낮음) 부터 사용 Shared Pool Library Cache SQL문, Execution Plan, Stored Procedure를 저장 Soft Parsing: 해당 SQL문에 대한 Execution Plan이 Shared Pool에 있어서 바로 재사용 Hard Parsing : Shared Pool에 내용이 없어서 Optimizer를 이용해서 Execution Plan을 다시 생성 Dictionary Cache 말그대로 딕셔너리 정보를 캐시 (여러 Object의 메타정보) Log Buffer DB Buffer Cache의 모든 변경사항을 저장 DB Block Buffer에 기록하기 전에 Redo Log Buffer에 먼저 기록. LGWR이 주기적으로 Redo Logfile에 기록. 늦어도 commit 시점에는 기록 (Log Force at commit) Dirty Buffer를 datafile에 기록하기 전에 항상 Log Buffer를 먼저 Logfile에 기록 (Write Ahead Logging) 왜냐면 인스턴스 장애 발생시 commit하지 않은 transaction을 rollback하기 위함. 만약 datafile을 먼저 기록해 보리면 최종 commit 되지 않은 transaction이 반영되어짐. 4.1 PGA (Process Global Area) UGA (User Global Area) Session별로 할당 Dedicated Server (전용 서버) 방식에서는 PGA에 할당 (1:1) Shared Server (공유 서버) 방식에서는 SGA에 할당 : Large Pool (설정되었을 경우). 그렇지 않을땐 Shared Pool CGA (Call Global Area) DB Call (Parse, Execute, Fetch)이 진행되는 동안만 필요한 데이터 Recursive Call이 발생하면 그 안의 (Parse, Execute, Fetch)에 대해서도 추가로 할당 Call이 끝나면 바로 해제되어 PGA로 반환 Sort Area Sort 작업이 진행되는 동안 조금씩 Chunk 단위로 할당 DML은 하나의 Execute4 Call에서 처리가 완료되므로 CGA에 할당 SELECT의 경우 중단 단계에서는 CGA에 할당되고, 최종 결과집합 출력하기 전에는 UGA에 할당 5. Wait EventDBMS 내부 Process들이 기다려야 할 상황에서 sleep상태로 대기하게 되는데, 그 정보가 공유 메모리 영역에 저장됨. Respone Time Analysis Session 또는 시스템 전체에 발생하는 병목 현상과 그 원인을 찾아 해결 12Response Time = Service Time + Wait Time = CPU Time + Queue Time CPU Time : Parsing에 소비한 시간인지 Query 자체 수행시간인지 분석 Wait Time : 각각 발생한 Wait Event를 분석해 가장 많은 시간을 소비한 이벤트 중심으로 해결방안 모색 Wait Event 라이브러리 캐시 부하 라이브러리 캐시에서 SQL 커서를 찾고 최적화하는 과정에서 발생한 경합 latch: shared pool latch: library cache 수행중인 SQL이 참조하는 오브젝트에 다른 사용자가 DDL을 수행할 경우 library cache lock library cache pin DB Call과 네트워크 부하 : application, network 간의 소모시간 SQL*Net message from client : DB 경합과 상관없음. client로부터 다음 명령이 올때까지 Idle 상태로 대기 SQL*Net message to client SQL*Net more data from client SQL*Net more data to client Disk I/O 부하 db file sequential read : Single Block I/O 수행시 발생 db file scattered read : Multi Block I/O 수행시 발생 direct patch read direct patch write direct patch write temp direct path read temp db file parallel read Buffer Cache 경합 latch: cache buffers chains latch: cache buffers lru chaine buffer busy waits free buffer waits Lock 관련 Wait Event enq: TM - contention enq: TX - row lock contention enq: TX - index contention enq: TX - index contention enq: TX - allocate ITL entry enq: TX contention latch free : latch를 여러번(2000번 가량) 요청했지만 계속 사용 중인 경우 잠시 Wait 상태로 빠짐 더 자세한 내용을 알고 싶으면 아래 slide를 참고하세요.더 자세한 내용은 Oracle 성능 고도화 원리와 해법 책을 참고해야 합니다. Oracle Architecture : http://www.slideshare.net/seokjoonyun9/warevalley-orange-db-study2015-0320-oracle-architecture DB Buffer Cache : http://www.slideshare.net/seokjoonyun9/2015-0327-db-buffer-cache Redo Log : http://www.slideshare.net/seokjoonyun9/2015-0403-redo-undo Transaction Isolation Level : http://www.slideshare.net/seokjoonyun9/2015-0409-consistency Wait Event : http://www.slideshare.net/seokjoonyun9/oracle-architecture2015-0429-wait-event-and-sharedpool Oracle Lock : http://www.slideshare.net/seokjoonyun9/2015-0529-oracle-lock TX Lock : http://www.slideshare.net/seokjoonyun9/20150605-oracle-tx-lock","categories":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/categories/Database/"},{"name":"SQLP","slug":"Database/SQLP","permalink":"http://DevStarSJ.github.io/categories/Database/SQLP/"}],"tags":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/tags/Database/"},{"name":"Oracle","slug":"Oracle","permalink":"http://DevStarSJ.github.io/tags/Oracle/"},{"name":"SQLP","slug":"SQLP","permalink":"http://DevStarSJ.github.io/tags/SQLP/"}]},{"title":"SQLP 2-3 Optimizing SQL","slug":"02.07.optimizer","date":"2016-01-26T15:00:00.000Z","updated":"2017-04-24T00:00:38.000Z","comments":true,"path":"2016/01/27/02.07.optimizer/","link":"","permalink":"http://DevStarSJ.github.io/2016/01/27/02.07.optimizer/","excerpt":"","text":"2과목 SQL 기본 및 활용 20문제 각 상황별로 SQL문 작성이 가능할 정도로 연습해야 합니다. 기본적인 SQL문법 및 함수는 생략하고 Tuning에 활용될수 있는 것 위주로 정리하고자 합니다. 3장 SQL 최적화 기본 원리여기서는 간단히 다루고 3과목에서 자세히 다룰 예정이므로 그냥 넘어가도 됩니다.(아마 SQPD의 경우 2과목까지가 범위이므로 SQLD용 문제를 내기위한 용도인듯 합니다.) Optimizer Optimizer : SQL문에 대한 최적의 실행 방법을 결정하는 역할 Execution Plan (실행계획) : Optimizer가 생성한 최적의 실행 계획 Optimizer 종류 RBO (Rule-based Optimizer) : 규칙(우선 순위)를 가지고 실행계획 생성 CBO (Cost-based Optimizer) : 통계정보를 기반으로 여러가지 실행계획을 생성하여 그중 최저비용의 실행계획을 선택 Rule-based Optimizer 규칙 Single row by rowid Sigle row by cluster join Single row by hash cluster key with unique or primary key Single row by unique or primary key Cluster join Hash cluster key Indexed cluster key Composite index Single column sindex Bounded range search on indexed columns Unbounded range search on indexed columns Sort merge join MAX or MIN of indexed column ORDER BY on indexed column Full table scan 요약하자면 Single row (rowid &lt; unique or primary key) &lt;&lt; Index ( Equal (composite &lt; single) &lt;&lt; Range (bounded &lt; unbounded) ) &lt;&lt; Full table scan Index1. B-Tree Index 구성 Root Block : Branch Block 중 가장 상위 Block Branch Block : 다음 단계를 가리키는 Pointer를 가지고 있음 Leaf Block : Index를 구성하는 칼럼의 데이터와 rowid, 인접한 Leaf Block의 Pointer를 가지고 있음 2. Cluster Index (MS-SQL) , IOT (Oracle)PK순으로 저장. Index의 Leaf Block에 Table 의 모든 데이터 저장 3. Bitmap Index일종의 Hash + Linked List 형태 4. FBI (Function-Based Index)함수값 순으로 Index에 저장 Full Table Scan vs Index Scan Optimizer 가 Full Table Scan을 하는 경우 SQL에 조건(WHERE)이 없을 경우 조건은 있는데 사용 가능한 INDEX가 없는 경우 Optimizer가 판단하여 Full Table Scan이 더 유리할때 : Index는 Single Block I/O, Table은 Multi Block I/O 기타 : 병렬처리, Hint 등… Index Scan 종류 Index Unique Scan : Unique Index에서 = 조건으로 검색 Index Range Scan : 조건이 = 가 아니거나 Non-unique Index를 이용 Index Range Scan Descending : MIN, MAX 값등을 쉽게 찾기 위해서 사용 Index Fast Scan : 검색하는 모든 컬럼이 Index에 포함된 경우 Table을 찾지않고 Index만으로 검색 Index Skip Scan : Index의 선두 컬럼이 검색 조건에 없을 경우 사용하는 방법 JOIN NL Join (Nested-loop) Driving Table을 먼저 읽은 다음에 Outer Table과 JOIN Driving Table에서 조건에 맞는 모든 row 만큼 JOIN이 이루어지므로 선행 테이블에서 작업량을 줄이는 것이 중요 양쪽 중 한쪽만 Index가 있는 경우 Outer Table쪽의 Index를 사용하는 것이 유리 (Driving은 Full Scan) JOIN 과정은 random access Sort Merge Join Join 칼럼을 기준으로 데이터를 정렬한 뒤에 JOIN을 수행 대량의 JOIN일 경우 NL Join의 random access보다 유리 Hash Join 선행 테이블(Build Input)에서 JOIN하는 컬럼의 Hash값을 메모리에 생성 후행 테이블(Prove Input)에 Hash값을 메모리에서 찾아서 JOIN 범위 검색은 불가능 하고 = 조건으로만 가능","categories":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/categories/Database/"},{"name":"SQLP","slug":"Database/SQLP","permalink":"http://DevStarSJ.github.io/categories/Database/SQLP/"}],"tags":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/tags/Database/"},{"name":"Oracle","slug":"Oracle","permalink":"http://DevStarSJ.github.io/tags/Oracle/"},{"name":"SQLP","slug":"SQLP","permalink":"http://DevStarSJ.github.io/tags/SQLP/"}]},{"title":"SQLP 2-2-5 PL/SQL","slug":"02.06.plsql","date":"2016-01-25T16:00:00.000Z","updated":"2017-04-23T23:59:20.000Z","comments":true,"path":"2016/01/26/02.06.plsql/","link":"","permalink":"http://DevStarSJ.github.io/2016/01/26/02.06.plsql/","excerpt":"","text":"2과목 SQL 기본 및 활용 20문제 각 상황별로 SQL문 작성이 가능할 정도로 연습해야 합니다. 기본적인 SQL문법 및 함수는 생략하고 Tuning에 활용될수 있는 것 위주로 정리하고자 합니다. 2장 SQL 활용 (#5)PL/SQL (Procedural Language/SQL)특징 Block 구조로 되어 있어 각 기능별로 모듈화가 가능 변수, 상수 등을 선언하여 SQL 문장 간 값을 교환 IF, LOOP 등의 절차형 언어를 사용하여 프로그램이 가능 DBMS 정의 에러/사용자 정의 에러를 사용 Oracle에 내장되어 있으므로 다른 Oracle Server로 옮길수 있음 여러 SQL문장을 Block으로 묶어서 한번에 서버로 보내기 때문에 통신량을 줄일수 있음 Server에서 수행되므로 Application의 성능을 향상 구조 DECLARE : BEGIN ~ END 사이에 변수, 인수에 대한 정의 및 데이터 타입 선언 BEGIN : PL/SQL 시작 EXCEPTION : BEGIN ~ END 에서 실행되는 SQL문에서 발생한 에러를 처리 (선택항목) END : PL/SQL 종료 문법 (Syntax) 생성1234567891011121314CREATE [OR REPLACE] PROCEDURE 명칭&#123; argument1 [mode] data_type1, argument2 [mode] data_type2, ...&#125;IS [AS]...BEGIN...EXCEPTION...END;/ mode : IN (입력) , OUT (출력) , INOUT(입출력) 삭제1DROP PROCEDURE 명칭; 예제DEPT table에 새로운 부서를 입력하는데,부서번호가 이미 존재하지 않을때만 입력하고 존재할 경우에는 그냥 종료되는 PROCEDURE를 작성해보자. 123456789101112131415161718192021222324CREATE OR REPLACE PROCEDURE INPUT_DEPT( v_deptno in NUMBER, v_dname in VARCHAR2, v_loc in VARCHAR2, v_result out VARCHAR2)ISis_exist NUMBER := 0;BEGIN SELECT COUNT(*) INTO is_exist FROM DEPT WHERE DEPTNO = v_deptno AND ROWNUM = 1; IF is_exist &gt; 0 THEN v_result := '이미 등록된 부서번호'; ELSE INSERT INTO DEPT (DEPTNO, DNAME, LOC) VALUES (v_deptno, v_dname, v_loc); COMMIT; v_result := '입력 완료'; END IF;EXCEPTION WHEN OTHERS THEN ROLLBACK; v_result := '에러 발생';END;/ 실행을 시켜 보겠다.1EXECUTE INPUT_DEPT(10,&apos;DEV&apos;,&apos;SEOUL&apos;,:result) 1EXECUTE INPUT_DEPT(60,&apos;NEW_DEV&apos;,&apos;SANGAM&apos;,:result) User Defined Function Function는 Procedure와는 다르게 반드시 1개의 값을 RETURN해야 한다. (SUM, NVL 같은 내장 함수를 생각하면 이해가 쉽다.) ABS 함수 구현 : 절대값을 RETURN1234567891011121314CREATE OR REPLACE FUNCTION ABS_NUM(v_input IN NUMBER) RETURN NUMBERIS v_return NUMBER := 0;BEGIN if v_input &gt;= 0 THEN v_return := v_input; ELSE v_return := v_input * -1; END IF; RETURN v_return;END;/ 1SELECT ABS_NUM(-20), ABS_NUM(3) FROM DUAL; Trigger 특정 Table에 DML (INSERT, UPDATE, DELETE)문이 수행했을 때 자동으로 동작 (사용자 실행이 아닌 DBMS가 실행) DBMS에서 실행을 하는 것이므로 DB에 바로 적용됨. (COMMIT, ROLLBACK이 불가) Syntax (문법) 123456CREATE [OR REPLACE] TRIGGER trigger_name -- TRIGGER 명칭BEFORE | AFTER -- 아래 작업이 일어나기 전(BEFORE) 또는 후(AFTER)에 실행INSERT | UPDATE | DELETE ON table_name -- 해당 table에 해당 작업이 일어났을 경우[ FOR EACH ROW ] -- 행 트리거 (행 데이터 제어가능), 없으면 문장 트리거 (각 행 데이터 제어 불가)[ WHEN (condition) ] -- 해당 조건에 맞을때에만 실행PL/SQL block... 행의 데이터는 :NEW.column_name , :OLD.column_name 으로 제어가 가능하다. INSERT : :NEW (입력되는 ROW) UPDATE : :NEW (변경된 새로운 값), :OLD (변경 전의 값) DELTE : :OLD (삭제된 값) 예 쇼핑몰의 경우 하루 수만건의 주문이 들어옴 직원들은 일자별, 상품별 총 판매수량 및 주문실적으로 온라인으로 조회함 이럴 경우 매번 수만건의 데이터로 집계를 낼려면 서버 부하가 크다.Trigger를 이용하여 주문이 들어올 때마다 집계를 계산하여 별도 Table에 보관하면 된다. Table 생성 123456789101112131415CREATE TABLE ORDER_LIST( ORDER_DATE CHAR(8) NOT NULL, PRODUCT VARCHAR2(10) NOT NULL, QTY NUMBER NOT NULL, AMOUNT NUMBER NOT NULL);CREATE TABLE SALES_PER_DATE( SALE_DATE CHAR(8) NOT NULL, PRODUCT VARCHAR2(10) NOT NULL, QTY NUMBER NOT NULL, AMOUNT NUMBER NOT NULL); Trigger 생성 1234567891011121314151617181920212223CREATE OR REPLACE TRIGGER SUM_SALES AFTER INSERT ON ORDER_LIST -- ORDER_LIST table에 INSERT 작업 후에 FOR EACH ROW -- 행 트리거로 실행DECLARE o_date ORDER_LIST.ORDER_DATE%TYPE; o_prod ORDER_LIST.PRODUCT%TYPE;BEGIN o_date := :NEW.ORDER_DATE; o_prod := :NEW.PRODUCT; UPDATE SALES_PER_DATE SET QTY = QTY + :NEW.QTY, AMOUNT = AMOUNT + :NEW.AMOUNT WHERE SALE_DATE = o_date AND PRODUCT = o_prod; IF SQL%NOTFOUND THEN INSERT INTO SALES_PER_DATE VALUES (o_date, o_prod, :NEW.QTY, :NEW.AMOUNT); END IF;END;/ 데이터 입력 및 결과 확인 1234567INSERT INTO ORDER_LIST VALUES ('20160127','Orange', 2, 10000);INSERT INTO ORDER_LIST VALUES ('20160127','Orange', 5, 20000);INSERT INTO ORDER_LIST VALUES ('20160127','PetaSQL', 1, 100);INSERT INTO ORDER_LIST VALUES ('20160127','ChakraMAX', 1, 1000);SELECT * FROM ORDER_LIST;SELECT * FROM SALES_PER_DATE;","categories":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/categories/Database/"},{"name":"SQLP","slug":"Database/SQLP","permalink":"http://DevStarSJ.github.io/categories/Database/SQLP/"}],"tags":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/tags/Database/"},{"name":"Oracle","slug":"Oracle","permalink":"http://DevStarSJ.github.io/tags/Oracle/"},{"name":"SQLP","slug":"SQLP","permalink":"http://DevStarSJ.github.io/tags/SQLP/"}]},{"title":"SQLP 2-2-4 DCL","slug":"02.05.dcl","date":"2016-01-25T15:00:00.000Z","updated":"2017-04-23T23:57:57.000Z","comments":true,"path":"2016/01/26/02.05.dcl/","link":"","permalink":"http://DevStarSJ.github.io/2016/01/26/02.05.dcl/","excerpt":"","text":"2과목 SQL 기본 및 활용 20문제 각 상황별로 SQL문 작성이 가능할 정도로 연습해야 합니다. 기본적인 SQL문법 및 함수는 생략하고 Tuning에 활용될수 있는 것 위주로 정리하고자 합니다. 2장 SQL 활용 (#4)DCL (Data Control Langeage) USER 생성 및 권한 관리에 관한 내용 DBMS별로 구조 및 내용이 많이 다름 (여기서는 Oracle 위주로 진행) USER 생성1CREATE USER 사용자명 IDENTIFIED BY 비밀번호; 권한부여12GRANT 권한 TO 사용자; -- 권한 부여REVOKE 권한 FROM 사용자; -- 권한 회수 앞서 본 사용자 생성 작업을 하기 위해서는 CREATE USER 권한이 필요함1GRANT CREATE USER TO 사용자명; 하지만 생성된 USER는 session 연결도 못한다.1GRANT CREATE SESSION TO 사용자명; session 연결을 하였다 하더라도 table 생성 권한이 없다.1GRANT CREATE TABLE TO 사용자명; OBJECT 권한 관리1GRANT 권한 ON 오브젝트 TO 사용자; OBJECT 별 권한목록1234- Table : DELETE, INSERT, SELECT, UPDATE, ALTER, INDEX, REFERENCES- View : DELETE, INSERT, SELECT, UPDATE- SEQUENCE : SELECT, ALTER- PROCEDURE : EXECUTE 기본적으로 자신이 생성하지 않은 object에는 접근이 불가능하다.object 생성자가 그것을 활용할 사람에게 권한을 부여해야만 사용이 가능하다. Role사용자를 새로 생성할때마다 권한을 다 부여하는 것은 번거로운 작업이다.Role을 생성하여 Role에다가 여러가지 역할을 부여하고, 사용자에게 해당 Role에 대한 권한을 주면 한방에 해결된다. 123CREATE ROLE ROLE명칭 -- ROLE 생성GRANT 권한[, ...] TO ROLE명칭 -- ROLE에 권한 부여GRANT ROLE명칭 TO 사용자 -- 사용자에게 ROLE 부여","categories":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/categories/Database/"},{"name":"SQLP","slug":"Database/SQLP","permalink":"http://DevStarSJ.github.io/categories/Database/SQLP/"}],"tags":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/tags/Database/"},{"name":"Oracle","slug":"Oracle","permalink":"http://DevStarSJ.github.io/tags/Oracle/"},{"name":"SQLP","slug":"SQLP","permalink":"http://DevStarSJ.github.io/tags/SQLP/"}]},{"title":"SQLP 2-2-3 Window function","slug":"02.04.window","date":"2016-01-24T16:00:00.000Z","updated":"2017-04-23T23:58:30.000Z","comments":true,"path":"2016/01/25/02.04.window/","link":"","permalink":"http://DevStarSJ.github.io/2016/01/25/02.04.window/","excerpt":"","text":"2과목 SQL 기본 및 활용 20문제 각 상황별로 SQL문 작성이 가능할 정도로 연습해야 합니다. 기본적인 SQL문법 및 함수는 생략하고 Tuning에 활용될수 있는 것 위주로 정리하고자 합니다. 2장 SQL 활용 (#3)WINDOW FUNCTION (윈도우 함수) 행과 행간을 비교, 연산하는 함수 종류 순위 관련 : RANK, DENSE_RANK, ROW_NUMBER 집계 관련 : SUM, MAX, MIN, AVG, COUNT 순서 관련 : FIRST_VALUE, LAST_VALUE, LAG, LEAD 비율 관련 : CUME_DIST, PERCENT_RANK, NTILE, RATIO_TO_REPORT 통계 분석 (순형 분석 포함) : CORP, COVAR_POP, STDDEV 등… (여기서는 다루지 않음) 문법 (syntax)123SELECT 함수명 (인자) OVER ([PARTITION BY 칼럼] [ORDER BY 절] [WINDOWING 절]) FROM 테이블; PARTITION BY 절 : 전체 집합을 기준에 의해 소그룹으로 분리 ORDER BY 절 : 순위 지정시 그 순서 WINDOWING 절 : 함수의 대상을 지정 ROWS : 물리적인 행수를 지정 RANGE : 논리적인 값에 의한 범위 지정123456789-- BETWEEN 사용 타입ROWS | RANGE BETWEEN UNBOUNDED PRECEDING | CURRENT ROW | VALUE_EXPR PRECEDING/FOLLOWINGAND UNBOUNDED FOLLOWING | CURRENT ROW | VALUE_EXPR PRECEDING/FOLLOWING-- BETWEEN 미사용 타입ROWS | RANGE UNBOUNDED PRECEDING | CURRENT ROW | VALUE_EXPR PRECEDING 1. 순위 함수 RANK : 특정 칼럼에 대한 순위를 구함1234SELECT JOB, ENAME, SAL, RANK() OVER (ORDER BY SAL DESC) ALL_RANK, -- SAL의 DESC 순서로 RANK RANK() OVER (PARTITION BY JOB ORDER BY SAL DESC) JOB_RANK -- JOB별로 SAL의 DESC 순서로 RANK FROM SCOTT.EMP; 한문장에 RANK가 2개 이상일 경우 먼저 나온것을 기준으로 ORDER BY된 결과가 나온다.JOB_RANK를 먼저 썼을 경우에는 ORDER BY JOB, SAL DESC 와 같은 순서로 결과가 나온다. DENSE_RANK : 동일한 순위를 하나의 건수로 계산한다. ROW_NUMBER : 동일한 순위에 대해서도 등수를 따로 매긴다. (Oracle의 경우 rowid가 낮은게 먼저 나옴) 12345SELECT JOB, ENAME, SAL, RANK() OVER (ORDER BY SAL DESC) RANK, DENSE_RANK() OVER (ORDER BY SAL DESC) DENSE_RANK, ROW_NUMBER() OVER (ORDER BY SAL DESC) ROW_NUMBER FROM SCOTT.EMP; 앞의 결과를 보면 RANK의 경우 2위가 2개이고 다음이 4위인데, DENSE_RANK는 2위가 2개이고 다음이 3위이다. ROW_NUMBER는 1 ~ 14로 모든 row의 순위가 다르다. 2. 집계 함수 SUM : 파티션별 윈도우의 합123SELECT DEPTNO, ENAME, SAL, SUM(SAL) OVER (PARTITION BY DEPTNO) \"부서별 연봉합계\" FROM SCOTT.EMP; 위 예제는 별로 어렵지 않다.이제 부서별로 SAL 순서로 ORDER BY한 다음에 부서별 연봉합계 대신 부서별 연봉누계로 출력해보겠다.1234SELECT DEPTNO, ENAME, SAL, SUM(SAL) OVER (PARTITION BY DEPTNO ORDER BY SAL RANGE UNBOUNDED PRECEDING) \"부서별 연봉누계\", RANK() OVER (PARTITION BY DEPTNO ORDER BY SAL) IDX FROM SCOTT.EMP; RANGE UNBOUNDED PRECEDING : 자신(ROW)을 기준으로 앞쪽(PRECEDING)으로 현재 PARTITION 내의 모든값(UNBOUNDED) 동일한 RANK에 대해서는 누계값도 동일하게 취급하여 두 값을 모두 더하게 된다. MIN, MAX : 파티션별 윈도우의 최소, 최대값1234SELECT DEPTNO, ENAME, SAL, MIN(SAL) OVER (PARTITION BY DEPTNO ORDER BY SAL) MIN_DEPT, MAX(SAL) OVER (PARTITION BY DEPTNO) MAX_DEPT FROM SCOTT.EMP; AVG : 파티션별 윈도우의 평균값 123SELECT DEPTNO, ENAME, SAL, HIREDATE, ROUND(AVG(SAL) OVER (PARTITION BY DEPTNO ORDER BY HIREDATE ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING)) AVG FROM SCOTT.EMP; ROW BETWEEN 1 PRECEDING AND 1 FOLLOWING : 자신(ROW)을 기준으로 앞쪽(PRECEDING) 1개와 뒤쪽(FOLLOWING) 1개의 ROW만을 대상으로 함. 만약 PARTITION 내에 앞에 값이 없으면 뒤에 값과 자신의 2개에 대한 평균만 계산. COUNT : 파티션별 개수를 구함 123SELECT DEPTNO, ENAME, SAL, COUNT(*) OVER (ORDER BY SAL RANGE BETWEEN 100 PRECEDING AND 100 FOLLOWING) COUNT FROM SCOTT.EMP; RANGE BETWEEN 100 PRECEDING AND 100 FOLLOWING : 값으로 앞뒤 100 사이에 있는 것만을 대상으로 함. 즉 자신의 연봉보다 +- 100 사이의 사원수를 측정 3. 순서 함수 FIRST_VALUE : 파티션내에서 가장 먼저 나온 값 (MIN으로 비슷하게 사용이 가능) LAST_VALUE : 파티션내에서 가장 나중에 나온 값 (MAX 로 비슷하게 사용이 가능) 각 부서별 가장 연봉이 많은 사람(RICH)와 가장 연봉이 적은 사람(POOR)를 구해보자.참고로 다음 SQL은 결과가 이상하게 나온다.1234SELECT DEPTNO, ENAME, SAL, FIRST_VALUE(ENAME) OVER (PARTITION BY DEPTNO ORDER BY SAL) POOR, LAST_VALUE (ENAME) OVER (PARTITION BY DEPTNO ORDER BY SAL) RICH FROM SCOTT.EMP; FIRST_VALUE의 경우에는 제대로 나왔는데, LAST_VALUE에 대해서는 뭔가 좀 이상하다.파티션 내에서 현재(ROW)를 기준으로만 계산이 되었다.LAST_VALUE의 경우에는 범위를 명시적으로 지정해주면 정상적으로 출력된다. 12345SELECT DEPTNO, ENAME, SAL, FIRST_VALUE(ENAME) OVER (PARTITION BY DEPTNO ORDER BY SAL) POOR, LAST_VALUE (ENAME) OVER (PARTITION BY DEPTNO ORDER BY SAL ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) RICH FROM SCOTT.EMP; 이 경우에는 SAL 순으로 정렬되었기 때문에 의미적으로 UNBOUNDED PRECEDING 대신에 CURRENT ROW를 적어도 결과는 같다. LAG : 이전 몇 번째 행의 값을 가져온다. LEAD : 이후 몇 번째 행의 값을 가져온다. 1234SELECT DEPTNO, ENAME, SAL, LAG (SAL) OVER (PARTITION BY DEPTNO ORDER BY SAL) LAG, LEAD(SAL) OVER (PARTITION BY DEPTNO ORDER BY SAL) LEAD FROM SCOTT.EMP; LAG, LEAD 함수는 인자를 3개까지 가질수 있다. 1LAG(컬럼, 몇칸 = 1, ISNULL = NULL) 첫번째 인자 : 어느 컬럼 값을 출력할지 지정 두번째 인자 : 몇칸 앞 (또는 뒤)의 값을 가져올지 지정 (default = 1) 세번째 인자 : NULL일 경우 어떻게 출력할지 지정 (default = NULL) 123456SELECT DEPTNO, ENAME, SAL, LAG (SAL,1,0) OVER (ORDER BY SAL) LAG_1, LAG (SAL,2,0) OVER (ORDER BY SAL) LAG_2, LEAD(SAL,1,0) OVER (ORDER BY SAL) LEAD_1, LEAD(SAL,2,0) OVER (ORDER BY SAL) LEAD_2 FROM SCOTT.EMP; 4. 비율 함수 RATIO_TO_REPORT : 파티션내 전체 SUM값 대비 백분율 비율 (0 ~ 1) 전 직원들의 연봉을 전체연봉 대비 얼마나 차지하는지를 구해보자.123SELECT ENAME, SAL, JOB, ROUND(RATIO_TO_REPORT(SAL) OVER(),3) AS RATIO FROM EMP PERCENT_RANK : 파티션내의 순서별 백분율. (처음값 = 0, 마지막값 = 1) CUME_DIST : 파티션내의 전체건수에서 자신보다 작거나 같은 건수에 대한 누적백분율 두 함수가 비슷한데 값이 약간 차이가 난다.PERCENT_RANK는 0 부터 시작하므로 파티션내의 개수 - 1 등분하고,CUME_DIST는 개수만큼 등분한다. 각 부서별 연봉 순위를 비율로 구해본다면1234SELECT DEPTNO, ENAME, SAL, PERCENT_RANK() OVER (PARTITION BY DEPTNO ORDER BY SAL DESC) AS PERCENT_RANK, ROUND(CUME_DIST() OVER (PARTITION BY DEPTNO ORDER BY SAL DESC),2) AS CUME_DIST FROM EMP NTILE : 파티션내의 전체 건수를 N 등분 전체 사원을 연봉 기준으로 4 LEVEL로 급수를 매길경우123SELECT ENAME, SAL, NTILE(4) OVER (ORDER BY SAL DESC) AS GRADE FROM EMP;","categories":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/categories/Database/"},{"name":"SQLP","slug":"Database/SQLP","permalink":"http://DevStarSJ.github.io/categories/Database/SQLP/"}],"tags":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/tags/Database/"},{"name":"Oracle","slug":"Oracle","permalink":"http://DevStarSJ.github.io/tags/Oracle/"},{"name":"SQLP","slug":"SQLP","permalink":"http://DevStarSJ.github.io/tags/SQLP/"}]},{"title":"SQLP 2-2-2 GROUP function","slug":"02.03.group","date":"2016-01-24T15:00:00.000Z","updated":"2017-04-23T23:56:12.000Z","comments":true,"path":"2016/01/25/02.03.group/","link":"","permalink":"http://DevStarSJ.github.io/2016/01/25/02.03.group/","excerpt":"","text":"2과목 SQL 기본 및 활용 20문제 각 상황별로 SQL문 작성이 가능할 정도로 연습해야 합니다. 기본적인 SQL문법 및 함수는 생략하고 Tuning에 활용될수 있는 것 위주로 정리하고자 합니다. 2장 SQL 활용 (#2) 표준에서 정한 데이터 분석 3가지 함수군 Aggregate function : 앞에서 본 GROUP BY 에서 사용한 집계함수 (SUM, AVG, MIN, MAX, …) Group function : 단계별 소계를 계산. SQL을 한번만 읽어 빠르게 보고서 작성이 가능하도록 도와주는 함수들 (ROLLUP, CUBE, GROUPING SET) Window function : 행간의 비교, 관계를 지원. DW에서 발전한 기능 (RANK로 대표됨. 함수명은 앞의 것들과 같지만 사용법이 다름) GROUP FUNCTION (그룹함수)솔직히 SQL 작성시 사용할 만한 함수는 ROLLUP 하나뿐이다.나머지는 시험에 나올 수 있으므로 그냥 어떤 역할을 한다는 정도만 알아두면 될듯하다. 1. ROLLUP소그룹간의 소계(subtotal)를 계산 부서별 업무별 인원수와 연봉의 소계를 일반적은 query로 다음과 같이 작성이 가능하다.12345SELECT DNAME, JOB, COUNT(*) AS TOTAL_EMP, SUM(SAL) AS SUM_SAL FROM DEPT A, EMP B WHERE A.DEPTNO = B.DEPTNO GROUP BY DNAME, JOB ORDER BY DNAME, JOB; 위 예제의 경우 부서별, 업무별의 대한 소계를 구했다.여기다가 부서별 소계 와 전체 합계까지 같이 출력하려면 어떻게 해야할까 ?부서별 소계를 구하는 SQL과 전체 합계를 구하는 SQL을 각각 호출해서 전체를 UNION ALL 하는 방법이 가장 손쉬운 방법이다. 123456789101112SELECT DNAME, JOB, COUNT(*) AS TOTAL_EMP, SUM(SAL) AS SUM_SAL, 1 AS DEPTH FROM DEPT A, EMP B WHERE A.DEPTNO = B.DEPTNO GROUP BY DNAME, JOB UNION ALLSELECT DNAME, 'TOTAL' AS JOB, COUNT(*) AS TOTAL_EMP, SUM(SAL) AS SUM_SAL, 2 AS DEPTH FROM DEPT A, EMP B WHERE A.DEPTNO = B.DEPTNO GROUP BY DNAME UNION ALLSELECT 'TOTAL' AS DNAME, '' AS JOB, COUNT(*) AS TOTAL_EMP, SUM(SAL) AS SUM_SAL, 3 AS DEPTH FROM EMP 그 결과들을 다시 순서대로 할려면 UNION ALL로 묶은 것을 subquery로 해서 SELECT문을 한번 더 써야 한다.위 SQL을 그냥 A라고 하겠다. 123SELECT DNAME, JOB, TOTAL_EMP, SUM_SAL FROM (SELECT ... ) A ORDER BY DNAME, DEPTH, JOB; 상당히 복잡한 과정을 거쳐서 소계를 구했는데,그냥 ROLLUP을 이용하면 쉽게 작성이 가능하다.12345SELECT DNAME, JOB, COUNT(*) AS TOTAL_EMP, SUM(SAL) AS SUM_SAL FROM EMP A, DEPT B WHERE A.DEPTNO = B.DEPTNO GROUP BY ROLLUP (DNAME, JOB) ORDER BY DNAME, JOB; GROUPING 함수 : 해당 컬럼을 기준으로 소계를 한 결과에 대해서는 GROUPING(컬럼) = 1을 출력한다. 위 결과에서 각 부서별 합계를 출력하는 row에 대해서는 GROUPING(JOB) = 1 이 되며,총 계에 대해서는 GROUPING(DNAME) = 1, GROUPING(JOB) = 1 이 출력된다.이 함수를 이용해서 그룹별 소계, 총 합계를 출력하는 row에 별도 label을 주고자 할 경우 작성법은 다음과 같다. 1234567SELECT DECODE (GROUPING(DNAME), 1, 'Total DEPT', DNAME) AS DNAME, DECODE (GROUPING(JOB), 1, 'Total JOB' , JOB) AS JOB, COUNT(*) AS TOTAL_EMP, SUM(SAL) AS SUM_SAL FROM EMP A, DEPT B WHERE A.DEPTNO = B.DEPTNO GROUP BY ROLLUP (DNAME, JOB); ROLLUP을 부분적으로 적용 소계에서 제외 항상 모든 GROUP BY에 사용된 컬럼에 대해서 ROLLUP을 해야하는 것은 아니다. 만약 DNAME, JOB 별로 GROUP BY를 하되 부서별 소계를 필요하지만, 전체 합계는 필요없을 경우 GROUP BY DNAME, ROLLUP(JOB) 라고 쓰면 위 결과에서 마지막줄인 Total DEPT가 출력되지 않는다. 2개 이상의 컬럼으로 구분 위의 경우 DNAME, JOB가 종속관계이다. DNAME 안에서 JOB별로 구분하였다. 만약 DNAME 아래에 JOB, MGR이 같은 것끼리 묶어서 소계를 구하고자 할때에는 두 컬럼 이상을 괄호로 묶으면 된다. GROUP BY ROLLUP( DNAME, (JOB, MGR)) 이라고 쓰면 JOB, MGR을 계층짓지않고, JOB, MGR이 모두 같은 것을 하나의 그룹으로 묶어서 소계를 구한다. 2. CUBE결합 가능한 모든 값에 대하여 다차원 집계를 생성한다.위 ROLLUP에서 사용한 예제에서 ROLLUP대신 CUBE를 쓸 경우 : GROUP BY CUBE(DNAME, JOB) DNAME 별 JOB의 소계 JOB 별 DNAME의 소계 전체 합계를 모두 출력한다. 즉, CUBE 내의 컬럼들의 순서를 바꿔가면서 ROLLUP을 수행한 뒤에 UNION 한것과 같은 결과이다.그만큼 연산량이 많다. 또 다른 차이점은 GROUPING 함수의 경우ROLLUP에서는 계층이 있으므로 GROUPING(DNAME) = 1 이면서 GROUPING(JOB) = 0 인 값이 없었다.CUBE에서는 GROUPING(DNAME) = 1 이면서 GROUPING(JOB) = 0이 가능하다. JOB별 all DNAME에 대한 소계의 경우이다. 3. GROUPING SETS다양한 소계들을 한번의 SQL로 구하는데 사용된다.나열한 컬럼들을 평등한 관계이므로 순서를 바꿔도 상관없다. 위 예제에서 GROUPING SETS를 쓸 경우 : GROUP BY GROUPING SETS(DNAME, JOB) DNAME별 소계 JOB별 소계를 UNION ALL 해준 결과를 출력해준다. GROUPING SET도 2개 이상의 컬럼으로 구분이 가능하다. ROLLUP에서 본것 같이 괄호로 컬럼들을 묶어주면 된다.GROUP BY GROUPING SETS ( (DNAME, JOB, MGR) , (DNAME, JOB) , DNAME ) 이라고 할 경우 DNAME-JOB-MGR 별 소계 DNAME-JOB 별 소계 DNAME 별 소계의 결과들을 UNION ALL 한 것과 같은 결과를 출력해준다.","categories":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/categories/Database/"},{"name":"SQLP","slug":"Database/SQLP","permalink":"http://DevStarSJ.github.io/categories/Database/SQLP/"}],"tags":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/tags/Database/"},{"name":"Oracle","slug":"Oracle","permalink":"http://DevStarSJ.github.io/tags/Oracle/"},{"name":"SQLP","slug":"SQLP","permalink":"http://DevStarSJ.github.io/tags/SQLP/"}]},{"title":"SQLP 2-2-1 SET, Hierarchical Query, Sub-query","slug":"02.02.sql.adv","date":"2016-01-22T15:00:00.000Z","updated":"2017-04-23T23:55:32.000Z","comments":true,"path":"2016/01/23/02.02.sql.adv/","link":"","permalink":"http://DevStarSJ.github.io/2016/01/23/02.02.sql.adv/","excerpt":"","text":"2과목 SQL 기본 및 활용 20문제 각 상황별로 SQL문 작성이 가능할 정도로 연습해야 합니다. 기본적인 SQL문법 및 함수는 생략하고 Tuning에 활용될수 있는 것 위주로 정리하고자 합니다. 2장 SQL 활용 (#1)1. 집합 연산자 (SET) UNON : 합집합, 중복된 행은 제거 UNION ALL : 합집합, 중복된 행을 그대로 표시하는 대신에 성능이 빠름 INTERSECT : 교집합, 중복된 행 제거 MINUS : 차집합, 앞의 SQL 결과에서 뒤의 결과를 제거한다. (오라클 이외의 대부분은 EXCEPT로 사용함) 솔직히 UNION과 UNION ALL의 차이만 이해하고 있으면 된다.UNION 과 UNION ALL의 결과가 같다는것이 보장되면 무조건 UNION ALL을 사용하는 것이 성능이 뛰어나다.INTERSECT 는 EXISTS 나 IN 서브쿼리로 변경이 가능하다. (그러므로 쓸일이 거의 없다.)MINUS 는 그냥 WHERE의 조건에서 논리적으로 제외시키는 것이 가능하다. (심지어 출력하지 않아도 될 ROW와 거기서 빼야할 ROW들을 읽어야 하므로 성능을 생각해서는 절대로 사용하면 안된다.) 2. 계층형 질의 (Hierarchical Query)계층형 데이터를 조회할때 사용한다. 계층형 데이터 : 동일 테이블에 계층적으로 상위, 하위 데이터가 포함된 데이터ex. EMP Table에 EMPNO, MANAGER 가 있으며 EMPNO는 해당 사원의 사원번호, MANAGER는 해당 사원의 부서장 사원번호인 경우 계층형 질의는 다음과 같은 모양이다. (Oracle 기준) 질의 구문 123456SELECT ... FROM table name WHERE (filter condition) START WITH (root condition) -- START WITH MANAGER IS NULL CONNECT BY [NOCYCLE] (hierarchical condition) -- CONNECT BY NOCYCLE PRIOR EMPNO = MANAGER [ORDER SIBLINGS BY columns...] START WITH : 시작조건. root data가 되는 조건을 적는다. CONNECT BY : 부모와 자식의 관계를 적는다. PRIOR 키워드는 전개방향 상 이전 레코드를 가리킨다. ORDER SIBLINGS BY :(같은 부모를 가진) 형재 node 의 ORDER BY이다. SELECT, FROM, WHERE 등은 일반 SQL문법과 동일하다. 가상 칼럼 LEVEL : ROOT = 1, LEAF방향으로 1씩 증가 CONNECT_BY_ISLEAF : LEAF이면 1, 자식이 있으면 0 CONNECT_BY_ISCYCLE : 자식을 가지면서, 자신이 자기 조상에도 있으면 1, 아니면 0 (CYCLE 옵션에서만 허용) 전용 함수 SYS_CONNECT_BY_PATH(column, separator) : Root부터 현재까지의 경로를 표시한다. CONNECT_BY_ROOT column : root 데이터의 칼럼을 표시한다. START WITH 조건과 CONNECT BY 조건을 어떻게 하냐에 따라서 부모 -&gt; 자식 방향 또는 자식 -&gt; 부모 방향으로의 전개가 가능하다. 부모 -&gt; 자식 방향전개 START WITH : ROOT 조건 CONNECT BY : PRIOR 자식ID = 부모ID 이 부분 해석이 좀 해깔릴수 있는데, EMPNO, MANAGER의 경우 PRIOR EMPNO = MANAGER 로 써야한다. 그냥 START WITH 조건의 row와 전개방향 바로 다음 row의 비교조건을 적는다고 생각하면 됨. 12345SELECT LPAD(' ', 4 * (LEVEL-1)) || LEVEL AS \"LEVEL\", EMPNO, MGR, CONNECT_BY_ISLEAF AS LEAF FROM SCOTT.EMP START WITH MGR IS NULLCONNECT BY PRIOR EMPNO = MGRORDER SIBLINGS BY EMPNO; 자식 -&gt; 부모 방향전개 START WITH : LEAF 조건 CONNECT BY : PRIOR 부모ID = 자식ID 1234SELECT LEVEL, EMPNO, MGR FROM SCOTT.EMP START WITH EMPNO = 7369 CONNECT BY PRIOR MGR = EMPNO; 3. SELF JOIN이것도 설명해야 할까 ?그냥 같은 테이블 2개를 JOIN, alias 필수(그래야 서로 다른 view인듯 제어가 가능하니깐) 4. Subquery SQL문 안에 포함되는 SQL문을 의미한다. 반드시 (괄호)로 감싸야한다. ORDER BY를 사용하지 못한다. (메인 쿼리의 마지막에 한번만 가능하다.) 분류 동작 방식 비연관 (Un-Correlated) : 메인쿼리의 컬럼을 가지고 있지 않음. 메인쿼리에 결과를 제공하기 위한 목적 연관 (Correlated) : 메인쿼리의 칼럼을 가지고 있음. 메인쿼리가 먼저 수행되면서 서브쿼리에서 조건 체크할 목적 반환되는 데이터 형태 Single row : 결과가 1건 이하 (단일행 비교연산자) Multi row : 결과가 여러 건 (IN, ALL, ANY, SOME, EXISTS 연산자) Multi column : 결과가 여러 컬럼 (메인쿼리와 비교하자고 하는 컬럼의 위치와 개수가 같아야함) Scalar Subquery : 1개의 data (1 row 1 column)만 반환. SQL문 중 column이 위치할 수 있는 대부분의 곳에 사용 가능 일단 이 2가지 분류방식에 대해서 먼저 이해를 하고, 이제 위치에 따라 올 수 있는 형태를 살펴보겠다. 1. WHERE에 위치 Single row SCOTT이 속한 부서의 직원목록을 보기 위해서는먼저 SCOTT의 DEPTNO를 가져와서 해당 값과 같은 직원들을 조회해야 한다.12SELECT * FROM EMP WHERE DEPTNO = (SELECT DEPTNO FROM EMP WHERE ENAME = 'SCOTT') -- 먼저 수행 Multi row SALEMAN job이 있는 부서와 해당 부서에 있는 CLERK job의 목록을 보기 위해서는먼저 SALEMAN 이 속한 부서의 DEPTNO를 구한 뒤, 해당 값과 같은 부서인원중 CLERK를 찾아야 한다.123SELECT * FROM EMP WHERE JOB = 'CLERK' AND DEPTNO IN (SELECT DISTINCT DEPTNO FROM EMP WHERE JOB = 'SALESMAN') -- 먼저 수행 Multi column 각 팀별 최고연봉자를 출력하기 위해서는먼저 각 팀별 최고연봉자에 대해서 GROUP BY로 구한 뒤 해당 칼럼정보와 같은 직원정보를 출력하면 된다.12SELECT * FROM EMP WHERE (DEPTNO, SAL) IN (SELECT DEPTNO, MAX(SAL) AS SAL FROM EMP GROUP BY DEPTNO) -- 먼저 수행 연관 서브쿼리 (Correlated subuery) 메인쿼리 칼럼이 서브쿼리 내에서 사용된다.메인쿼리가 먼저 수행되면서 row마다 서브쿼리를 한번씩 수행하므로 성능상에는 좋지않다. 각 부서별 평균영봉 이상을 받는 직원정보를 출력하고자 하기 위해서는매 직원정보마다 해당 직원의 연봉이 해당 부서의 평균이상인지를 비교(check)해야 한다.12SELECT * FROM EMP A -- 메인쿼리가 먼저 수행되면서 매 ROW마다 아래 서브쿼리 수행 WHERE SAL &gt;= (SELECT AVG(SAL) AS SAL FROM EMP B WHERE B.DEPTNO = A.DEPTNO GROUP BY B.DEPTNO) 2. SELECT에 위치 (Scalar Subquery)대부분 연관(correlated) 관계로 호출한다.비연관으로 가능하다면 그냥 Inline View로 하는게 더 효과적이다. 직원정보를 호출하면서 소속부서의 평균연봉도 같이 출력할 경우 다음과 같다.1234SELECT DEPTNO, ENAME, SAL, ROUND((SELECT AVG(SAL) FROM EMP B WHERE B.DEPTNO = A.DEPTNO GROUP BY B.DEPTNO)) AS AVG_SAL FROM EMP A ORDER BY DEPTNO, SAL; 3. FROM에 위치 (Inline View)View나 Table이 올수 있는 위치에는 사용이 가능하다.해당 query내에서는 마치 dynamic view처럼 사용된다.사용상 아무런 제약을 받지않고 SELECT문을 자유롭게 쓸 수 있다. (ORDER BY도 사용이 가능하다.) 바로 위에 연관관계로 호출된 Scalar subquery는 성능이 좋지 않으므로 inline view로 고쳐보자.각 부서별 평균연봉을 dynamic view로 구한 다음 JOIN을 하면 된다.12345SELECT A.DEPTNO, A.ENAME, A.SAL, B.AVG_SAL FROM EMP A, (SELECT DEPTNO, ROUND(AVG(SAL)) AS AVG_SAL FROM EMP GROUP BY DEPTNO) B WHERE A.DEPTNO = B.DEPTNO ORDER BY DEPTNO, SAL; TOP-N 쿼리 data를 정렬하고 그 중 일부만 추출하고자 할때는 inline view로 ORDER BY를 한 뒤 ROWNUM으로 추출하면 된다. MANAGER 중 연봉 BEST 2를 순서대로 출력하고자 할 경우 (MANAGER는 총 3명)123SELECT * FROM (SELECT * FROM SCOTT.EMP WHERE JOB = 'MANAGER' ORDER BY SAL DESC) WHERE ROWNUM &lt;= 2; 4. HAVING에 위치WHERE에 위치와 크게 다르지않다.하지만 집계함수 사용시 그 결과를 filtering 하는 것이므로 의미상 필요할 경우 사용하면 된다. 부서별 평균연봉이 전체평균연봉보다 큰 부서명을 출력하고자 할 경우1234567SELECT C.DNAME, B.AVG_SAL FROM DEPT C, (SELECT A.DEPTNO, ROUND(AVG(A.SAL)) AS AVG_SAL FROM EMP A GROUP BY DEPTNO HAVING AVG(A.SAL) &gt;= (SELECT AVG(SAL) FROM EMP)) B WHERE C.DEPTNO = B.DEPTNO; 5. UPDATE의 SET에 위치UPDATE 할 TABLE과 JOIN하여 여러 row에 대한 UPDATE를 한번에 수행이 가능하다.DEPT table에 AVG_SAL(평균연봉) 컬럼을 추가한 뒤 해당 값을 한번에 넣고자 하는 경우12UPDATE DEPT A SET AVG_SAL = (SELECT AVG(SAL) AS AVG_SAL FROM EMP B WHERE B.DEPTNO = A.DEPTNO GROUP BY B.DEPTNO); 6. INSERT의 VALUES에 위치주로 새로운 값을 추가할 때 기존에 저장된 마지막 일련번호(s/n)의 다음 번호로 저장하고자 할때 사용하며 편하다.12INSERT INTO EMP (EMPNO, ENAME)VALUES ((SELECT MAX(EMPNO) + 1 FROM EMP), 'LUNA'); 5. ViewSELECT 질의문을 이용하여 가상의 table을 선언하는 것이다.실제로 물리적으로 해당 table이 생성되는 것이 아니라 수행할때마다 DBMS 내부적으로 View의 정의를 참조하여 쿼리를 재정의한다. View의 장점 독립성 : Table의 구조가 변경되어도, View를 사용하는 application은 변경하지 않아도 된다. (물론 View를 변경해줘야 하지만) 편리성 : 자주 이용되는 복잡한 query를 미리 view로 정의해두면 편리하게 재사용이 가능하다. 보안성 : 보안상 숨기고 싶은 데이터에 대해서는 view 생성시 해당 정보를 제외하고 view를 배포하면 된다. View 생성방법 123CREATE VIEW 뷰명칭ASSELECT ...","categories":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/categories/Database/"},{"name":"SQLP","slug":"Database/SQLP","permalink":"http://DevStarSJ.github.io/categories/Database/SQLP/"}],"tags":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/tags/Database/"},{"name":"Oracle","slug":"Oracle","permalink":"http://DevStarSJ.github.io/tags/Oracle/"},{"name":"SQLP","slug":"SQLP","permalink":"http://DevStarSJ.github.io/tags/SQLP/"}]},{"title":"SQLP 2-1 SQL 기본","slug":"02.01.sql.basic","date":"2016-01-20T15:00:00.000Z","updated":"2017-04-23T23:54:15.000Z","comments":true,"path":"2016/01/21/02.01.sql.basic/","link":"","permalink":"http://DevStarSJ.github.io/2016/01/21/02.01.sql.basic/","excerpt":"","text":"2과목 SQL 기본 및 활용 20문제 각 상황별로 SQL문 작성이 가능할 정도로 연습해야 합니다. 기본적인 SQL문법 및 함수는 생략하고 Tuning에 활용될수 있는 것 위주로 정리하고자 합니다. 1장 SQL 기본1.1 SQL 종류 DML (Data Manipulation Language) : 데이터 조작어 SELECT : 조회 INSERT, UPDATE, DELETE : 데이터에 변형을 가하는 명령어 DDL (Data Definition Language) : 데이터 정의어 CREATE, ALTER, DROP, RENAME : 테이블 등의 데이터 구조를 생성, 변경, 삭제하는 명령어 DCL (Data Control Language) : 데이터 제어어 GRANT, REVOKE : DB 및 객체의 접근, 사용 권한을 주고 회수하는 명령어 TCL (Transaction Control Language) : 트랜잭션 제어어 COMMIT, ROLLBACK : 트랜잭션을 제어하는 명령어 1.2 CREATE TABLE1. 기본적인 생성법123456CREATE TABLE 테이블명 ( 컬럼명 DATATYPE [DEFAULT 형식], ... CONSTRAINT 테이블명_PK PRIMARY KEY (컬럼, ...), CONSTRAINT 테이블명_FK FOREIGN KEY (컬럼, ...) REFERENCES 테이블2(컬럼, ...)); 2. CTAS (Create Table as Select) Oracle 12CREATE TABLE EMP_COPYAS SELECT * FROM SCOTT.EMP; MS-SQL 1SELECT * INTO EMP_COPY FROM SCOTT.EMP; NOT NULL 제약조건을 제외하고는 모두 삭제 1.3 TRUNCATE TABLE vs DROP TABLE, DELETE TABLE TRUNCATE TABLE DROP TABLE과의 차이점 : Table을 삭제하지 않고 모든 row들을 제거한다. DELETE TABLE과의 차이점 : 시스템 부하가 훨씬 적인 대신에 복구가 불가능하다. (rollback 불가) 1.4 TRANSACTION특징 원자성 (atomicity) : 모두 정상적으로 실행되거나, 실행되지 않은 상태로 되거나 (all or nothing ) 일관성 (consistency) : 실행전에 잘못된 상태가 아니었다면, 실행후에도 잘못이 있으면 안됨 고립성 (isolation) : 도중에 다른 트랜잭션의 영향을 받지 않음 지속성 (durability) : 수행후 갱신한 내용은 영구적으로 저장 명령어 COMMIT : 변경된 상태를 DB에 반영 ROLLBACK : 트랜잭션 수행 이전 상태로 되돌림 SAVEPOINT [저장명칭] : 현시점까지만 ROLLBACK이 가능하도록 SAVEPOINT 지정 (MS-SQL에서는 SAVE TRANSACTION [저장명칭]) ROLLBACK TO [저장명칭] : 해당 SAVEPOINT 까지 ROLLBACK (MS-SQL에서는 ROLLBACK TRANSACTION [저장명칭]) 1.5 ROWNUM (Oracle), TOP (MS-SQL) ROWNUM : SQL 처리결과 각 행의 임시 일련번호 1개의 행만 출력할 경우 123SELECT ... FROM ... WHERE ROWNUM = 1;SELECT ... FROM ... WHERE ROWNUM &lt;= 1;SELECT ... FROM ... WHERE ROWNUM &lt; 2; n개의 행을 출력할 경우 12SELECT ... FROM ... WHERE ROWNUM &lt;= n;SELECT ... FROM ... WHERE ROWNUM &lt; n+1; TOP : 출력결과의 행 수를 제한 1SELECT TOP( n [PERCENT] [WITH TIES] ) ... FROM ...; n : n의 갯수 만큼 행을 출력 PERCENT : n % 만큼 출력 WITH TIES : 마지막 행과 동일한 값과 동일한 값은 추가로 같이 출력 1.6 CASE 프로그래밍의 IF-THEN-ELSE와 비슷한 표현식입니다. 1. 단순비교 : 해당 값에 따라 분류1234CASE value WHEN 1 THEN 'one' WHEN 2 THEN 'two' ELSE NULLEND 2. 조건비교 : 해당 조건에 따라 분류1234CASE WHEN value = 1 THEN 'one' WHEN value = 2 THEN 'two' ELSE NULLEND 3. DECODE : 단순비교를 보다 짧게 표한하는 Oracle 함수1DECODE(value, 1,'one', 2,'two', NULL) 1.7 NULL NULL 관련 문제는 반드시 출제된다. NVL (Oracle), ISNULL (MS-SQL)해당 값이 NULL일 경우 2번째 인자의 값을 출력한다.12SELECT NVL(SAL,0) FROM EMP; -- OracleSELECT ISNULL(SAL,0) FROM EMP; -- MS-SQL COALESCE인수 중 최초로 NULL이 아닌 값을 출력한다. 모두 NULL인 경우 NULL이 출력된다.1SELECT ENAME, COMM, SAL, COALESCE(COMM, SAL) COAL FROM EMP; 위 문장은 아래의 CASE문으로 표현한 것과 같다.123456SELECT ENAME, COMM, SAL, CASE WHEN COMM IS NOT NULL THEN COMM WHEN SAL IS NOT NULL THEN SAL ELSE NULL END COAL FROM EMP; 1.8 집계함수 (Aggregate function) GROUP 당 단 1개의 값만 출력하는 함수 SELECT , HAVING, ORDER BY 절에서 사용할 수 있다. 집계함수에 들어온 NULL값은 계산에 포함시키지 않는다. (참고로 산술연산에 NULL 값이 포함되어 있으면 결과는 무조건 NULL이다.) SELECTGROUP BY에 명시된 컬럼, 집계함수의 결과값 만 가능하다. GROUP BY여기에 명시한 컬럼, 표현식 단위로 집계함수를 이용하여 계산한다. WHERE여기에 적은 조건에 부합하는 row만 집계함수 계산에 참여한다. (GROUP BY 이전 필터링 역할) HAVING집계된 결과 중 HAVING 절의 조건에 만족하는 것만 출력한다. (GROUP BY 이후 필터링 역할) 1234567SELECT D.DEPTNO, MAX(DNAME) AS DNAME, SUM(SAL) AS SUM, AVG(SAL) AS AVG FROM DEPT D, EMP E WHERE D.DEPTNO = E.DEPTNO AND D.DEPTNO IN (10, 30) -- DEPTNO가 10, 30 인것만 집계로 계산 GROUP BY D.DNAMEHAVING SUM(SAL) &gt;= 10000 -- 계산된 결과중 10000이 넘는 것만 출력 ORDER BY SUM(SAL); SELECT 문장 실행순서 FROM : 대상 Table 검색 WHERE : 검색 대상이 아닌 데이터 제거 GROUP BY : 집계할 단위로 그룹화 HAVING : 집계한 것중 조건에 맞는 것만 선택 SELECT : 출력할 값들을 계산 및 함수적용 ORDER BY : 데이터를 정렬하여서 출력 CASE - GROUP BY1정규화로 모델링된 테이블들에서 보고서를 만들때 많이 사용되는 기법이다. 예를 들어서 각 부서별로 입사월별 급여합계가 필요한 경우가 있다고 가정했을 때 먼저 부서, 사원명, 입사월, 급여를 출력해보자. 123SELECT ENAME, DEPTNO, EXTRACT(MONTH FROM HIREDATE) M, SAL FROM SCOTT.EMP ORDER BY SAL DESC; 위 문장을 이용하여 각 월별로 컬럼을 생성하여 해당 월에 급여를 출력해보자.(CASE랑 기능이 같은 DECODE를 사용하겠다.) 12345678910111213141516SELECT ENAME, DEPTNO, DECODE(M, 1,SAL) AS M01, DECODE(M, 2,SAL) AS M02, DECODE(M, 3,SAL) AS M03, DECODE(M, 4,SAL) AS M04, DECODE(M, 5,SAL) AS M05, DECODE(M, 6,SAL) AS M06, DECODE(M, 7,SAL) AS M07, DECODE(M, 8,SAL) AS M08, DECODE(M, 9,SAL) AS M09, DECODE(M,10,SAL) AS M10, DECODE(M,11,SAL) AS M11, DECODE(M,12,SAL) AS M12 FROM (SELECT ENAME, DEPTNO, EXTRACT(MONTH FROM HIREDATE) M, SAL FROM SCOTT.EMP ) ORDER BY DEPTNO, ENAME; 이제 위 문장을 부서별로 GROUP BY 하는건 어렵지 않을 것이다.참고로 NULL인 경우 0으로 표시하도록 NVL을 이용하였다. 12345678910111213141516SELECT DEPTNO, NVL(SUM(DECODE(M, 1,SAL)),0) AS M01, NVL(SUM(DECODE(M, 2,SAL)),0) AS M02, NVL(SUM(DECODE(M, 3,SAL)),0) AS M03, NVL(SUM(DECODE(M, 4,SAL)),0) AS M04, NVL(SUM(DECODE(M, 5,SAL)),0) AS M05, NVL(SUM(DECODE(M, 6,SAL)),0) AS M06, NVL(SUM(DECODE(M, 7,SAL)),0) AS M07, NVL(SUM(DECODE(M, 8,SAL)),0) AS M08, NVL(SUM(DECODE(M, 9,SAL)),0) AS M09, NVL(SUM(DECODE(M,10,SAL)),0) AS M10, NVL(SUM(DECODE(M,11,SAL)),0) AS M11, NVL(SUM(DECODE(M,12,SAL)),0) AS M12 FROM (SELECT ENAME, DEPTNO, EXTRACT(MONTH FROM HIREDATE) M, SAL FROM SCOTT.EMP ) GROUP BY DEPTNO; 1.9 JOINJOIN은 한번에 2개의 집합간에만 가능하다.FROM A, B, C, D 가 있더라도 이 중 2개를 먼저 JOIN하고 그 결과를 다음과 JOIN하는 식으로 처리된다. JOIN에 대해서는 2장에서 자세히 다루려했으나…거기에 시간을 빼았겨서는 안될듯하여 그냥 여기서 간단히 다루겠습니다. JOIN 연산 EQUI JOIN 일반적으로 PK - FK 의 관계에서 많이 이루어진다.WHERE 절이나 ON 절에서 = 연산으로 JOIN 한다. Non EQUI JOIN =연산이 아닌 연산으로 JOIN을 수행한다. ( BETWEEN, &gt;, &gt;=, &lt;, &lt;=, &lt;&gt;, != ) 예를 들어 SALGRADE Table에 각 급여구간별 GRADE가 저장된 경우, EMP의 각 사원별로 급여등급을 구하고자할때 다음과 같이 작성하면 된다. 1234SELECT E.ENAME, E.DEPTNO, E.SAL, G.GRADE FROM SCOTT.EMP E, SCOTT.SALGRADE G WHERE E.SAL BETWEEN G.LOSAL AND G.HISAL ORDER BY SAL DESC; JOIN 종류 INNER JOIN 양쪽 Table 모두 조건에 해당되는 데이터만 출력 (교집합) Natural JOIN : INNER JOIN 에서 중복된 컬럼은 한번만 출력됨 모든 일치된 칼럼에 대해서 JOIN 되지만, USING으로 원하는 컬럼만 선택이 가능 (실제로 해보니 USING 안쓰면 ERROR)12345SELECT * FROM EMP E, DEPT D WHERE E.DEPTNO = D.DEPTNO;SELECT * EMP E INNER JOIN DEPT D ON E.DEPTNO = D.DEPTNO;SELECT * FROM EMP NATUAL JOIN DEPT USING (DEPTNO); OUTER JOIN LEFT OUTER JOIN : 왼쪽 Table의 모든 row 출력, 오른쪽 Table에는 조건에 맞으면 출력하고 아니면 NULL RIGHT OUTER JOIN : 오른쪽 Table의 모든 row 출력, 왼쪽 Table에는 조건에 맞으면 출력하고 아니면 NULL FULL OUTER JOIN : 좌,우측을 모두 읽어서 서로 상대에게 있으면 출력 없으면 NULL (LEFT OUTER와 RIGHT OUTER를 UNION 한거랑 결과가 같음) 12345SELECT * FROM SCOTT.EMP E LEFT JOIN SCOTT.DEPT D ON E.DEPTNO = D.DEPTNO;SELECT * FROM SCOTT.EMP E RIGHT JOIN SCOTT.DEPT D ON E.DEPTNO = D.DEPTNO;SELECT * FROM SCOTT.EMP E FULL JOIN SCOTT.DEPT D ON E.DEPTNO = D.DEPTNO; CROSS JOIN (CARTESIAN PRODUCT) 양쪽 Table의 모든 row 들을 모두 관계짓는다. (A에 10개 row, B에 5개 row가 있을 경우 결과는 10 x 5 = 50개가 된다.) 123SELECT * FROM SCOTT.EMP CROSS JOIN SCOTT.DEPT;SELECT * FROM SCOTT.EMP, SCOTT.DEPT;","categories":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/categories/Database/"},{"name":"SQLP","slug":"Database/SQLP","permalink":"http://DevStarSJ.github.io/categories/Database/SQLP/"}],"tags":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/tags/Database/"},{"name":"Oracle","slug":"Oracle","permalink":"http://DevStarSJ.github.io/tags/Oracle/"},{"name":"SQLP","slug":"SQLP","permalink":"http://DevStarSJ.github.io/tags/SQLP/"}]},{"title":"SQLP 1-2 데이터 모델과 성능","slug":"01.02.modeling_performance","date":"2016-01-19T16:00:00.000Z","updated":"2017-04-23T23:58:36.000Z","comments":true,"path":"2016/01/20/01.02.modeling_performance/","link":"","permalink":"http://DevStarSJ.github.io/2016/01/20/01.02.modeling_performance/","excerpt":"","text":"1과목 데이터 모델링의 이해 10문제 외우기 보다는 반복적으로 읽어서 전반적인 내용을 이해하는 수준에서 마무리 하는것을 목표로 잡아야 겠습니다. 제 2장 데이터 모델과 성능1절 성능 데이터 모델링의 개요 성능 데이터 모델링이란 ? 성능향상을 목적으로 모델링 하는 것 수행시점은 ? 빠르면 빠를수록 좋다. 분석/설계 단계에서는 운영때보다 더 적은 비용으로 가능하다. 성능 모델링 고려사항 기본적으로 정규화를 수행해놓고 시작한다. 데이터베이스 용량산정 데이터베이스 트랜잭션 유형 파악 용량과 트랜잭션 유형에 따라 반정규화 수행 이력모델의 조정, PK/FK 조정, 슈퍼타입/서브타입 조정 성능관점의 데이터 모델 검증 일단 정규화를 완벽하게 해놓고 시작해야 한다.그 상태에서 어느 엔터티에 트랜잭션이 들어오는지 알아봐야 하는데,가장 간단한 방법이 용량이 집중적으로 늘어나는 엔터티를 찾는 것이다.트랜잭션 유형도 파악할 필요가 있는데, CRUD, 시퀀스 다이어그램 등을 참조하면 된다.파악된 트랜잭션 유형으로 SQL문장의 조인관계 테이블의 칼럼들을 파악할 수 있으며,이렇게 모은 자료를 근거로 반정규화를 적용한다.그 다음에 성능을 고려하야 PK/FK를 성능이 우수한 순서대로 칼럼 순서를 조정한다.데이터 모델 규칙보다는 성능적인 측면을 충분히 고려해야 한다. 2절 정규화와 성능일반적으로 정규화를 하면 조회시 JOIN이 늘어나기 때문에 성능이 저하되고,DML (INSERT, UPDATE, DELETE) 연산의 성능이 향상된다.하지만 모든 조회에서 성능이 저하되는 것은 아니고, 정규화를 해야만 성능이 향상되는 경우도 아주 많다. 정규화가 더 빠른 사례 1 : 컬럼이 많을 경우 (버퍼 낭비)원래 (반정규화된) 테이블에는 컬럼이 10개가 있었다.조회시 해당 테이블에서 PK를 제외하고 2개의 컬럼만 자주 읽힌다.오랜기간 동안의 이력중 PK 포함 그 3개의 컬럼만 자주 읽을 경우라면,나머지 컬럼들을 PK값에 종속적인 테이블로 따로 분리를 하는 것이 유리하다. 정규화가 더 빠른 사례 2 : DISTINCT를 써야 할 경우 일자별 거래물건 (100만건) : 물건번호(PK), 일자, 시간, 장소, … 일자별 거래내역 (2만건) : (일자, 장소) (PK) 금액, 건수, … 광화문에서 거래된 금액을 구하는 SQL문은 다음과 같다. 12345SELECT B.금액 FROM (SELECT DISTINCT 일자, 장소 FROM 일자별거래물건 WHERE 장소 = '광화문`) A, -- 100만건을 DISTINCT 일자별거래내역 B WHERE A.일자 = B.일자 AND A.장소 = B.장소 만약 위에서 DISTICT 한 결과가 5천건이라면, (일자, 장소) 를 별도의 테이블로 생성하는 것이 유리하다. 일자별 거래물건 (100만건) : 물건번호(PK), 일자(FK), … 거래 (5천건) : 일자(PK), 시간, 장소 일자별 거래내역 (2만건) : (일자(FK), 장소) (PK) , 금액, 건수, … 12345SELECT B.금액 FROM 거래 A, 일자별거래내역 B WHERE A.장소 = '광화문' -- 5천건 AND A.일자 = B.일자 AND A.장소 = B.장소 정규화가 더 빠른 사례 3 : 동일한 속성 형식이 여러개 나열된 경우한 테이블에 속성1, 속성2, 속성3, … 이 여러개 있고, 각각에 INDEX가 걸려 있는 경우를 말한다.이런 경우 DML 작업에서의 성능저하 때문에 INDEX를 두지 않거나, 1개 정도만 만드는 경우가 많다.각 속성에 부합하는 데이터를 찾는 SQL문은 다음과 같다. 123456SELECT ... FROM 장비 WHERE 속성1 = '1' OR 속성2 = '2' OR 속성3 = '3' ... 각각의 속성에 모두 INDEX를 걸어둔 경우가 아니라면 Full Scan이나 Index Range Scan으로 넓은 범위를 찾아야 한다. 위 Table을 아래와 같이 먼저 정규화를 수행한다. 장비 : 장비코드(PK), … (속성들은 모두 제외) 속성 : (장비코드(FK), 속성코드) (PK), 속성값 위 상태에서는 속성 테이블에 PK로 인하여 INDEX가 생성되어 있으므로 조회시 성능이 향상된다.조회는 다음과 같이 수행하면 된다.123456SELECT ... FROM 장비 A, 속성 B WHERE A.장비코드 = B.장비코드 AND ( (B.속성코드 = '1' AND B.속성값 = '1') OR (B.속성코드 = '2' AND B.속성값 = '2') OR (B.속성코드 = '3' AND B.속성값 = '3') ) 위와 같이 속성1, 2, 3 뿐만 아니라 이력 같은 데이터를 함께 보관하면서장기재고 1개월 수량,금액 , 2개월 수량,금액 , 3개월 수량,금액 과 같은 형식의 컬럼이 있는경우재고기간 별 수량,금액 을 별도 테이블로 분리하는 것이 유리하다. 3절 반정규화와 성능 반정규화란 ? 성능향상, 개발, 운영의 편리를 위하여 데이터 중복을 각오하고 테이블을 통합하는 것을 의미한다.단순히 JOIN이 귀찮아서 컬럼들을 통합하다가는 데이터의 무결성을 깨트리게 된다. 3.1 반정규화 적용방법 반정규화 대상조사 자주 사용되는 table에 range-scan을 하는 경우 대량의 데이터가 있는 table에 range-scan을 하는 경우 통계성 프로세스에서 통계정보를 필요로 할때 -&gt; 별도의 통계테이블 생성 (반정규화) 지나치게 많은 JOIN으로 조회 작업이 기술적으로 어려워 질때 대안 검토 (반정규화가 아닌 다른 방법들) 지나치게 많은 JOIN -&gt; View 생성 대량의 데이터 처리, 부분처리가 유리한 경우 -&gt; 클러스터링 적용 또는 INDEX 조정 (단 DML이 적고 조회 위주의 테이블에만 효과적) 대량의 데이터를 PK 성격에 따라 분리가 가능한 경우라면 -&gt; 파티셔닝 기법 적용해서 물리적으로 분리 Application 로직을 변경하여 성능 개선 반정규화 적용 테이블 반정규화 속성 반정규화 관계 반정규화 ###3.2 반정규화 기법 테이블 반정규화 테이블 병합 : 1:1 , 1:M , 슈퍼/서브타입 관계의 테이블들을 병합하여 성능향상 테이블 분할 수직분할 : 컬럼단위로 테이블을 1:1로 분리하여 트랜잭션을 분산 (트랜잭션의 유형이 선행되어야 함) 수평분할 : row 단위로 테이블을 분리하여 트랜잭션을 분산 테이블 추가 중복테이블 추가 : 원격 등의 환경에서 서버가 다른 경우 동일한 테이블 중복생성 통계테이블 추가 : 통계값을 미리 계산해 둠 이력테이블 추가 : 마스터 테이블에 존재하는 레코드를 중복으로 이력테이블에 저장 부분테이블 추가 : 자주 이용하는 집중화된 칼럼들을 모아놓은 별도 테이블 생성 컬럼 반정규화 중복칼럼 추가 : JOIN을 줄이기 위함 파생칼럼 추가 : 미리 계산하여 저장 이력테이블 칼럼추가 : 이력테이블은 대용량이므로 처리속도가 느림. 그 중 자주 사용되는 컬럼을 추가 (최근값, 시작, 종료일자…) PK에 의한 칼럼추가 : 복합의미 단일PK의 경우, 그 중 특정 값만 자주 사용한다면 일반속성으로 추가 응용시스템 오작동을 위한 칼럼추가 : 잘못 처리되었을 경우를 대비한 백업용 칼럼 관계 반정규화 중복관계 추가 : 여러 경로를 거쳐야 하는 JOIN을 줄이고자 관계추가 반정규화가 더빠른 사례 1 : 이력테이블의 최근값이 필요한 경우 고객 Table : 고객번호(PK), 고객명 전화번호 Table : (고객번호(FK), 순번) (PK) , 전화번호 메일주소 Table : (고객번호(FK), 순번) (PK) , 메일주소 고객의 전화번호, 메일주소의 변경이력까지 같이 관리해야 할 경우 위와 같이 전화번호, 메일주소를 별도의 Table로 관리하여야 한다.이 경우 특정 고객의 가장 최근 전화번호와 메일주소를 알고 싶다면 아래와 같이 SQL문을 작성해야 한다. 123456789101112SELECT A.고객명, D.전화번호, G.메일주소 FROM 고객 A, (SELECT B.고객번호 B.전화번호 FROM 전화번호 B, (SELECT MAX(순번) FROM 전화번호 WHERE 고객번호 = :custNo) C WHERE B.고객번호 = C.고객번호) D, (SELECT E.고객번호 E.메일주소 FROM 메일주소 E, (SELECT MAX(순번) FROM 메일주소 WHERE 고객번호 = :custNo) F WHERE E.고객번호 = F.고객번호) G, WHERE A.고객번호 = D.고객번호 AND A.고객번호 = G.고객번호 고객 Table에 최근전화번호, 최근메일주소 칼럼을 추가하여 관리할 경우에는 SQL문을 더 쉽게 작성이 가능하다. 123SELECT 고객명, 최근전화번호, 최근메일주소 FROM 고객 WHERE 고객번호 = :custNo 반정규화가 더빠른 사례 2 : 원격서버와 JOIN할 경우 서버 A 부서 Table : 부서코드(PK), 부서명 접수 Table : (접수번호, 부서코드(FK))(PK), … 서버 B 연계 Table : (연계번호, (접수번호, 부서코드)(FK))(PK), 연계상태, 연계일자, … 특정 일자 사이의 부서명에 따른 연계상태를 알고 싶은 경우 아래와 같이 SQL을 작성해야 한다. 12345SELECT A.부서명, C.연계상태 FROM 부서 A, 접수 B, 연계 C WHERE A.부서코드 = B.부서코드 AND B.부서코드 = C.부서코드 AND B.접수번호 = C.접수번호 -- 서버A와 서버B의 원격 JOIN이 발생 AND C.연계일자 BETWEEN :startdate AND :enddate 원격 JOIN이 일어나서 성능이 저하 될수 있다.부서명 칼럼을 연계 Table에 중복생성하면 원격JOIN을 없앨수 있다. 123SELECT 부서명, 연계상태 FROM 연계 WHERE 연계일자 BETWEEN :startdate AND :enddate 하지만, 반정규화를 할 경우 데이터 입력, 수정, 삭제시 성능이 저하 된다는 점을 명심해야 한다. 4절 대량 데이터에 따른 성능4.1 칼럼 수가 많은 경우 많은 DISK I/O 및 buffer miss를 발생시킨다. : 레코드 크기가 거져서 블록 당 적제된 레코드 수가 줄어든다. 200개가 넘는 컬럼의 데이터를 한번에 다 조회할 일이 과연 얼마나 될까 ? 화면에 다 표현은 가능한가 ? 테이블을 분리시키는 방법이 있다.도서관에서 관리하는 아래와 같은 table을 살펴보자. 도서정보 Table : 도서번호(PK), 위치, 수량, 책정보관련 칼럼 10여개, 전자출판관련 칼럼 10여개, 대체제품관련 칼럼 10여개, … 위의 경우 전자출판관련 정보나 대체제품관련 정보는 자주 이용되지 않는 항목이라면 별도의 table로 분리하는게 효과적이다. 도서정보 Table : 도서번호(PK), 위치, 수량, 책정보관련 칼럼 10여개, … 전자출판 Table : 도서번호(FK, PK), 전자출판관련 칼럼 10여개 대체제품 Table : 도서번호(FK, PK), 대체제품관련 칼럼 10여개 4.2 테이블에 데이터가 많은 경우 파티션(partition)을 적용하여 레코드를 분리하면 된다. 파티션 종류 Range Partition : PK값의 범위별로 분리 (ex. 핸드폰요금 Table의 경우 요금일자를 범위로 하여 매 달마다 파티션 분리) List Partition : PK의 특정값별로 분리 (ex. 핸드폰대리점 Table의 경우 사업소의 위치지역 별로 파티션 분리) Hash Partition : PK의 해쉬값으로 분리 (범위 검색이 안되며, 데이터 보관주기를 통한 삭제 등의 관리가 어렵다.) 4.3 테이블의 수평/수직 분할 절차 데이터 모델링 완성 데이터베이스 용량산정 어느 테이블에 데이터가 대용량화 되는지 분석 대량 데이터가 처리되는 테이블의 트랜잭션 처리 패턴 분석 대용량화 테이블에 컬럼수가 많은가 ? 대용량화 테이블에 레코드수가 많은가 ? 컬럼 단위 집중화, 로우 단위 집중화를 분석하여 테이블 분리 검토 트랜잭션에서 많은 컬럼들을 항상 다 사용하는가 ? 테이블 분리가 가능한가 ? 트랜잭션에서 특정 범위 단위로 작업을 많이 하는가 ? 해당 범위별로 파티셔닝이 가능한가 ? 5절 데이터베이스 구조와 성능5.1 슈퍼/서브타입 데이터 모델링 공통부분을 슈퍼타입으로 모델링하고 이를 상속받아서 차이가 있는 속성별로 별도의 서브엔터티로 구분 논리적 데이터 모델링, 분석단계에서 사용됨 물리적으로는 3가지 형태로 구현함 ( One to One Type (1:1) , Plus Type (슈퍼+서브), Single Type (All in One) ) 트랜잭션의 유형을 보고 각각의 형태로 구현해야 한다. 1. 개별로 발생하는 트랜잭션에는 개별로 구현하는게 유리 (1:1)부동산거래 관리 어플리케이션에서 계약 내역에 이해관계자들(매수인,매도인,중개인)이 표시가 되고 상세를 눌렀을 경우 해당 인물에 대한 상세정보가 나오는 경우라면 이해관계자들을 별도의 테이블로 관리하는 것이 좋습니다. 계약 Table : 계약번호(PK), … , 중개인번호(FK), 매도인번호(FK), 매수인번호(FK) 이해관계자 Table : 이해관계자번호(FK) , 역할, … 2. 슈파타입+서브타입에 대해 발생되는 트랜잭션에 대해서는 슈퍼타입+서브타입으로 구분위 예제에서 중개인이 10만명, 매수인이 500만명, 매도인이 500만명인 경우 (즉, 이해관계자 Table은 1010만건)중개인에 대한 처리가 필요한 경우 최대10만건의 데이터가 필요한데 최대1010만건을 읽을 경우도 발생할 수 있다.이럴때는 슈퍼/서브타입으로 분리하는 것이 좋다. 계약 Table : 계약반호(PK), … 이해관계자 Table : 계약번호(PK), 중개인번호(FK), 매도인번호(FK), 매수인번호(FK) 중개인 Table : 중개인번호(PK), … 매도인 Table : 매도인번호(PK), … 매수인 Table : 매수인번호(PK), … 3. 전체를 하나로 묶어서 트랜잭션이 발생하는 경우항상 계약관련 사항을 조회하는데, 각 이해관계자들의 정보까지 동시에 화면에 출력이 되는 경우라면 하나의 테이블로 관리하는게 유리하다. 계약 Table : 계약번호(PK), … , 중개인 정보들, 매도인 정보들), 매수인 정보들 5.2 INDEX 특성을 고려한 PK/FK 설정 PK는 Unique Index를 자동으로 생성한다. 이하 생략 (자세한 내용은 뒤에 나올 Index 부분을 참조) FK도 Index를 생성한다. FK가 없어도 WHERE 절에서 조건을 적어주는 것으로 SQL 작성이 가능하지만, Full Table Scan이 될 수 있다. 가능하면 일단 FK를 생성하는 것을 기본 정책으로하고, 트랜잭션을 분석하여 거의 활용되지 않을때는 지우는 것이 적절한 방법이다. 6절 분산 데이터베이스와 성능6.1 분산 데이터베이스의 투명성(transparency) : 6가지 조건을 만족해야 한다. 분할 투명성 (단편화) : 하나의 논리적인 relation이 여러 단편으로 분할되어 각 단편의 사본이 여러 site에 저장 위치 투명성 : 위치정보는 system catalog에 유지되어야 하며, 사용자가 데이터 사용시는 명시할 필요가 없어야 함 지역사상 투명성 : 지역DBMS와 물리적 DB 사이의 Mapping 보장. 지역시스템과 무관한 이름 사용 가능 중복 투명성 : DB 객체가 여러 site에 중복되어 있는지 알 필요가 없음 장애 투명성 : DBMS의 장애와 무관하게 Transaction 일관성 유지 병행 투명성 : 다수 Transaction 수행시 일관성 유지, 분산 2단계 Locking을 이용하여 구현 6.2 장단점 장점 신뢰성, 가용성 빠른 응답 속도와 통신비용 절감 각 지역 사용자의 요구 수용 증대 지역 자치성, 점증적 시스템 용량 확장 단점 소프트웨어 개발 비용 처리 비용 설계, 관리의 복잡성과 비용 불규칙한 응답속도 통제가 어려움 6.3 적용 기법1. 테이블 분산테이블을 위치별로 분산 (ex. 자재품목은 본사, 생산제품은 지사) 2. 테이블 분할(fragmentation) 분산 수평분할 : 지사별로 각각 다른 PK를 가진 레코드들을 저장. 통합처리시 수행속도가 느려짐 수직분할 : 사이트별로 동일한 PK를 가진 레코드를 저장하나 컬럼을 분리해서 저장 (ex. 본사에는 단가를 저장, 각 지사에는 지사별 재고량을 저장) 3. 테이블 복제(replication) 분산동일한 테이블을 여러 곳에서 동시에 생성하여 관리 부분복제(segment replication) : 통합본은 본사에 있고, 각 지사별로 수평분할 형태. 데이터 입력은 지사에서 하고, 본사에서 지사 데이터를 이용하여 통합 광역복제 (broadcast replication) : 본사의 데이터를 지사에서도 동일하게 가지고 있음. 본사를 통해서 입력을하고, 주기별로 해당 데이터를 지사로 복사 4. 테이블 요약(summarization) 분산 분석요약 (rollup replication) : 지사별로 존재하는 요약정보를 본사에서 통합하여 지사로 전송 (모든 지사가 동일 정보) 통합요약 (consolidation replication) : 지사별로 존재하는 다른 정보를 본사에서 통합하여 관리 (모든 지사가 다른 정보) 6.4 분산 데이터베이스를 통한 성능 향상 사례인사팀DB에만 직원 정보가 있는 경우 업무DB에서는 항상 인사팀DB를 JOIN해야함.직원 정보를 각 업무DB로 복사를 하면 성능이 향상 됨 성능이 중요한 사이트에 적용 master 성격의 table을 분산하면 성능이 향상됨 실시간 동기화가 요구되지 않으면 유리. 특정시간에 batch로 동기화 특정 서버에 부하가 집중될떄 분산시킬수 있음 백업사이트를 구성할 때 분산기능을 적용할 수 있음","categories":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/categories/Database/"},{"name":"SQLP","slug":"Database/SQLP","permalink":"http://DevStarSJ.github.io/categories/Database/SQLP/"}],"tags":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/tags/Database/"},{"name":"Oracle","slug":"Oracle","permalink":"http://DevStarSJ.github.io/tags/Oracle/"},{"name":"SQLP","slug":"SQLP","permalink":"http://DevStarSJ.github.io/tags/SQLP/"}]},{"title":"SQLP 1-1 데이터 모델링","slug":"01.01.modeling","date":"2016-01-19T15:00:00.000Z","updated":"2017-04-23T23:57:23.000Z","comments":true,"path":"2016/01/20/01.01.modeling/","link":"","permalink":"http://DevStarSJ.github.io/2016/01/20/01.01.modeling/","excerpt":"","text":"1과목 데이터 모델링의 이해 10문제 외우기 보다는 반복적으로 읽어서 전반적인 내용을 이해하는 수준에서 마무리 하는것을 목표로 잡아야 겠습니다. 제 1장 데이터 모델링의 이해1절 데이터 모델의 이해모델링의 특징 추상화 : 일정한 형식에 맞추어 표현 단순화 : 약속된 규약에 의해 제한 명확화 : 애매모호함을 제거 정확하게 기술 모델링의 3가지 관점 데이터 관점 (what) : 업무가 어떤 데이터와 관려이 있는지, 데이터간의 관계가 무엇인지 프로세스 관점 (how) : 업무가 실제하고 있는 일이 무엇인지, 무엇을 해야 하는지 데이터와 프로세스의 상관관점 (interaction) : 업무가 처리됨에 따라 데이터는 어떻게 영향을 받고 있는지 데이터 모델링이란… 정보시스템을 구축하기 위한 데이터관점의 업무 분석 기법 현실세계의 데이터(what)에 대해 약속된 표기법에 의해 표현하는 과정 데이터베이스를 구축하기 위한 분석/설계의 과정 데이터 모델의 중요성 파급효과(leverage) : 데이터 모델이 잘못되어서 나중에 변경될때에는 전체 시스템에 큰 변경 사항이 발생함 복잡한 정보 요구사항의 간결한 표현(conciseness) : 요구사항을 정확하고 간결하게 표현. 요구사항 파악시 데이터 모델을 리뷰하는 것이 더 빠름. 데이터 품질(data quality) : 기간이 오래되고 쌓인 데이터를 활용하려면 품질이 중요. (정확성, 중복데이터 등…). 품질이 안좋으면 활용하지 못한 쓰레기가 될수 있음 데이터 모델링의 유의점 중복(duplication) : 여러 곳에 같은 정보 저장하지 않도록 비유연성(inflexibility) : 데이터 정의와 사용 프로세스를 분리. 각각의 작은 변화가 서로에게 영향을 미치지 않도록 비일관성(inconsistency) : 서로 영향을 미치는 데이터간 상호 연관 관계에 대한 명확한 정의가 필요 (ex. 납부이력과 신용상태) 데이터 모델링의 3단계 진행 (추상화 수준에 따라) 개념적 데이터 모델(conceptual) 추상화 수준이 높고 업무중신적이고 포괄적인 수준의 모델링 진행. 전사적 데이터 모델링, EA수립시 많이 이용 엔티티 - 관계 다이어그램 생성 전사적 데이터 모델링 (enterprise) 중요한 2가지 기능 사용자와 시스템 개발자가 데이터 요구 사항을 발견하는 것을 지원 현 시스템이 어떻게 변형되어야 하는지를 이해하는데 유용 논리적 데이터 모델 (logical) 시스템으로 구축하고자 하는 업무에 대한 Key, 속성, 관계 등을 정확하게 표현, 재사용성이 높음 식별자 확정, 정규화, M:M 관계 해소, 참조 무결성 규칙 정의 등 데이터베이스 설계 프로세스의 input으로 비즈니스 정보의 논리적인 구조와 규칙을 명확하게 표현하는 기법 또는 과정 물리적 데이터 모델 (physical) 실제로 데이터베이스에 이식할 수 있도록 성능, 저장 등 무리적인 성격을 고려하여 설계 물리적 스키마 : 데이터가 물리적으로 컴퓨터에 어떻게 저장될 것인가에 대한 정의 테이블, 칼럼 등의 저장구조와 저장 장치, 접근 방법 등 데이터 독립성의 필요성 &lt;-&gt; 데이터 종속성 유지보수 비용증가 데이터 중복성 증가 데이터복잡도 증가 요구사항 대응 저하 데이터 독립성 확보시 효과 각 View의 독립성을 유지하고 계층별 View에 영향을 주지 않고 변경 가능 단계별 Schema에 따라 DDL과 DML가 다름을 제공 데이터베이스 3단계 구조 외부단계 (External Schema) : 사용자 관점 DB의 개개 user나 application이 접근하는 DB 정의 개념적단계 (Conceptual Schema) : 통합 관점 사용자가 처리하는 데이터 유형의 공통적인 사항을 처리하는 통합된 뷰를 스키마 구조로 디자인한 형태 모든 사용자 관점을 통합한 조직 전체의 DB 모든 user와 application이 필요로하는 데이터를 통합한 조직 전체의 DB를 기술 DB에 저장되는 데이터와 그들간의 관계를 표현하는 스키마 내부적단계 (Internal Schema) : 물리적 저장구조 논리적, 물리직 독립성 독립성 내용 특징 논리적 독립성 - 개념 스키마가 변경되어도 외부 스키마에는 영향 없음 - 논리적 구조가 변경되어도 Application에는 영향 없음 - 사용자 특성에 맞는 변경가능 - 통합 구조 변경가능 물리적 독립성 - 내부스키마가 변경되어도 외부/개념 스키마에 영향 없음 - 저장장치의 구조변경은 Application과 개념스키마에 영향 없음 - 물리구조, 개념구조를 서로 영향없이 변경가능 사상 (Mapping) 논리적 mapping (외부적 &lt;-&gt; 개념적) : 외부적 뷰와 개념적 뷰의 상호 관련성 정의 사용자가 접근하는 뷰의 필드는 다른 타입을 가질 수 있으나, 개념적 뷰의 필드 타입은 변화가 없음 물리적 mapping (개념적 &lt;-&gt; 내부적) : 개념적 뷰와 데이터베이스의 상호 관련성 정의 데이터베이스 구조가 바뀔 경우 물리적 mapping이 바뀌어야 함. 개념적 스키마는 안바뀌도록 해야 함 데이터 모델링의 3가지 개념 업무가 관여하는 어떤 것 : things (table) 어떤 것이 가지는 성격 : attributes (column) 업무가 관여하는 어떤 것 간의 관계 : relationships 좋은 데이터 모델의 요소 완전성 (completeness) : 업무에 필요한 모든 데이터가 데이터 모델에 정의되어 있어야 함 중복배제 (non-redundancy) : 동일한 사실은 반드시 한 번만 기록 (ex. 나이, 생년월일 은 중복) 업무규칙 (business rules) : 수많은 업무규칙을 데이터 모델에 표현 데이터 재사용 (data reusability) : 데이터 통합성, 독립성을 충분히 고려 의사소통 (communication) : 데이터 모델은 업무를 데이터 관점에서 분석하고 설계하여 나오는 최종 산출물. 모든 업무 규칙을 엔티티, 서브타입, 속성, 관계 등의 형태로 최대한 자세하게 표현. 업무관련자들은 이를 업무 규칙과 동일하게 받아들이고 정보시스템 활용 통합성 (integration) : 각 부서별 따로 존재했던 데이터 중 중복적인 성격들(마스터 테이블)을 통합 관리 2절 엔터티 (entity)2.1 엔터티의 특성 업무에 필요하고 유용한 정보를 저장하고 관리하기 위한 집합적인 것(thing) 반드시 필요한 정보 unique하게 식별이 가능 반드시 속성(attribute)를 가져야 함 업무 프로세스에서 사용되어야 함 최소 한 개 이상의 다른 엔터티와의 관계 필수 영속적으로 존재하는 인스턴스(instance)의 집합 2.2 엔터티의 분류 유무형에 따른 분류 유형엔터티 : 사원, 물품 개념엔터티 : 부서, 보험상품 사건엔터티 : 주문, 청구 발생시점에 따른 분류 기본 엔터티 (fundamental entity, key entity) : 독립적 생성 가능, 다른 엔터티의 주어 역할 (ex. 사원 부서, 고객, 상품) 중심 엔터티 (main entity) : 기본 엔터티로 부터 발생하고, 업무의 중심 역할 (ex. 계약, 주문, 매출) 행위 엔터티 (active entity) : 2개 이상의 부모로 부터 발생하고 자주 바뀌거나 데이터량이 증가되는 성격을 가짐 (ex. 주문목록, 사원변경이력) 2.3 인스턴스 (instance) 엔터티로부터 생성된 하나의 개체 entity가 class하면 instance 는 object 3절 속성 (attribute)3.1 속성의 특징 의미상 더 이상 분리되지 않음 : 2개 이상의 값을 가질 경우 분리해야 함 엔터티를 설명하고 인스턴스의 구성요소 정규화 규칙에 의거해 주식별자에 함수적 종속성을 가져야 함 업무상 필요로 해야한다. 3.2 속성의 분류 특성에 의한 분류 기본속성 (basic attribute) : 업무로부터 추출한 모든 속성 설계속성 (designed attribute) : 업무를 규칙화하기 위해 새로 만들거나 변형한 속성 (ex. 일련번호) 파생속성 (derived attribute) : 다른 속성에 영향을 받는 속성. 주로 계산 값들. 되도록이면 적게 정의하는게 좋음 구성방식에 따른 분류 PK (primary key), FK (foreign key), 일반속성 등… 3.3 도메인 (domain) 속성이 가질 수 있는 값의 범위 4절 관계 (relationship) 인스턴스 사이의 연관성 4.1 관계의 분류 존재에 의한 관계 : 부서 (1) : 사원 (M) 행위에 의한 관계 : 고객 (1) : 주문 (M) 4.2 관계 차수(degree, cardinality) 1 : 1 관계 : 사원 - 병역사항 1 : M 관계 : 부서 (1) : 사원 (M) M : M 관계 : 주문 (M) : 제품 (M) 5절 식별자 (identifiers) entity 내에서 instance의 구분자 5.1 식별자의 특징 유일성 : 주식별자에 의해 엔터티 내의 모든 인스턴스가 유일하게 부분 최소성 : 주식별자를 구성하는 속성의 수는 유일성을 만족하는 최소의 수 불변성 : 자주 변하지 않는 값이어야 함 존재성 : 반드시 값이 있어야함 (NOT NULL) 5.2 주식별자 도출기준 업무에서 자주 이용되는 속성 : PK로 등록 = index 생성 명칭, 내역등과 같은 이름은 피해야 함 : 다른 적당한 구분자가 존재하지 않으면 일변번호 같은 것을 새로 생성 속성수가 많아지지 않도록 함 : WHERE 조건이 복잡해짐. 새로운 인조식별자를 생성하는게 편함 5.3 외부식별자 (foreign identifier)와의 관계5.3.1 식별관계, 비식별관계 식별자관계 : 부모의 식별자를 자식의 식별자로 사용 FK가 NOT NULL이어야 함 종속관계 : 1 : 1 또는 1 : M 상속받은 주식별자속성을 타 엔터티에 이전 필요 비식별관계 : 부모없는 자식이 생성될 수 있음 자식의 일반 속성에 생성 됨 : NULL 일 수 있음 부모와 자식의 생명주기(life cycle)을 달리할 경우 유용함 자식 엔터티의 주 식별자로 사용되어도 되지만, 따로 생성하는게 더 유리하다고 판단 될 경우 5.4.2 관계에 대한 주의사항 식별관계 / 비식별관계 결정 어떻게 관계를 짓는냐에 따라 속성의 정의 및 SQL 작성시에 달라지므로 SQL 전략에 맞게 결정해야 한다. 식별관계로만 설정할 경우 문제점 PK 속성의 수가 데이터 모델 흐름에 따라 계속 증가하게 된다. : 자식의 PK 속성수는 부모의 PK 속성수 + n JOIN 할때 적어줘야 할 WHERE절의 조건 수가 늘어난다. 비식별관계로만 설정할 경우 문제점 자식 엔터티의 데이터를 조회할때 부모 엔터티에 WHERE 조건을 추가해 주어야 할 경우가 발생한다.","categories":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/categories/Database/"},{"name":"SQLP","slug":"Database/SQLP","permalink":"http://DevStarSJ.github.io/categories/Database/SQLP/"}],"tags":[{"name":"Database","slug":"Database","permalink":"http://DevStarSJ.github.io/tags/Database/"},{"name":"Oracle","slug":"Oracle","permalink":"http://DevStarSJ.github.io/tags/Oracle/"},{"name":"SQLP","slug":"SQLP","permalink":"http://DevStarSJ.github.io/tags/SQLP/"}]},{"title":"선대인의 빅픽처 저성장 시대의 생존 경제학","slug":"BigPicture","date":"2015-12-26T15:00:00.000Z","updated":"2017-04-30T03:38:42.000Z","comments":true,"path":"2015/12/27/BigPicture/","link":"","permalink":"http://DevStarSJ.github.io/2015/12/27/BigPicture/","excerpt":"","text":"선대인의 빅픽처 저성장 시대의 생존 경제학 웅진지식하우스 선대인 책소개 Link : http://book.naver.com/bookdb/book_detail.nhn?bid=9770144 안녕하세요.이번에 소개 드릴 책은 선대인의 빅픽처 저성장 시대의 생존 경제학입니다.제목 그대로 요즘같은 저성장 시대에서 개인이 어떤 관점을 가지고 경제를 바라 보아야 할 것인가에 대한 소개와어떻게 투자를 해야 할 것인지에 대한 거시적인 안목을 가지는 방법 및 투자 방법을 한가지 소개해 주고 있습니다. BIG PICTURE세계 시장에 대해서 큰 시각으로 바로 보라는 의미와 주목해야 할 10가지 키워드의 머릿글자라는 2가지 의미로 저자는 소개하였습니다. B : Bio-health Care I : Interest Rate (금리) G : Green (녹색산업) P : Petroleum (석유) I : India (인도) C : China (중국) T : Tech Companies (기술기업) U : USA (미국) R : Risk (리스크) E : Exchange Rate (환율) 책 내용이 크게 어렵다던지, 무조건 이렇게 해라는 식은 아니어서 별 다른 거부감 없이 잘 읽혔습니다.저금리 시대에 은행에 돈을 넣어두자니 아깝고, 너도 나도 부동산 하고 있으니 부동산에 투자하자니 불안하고…등 고민이 많으신 분들은 꼭 읽어보시길 추천 합니다. 예전같이 금리가 15%씩 하는 이런 시절로 다시 돌아가기는 힘들기 때문에 그 시절의 경제적 논리로 투자를 하면 안된다는 것을 설명해 주고 있습니다. 현 시대의 투자법에 대해서 잘 정리가 되어 있냐 ? 그렇지도 않습니다. 왜냐하면 인류가 아직 이런 저 금리시대에 살아본 적이 없기 때문입니다. 지금의 경제 상황은 인류가 한번도 경험해보지 못한 상황이니 만큼 어느 누구하나 이게 정답이다 라고 할 수도 없는 상황입니다. 1장에서는 국내 증권사는 철저하게 개인의 이익에는 관심이 전혀 없다는 내용과, 달러 - 유가 - 금값 의 상관관계, 세계 4대 경제권과 우리나라 경제의 관계에 대해서 거시적인 관점에서 소개를 해주고 있습니다. P.35에 아래와 같은 내용이 나오는데 참 공감이 갑니다. 가이드가 정박 중인 멋진 보트들을 가리키며 말했다.“보세요 저 배들이 바로 은행가와 주식중개인들의 요트랍니다.”그러자 순진한 방문객이 물었다.“그러면 고객들의 요트는 어디에 있나요?” 1장에서는 세계 경제에 대한 이야기 였다면, 2장에서는 한국 경제에 대해서 지금 현재 상황과 앞으로 어떻게 될 것이라는 작가의 의견이 서술되어 있습니다. 3장에서는 앞서 얘기한 10가지 키워드에 대해서 설명을 해주고 있습니다.역시 중국 경제에 대해서 주목을 해야 한다는 것에 대해서 강조를 하고 있습니다.중국이 현재 경제 불황이라고는 하지만, 그래도 다른 나라보다는 훨씬 높은 7% 대의 성장률을 보이고 있으며,계속해서 투자가 일어나며 임금은 올라가고 일자리도 늘어나고 있다는 것에 대해서 주목을 해야 한다는 군요.나머지 키워드에 대해서도 설명을 해주고 있는데, 서평에서는 생략하도록 하겠습니다. 다음에는 경제 흐름을 읽는 방법들에 대한 소개하고 있습니다.비교적 위험 부담이 적고 회사일을 하면서도 크게 신경을 쓰지 않을 수 있는 투자 방법중 하나인 성장형 우량주 투자방법에 대해서 소개를 해주었습니다.그리고 지난 4년간 그 방법으로 투자를 하여 수익을 냈다는 소개도 같이 해주고 있습니다. 뒷 부분에는 참조할 만한 사이트 4곳의 소개와 같이 읽으면 좋은 경제학 관련 책들에 대한 소개가 있었습니다.","categories":[{"name":"Book","slug":"Book","permalink":"http://DevStarSJ.github.io/categories/Book/"},{"name":"Review","slug":"Book/Review","permalink":"http://DevStarSJ.github.io/categories/Book/Review/"}],"tags":[{"name":"Book","slug":"Book","permalink":"http://DevStarSJ.github.io/tags/Book/"},{"name":"Review","slug":"Review","permalink":"http://DevStarSJ.github.io/tags/Review/"}]},{"title":"훌륭한 프로그래머가 되는 법","slug":"hanbit.BBP","date":"2015-12-23T15:00:00.000Z","updated":"2017-04-30T03:47:19.000Z","comments":true,"path":"2015/12/24/hanbit.BBP/","link":"","permalink":"http://DevStarSJ.github.io/2015/12/24/hanbit.BBP/","excerpt":"","text":"훌륭한 프로그래머가 되는 법 : 프로젝트와 팀을 성공으로 이끄는 선배 개발자의 노하우 한빛미디어 옮긴이 : 최원재, 강전희, 안재덕, 남윤화 책소개 Link : http://www.hanbit.co.kr/book/look.html?isbn=978-89-6848-230-4 원서 : Becoming a Better Programmer - Pete Goodliffe - O’Reilly Media, Inc. : http://shop.oreilly.com/product/0636920033929.do 안녕하세요. 이번에 소개해 드릴 책은 최근에 나온 화제의 도서 훌륭한 프로그래머가 되는 법 : 프로젝트와 팀을 성공으로 이끄는 선배 개발자의 노하우 입니다.프로그래머로 사는 법 처럼 부담없이 읽을 수 있는 에세이라고 생각을 했는데, 엄청난 착각이었습니다.팟캐스트 나는 프로그래머다: 뉴욕, 서울, 도쿄 개발자의 촌철살인 IT 이야기 처럼 재미있는 책도 아니었구요. 한마디로 표현하자면 율법서 같다고나 할까요 ?생각보다 많이 무거운 내용이었습니다. 읽는 내내 엄청 아픕니다. 가슴을 엄청 찔러대더군요.가끔씩 나름 개그라고 쓴 내용도 있고, 그림도 있긴 했습니다만… 전체적인 분위기가 너무 무겁다 보니 그것 또한 웃음으로 다가오기 보다는 좀 심각한 표정으로 보게되더군요. 이 책의 내용을 짧게 요약하자면… 요약이 안됩니다.그럼 책 내용중 중요한 부분만 정리하자면… 정리가 안됩니다.어디하나 버릴 내용이 없습니다. 433페이지까지 모든 페이지가 다 중요합니다.그 중 특히 이 부분이 더 중요하다 싶은데를 꼽을 수도 없습니다. 다~ 중요한 내용입니다.말그대로 율법서 입니다. you.write(code); 연습을 통해 완벽해진다. 개인적인 일로 받아들이기 일 끝내기 사람의 일부록. 국내 개발자 이야기 이렇게 5개의 부분을 39개의 챕터로 나눠놨습니다. Part 1 you.write(code);13개의 챕터로 구성되어 있으며, 주로 코드 작성시 주의해야 할 사항에 대해서 설명되어 있습니다.각각의 테스트 단계에 대한 설명 및 오브젝트간의 복잡도(complexity)에 관한 설명도 같이 있습니다.일반적인 프로젝트의 형태와 처음부터 디자인을 잘잡고 시작한 프로젝트에 대한 비교를 이야기 형식으로 서술한 부분의 이야기가 참 재밌으면서도, 안타까우면서도, 부러우면서도, 그랬습니다. ;; Part 2 연습을 통해 완벽해진다.코딩시의 규칙들, 코드 재사용에 대한 이야기, 버전 관리 및 배포(release)에 관한 이야기들이 있습니다.개인의 개발규칙보다는 회사에서 팀으로 작업할때 필요한 이야기들입니다. Part 3 개인적인 일로 받아들이기이 파트에서는 개발자로서의 삶, 자세에 대한 이야기가 주를 이룹니다.개발자로서 배움을 지속해야 한다는 이야기 및 개발자의 윤리, 언어 및 자세에 대한 이야기를 하고 있습니다. Part 4 일 끝내기이 파트도 개인적인 이야기 보다는 회사내에서 팀으로서의 작업에 대한 이야기 입니다. (파트 2의 후속 파타라는 느낌이 강합니다.)개발이라는 과정이 끝이 명확한 작업이 아닌 만큼, 어떻게 끝을 규정할 것인가 ? 누군가가 일의 진행 사항을 물었을때 어떻게 대답해야 하는가 등에 대한 이야기가 있습니다. Part 5 사람의 일프로그래머로서 개발에 대한 이야기 뿐 아니라 삶의 대한 이야기도 같이 있습니다. (파트 3의 후속이랄까요 ?)생각, 말하기, 태도 등에 대한 이야기를 포함해서 전반적인 삶, 생활에 대한 이야기가 있습니다. 부록 국내 개발자 이야기국내 개발자 4분께서 여러 가지 조언을 많이 해 주십니다.굉장히 현실적인 조언이 많이 있어서 큰 도움이 되었습니다.특히 프로그래머의 미래가 어둡다고 넋두리하는 것에 귀담아 듣지 말라고 하는 염재현님의 조언에 크게 공감이 되었습니다. ####총평 진짜 어느하나 버릴 주제가 없는 꼭 필요한 책입니다.가볍게 읽을 수 있는 책은 아니었습니다.이 책을 읽으면서 내가 많이 부족하구나, 내가 많이 건방졌구나 란 질책도 많이 느껴졌으며,반면 그래도 내가 완전 잘못된 방향으로 걸어온 것은 아니구나 라는 위안도 같이 받았습니다.앞으로도 지금처럼 노력하면서, 책을 보고 느꼈던 나의 부족한 점을 하나하나 고쳐가야 겠습니다.매일 기도하는 마음으로 책의 한 챕터씩 아니면 한 페이지씩이라도 읽으면서 이 책의 내용에 대해서 계속해서 되씹으면서 늘 옆에 두어야 할 책이라 여겨집니다.","categories":[{"name":"Book","slug":"Book","permalink":"http://DevStarSJ.github.io/categories/Book/"},{"name":"Review","slug":"Book/Review","permalink":"http://DevStarSJ.github.io/categories/Book/Review/"}],"tags":[{"name":"Book","slug":"Book","permalink":"http://DevStarSJ.github.io/tags/Book/"},{"name":"Review","slug":"Review","permalink":"http://DevStarSJ.github.io/tags/Review/"}]},{"title":"팟캐스트 나는 프로그래머다","slug":"hanbit.naProDa","date":"2015-11-21T15:00:00.000Z","updated":"2017-04-30T03:46:14.000Z","comments":true,"path":"2015/11/22/hanbit.naProDa/","link":"","permalink":"http://DevStarSJ.github.io/2015/11/22/hanbit.naProDa/","excerpt":"","text":"팟캐스트 나는 프로그래머다: 뉴욕, 서울, 도쿄 개발자의 촌철살인 IT 이야기 한빛미디어 임백준, 정도현, 김호광 지음 책소개 Link : http://www.hanbit.co.kr/book/look.html?isbn=978-89-6848-228-1 안녕하세요. 오늘 정말 재미있고 유익한 책 한권을 소개할께요.최근 본 개발자 관련 서적중에 가장 재미있는 책입니다.위에 제목에 나와 있듯 팟캐스트 나는 프로그래머다: 뉴욕, 서울, 도쿄 개발자의 촌철살인 IT 이야기 입니다.팟캐스트 방송으로 이미 너무나도 유명한 책이죠. 팟캐스트 소개저도 아직 제대로 들어보진 않았습니다.이런 방송이 있다고는 알고 있었지만요.그러다가 10월 말에 열린 나는 프로그래머다 컨퍼런스 관련 동영상들이 소개된 것을 통해서 들었는데 너무 재미있고, 개발자들의 입장에서 공감되는 이야기를 적나라게 해주는 것이 너무나도 시원시원 하였습니다. 나는 프로그래머다 Youtube 페이지 : https://www.youtube.com/channel/UCTaAL7nKLOEnRsTW9uujxSQ 위 Link에서 컨퍼런스 영상 및 팟캐스트 영상 모두 확인이 가능 합니다. 첫 인상겉표지가 귀여우면서도 세련되었습니다.캐릭터도 너무 귀엽구요. 개인적으로 데니스님 케릭이 가장 귀여워요. ㅎ저번에 질문에 몇 번 답해주었다고 스타벅스 쿠폰을 2개나 보내주셨는데, 잘 마셨다고 인사도 못드렸네용..개발자의 가려운 곳을 긁어주마! 라는 말이 너무나도 인상적이었구요.저런 말이야 누구나 다 할 수 있지.정말 그렇게 다 긁어줄까 ? 라고 의문을 느낄 수 있겠지만, 이미 나프다 컨퍼런스 영상을 본 후라서 정말 그럴꺼라는 확신이 들었습니다. 책 구성실제 팟캐스트 방송에서 얘기한 것을 책으로 옮겨둔 것입니다.물론 그 내용이 그대로 대본같이 들어있는 것은 아니겠죠.그리고 거기다가 방송에서는 미처 얘기하지 못한 작가님들의 설명글도 중간중간에 포함되어 있습니다.총 11개의 이야기로 구성되어 있구요.각각의 이야기마다 주제가 있습니다. 언어 : Java, Go, Scala 기술 : MS, MS Build, AWS, FinTech 삶 : MS MVP, 여자 개발자, 개발자영어, SI 이렇듯 모든 개발자라면 모두 관심있어할 만한 주제부터 해서 힘들어하시는 소외받으신 분들 이야기까지 개발자 분야의 꼭대기에서 바닥까지 모든 것을 다 다룬다고 해야 하나요 ? 1부 언어Java, Go, Scala 3가지 언어에 대한 내용으로 각각 방송을 진행한 이야기를 소개해 줍니다.모든 방송마다 관련 guest를 초대해서 같이 이야기를 나누는 형식으로 진행됩니다. Java 에서는 주로 자바의 미래가 어두운 점과 아쉬운 점에 대한 이야기가 주가 되구요.한국의 전자정부 프레임워크가 만들어지게 된 배경부터 한국에서의 Java 개발자들의 안타까운 현실에 대해서 물론 직접 격으신 분들도 많으시겠지만, 직접 겪어보지 않으신 분들도 어느 정도 공감할 수 있도록 적나라하게 이야기를 해줍니다. Go 언어에 대한 이야기에서는 현재 Google에서 활동하고 계시는 개발자분을 초대해서 이야기가 진행됩니다.Go 언어의 탄생 배경을 시작으로, ActiveX 이야기, Ruby에 대한 이야기등 개발자들이 관심 가질만한 주제에 대해서 이야기를 해줍니다. Scala에 대해서 안 들어보신 분들은 없겠지만, 어떤 언어인지 제대로 아시는 분들은 아마 많지 않을 듯 한데요.저도 그런 부류 중 하나이구요.함수형 언어 ? 이게 뭐지 ? 란 생각은 들어도 그게 뭔지에 대해서 제대로 찾아 보신분들도 많지 않으리라 봅니다.그나마 함수형 언어가 무엇인지에 대해서 감을 잡을 수 있도록 이야기를 해줍니다.Scala 언어의 탄생 배경부터해서 현재 스터디 활동 중이신 분들을 guest로 모셔서 이야기를 하고 있구요.스터디를 함께 하고싶으신 분들을 위한 안내까지 해줍니다.정말 앞으로는 함수형 언어가 대세가 될까요 ? 이 책에 따르면 그럴 수도 있겠단 생각이 드네요.제가 이 책을 읽고 간단히 이해한 함수형 언어라는 것은 모든 함수는 return값이 있어야 하며 call by reference로 인자를 전달하면 안됩니다. 함수 안에서 인자로 전달받은 값이 아닌 다른 자원에 대해서 수정을 하면 안됩니다. 즉 모든 제어를 함수의 입/출력을 통해서 해야합니다. 그러므로, Unit Test 작성이 용의하며, bug 발생 가능성도 줄어들며, bug가 발생하더라도 예측하기 쉽습니다. 2부 기술2부에서는 최신 기술들의 흐름에 대해서 알아 볼 수 있었습니다.MS의 신기술들, MS Azure, Amazon AWS 등 Cloud 활용시의 장단점을 비롯하여 FinTech의 범위와 국내 해외의 FinTech 현재 상황까지…기술적인 부분부터 해서 서비스단의 이야기까지 많은 부분에 대해서 간접적으로 나마 이해하는데 많은 도움이 되었습니다.그 동안 여러가지 컨퍼런스에서 직접 봐왔던 분들이 guest로 오셔서 이야기를 진행해주셨는데, 그 분들이 정말 대단한 분들이란 것을 느끼게 되었습니다. 3부 삶이 부분에서 정말 느낀게 많았습니다.MS MVP, 여자 개발자, 개발자 영어, SI 까지 여자 개발자 빼고 나머지 3가지 부분은 제가 관심을 가지고 있다던지, 아니면 직접 겪은 부분이라서 더 관심이 많이 가는 부분이었습니다.지금도 온라인으로 영어강좌를 신청해서 듣고 있는데, 영어 학습과 개발자의 삶에 대해서 직접 임작가님의 재밌는 실수담 부터 해서 영어에 대한 두려움을 없에주는 용기도 주었습니다.알게 모르게 일어나고 있는 여자 개발자에 대해서 한국 업체들에서 벌어지는 차별들에 대한 소개와, SI업체의 힘든 현실에 대한 부분도 알지 못했던 현실들이었구요. 총평이야기 하나하나에서 다루는 주제가 개발자들이 관심을 가질 수 있는 주제에 대해서 미리 겪어본 선배님들의 이야기를 들음으로써 나중에 그 분야에 대해서 학습을 할때 시행착오를 덜 겪을 수 있도록 큰 도움을 주는 책으로도 괜찮으리라 봅니다.물론 그냥 재미로 보기에도 좋은 책입니다. 너무너무 재미있구요.이 책을 보니깐 시간내서 팟캐스트도 한번 쭉~ 보고 싶다는 생각이 듭니다.책에는 11개의 이야기를 다루었지만, 팟캐스트는 쭉 진행중에 있죠.반드시 2권이 출간되었으면 좋겠습니다.이번 책은 한빛미디어에서 제공해주어서 좋은 기회에 좋은 책을 읽을 수 있었던것 같구요.2권이 출간되면 반드시 사서 보겠습니다. ㅎ좋은 책을 제공해주신 한빛미디어에 다시 한번 감사드립니다.","categories":[{"name":"Book","slug":"Book","permalink":"http://DevStarSJ.github.io/categories/Book/"},{"name":"Review","slug":"Book/Review","permalink":"http://DevStarSJ.github.io/categories/Book/Review/"}],"tags":[{"name":"Book","slug":"Book","permalink":"http://DevStarSJ.github.io/tags/Book/"},{"name":"Review","slug":"Review","permalink":"http://DevStarSJ.github.io/tags/Review/"}]},{"title":"Install Jenkins","slug":"Devops.Jenkins","date":"2015-11-09T15:00:00.000Z","updated":"2017-04-23T09:57:26.000Z","comments":true,"path":"2015/11/10/Devops.Jenkins/","link":"","permalink":"http://DevStarSJ.github.io/2015/11/10/Devops.Jenkins/","excerpt":"","text":"Install Jenkins1. Jenkins 란 ?Jenkins Server는 Open Source CI (Continuous Integration) 을 자동화해주는 Tool입니다. 대부분 다음과 같은 방식으로 Jenkins를 이용합니다. Repository (SVN, Git)에서 source code를 가져옵니다. 정해진 절차에 따라 build 및 unit test, integration test를 수행합니다. 수행 결과 이상이 있을 때 e-mail을 통해서 reporting해주는 역할까지 수행해 줍니다. 정상적으로 build 되었으며, 모든 test 결과에 이상이 없는 경우 배포 파일(setup, update)을 생성합니다. Jenkins 자체는 사용자가 입력한 command line 명령어들을 특정 조건에 맞게 또는 특정 시간이나 일정한 간격으로 수행해주는 역할을 해줍니다.build 및 test, deploy하는 역할 자체는 command line에서 수행가능한 형태로 사용자가 직접 입력해 놓으면 그 명령어를 수행해주는 역할을 할 뿐이지, Jenkins 자체에 build tool이 있다던지 그러진 않습니다. 2. 이번 Posting에서 다룰 내용 Jenkins download 및 설치 (Windows 기준) MSBuild plugin 설치 Jenkins item 설정 SVN Repository에서 source code 내려받기 VisualStudio Solution (.sln)을 command line에서 실행시키기 (MSBuild 이용) Jenkins item에서 build 후 다른 item 실행 3. Jenkins download 및 설치 Link : http://jenkins-ci.org 위 Link에서 우측에 있는 Windows를 눌러서 다운로드 받으면 됩니다.zip 파일이 다운로드 받아지는데 압축을 풀어서 셋업을 실행하면 설치가 끝납니다.바로 Jenkins 창이 실행됩니다. 기본적으로는 http://localhost:8080 로 접속이 가능합니다. (다른 PC에서 접속시에는 PC ip나 hostname 에 8080 포트로 접속을 하면 됩니다.) ###3. MSBuild plugin 설치 Visual Studio에서 작업한 solution 파일 (.sln)을 command line에서 build 하기 위해서는 MSBuild.exe를 실행해서 build 해야 합니다. MSBuild.exe는 Visual Studio 설치시 같이 설치가 됩니다.Jenkins에서 MSBuild를 사용하기 위해서는 별도의 plugin이 필요합니다. 먼저 Jenkins 화면에서 Jenkins 관리-&gt; 플러그인 관리 로 들어갑니다. internet에 연결된 환경이라면 설치가능 탭에서 바로 MSBuild를 선택해주시면 됩니다. offline 상태의 pc라면 https://updates.jenkins-ci.org/download/plugins로 들어가서 원하는 버전의 MSBuild plugin을 다운로드 받으시면 됩니다. 다운로드 받은 뒤 고급 탭을 눌러서 플러그인 올리기 에서 다운로드 받은 파일을 선택하면 됩니다. 그런 뒤 Jenkins를 재가동 하면 됩니다. 4. Jenkins 환경설정SVN , MSBuild 설정에 대한 부분을 설명드리겠습니다.다른 Tool 들에 대해서도 어렵지 않게 스스로 설정이 가능하거나, 검색을 하시면 자료가 많이 나올 것입니다. 먼저 Jenkins 화면에서 Jenkins 관리-&gt; 시스템 설정 으로 들어갑니다. 아래로 쭉 내리시면 Subversion이란 부분이 있습니다.현재 PC에 설치된 SVN과 같은 버전으로 설정하면 끝입니다. 거기서 조금 위로 올리시면 MSBuild 부분이 있습니다. 거기 버튼을 누른 뒤 PC상의 MSBuild.exe파일의 위치를 입력해줍니다. 단순히 여기에 위치만 입력해 줘도 되지만, 개인적으로는 해당 위치를 시스템환경변수에 PATH로 잡아두시는 것을 추천합니다.그러면 cmd 창에서 직접 실행도 가능합니다. MSBuild의 자세한 사용법에 대해서는 여기서 다루지 않겠습니다. MSDN에 자세한 설명이 있으니 참조하시면 됩니다. https://msdn.microsoft.com/ko-kr/library/ms164311.aspx 그 중 Jenkins에서 자주 사용하는 예시 한가지만 든다면… 1/p:Configuration=&quot;Release&quot; /t:Clean,Build Release 모드로 Clean 후 Build를 할 경우 위와 같이 써주시면 됩니다. ###5. Jenkins item 추가 새로운 item을 누르면 추가가 가능합니다. 원하시는 이름을 입력한 뒤 Freestyle project를 선택합니다. 먼저 고급 프로젝트 옵션에서 고급 버튼을 눌러서 사용자 빌드 경로 사용을 체크하셔서 source code를 받을 경로를 입력해 줍니다. ex. d:\\build\\svn\\test_project 소스코드관리에는 Subversion을 선택하시고 Repository URL을 입력합니다. ex. svn://192.168.0.1/repo/test_project/trunk Add Build Step 을 눌러서 MSBuild를 선택합니다. build할 solution이나 project 파일명을 전체경로나 위에 정한 사용자 빌드 경로로 부터의 상태경로로 입력합니다. ex. ./workspace/buildAll.sln 그리고 command line argument에 옵션을 적어줍니다. ex. /p:Configuration=&quot;Release&quot; /t:Clean,Build 한 item에서 여러가지의 build step을 가질 수 있습니다. 예를 들어서 Release로 빌드하고, Debug로도 빌드 한다던지, 다른 project나 solution 들을 build 한다든지 등요. build step에서 Execute Windows batch command를 선택하시면 일단 command line에서 선택하는 명령어를 그대로 입력하셔서 실행이 가능합니다. 관련 내용을 미리 batch file (.bat)나 python으로 생성해 놓고 실행하면 편리합니다. 특정 file들을 다른 folder로 옮겨 놓고 파일이름을 다르게 복사하고 등등의 작업이 가능합니다. 현재 item이 끝난 후 다른 item을 자동으로 시작 시킬려면 빌드 후 조치 추가에서 Build other projects를 눌러서 다른 item명을 입력하시면 선택이 됩니다. 콤마(,)를 입력해서 여러개 project 실행이 가능합니다. Test Project를 실행한다던지, InstallShield를 이용하여 배포 파일을 생성하는 등의 작업을 하면 편리하게 활용이 가능합니다. 주기적으로 build를 할려면 빌드 유발에 Build periodically를 선택하셔서 Schedule에 입력하시면 됩니다. 참고로 매일 새벽에 돌리실려면 @midnight라고 입력하시면 됩니다. 오른쪽 ?를 누르면 자세한 설명이 나옵니다.","categories":[{"name":"DevOps","slug":"DevOps","permalink":"http://DevStarSJ.github.io/categories/DevOps/"}],"tags":[{"name":"DevOps","slug":"DevOps","permalink":"http://DevStarSJ.github.io/tags/DevOps/"},{"name":"CI/CD","slug":"CI-CD","permalink":"http://DevStarSJ.github.io/tags/CI-CD/"}]},{"title":"자바 네트워크 소녀 Netty","slug":"hanbit.netty","date":"2015-10-28T15:00:00.000Z","updated":"2017-04-30T03:43:52.000Z","comments":true,"path":"2015/10/29/hanbit.netty/","link":"","permalink":"http://DevStarSJ.github.io/2015/10/29/hanbit.netty/","excerpt":"","text":"자바 네트워크 소녀 Netty 한빛미디어 정경석 지음 책소개 Link : http://www.hanbit.co.kr/book/look.html?isbn=978-89-6848-224-3 첫 인상처음 책을 받고 깜짝 놀랐습니다.내가 분명 주문한 것은 IT 기술서적인데…미소녀의 대형 브로마이드가 배송되었으며, 덤으로 책이 한권 같이 왔더군요. 두께가 많이 두껍지 않아서 부담없이 들고 다니기 좋아 보입니다. 하지만 표지 그림때문에 약간 들고다니기는 망설여 지더군요.종이재질은 한빛미디어다 보니 당연히 최상이구요.책안의 그림, 소스코드, 스크린샷 모두 눈에 쏙쏙 들어오게 되어 있었습니다. 그림 스크린샷 Source Code 전체적인 서평수많은 개발자들이 사용하는 언어,Java. Netty는 범용 자바 네트워크 프레임 워크입니다. Facebook에서 출시 된 것을 보고 어떤 내용일까 궁금했는데, 한빛리더스 2기 활동 중인데 이번 달의 목록에 이 책이 있었습니다. 그것도 선착순 5명만 가능하다고 해서 얼릉 신청했습니다.12Network Server 개발을 하기 위해서는 Socket을 이용한 Chatting Server만 만들어보면 됩니다.Web Server 개발을 하기 위해서는 게시판만 한번 만들어보면 됩니다. 와 같은 말이 있습니다. 마침 Chatting Server 쪽에 대해서 괌심이 있었습니다. Netty의 내부를 이해하기 어려운 점이 있긴 하지만 처음에 추천의 말에서 네티를 처음 접하신 분은 4-5장을 꼭 정독하라는 글귀를 읽고 우선 4-5장부터 차례대로 보기 시작했습니다. 이 책을 읽어야 하는 독자들은 학생들 보다는 Java 현업에서 네트워크 통신 개발이 경험이 있는 프로그래머나 네트워크에 대한 기반과 Java 기본 개념에서 중급으로 넘어갈 수 있는 학생들이라면 추천합니다. 무작정 Java 초급이었다가 Chatting Server를 만들려고 이 책을 접했더라면 엄청 험난한 길에 접어들 것이라 예상됩니다. 기본적인 Linux 사용법과 전반적인 Server에 대한 지식, Java 개발 경험이 있는 개발자들에게 도움이 된다고 할 수 있겠습니다. 저는 Windows 환경의 개발자이고 Java도 공부를 한적은 있지만, Project 경험은 없어서 보는데 애를 좀 먹었습니다. 예전에 TCP를 이용한 Chatting Server / Client는 교육과정을 통해서 직접 만들어 본적은 있었습니다. 책을 전체적으로 볼 때 각 단원마다 마치며 라는 부분이 너무 좋았습니다. 이해 되지 않았던 단어들 및 그리고 현재에 이용해야 하는 개발자들에게 참고 사항같이 독자들의 배려로 보이는 것으로 집필자의 작성 글들이 섬세하다는 것을 많이 느꼈습니다. ####1장 네티 맛보기 Network 관련된 기초 설명이 별도로 없기 때문에 Java 네트워크 프로그램에 대한 기본 지식이 있는 상태에서 접근해야 책을 보는데 도움이 될것입니다. 바로 다운받고 설치하는 과정으로 들어가고 특히 환경 설정에서 그림을 보여 주며 설명 해주는 부분은 기존 책들과 비슷합니다. 다만 책에서는 Windows 7을 기준으로 설명하고 있어서, Windows 8.1이나 Windows 10을 사용하는 독자들은 Putty 설치방법 등에 대해서 따로 찾아봐야 합니다. 각각의 필요한 Server에 대해 이해 할 수 있도록 우선 코드를 작성하면서 개념에 대해 설명해주는 것도 좋았습니다.Source Code에 번호를 붙여 별도로 설명을 해줌으로써 Code를 작성하고 참고할 개발자들에게는 주석을 달아 놓도록 간단하게 설명해주기때문에 그 부분도 좋았습니다. 2장 네티 주요 특징Netty의 주요 특징에서는 동기와 비동기에 대해 자세히 설명 해주지만 프로그램적 보다는 사전에 있는 내용을 인용했기 때문에 독자들의 호불호가 갈릴것 같습니다. 그리고 다른 책과는 달리 한 장 한 장씩 동기와 비동기를 그림으로 보여 주고 각각 설명 해주는 부분이 읽기에 부담 없고 이해하는데도 쉽게 도움이 되어 좋았습니다. 블로킹과 논블로킹 소켓에 대한 부분은 직접 Code를 입력해 보면서 숫자를 매겨 설명을 별도로 해주는 방식이라 Source Code에 대한 분석도 좋았습니다. 그림을 통해 다양한 종류로 보여 주기 때문에 이해되지 않는 부분에 대해서도 쉽게 이해할 수 있도록 노력한 점도 좋았습니다. 글만 읽게 되는 것과 글과 그림을 동시에 보여 주는 이해도는 엄청나게 차이가 난다는 것을 다시 한번 느꼈습니다. 3장 부트스트랩부트스트랩은 개발자, 디자이너, 퍼블리셔라면 접해야 되는 부분인데 부트스랩의 기본 정의부터 API, 다양한 이벤트 핸들러 관련 부분과 설정까지 다양하게 정리되어 있고 우선 구조에 대해서도 그림으로 보여줌으로써 한눈에 특징을 볼 수 있습니다. Java 개발자들에게 볼 수 있는 다이어그램 및 패턴을 code로 작성해 보면서 code에 붙여 진 주요한 method의 특징을 기호를 찾아 설명을 읽으면 더 자세하면서도 바로 실무에 적용할 수 있는 code가 있는 점이 너무 좋았습니다. 4장 채널 파이프라인과 코덱Event 실행을 할 경우에 실행 과정을 보여 줄 때 기호를 표기 해 준 것이 좋았습니다. 보통 책을 읽을 때 순서를 매기지 않고 설명 식으로 진행 해주는 책이 많은데 이 책은 이해하기 쉬웠습니다. 채널 파이프 라인 예시는 관련 개념을 모르는 사람이 보기에도 적절 했습니다. 전력 공급 과정으로 채널과 채널 파이프 라인의 관계를 표현 해주는 쉽게 이해가 되었고 그림 자체도 도움이 많이 되었습니다. 각각의 구성과 설명을 그림으로 표현하고 번호를 붙여 설명해 주는 것이 특히 채널 생성과 채널 파이프라인의 구성에 대해 1장에서 작성했던 code와 주석과 설명 그리고 그림까지 한꺼번에 번호를 매겨 보여 주는 것은 독자들로 하여금 작성하면서 이해 안되어 있던 부분까지 상세하게 보여 주는 배려가 보여 너무 좋았습니다. 이벤트 핸들러의 각각의 이벤트마다 간단한 설명만 있어서 독자들이 각각 해봐야만 이해할 수 있는 부분은 조금 아쉬웠습니다. 5장 이벤트 모델 웹 개발자라면 눈 여겨 봐도 좋은 chapter입니다. Node.js 와 ver.x(Netty)의 차이점을 이용해서 Netty 이벤트 모델에 대해 설명 해주기 때문에 기존에 웹 프로그램 경험이 있는 개발자들이라면 바로 개념을 이해하고 사용할 수 있도록 그림 설명과 처리량에 대해서는 그래프로 작성해 주어 바쁜 상황에 글을 읽지 못하더라도 한눈에 표로 확인할 수 있도록 배려한 것이 좋았습니다. 그리고 code가 예시로 나오기 때문에 직접 독자들이 작성해 보면서 이해할 수 있도록 해주는 것이 다른 기존 책들보다 상세하게 표현되어 있어 이해하는데 훨씬 도움이 되었습니다. ####6장 바이트 버퍼 이 부분은 Java 개발자이면서 전공자면 조금 쉽게 접근할 수 있을듯 합니다. 예전에 NIO에 대해서 교육받은 적이 있어서 쉽게 이해할 수 있었습니다. 자료 구조와 관련된 부분이 많고 source code로 설명을 해주기는 하나 이 내용을 이해할 수 있는 것은 학생들 보다는 현업에 있는 개발자들 특히 버퍼를 많이 이용하는 개발자에게도 내용이 조금은 어려울 것 같습니다. 버퍼를 많이 이용한 개발자들에게는 예제를 통해서 Netty와의 차이점을 확연히 알아볼 수 있을 것 같습니다. 7장 네티와 채널 보안7장부터 끝까지는 3부 Netty응용부분이라 기존에 Netty를 사용하는 개발자들에게는 필요한 부분과 이용할 때 참고 사항이 많아지는 부분입니다. 특히 Netty는 범용 네트워크 프레임워크기 때문에 보안에 대해 관심이 많고 그 보안을 어떻게 해야 할지 모르는 개발자들에게는 한줄기 빛과 같은 단원일듯 판단됩니다. 그리고 네트워크 보안에 대해서도 짧게나마 설명해주는 부분이 있기 때문에 개념에 대해 잘 모르고 이용이 어려울 경우에는 책에 있는 자료를 참고하는것도 좋은 방법일것 같습니다. Netty server에 SSL을 이용하는 내용을 추가해 주는데 Windows와 Lunux에 대한 설명이 같이 있고, OpenSSL을 이용하는 방법에 압축이나 명령 같은 부분을 직접 이용한 명령어로 보여줌으로써 쉽게 따라 할 수 있도록 배려해 준 것이 좋았습니다. 그리고 채널 보안 적용하기에 서버 부트스트랩 설정 코드와 번호를 붙여 간단하게 주석을 작성할 수 있도록 해주는 배려도 좋았습니다. 실제 네트워크 데이터를 캡쳐하여 유용하게 사용하는 도구와 방법을 언급해주므로서 필요할 경우 적용 할 수 있는 점이 좋았습니다. 8장 네티와 서드 파티 연동Spring framework에 대한 기본 지식이 있어야 Maven에 접근이 가능합니다. 즉 Java만 배운 학생에게는 어려운 부분이 많아 보입니다. 하지만 Eclipse를 이용할 수 있는 사람이라면 실습은 쉽게 따라 할 수 있도록 잘 설명되어 있습니다. Eclipse에서 market이용하여 Maven 설치와 실습까지 동시에 진행이 되나 Linux에서 실행되는 것이기 때문에 CentOS를 잘 아는 학생이나 개발자들에게는 쉽게 이해 할수 있을듯 합니다. 그렇지 않을 경우 Linux와 Spring 기본 개념에 대해 공부를 하고 source code를 봐야지만 잘 알아 볼 수 있을 것입니다. 기본을 잘 알고 Spring까지 애플리케이션 작성 source code까지 있기 때문에 그대로 따라 해보고 실행해 보거나 응용할 수 있도록 해 주었습니다. 9장 네티로 구현한 API 서버마지막은 Netty로 아예 처음부터 설계와 작업을 해서 실습이 되고 API 통합 테스트까지 해주므로서 Netty를 한번 더 과정을 볼 수 있게 해주는 과정이라 좋았습니다.","categories":[{"name":"Book","slug":"Book","permalink":"http://DevStarSJ.github.io/categories/Book/"},{"name":"Review","slug":"Book/Review","permalink":"http://DevStarSJ.github.io/categories/Book/Review/"}],"tags":[{"name":"Book","slug":"Book","permalink":"http://DevStarSJ.github.io/tags/Book/"},{"name":"Review","slug":"Review","permalink":"http://DevStarSJ.github.io/tags/Review/"}]},{"title":"MFC SIMD Vector Class 사용법 정리","slug":"SIMD","date":"2013-06-25T06:28:00.000Z","updated":"2017-05-29T23:28:08.000Z","comments":true,"path":"2013/06/25/SIMD/","link":"","permalink":"http://DevStarSJ.github.io/2013/06/25/SIMD/","excerpt":"","text":"Header File : &lt;dvec.h&gt; SIMD Vector Class 명명법12 &lt;Type&gt;&lt;Signed&gt;&lt;Bits&gt;vec&lt;Nums&gt;&#123; F | I &#125; &#123; s | u &#125; &#123; 64 | 32 | 16 | 8 &#125; vec &#123; 8 | 4 | 2 | 1 &#125; F : 실수 , I : 정수 s : signed, u : unsigned ( I에만 사용됨) 64 : double, __int64 , 32 : float, int , 16: short , 8 : char 8,4,2,1 : pack 개수 (Bits x Nums 는 128을 넘어 갈 수 없다. ) 1Ex) unsigned int 4개pack class : Iu32vec4 , float 4개 packclass : F32vec4 초기화 괄호 안에 각 변수들을 지정1Ex) Is32vec4 pint4(10,20,30,40); 1. 연산자 ( vec = vec op vec)12345678 = : 대입+, += : 덧셈- , -= : 뺄셈* , *= : 곱셈/ , /+ : 나눗셈 (실수 연산만 가능)&amp; : 논리연산 AND| : 논리연산 OR^ : 논리연산 XOR 2. 연산자 (vec = vec op n )12&lt;&lt;, &lt;&lt;== : Left Shift ( x2 )&gt;&gt; , &gt;&gt;== : Right Shift ( /2 ) 3. 함수 (vec = func(vec, vec)123simd_min() : 최소값simd_max() : 최대값andnot() : 논리연산 And Not 4. 비교함수 ( 참이면 0xff…, 거짓이면 0 )12345678910cmpeq : ==cmpneq : !=cmpgt : &gt;cmpge : &gt;=cmplt : &lt;cmple : &lt;=cmpnlt : !(A &lt; B)cmpnle : !(A &lt;= B)cmpngt : !(A &gt; B)cmpnge : !(A &gt;= B) 5. Select : R = Select(A,B,C,D)=&gt; if (A 비교 B) R = C else R = D12345678910select_eq : ==select_neq : !=select_gt : &gt;select_ge : &gt;=select_lt : &lt;select_le : &lt;=select_nlt : !(A &lt; B)select_nle : !(A &lt;= B)select_ngt : !(A &gt; B)select_nge : !(A &gt;= B) 6. Unpacked / Pack (예제는 Is32vec4)123R = unpack_low( A, B) =&gt; R = ( B1 , A1 , B0 , A0 )R = unpack_high(A, B) =&gt; R = ( B3 , A3 , B2 , A2 )R = pack_sat(A, B) =&gt; Is16vec8 R = (B3, B2, B1, B0, A3, A2, A1, A0) : 정수형만지원 7.정수 Vector &lt;-&gt; Array :Vector Class에서 지원하지 앟음 intrinsic 함수 이용1234567Is32vec4 A = _mm_load_si128((__m128i*) p) : 배열 Pointer를 __m128i* 로 casting 후 저장 (정렬된 메모리)s32vec4 A = _mm_loadu_si128((__m128i*) p) : 정렬되지 않은 메모리에서 데이터 읽어오기_mm_store_si128((_m128i*) p , A) : A에 저장된 값들을 배열 p에순서대로 저장 (정렬된 메모리)_mm_storeu_si128((_m128i*) p , A) : 정렬되지 않은 메모리에 데이터 쓰기 8. 실수 Vector &lt;-&gt; Array123loadu (F32vec4 R, float* a) : a[0] ~ a[3] 4개의 float 값을읽어서 R에 저장storeu(float* a, F32vec4 R) : R의 값을 a[0] ~ a[3]에저장store_nta(float* a, F32vec$ R) : 버퍼 없이 메모리 a[0] ~ a[3]에저장 9.수학 함수 (실수 연산만 가능)123456R = sqrt(A) : 제곱근 RootR = rcp(A) : 역분수 : R = 1 / AR = rsqrt(A) : 제곱근 역분수 : R = 1 / Root AR = rcp_nr(A) : Newton-Raphson법의 역분수 : R = rcp(A) * 2 –A * rcp(A) * rcp(A)R = rsqrt_nr(A) : Newton-Raphson법의 제곤근 역분수 : R = rsqrt(A)/ 2 * ( 3 – A * rsqrt(A) * rsqrt(A) )F = add_horizontal(A) : float F = A0 + A1 + A2 + A3","categories":[{"name":"CPP","slug":"CPP","permalink":"http://DevStarSJ.github.io/categories/CPP/"},{"name":"MFC","slug":"CPP/MFC","permalink":"http://DevStarSJ.github.io/categories/CPP/MFC/"}],"tags":[{"name":"CPP","slug":"CPP","permalink":"http://DevStarSJ.github.io/tags/CPP/"},{"name":"MFC","slug":"MFC","permalink":"http://DevStarSJ.github.io/tags/MFC/"},{"name":"SIMD","slug":"SIMD","permalink":"http://DevStarSJ.github.io/tags/SIMD/"}]}]}