<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Dev Star SJ</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Sharing the common developer&apos;s try-on">
<meta property="og:type" content="website">
<meta property="og:title" content="Dev Star SJ">
<meta property="og:url" content="http://DevStarSJ.github.io/index.html">
<meta property="og:site_name" content="Dev Star SJ">
<meta property="og:description" content="Sharing the common developer&apos;s try-on">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Dev Star SJ">
<meta name="twitter:description" content="Sharing the common developer&apos;s try-on">
  
    <link rel="alternate" href="/atom.xml" title="Dev Star SJ" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Dev Star SJ</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">DevStarSJ</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://DevStarSJ.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-aws-batch-tutorial" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/11/24/aws-batch-tutorial/" class="article-date">
  <time datetime="2018-11-24T03:08:00.000Z" itemprop="datePublished">2018-11-24</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/AWS/">AWS</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/24/aws-batch-tutorial/">Introduce to AWS Batch</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1>Introduce to AWS Batch</h1>
<h2>1. Introduction to AWS Batch</h2>
<p><strong>AWS batch</strong>는 ECR (Amazon Elastic Container Registry)또는 EC2 AMI (Amazon Machine Image)를 이용해서 작업을 수행시키는 서비스이다.</p>
<p><a href="https://aws.amazon.com/batch" target="_blank" rel="external">Amazon Batch</a></p>
<p>ECS (Amazon Elastic Container Service)에서도 작업 수행이 가능하지만 몇가지 차이점이 있다.</p>
<ol>
<li>
<p><strong>ECS</strong>에서는 미리 <strong>Cluster</strong> (EC2)를 만들어 두고 <strong>Task</strong> (ECR)를 해당 Cluster에서 수행하는 방식이지만, <strong>Batch</strong>에서는 <strong>Job queue</strong> (EC2)를 만들어 두고 <strong>Job</strong>(ECS or EC2 AMI) 수행시 실행할 Job queue를 선택하면 런타임에 해당 instance가 생성된 후 job 실행이 끝나면 종료된다. instance가 실제 수행시에만 할당되므로 비용적인 면에서 유리하다. ECS, Batch 둘 다 Spot Instance를 지원한다.</p>
</li>
<li>
<p><strong>ECS</strong>, <strong>Batch</strong> 모두  <strong>Task</strong> / <strong>Job</strong> 실행 후 종료와 <strong>Service</strong>형태로 계속 실행되는 방식이 둘 다 가능하다. 하지만 Batch의 경우 service 방식으로 실행하는게 원래 의도된 방법이 아니긴하다.</p>
</li>
<li>
<p><strong>Batch</strong>의 경우 <strong>Job</strong>의 dependancy설정이 가능하다. 즉, 다른 job이 종류된 이후 수행하도록 설정이 가능하다. 이것이 <strong>ECS</strong>의 <strong>Task</strong>와 가장 큰 차이점이다.</p>
</li>
<li>
<p><strong>ECS</strong>는 <strong>ECR</strong>의 docker image만을 지원히지만, <strong>AWS Batch</strong>는 <strong>ECR</strong> 과 <strong>AMI</strong> 모두를 지원한다. 단, AMI의 경우 Amazon Linux 1 or 2 OS에 별도의 docker agent가 설치되어 있어야 한다.</p>
</li>
</ol>
<h2>2. 설명 범위</h2>
<p><strong>AWS Batch</strong>를 수행하기 위한 최소한의 정의 및 실행 방법에 대해서 소개하겠다.</p>
<ul>
<li>ECR : Batch에서 실행할 docker image</li>
<li>Batch Job : Batch에서 수행할 작업</li>
<li>Batch Job queue : Batch가 수행될 instance 정의</li>
<li>Batch Compute Environment : Job queue에서 포함시킬 instance들의 세부 정의</li>
<li>AWS Lambda : Batch job의 dependancy 적용을 위한 간단한 코드</li>
<li>CloudWatch : Batch job을 주기적으로 수행하기 위한 trigger</li>
</ul>
<p><strong>AMI</strong>를 활용하는 방법에 대해서는 설명은 하지 않을 것이며, <strong>ECR</strong>을 이용한 방법만을 다룬다.</p>
<p>추가적으로 <strong>Terraform</strong>을 이용하여 인프라스트럭쳐를 배포하기 위한 최소한의 정의사항에 대해서도 소개를 하겠다.</p>
<h2>3. Define AWS Batch Infrastructure</h2>
<p>단 1개 Job을 AWS Batch를 수행하기 위해서 필요한 최소한의 AWS상의 infrastructure 는 다음과 같다.</p>
<ul>
<li>
<p>Job definitions</p>
<ul>
<li>Job role : IAM role</li>
<li>Container image : ECR or AMI</li>
</ul>
</li>
<li>
<p>Computer environment</p>
<ul>
<li>Service role : IAM role</li>
<li>Instance role : IAM role (profile)</li>
<li>EC2 key pair : IAM (optional)</li>
<li>Spot fleet role : IAM role (Provisioning model을 On-Demand가 아닌 Spot으로 설정할 경우)</li>
<li>VPC</li>
<li>Subnet</li>
<li>Security Group</li>
</ul>
</li>
<li>
<p>Job queue</p>
<ul>
<li>Compute environment</li>
</ul>
</li>
</ul>
<p>각종 작업들을 위한 권한(IAM role)들과 수행할 작업(software)가 포함된 이미지(ECR or AMI), 수행될 instace에 필요한 network설정(VPC, Subnet, Security Group)들의 정의가 미리 이루어져야 한다. 해당 인프라의 정의는 이 글에서는 다루지 않겠다. <strong>Terraform</strong> 코드에서도 해당 인프라는 <strong>resource</strong>가 아닌 <strong>data</strong>로 정의하여 미리 정의된 내용을 사용하는 방향으로 진행하겠다.</p>
<p><strong>AWS Batch</strong> console로 들어가면 왼쪽 목록에 5개의 메뉴를 볼 수가 있다.</p>
<ul>
<li>Dashboard : 정의된 Job queue와 Computer environment의 목록을 볼 수 있으며, 각각의 Job queue별로 Job의 Status(submitted, pending, runnable, starting, running, failed, succeeded) 상태를 볼 수 있다.</li>
<li>Jobs : Job queue별로 Status별 job의 목록을 볼 수있다.</li>
<li>Job definitions : 정의된 Job들을 볼 수 있으며, 생성 / 삭제가 가능하다. Job을 console상에서 실행할 경우 Dashboard, Jobs, Job definitions 3곳에서 모두 관련 버튼이 있으나 Job definitions에서만 원하는대로 Job 선택이 가능했다.</li>
<li>Job queues : 정의된 Job queue 확인 및 생성 / 삭제가 가능하다. 삭제시 Disable -&gt; Delete 순으로 작업해야 한다.</li>
<li>Compute environments : 정의된 Compute environment 확인 및 생성 / 삭제가 가능하다. 삭제시 Disable -&gt; Delete 순으로 작업해야 한다. 그리고 Job queue에서 사용중이지 않은 경우에만 삭제가 가능하다.</li>
</ul>
<h2>3.1 Job definitions</h2>
<p>실행할 container image및 명령어를 정의하는 곳이다.</p>
<p><code>Create</code>를 누르면 Job 정의가 가능하다.</p>
<ul>
<li>Create a job definition
<ul>
<li>Job definition name : Job difinition의 이름</li>
<li>Job attempts : Job 실패시 다시 시도해야 할 경우 몇 회까지 수행할 것인지에 대한 설정</li>
<li>Execution timeout : Job의 실행이 특정 시간내에 끝나야 할 경우 설정(초 단위)</li>
</ul>
</li>
<li>Environment
<ul>
<li>Job role : Job 수행을 위해서는 ECS IAM role이 필요하다. 해당 권한이 있는 role로 설정</li>
<li>Container image : 수행할 ECR or AMI 이미지의 url을 입력한다. ECR의 경우 version까지 입력할 경우 <code>{Repository URI}:latest</code>와 같은 형식으로 입력하면 된다.</li>
<li>Command : 실행할 명령어 <code>python src/run.py</code>와 같은식으로 띄워쓰기로 입력하면 된다.</li>
<li>vCPUs : Job 수행에 필요한 CPU수</li>
<li>Memory (MiB) : Job 수행에 필요한 메모리</li>
</ul>
</li>
<li>Environment variables : Job 실행시 참고할 환경변수들</li>
</ul>
<p>나머지 값들은 필수값이 아니라 설명을 생략한다. 위에 소개한 특성들 중에서도 필수값이 아닌 것들이 존재하지만, 대부분의 작업에 필요해 보이는 것 위주로 나열하였다.</p>
<h2>3.2 Compute environment</h2>
<p><strong>Job queue</strong>를 정의하기 전에 <strong>Compute environment</strong>를 먼저 정의해야 한다.<br>
Job queue에 포함될 instance에 대한 정의를 하는 곳이다.</p>
<p><code>Creare environment</code>를 누르면 정의가 가능하다.</p>
<ul>
<li>Create a compute environment
<ul>
<li>Compute environment type : 그냥 <code>Managed</code>를 하자. AWS에서 관리를 해주는 것이다. <code>Unmanaged</code>를 선택하면 아래에 정의가능한 것들이 거의 없어진다.</li>
<li>Compute environment name : Compute environment의 이름</li>
<li>Service role : AWSBatchServiceRole IAM role이 필요하다.</li>
<li>Instance role : ecsInstanceRole IAM instance profile이 필요하다.</li>
<li>EC2 key pair : 해당 instance에 직접 접속할 필요가 있을 경우 그때 사용할 key-pair를 선택한다.</li>
</ul>
</li>
<li>Configure your compute resources
<ul>
<li>Provisioning model : On-Demand와 Spot 중 선택이 가능하다. Spot을 선택 할 경우 하위 항목을 2개 더 정의해야 한다.
<ul>
<li>Maximum Price : On-Demand 가격 대비 몇%의 가격까지 지불할 것인지를 정의한다.</li>
<li>Spot fleet role : Spot을 사용할 수 있는 IAM role이 필요하다.</li>
</ul>
</li>
<li>Allowed instance types : 사용할 instance 타입들을 멀티로 선택이 가능하다.</li>
<li>Minimum / Desired / Maximum vCPUs : 최소/희망/최대 vCPU 개수에 대한 정의인데 그냥 모두 기본값으로 해도 무관하다.</li>
</ul>
</li>
<li>Networking
<ul>
<li>VPC Id</li>
<li>Subnets</li>
<li>Security groups</li>
</ul>
</li>
<li>EC2 tags</li>
</ul>
<p>Networking 과 tags에 대해서는 따로 설명을 하지 않겠다. 일반적으로 EC2 정의에서 필요로하는 필수값들이다.</p>
<h2>3.3 Job queue</h2>
<p><strong>Job</strong>이 수행되는 <strong>Compute environment</strong>들을 정의하는 곳이다.
<code>Creare queue</code>를 누르면 정의가 가능하다.</p>
<ul>
<li>Create a job queue
<ul>
<li>Queue name : Job queue의 이름</li>
<li>Priority : 우선순위</li>
</ul>
</li>
<li>Connected compute environments for this queue : 정의된 <strong>Compute environment</strong>를 순서대로 나열이 가능</li>
</ul>
<p>만약 하나의 <strong>Job queue</strong>에 여러 개의 <strong>Job</strong>이 수행되도록 제출한 경우 정의된 Compute environment들의 범위 안에서만 동시에 수행이 가능하다.</p>
<p>예를 들어서 vCPU 10개가 필요한 Job 10개를 1개의 Job queue에 모두 할당 할 경우, 해당 Job queue에 정의된 Compute environment가 vCPU 36개일 경우 동시에 3개씩 밖에 수행을 할 수가 없다. 만약 정의된 Compute environment가 vCPU 36개, vCPU 24개 이렇게 2개가 있을 경우 먼저 제출된 3개는 앞의 머신에서 다음 2개는 뒤의 머신에서 수행되며, 마저미 5개는 먼저 제출된 Job중에 끝난 것이 있으면 해당 머신에 하나씩 할당이 된다.</p>
<h2>4. Job 실행</h2>
<h3>4.1 Console에서 Job 실행</h3>
<p>먼저 console에서 바로 실행시키는 방법이 있다.</p>
<ul>
<li>
<p><code>Job definitions</code>에서 실행시킬 Job definition을 선택</p>
<ul>
<li><code>Revision X</code>와 같은 버전정보를 선택
<ul>
<li>상위 <code>Action</code>버튼의 <code>Submit job</code>을 선택</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Job run-time</p>
<ul>
<li>Job name : 실행 Job의 이름 (Job definition 이름과는 다름)</li>
<li>Job queue : 어느 Job queue에서 실행할지 선택</li>
<li>Job depends on : 다른 Job이 끝난 다음에 실행되어야 할 경우 해당 Job의 id를 입력</li>
</ul>
</li>
</ul>
<p>나머지 사항들은 <code>Job definitions</code>에서 이미 설정된 값을 따른다. 해당 Job에서만의 값으로 수정하는 것도 가능하다.</p>
<h3>4.2 Python에서 AWS SDK(boto3)로 실행</h3>
<p>아래 코드는 연속된 3개의 Job을 실행하는 예제 코드이다.</p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> boto3</div><div class="line">client = boto3.client(<span class="string">'batch'</span>)</div><div class="line"></div><div class="line">job_list = [<span class="string">'Job1'</span>, <span class="string">'Job2'</span>, <span class="string">'Job3'</span>]</div><div class="line">env_list = [<span class="string">'queue_72'</span>, <span class="string">'queue_simple'</span>, <span class="string">'queue_72'</span>]</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_request</span><span class="params">(name, env, depends_job=None)</span>:</span></div><div class="line">    request = &#123;<span class="string">'jobQueue'</span>: env, <span class="string">'jobName'</span>: name,  <span class="string">'jobDefinition'</span>: name&#125;</div><div class="line">    <span class="keyword">if</span> depends_job <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">        job_id = depends_job[<span class="string">'jobId'</span>]</div><div class="line">        request[<span class="string">'dependsOn'</span>] = [ &#123;<span class="string">'jobId'</span>: job_id&#125;]</div><div class="line">    <span class="keyword">return</span> request</div><div class="line"></div><div class="line">response = <span class="keyword">None</span></div><div class="line"><span class="keyword">for</span> job, env <span class="keyword">in</span> zip(job_list, env_list):</div><div class="line">    response = client.submit_job(**make_request(job, env, response))</div><div class="line">    print(job)</div><div class="line">    print(response)</div><div class="line">    print(<span class="string">''</span>)</div></pre></td></tr></table></figure></p>
<p>3개의 Job은 각각 앞에 정의된 Job이 실행된 이후 실행되어야 한다.<br>
Job1, Job3는 vCPU가 72개 필요한 instance에서 실행되어야 하며, Job2는 vCPU 1개에서도 실행이 가능하므로 이 두 그룹의 Job queue를 다르게 설정하였다.</p>
<p>위 코드는 <strong>AWS Lambda</strong>에 정의헤 두고 실행하는 것이 가능하다. 이 경우 <strong>AWS CloudWatch</strong>에서 주기적으로 실행되로록 설정이 가능하다.</p>
<ul>
<li><code>AWS CloudWatch</code> console
<ul>
<li><code>Events</code> -&gt; <code>Rules</code>
<ul>
<li><code>Create rule</code>
<ul>
<li>Event Source : Schedule
<ul>
<li>주기적으로 수행하도록 또는 Cron Express를 이용하여 수행하도록 설정</li>
</ul>
</li>
<li>Add Target
<ul>
<li>Lambda Function 선택 후 정의된 Function name을 선택</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>Job</strong> 실행 결과는 <strong>AWS Batch</strong> Dashboard 상에서 세부정보로 들어가면 <strong>CloudWatch</strong> 링크가 보이는데 그것을 이용해서 로그 확인이 가능하다.</p>
<h2>5. Terraform Code</h2>
<p><strong>AWS Batch</strong> 정의를 <strong>Terraform</strong>을 이용하여 정의한 예제코드이다.</p>
<p><strong>VPC</strong>, <strong>IAM Role</strong>등 외부설정은 기존에 정의된 것을 사용한다는 전제하에 <code>data</code>로 정의하였으며 <strong>Batch</strong>상에서의 정의만 <code>resource</code>로 정의하였다.</p>
<p>참고로 현재(2018-11) 기준으로 <strong>Compute Environment</strong>가 설정된 상태에서 수정해서 <code>apply</code>할 경우 오류가 발생하며 <code>rollback</code>이 되지 않는다. 수동으로 작업을 하려고 해도 해당 리소스를 사용하고 있는 모든 <strong>Job queue</strong>를 모두 <code>Disable</code> -&gt; <code>Delete</code>한 후에 <strong>Compute Environment</strong>를 <code>Disable</code> -&gt; <code>Delete</code>하고 새로 만들어야 한다.</p>
<p><strong>CloudFomation</strong>에서는 정상적으로 수정이 되는지 확인해보지는 않았다.</p>
<ul>
<li>
<p>role.tf
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">data &quot;aws_iam_instance_profile&quot; &quot;AWSEC2ContainerServiceForEC2Policy&quot; &#123;</div><div class="line">    name = &quot;AWSEC2ContainerServiceForEC2Policy&quot;</div><div class="line">&#125;</div><div class="line"></div><div class="line">data &quot;aws_iam_role&quot; &quot;AWSBatchServiceRole&quot; &#123;</div><div class="line">    name = &quot;AWSBatchServiceRole&quot;</div><div class="line">&#125;</div><div class="line"></div><div class="line">data &quot;aws_iam_role&quot; &quot;AWSServiceRoleForEC2SpotFleet&quot; &#123;</div><div class="line">    name = &quot;AWSServiceRoleForEC2SpotFleet&quot;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
</li>
<li>
<p>subnet.tf
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">variable &quot;subnet_id&quot; &#123;</div><div class="line">    type = &quot;string&quot;</div><div class="line">    default = &quot;subnet-example&quot;</div><div class="line">  </div><div class="line">&#125;</div><div class="line"></div><div class="line">data &quot;aws_subnet&quot; &quot;subnet_default&quot; &#123;</div><div class="line">    id = &quot;$&#123;var.subnet_id&#125;&quot;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
</li>
<li>
<p>security_group.tf
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">variable &quot;security_group_id&quot; &#123;</div><div class="line">    type = &quot;string&quot;</div><div class="line">    default = &quot;sg-example&quot;</div><div class="line">&#125;</div><div class="line"></div><div class="line">data &quot;aws_security_group&quot; &quot;default_sg&quot; &#123;</div><div class="line">    id = &quot;$&#123;var.security_group_id&#125;&quot;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
</li>
<li>
<p>ecs.tf
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">resource &quot;aws_ecr_repository&quot; &quot;batch_image&quot; &#123;</div><div class="line">  name = &quot;batch_image&quot;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
</li>
</ul>
<p><strong>ECR</strong>의 경우 미리 정의된 것을 사용할 경우 위 코드에서 <code>resource</code>만 <code>data</code>로 수정하면 된다.</p>
<ul>
<li>batch.tf
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div></pre></td><td class="code"><pre><div class="line">resource &quot;aws_batch_compute_environment&quot; &quot;env_72&quot; &#123;</div><div class="line">  compute_environment_name = &quot;env_72&quot;</div><div class="line"></div><div class="line">  compute_resources &#123;</div><div class="line">    instance_role = &quot;$&#123;data.aws_iam_instance_profile.AWSEC2ContainerServiceForEC2Policy.arn&#125;&quot;</div><div class="line">    spot_iam_fleet_role  = &quot;$&#123;data.aws_iam_role.AWSServiceRoleForEC2SpotFleet.arn&#125;&quot;</div><div class="line"></div><div class="line">    instance_type = [</div><div class="line">      &quot;c5.18xlarge&quot;,</div><div class="line">      &quot;m5.24xlarge&quot;,</div><div class="line">      &quot;m5.12xlarge&quot;</div><div class="line">    ]</div><div class="line"></div><div class="line">    max_vcpus = 256</div><div class="line">    min_vcpus = 0</div><div class="line"></div><div class="line">    security_group_ids = [</div><div class="line">      &quot;$&#123;data.aws_security_group.default_sg.id&#125;&quot;,</div><div class="line">    ]</div><div class="line"></div><div class="line">    subnets = [</div><div class="line">      &quot;$&#123;data.aws_subnet.subnet_default.id&#125;&quot;,</div><div class="line">    ]</div><div class="line"></div><div class="line">    type = &quot;EC2&quot;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  service_role = &quot;$&#123;data.aws_iam_role.AWSBatchServiceRole.arn&#125;&quot;</div><div class="line">  type         = &quot;MANAGED&quot;</div><div class="line">&#125;</div><div class="line"></div><div class="line">resource &quot;aws_batch_compute_environment&quot; &quot;env_simple&quot; &#123;</div><div class="line">  compute_environment_name = &quot;env_simples&quot;</div><div class="line"></div><div class="line">  compute_resources &#123;</div><div class="line">    instance_role = &quot;$&#123;data.aws_iam_instance_profile.AWSEC2ContainerServiceForEC2Policy.arn&#125;&quot;</div><div class="line">    spot_iam_fleet_role  = &quot;$&#123;data.aws_iam_role.AWSServiceRoleForEC2SpotFleet.arn&#125;&quot;</div><div class="line"></div><div class="line">    instance_type = [</div><div class="line">      &quot;r3.xlarge&quot;</div><div class="line">    ]</div><div class="line"></div><div class="line">    max_vcpus = 256</div><div class="line">    min_vcpus = 0</div><div class="line"></div><div class="line">    security_group_ids = [</div><div class="line">      &quot;$&#123;data.aws_security_group.default_sg.id&#125;&quot;,</div><div class="line">    ]</div><div class="line"></div><div class="line">    subnets = [</div><div class="line">      &quot;$&#123;data.aws_subnet.subnet_default.id&#125;&quot;,</div><div class="line">    ]</div><div class="line"></div><div class="line">    type = &quot;EC2&quot;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  service_role = &quot;$&#123;data.aws_iam_role.AWSBatchServiceRole.arn&#125;&quot;</div><div class="line">  type         = &quot;MANAGED&quot;</div><div class="line">&#125;</div><div class="line"></div><div class="line">resource &quot;aws_batch_job_queue&quot; &quot;queue_72&quot; &#123;</div><div class="line">  name                 = &quot;queue_72&quot;</div><div class="line">  state                = &quot;ENABLED&quot;</div><div class="line">  priority             = 100</div><div class="line">  compute_environments = [&quot;$&#123;aws_batch_compute_environment.env_72.arn&#125;&quot;]</div><div class="line">&#125;</div><div class="line"></div><div class="line">resource &quot;aws_batch_job_queue&quot; &quot;queue_simple&quot; &#123;</div><div class="line">  name                 = &quot;queue_simple&quot;</div><div class="line">  state                = &quot;ENABLED&quot;</div><div class="line">  priority             = 100</div><div class="line">  compute_environments = [&quot;$&#123;aws_batch_compute_environment.env_simple.arn&#125;&quot;]</div><div class="line">&#125;</div><div class="line"></div><div class="line">resource &quot;aws_batch_job_definition&quot; &quot;Job1&quot; &#123;</div><div class="line">  name = &quot;Job1&quot;</div><div class="line">  type = &quot;container&quot;</div><div class="line"></div><div class="line">  container_properties = &lt;&lt;CONTAINER_PROPERTIES</div><div class="line">&#123;</div><div class="line">    &quot;command&quot;: [&quot;python&quot;, &quot;src/run1.py&quot;],</div><div class="line">    &quot;image&quot;: &quot;$&#123;data.aws_ecr_repository.batch_image.repository_url&#125;:latest&quot;,</div><div class="line">    &quot;memory&quot;: 102400,</div><div class="line">    &quot;vcpus&quot;: 72</div><div class="line">&#125;</div><div class="line">CONTAINER_PROPERTIES</div><div class="line">&#125;</div><div class="line"></div><div class="line">resource &quot;aws_batch_job_definition&quot; &quot;Job2&quot; &#123;</div><div class="line">  name = &quot;Job2&quot;</div><div class="line">  type = &quot;container&quot;</div><div class="line"></div><div class="line">  container_properties = &lt;&lt;CONTAINER_PROPERTIES</div><div class="line">&#123;</div><div class="line">    &quot;command&quot;: [&quot;python&quot;, &quot;src/run1.py&quot;],</div><div class="line">    &quot;image&quot;: &quot;$&#123;data.aws_ecr_repository.batch_image.repository_url&#125;:latest&quot;,</div><div class="line">    &quot;memory&quot;: 1024,</div><div class="line">    &quot;vcpus&quot;: 1</div><div class="line">&#125;</div><div class="line">CONTAINER_PROPERTIES</div><div class="line">&#125;</div><div class="line"></div><div class="line">resource &quot;aws_batch_job_definition&quot; &quot;Job3&quot; &#123;</div><div class="line">  name = &quot;Job3&quot;</div><div class="line">  type = &quot;container&quot;</div><div class="line"></div><div class="line">  container_properties = &lt;&lt;CONTAINER_PROPERTIES</div><div class="line">&#123;</div><div class="line">    &quot;command&quot;: [&quot;python&quot;, &quot;src/run3.py&quot;],</div><div class="line">    &quot;image&quot;: &quot;$&#123;data.aws_ecr_repository.batch_image.repository_url&#125;:latest&quot;,</div><div class="line">    &quot;memory&quot;: 102400,</div><div class="line">    &quot;vcpus&quot;: 72</div><div class="line">&#125;</div><div class="line">CONTAINER_PROPERTIES</div><div class="line">&#125;</div></pre></td></tr></table></figure></li>
</ul>
<h2>6. 맺음말</h2>
<p><strong>AWS Batch</strong>를 이용하면 실제로 구동할때만 <strong>EC2 Instance</strong>를 띄워서 수행 할 수 있으며, <strong>Job</strong>의 dependency를 이용하여 workflow 관리도 가능하다. 그리고 <strong>AWS Lambda</strong>와 <strong>CloudWatch</strong>를 활용해서 주기적으로 실행하도록도 설정이 가능하다.</p>
<p>아쉬운 점으로는 첫째, dependency를 1개만 설정이 가능해서, 동시에 여러가지 일을 수행하고 그 모든게 다 끝난 후에 다음 Job을 수행하는 식의 정의는 안된다는 점이다. 최대한 병렬성을 높여서 전체 수행시간을 줄이는데에는 한계점이 보인다.</p>
<p>두번째 아쉬운 점으로는 Job간의 dependency를 run-time에 제출된 job id를 가지고 해야한다는 점이다. 미리 인프라 정의할때 Job의 default dependency를 걸어두고 job 제출시 dependency를 수정가능하도록 한다던지, 아니면 <strong>Job Workflow definition</strong>의 기능을 별도로 제공해서 미리 정의가능해서 그것만 수행하는 식으로 된다면 <strong>AWS Lambda</strong>를 따로 활용하지 않고 <strong>CloudWatch</strong>에서 바로 job workflow를 실행한다던지 아니면 workflow 정의시 실행주기까지 같이 설정이 가능하게 하면 훨씬 편리하겠다는 생각이 든다.</p>
<p>참고로 앞에서 설명한 예제와 같이 <code>Job1</code>과 <code>Job3</code>가 하나의 queue에서 수행되고 <code>Job2</code>가 다른 queue에서 수행될 경우, <code>Job1</code>의 실행이 끝난 시점에 <code>Job2</code>를 실행할 queue에 instance가 떠있지 않은 상태라면 instance가 할당될 동안 기다려야 한다. 그렇게 기다린 후 <code>Job2</code>의 실행이 끝난 시점에 <code>Job1</code>을 실행한 queue에 다른 job이 오랜시간동안 할당이 안되어서 내려갔을 경우 다시 <code>Job3</code> 수행전에 해당 queue상의 instance가 뜰동안 기다려야 한다. 만약 <code>Job2</code>가 너무나도 단순한 작업이어서 <code>Job1</code>을 실행시킨 고사양의 instance에서 수행되는게 낭비라고 생각해서 별도 queue에서 수행하도록 설정을 했다면 <code>Job1</code>의 수행이 종료되자마자 해당 queue의 instance가 내려가는 것이 아니라 다른 job을 기다리는 일정시간동안은 instance가 유지되므로 전체 수행시간도 더 길게되고, 비용도 오히려 더 나올 수가 있으니, 이점을 주의해야 한다.</p>
<h2>마치며...</h2>
<p>잘못되었거나, 변경된 점, 기타 추가 사항에 대한 피드백은 언제나 환영합니다. - <a href="mailto:seokjoon.yun@gmail.com" target="_blank" rel="external">seokjoon.yun@gmail.com</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://DevStarSJ.github.io/2018/11/24/aws-batch-tutorial/" data-id="cjov1wtqq007rjw7bk5j4yx0h" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AWS/">AWS</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Batch/">Batch</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-kaggle.coursera.competition.03.02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/11/04/kaggle.coursera.competition.03.02/" class="article-date">
  <time datetime="2018-11-04T02:04:00.000Z" itemprop="datePublished">2018-11-04</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/DataScience/">DataScience</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/04/kaggle.coursera.competition.03.02/">Coursera Kaggle 강의(How to win a data science competition) week 3,4 Advanced Feature Engineering 요약</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1>Coursera Kaggle 강의(How to win a data science competition) week 3,4 Advanced Feature Engineering 요약</h1>
<h2>1. Mean encodings</h2>
<ul>
<li>Categorical feature로 <strong>groupby</strong>하여 <code>target의 mean</code> 값을 feature로 추가
<ul>
<li>mean뿐 아니라 median, std, min, max 등 해당 데이터의 성격을 잘 나타내는 통계 연산</li>
</ul>
</li>
</ul>
<p>ex)
<img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.03.15.png" alt=""></p>
<p>위 그림의 경우</p>
<ul>
<li>Moscow : 1 2개, 0 3개 -&gt; 0.4</li>
<li>Tver : 1 4개, 0 1개 -&gt; 0.8</li>
<li>Klin : 0 all -&gt; 0.0</li>
</ul>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.03.16.png" alt=""></p>
<p>Label encoding의 경우 단순히 순서에 의해 부여된 숫자일뿐 target과의 관련성이 전혀 없지만, <code>Mean encoding</code>의 경우 0 ~ 1 사이 값으로 target값과 연관성이 있이 있다. 특히 0인 것과 아닌 것은 완전히 구분이 된다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.03.17.png" alt=""></p>
<p>더 짧은 tree로도 더 좋은 성능을 발휘한다.</p>
<p>적용 방법들</p>
<ul>
<li>Likelihood : Goods / (Goods + Bads) = mean(target)</li>
<li>Weight of Evidence = ln(Goods / Bads) * 100</li>
<li>Count = Goods = sum(target)</li>
<li>Diff = Goods - Bads</li>
</ul>
<p>cf. Goods : 1의 개수, Bads : 0의 개수</p>
<p>tree 개수가 증가하면면서 정확도가 계속 증가한다면 아직 overfitting이 아니라는 뜻이다.
이럴 때 <code>mean encoding</code>을 적용하여 더 빨리 정확도를 올릴 수 있다.
하지만 overfitting은 항상 주의해야 한다.
왜냐면 train, validation의 비율이 다를 경우 overfitting된 상태라면 결과가 좋지 않다.</p>
<h2>2. Regularization (정규화)</h2>
<h3>2.1 CV Loop regularization</h3>
<ul>
<li>매주 직관적이고 강력한(robust)한 방법</li>
</ul>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">y_tr = df_tr[<span class="string">'target'</span>].values</div><div class="line">skf = StratifiedKFold(y_tr, <span class="number">5</span>, shuffle=<span class="keyword">True</span>, random_state=<span class="number">123</span>)</div><div class="line"></div><div class="line"><span class="keyword">for</span> tr_ind, val_ind <span class="keyword">in</span> skf:</div><div class="line">    X_tr, X_val = df_tr.iloc[tr_ind], df_tr.iloc[val_ind]</div><div class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> cols:</div><div class="line">        means = X_val[col].map(X_tr.groupby(col).target.mean())</div><div class="line">        X_val[col+<span class="string">'_mean_target'</span>] = means</div><div class="line">    train_new.iloc[val_ind] = X_val</div><div class="line"></div><div class="line">prior = df_tr[<span class="string">'target'</span>].mean() <span class="comment"># global mean</span></div><div class="line">train_new.fillna(prior, inplace=<span class="keyword">True</span>)</div></pre></td></tr></table></figure></p>
<ul>
<li>Fold를 나누어서 validation set의 feature를 train set의 <code>mean encoding</code>으로 설정 (보통 4~5 정도면 충분)
<ul>
<li>NA값은 global mean으로 설정</li>
</ul>
</li>
</ul>
<p>단 LOO (Leave one out)같은 극단적인 경우는 주의</p>
<h3>2.2 Smoothing</h3>
<p>다른 regularization을 얼만큼 적용시킬지를 <code>Alpha</code>값을 이용하여 설정</p>
<p>$$ \frac{mean(target)<em>nrows + globalmean</em>alpha}{nrows + alpha} $$</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.03.21.png" alt=""></p>
<h3>2.3 Noise</h3>
<p>통상적으로 노이즈를 추가하면 encoding의 품질이 저하되어서 얼마나 넣어야 할지 고민을 많이 해야 한다. LOO와 함께 사용하면 효과적이다. (자세한 설명이 없음)</p>
<h3>2.4 Expanding mean</h3>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">cumsum = df_tr.groupby(col)[<span class="string">'target'</span>].cumsum() - df_tr[<span class="string">'target'</span>]</div><div class="line">cumcnt = df_tr.groupby(col).cumcount()</div><div class="line">train_new[col+<span class="string">'_mean_target'</span>] = cumsum/cumcnt</div></pre></td></tr></table></figure></p>
<ul>
<li>CatBoost애는 내장된 방식</li>
<li>Leakage를 줄일 수 있으나 품질이 불규칙적이다.</li>
</ul>
<h2>3. Generalizations and extensions</h2>
<h3>3.1 Regression과 Multiclass</h3>
<ul>
<li>Regression : percentile, std, distribution bin등의 통계함수를 추가</li>
<li>Multiclass : 각각의 class별로 encoding</li>
</ul>
<h3>3.2 Many-to-many relation</h3>
<ul>
<li>Cross product</li>
<li>Statistics from vectors</li>
</ul>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.03.18.png" alt=""></p>
<p>APPS를 각각의 row로 나눔</p>
<h3>3.3 Time series</h3>
<p>time-series 데이터의 경우 앞의 방법들을 사용하는게 의미 없을 수 있다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.03.19.png" alt=""></p>
<p>위 예제의 경우 <code>Day-User-전날 Amount 합</code>과 <code>Day-Spend-전날 Amount 평균</code>을 feature로 추가하였다.</p>
<h3>3.4 Interactions and numerical features</h3>
<ul>
<li>numeric feature를 bin하여 categorical feature로 만드는 방법이다.
<ul>
<li>EDA 과정을 통해서 숫자상의 어떤 점에서 target값의 분기가 일어나는지를 관찰하는 것이 유용하다.</li>
</ul>
</li>
<li>feature 2개 이상이 상호작용적으로 동작하는 경우에는 그것들을 합하여 <code>mean encoding</code>하는 방법도 있다.</li>
</ul>
<h3>Correct validation reminder</h3>
<ul>
<li>Local experiments:
‒ Estimate encodings on X_tr
‒ Map them to X_tr and X_val
‒ Regularize on X_tr
‒ Validate model on X_tr/ X_val split</li>
<li>Submission:
‒ Estimate encodings on whole Train data
‒ Map them to Train and Test
‒ Regularize on Train
‒ Fit on Train</li>
</ul>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.03.20.png" alt=""></p>
<ul>
<li>Main advantages:
‒ Compact transformation of categorical variables
‒ Powerful basis for feature engineering</li>
<li>Disadvantages:
‒ Need careful validation, there a lot of ways to overfit
‒ Significant improvements only on specific datasets</li>
</ul>
<h2>4. Statistics and distance based features</h2>
<p>1개의 feature를 <code>groupby</code>하여 계산한 다양한 통계값을 활용</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.11.png" alt=""></p>
<p>위 그림의 경우 <code>[User_id, Page_id, Ad_price, Ad_position]</code>은 원래 있던 feature들이고 <code>[Max_price, min_price, Min_price_position]</code>은 추가로 생성한 feature들이다.</p>
<ul>
<li>Max_price : Page_id로 groupby한 MAX(Ad_price)</li>
<li>min_price : Page_id로 groupby한 MIN(Ad_price)</li>
<li>Min_price_position : Page_id내에서 Ad_price == min_price 에 해당하는 Ad_posision</li>
</ul>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">gb = df.groupby([<span class="string">'user_id'</span>, <span class="string">'page_id'</span>], as_index=<span class="keyword">False</span>)</div><div class="line">       .agg(&#123;<span class="string">'ad_price'</span>: &#123;<span class="string">'max_price'</span>: np.max, <span class="string">'min_price'</span>: np.min&#125;&#125;)</div><div class="line">gb.columns = [<span class="string">'user_id'</span>, <span class="string">'page_id'</span>, <span class="string">'min_price'</span>, <span class="string">'max_price'</span>]</div><div class="line"></div><div class="line">df = pd.merge(df, gb, how=<span class="string">'left'</span>, on=[<span class="string">'user_id'</span>, <span class="string">'page_id'</span>])</div></pre></td></tr></table></figure></p>
<p>위에 예제로 보인 featue뿐만 아니라 다양한 것들을 생각해 볼 수 있다.</p>
<ul>
<li>user가 얼마나 많은 page를 방문했는지</li>
<li>price의 표준편차</li>
<li>가장 많이 방문한 page</li>
<li>등등...</li>
</ul>
<p>그런데, groupby 할 수 없는 feature는 어떻게 해야할까 ? 그럴 경우 <code>kNN</code>과 같은 클러스터링 기법들로 대체가 가능하다.</p>
<ul>
<li>500m, 1000m 이내에 있는 집의 수</li>
<li>500m, 1000m 이내에 있는 집의 평균 평당가</li>
<li>500m, 1000m 이내에 있는 학교/슈퍼마켓/주차장 수</li>
<li>가장 가까운 지하철역</li>
</ul>
<p>사례: <em>Springleaf</em>에 사용된 kNN feature들</p>
<ul>
<li>모든 변수에 대해서 <code>mean encoding</code></li>
<li>모든 point에서 <em>Bray-Cutis metric</em>을 이용하여 2000-NN을 찾음
<img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.12.png" alt=""></li>
<li>2000개의 이웃으로 다양한 feature들을 계산
<ul>
<li>5, 10, 15, 500, 2000개의 NN의 target mean값</li>
<li>10개의 가까운 이웃들과의 distance mean값</li>
<li>10개의 가까운 이웃중 target이 1/0인 것과의 distance mean</li>
<li>등등...</li>
</ul>
</li>
</ul>
<h2>5. Matrix Factorizations for Feature Extraction</h2>
<p>feature 추출에 행렬 분해 기법을 활용하는 방법들이다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.13.png" alt=""></p>
<p>예를 들어 사용자별로 연령, 지역, 관심사, 성별 등의 feature들이 있고, 이러한 정보에 따른 등급 정보가 있는 경우 이 둘을 matrix 곱으로 표현할 수 있다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.14.png" alt=""></p>
<p>text 분류기의 경우에도 보통 sparse matrix로 표현되는 것을 각각의 matrix로 표현하는 것이 가능하다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.15.png" alt=""></p>
<p>여러 방법들을 섞어서 사용하기도 한다.</p>
<p>Matrix Factorization 진행시</p>
<ul>
<li>몇개의 column만을 적용시키기도 함.</li>
<li>다양한 것의 추가가 가능하다. (Ensemble에 효과적)</li>
<li>손실 변환(lossy transformation)이다.
<ul>
<li>특정 작업에 의존적이므로 경험적으로 해야한다.</li>
<li>factor는 보통 5 ~ 100 사이로 설정한다.</li>
</ul>
</li>
</ul>
<p><strong>sklearn</strong>에 Matrix Factorization의 구현체가 있음</p>
<ul>
<li><code>SVD</code>, <code>PCA</code> : MF용 stadard tool</li>
<li><code>TruncatedSVD</code> : sparse matrices용</li>
<li><code>NMF</code> (Non-negative MF) : count-like한 데이터에 좋음. 모든 데이터가 non-negative인게 보장됨</li>
</ul>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.16.png" alt=""></p>
<p>위 그림을 보면 <code>NMF</code>를 적용하니 linear model처럼 분리되는 것을 볼 수 있다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.17.png" alt=""></p>
<p><code>log(X+1)</code>를 적용하는 등의 다양한 trick을 시도해 볼 수 있다.</p>
<p>MF 적용시 train, test를 각각따로 적용하면 안된다. 둘을 함께 적용시켜야 올바른 결과가 나온다.</p>
<ul>
<li>
<p>Wrong way
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">pca = PCA(n_components=<span class="number">5</span>)</div><div class="line">X_train_pca = pca.fit_transform(X_train)</div><div class="line">X_test_pca = pca.fit_transform(X_test)</div></pre></td></tr></table></figure></p>
</li>
<li>
<p>Right way
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">X_all = np.concatenate([X_train, X_test])</div><div class="line">pca.fit(X_all)</div><div class="line">X_train_pca = pca.transform(X_train)</div><div class="line">X_test_pca = pca.transform(X_test)</div></pre></td></tr></table></figure></p>
</li>
<li>
<p>MF는 차원 축소와 feature 추출에 좋다.</p>
</li>
<li>
<p>categorical feature를 좀 더 현실적인 값으로 변경해준다.</p>
</li>
<li>
<p>linear model화 되도록 적절한 trick을 적용하면 유용하다.</p>
</li>
</ul>
<h2>6. Feature interactions</h2>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.18.png" alt=""></p>
<p>위 경우를 보면 category_ad와 category_site가 있는데, 정작 중요한 것은 그 둘의 조합이다. 이 경우 그 둘을 concat하여 ad_site로 하는게 더 효율적일 수 있다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.19.png" alt=""></p>
<p>위 경우에서 FI 방법에 대해서 2가지로 생각해보다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.20.png" alt=""></p>
<p>첫번째 방법은 앞에서 본 경우와 같이 f1과 f2를 조합하여 one-hot을 적용시킨 방법이다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.21.png" alt=""></p>
<p>두번째 방법으로는 f1과 f2를 각각 one-hot한 다음 그 둘을 조합한다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.22.png" alt=""></p>
<p>FI의 또 다른 예로 f1과 f2가 둘 다 numeric일 경우 그 둘을 곱하는 방법도 있다.</p>
<p>이렇게 곱, 합, 차, 나누기 등을 적용하는 방법들을 생각해 보자.<br>
모든 feature에 그렇게하기에는 조합을 할 수 있는 경우의 수가 너무나도 많다.<br>
어떻게 유의미한 것들만을 골라내서 차원을 줄일 수 있을까 ?</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.23.png" alt=""></p>
<ul>
<li>Random Forest로 일단 돌려본 다음</li>
<li>Feature Importance를 보고</li>
<li>유의미한 것들만을 추출</li>
</ul>
<p><code>Decision Tree</code>를 이용하여 feature를 추출하는 방법도 있다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.24.png" alt=""></p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># In sklearn</span></div><div class="line">tree_model.apply()</div><div class="line"></div><div class="line"><span class="comment"># In XGBoost</span></div><div class="line">booster.predict(pred_leaf=<span class="keyword">True</span>)</div></pre></td></tr></table></figure></p>
<h2>7. tSNE</h2>
<p>앞서 <code>NMF</code>를 이용하여 linear model에 가깝게 변화시키는 것을 본 적이 있다.</p>
<h3>7.1 Manifold Learning</h3>
<p>비선형 차원 축소 방법 (non-linear method of dimensionality reduction)</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.25.png" alt=""></p>
<p>데이터를 차원변환시켜서 해석하기 쉬운형태로 분리하는게 가능하다.</p>
<h3>7.2 MNIST의 tSNE 반영 결과</h3>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.26.png" alt=""></p>
<p>2차원 공간에 투영된 700차원 공간</p>
<p><code>Perplexity</code> hyperparameter를 어떻게 설정하느냐에 따라 결과가 달라진다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.27.png" alt=""></p>
<p>여기에 대해 정리된 내용은 다음과 같다.</p>
<ul>
<li><code>Perplexity</code> hyperparameter값에 크게 의존적이다.
<ul>
<li>5 ~ 100 사이 값이 결과가 대체로 좋았다.</li>
</ul>
</li>
<li>확률적 특징때문에 같은 데이터, perplexity 갑이라도 다른 결과가 나온다.
<ul>
<li>train, test는 같이 투영되어야 한다.</li>
</ul>
</li>
<li>feature가 많으면 오래 걸린다.
<ul>
<li>그래서 보통 투영하기전에 차원축소를 한다.</li>
</ul>
</li>
<li>tSNE의 구현체는 <code>sklearn</code>에 있다.
<ul>
<li>하지만, 파이썬의 개별패키지로 하는게 더 빠르기 때문에 추천하지는 않는다.</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://DevStarSJ.github.io/2018/11/04/kaggle.coursera.competition.03.02/" data-id="cjov1wtre009bjw7bpx5jafa7" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DataScience/">DataScience</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kaggle/">Kaggle</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MachineLearning/">MachineLearning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-kaggle.coursera.competition.04.02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/10/30/kaggle.coursera.competition.04.02/" class="article-date">
  <time datetime="2018-10-30T08:53:00.000Z" itemprop="datePublished">2018-10-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/DataScience/">DataScience</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/10/30/kaggle.coursera.competition.04.02/">Coursera Kaggle 강의(How to win a data science competition) week 4-4 Ensemble 요약</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1>Coursera Kaggle 강의(How to win a data science competition) week 4-4 Ensemble 요약</h1>
<h2>Ensemble</h2>
<ul>
<li>여러가지 머신 러닝 모델을 결합하는 방법</li>
</ul>
<h3>1. Averaging (or blending)</h3>
<p>여러 모델의 결과값의 평균을 취함</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.01.png" alt=""></p>
<p>위와 같은 2개의 모델이 있을 경우</p>
<h4>1.1 Averaging</h4>
<p>단순 평균</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.02.png" alt=""></p>
<h4>1.2 Weighted averaging</h4>
<p>가중 평균</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.02.png" alt=""></p>
<h4>1.3 Conditional averaging</h4>
<p>조건 평균</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.04.png" alt=""></p>
<h3>2. Bagging</h3>
<p>동일한 모델의 약간 다른 버전의 평균. 대표적인 예로 Random Forest</p>
<p>Bagging을 하는 이유로는 모델이 가지는 2가지 문제를 해결하기 위해서다.</p>
<ol>
<li>Underfitting : Bias</li>
<li>Overfitting : Variance</li>
</ol>
<p>Bagging용 파라메터</p>
<ul>
<li>Random seed</li>
<li>Row (Sub) sampling or Bootstrapping</li>
<li>Shuffling</li>
<li>Column (sub) sampling</li>
<li>Model-specific parameters</li>
<li>Number of models (or bags) : 보통 10 이상으로 하지만, 어느 순간 성능의 정체상태가 온다.</li>
</ul>
<p>Bagging 예제 코드 : <code>BaggingClasifier</code> and <code>BeggingRegressor</code> from sklearn</p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">model = RandomForestRegressor()</div><div class="line">bags = <span class="number">10</span></div><div class="line">seed = <span class="number">1</span></div><div class="line"></div><div class="line">bagged_prediction = np.zeros(test.shape[<span class="number">0</span>])</div><div class="line"></div><div class="line"><span class="keyword">for</span> n <span class="keyword">in</span> range(<span class="number">0</span>, bags):</div><div class="line">    model.set_params(random_state = seed + n)</div><div class="line">    model.fit(train, y)</div><div class="line">    preds = mpdel.predict(test)</div><div class="line">    bagged_prediction += preds</div><div class="line"></div><div class="line">bagged_prediction /= bags</div></pre></td></tr></table></figure></p>
<h3>3. Boosting</h3>
<p>Boosting이란 이전 모델의 성능을 고려한 방식으로 순차적으로 구축되는 모델의 가중 평균으로 구하는 방식이다.</p>
<p>Boosting에는 2가지 방법이 있다.</p>
<ol>
<li>Weight based Boosting (웨이트 기반)</li>
<li>Residual based Boosting (잔여 오류 기반)</li>
</ol>
<h4>3.1 Weight based Boosting</h4>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.05.png" alt=""></p>
<p>위 예에서 우리가 구한 predict값이 <code>pred</code>라고 했을시 타겟(y)과의 절대차를 <code>abs.error</code>라고 했을 경우, 1에다가 절대차를 더한 값으로 <code>weight</code>로 설정한다. weight를 계산하는 방법은 이것 말고도 다른 방법들이 있다.</p>
<p>다음에 학습시킬 때는 이 weight를 feature에 추가하여 진행한다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.06.png" alt=""></p>
<p>Weight based Boosting의 parameter들</p>
<ul>
<li>Learning rate</li>
<li>Number of estimators</li>
<li>Input model</li>
<li>Sub boosting type : AdaBoost (sklearn), LogitBoost (Weka - Java)</li>
</ul>
<h4>3.2 Residual based boosting</h4>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.07.png" alt=""></p>
<p>이번에는 <code>pred</code>값으로 <code>error</code>값을 구한 다음 그 error를 타겟으로 해서 학습을 진행한다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.08.png" alt=""></p>
<p>그렇게 학습한 뒤에 새로운 <code>new_pred</code>값에 기존 <code>pred</code> 값을 더하여 최종 <code>predict</code>값으로 설정한다.<br>
위 그림에서 Rownum = 1의 경우 <code>0.2 + 0.75 = 0.95</code>가 최종 predict가 되는 것이며, Rownum = 4의 경우에는 <code>-0.2 + 0.55 = 0.35</code>가 되는 것이다. 이런식으로 계산하면 정확도가 많이 향상된다.</p>
<p>Weight based Boosting의 parameter들</p>
<ul>
<li>Learning rate</li>
<li>Number of estimators</li>
<li>Row (sub) sampling</li>
<li>Column (sub) sampling</li>
<li>Input model : tree 모델이 좋음</li>
<li>Sub boosting type: Fully gradient based, Dart</li>
</ul>
<p>Residual based로 구현된 모델로는 XGBoost, LightGBM, H2O's GBM, CatBoost, Sklearn's GBM 등이 있다.</p>
<h3>4. Stacking</h3>
<p>여러가지 모델로 학습한 결과로 새로운 데이터셋을 만드는 방법이다. 앙상블 방법 중 가장 인기가 많다.</p>
<p>1992년 Wolpert에 의해서 stacking이 소개 되었다. 그것은 다음과 같다.</p>
<ol>
<li>train 데이터를 2개로 나눈다.</li>
<li>그중 하나로 여러 가지 모델을 학습시킨다. (base learner)</li>
<li>2번에서 생성한 모델들로 prediction을 진행한다</li>
<li>3번에서 생성한 prediction으로 다른 모델을 학습한다. (higher level learner)</li>
</ol>
<p>Stacking example
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</div><div class="line"><span class="keyword">from</span> sklearn.lear_model <span class="keyword">import</span> LinearRegression</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</div><div class="line"></div><div class="line">training, valid, ytraining, yvalid = train_test_split(train, y, test_size=<span class="number">0.5</span>)</div><div class="line"></div><div class="line">model1 = RandomForestRegerssor()</div><div class="line">model2 = LinearRegression()</div><div class="line"></div><div class="line">model1.fit(training, ytraining)</div><div class="line">model2.fit(training, ytraining)</div><div class="line"></div><div class="line">preds1 = model1.predict(valid)</div><div class="line">preds2 = model2.predcit(valid)</div><div class="line"></div><div class="line">test_preds1 = model1.predict(test)</div><div class="line">test_preds2 = model2.predcit(test)</div><div class="line"></div><div class="line">stacked_predictions = np.column_stack((preds1, preds2))</div><div class="line">stacked_test_predictions = np.column_stack((test_preds1, test_preds2))</div><div class="line"></div><div class="line">meta_model = LinearRegression()</div><div class="line">meta_model.fit(stacked_predictions, yvalid)</div><div class="line"></div><div class="line">final_predictions = meta_model.predict(stacked_test_predictions)</div></pre></td></tr></table></figure></p>
<h3>4. StackNet</h3>
<p>Stacking을 Neural Network 방식으로 여러 Layer로 구성한 방법이다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.09.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.04.10.png" alt=""></p>
<p>앞서 본 Stacking에서는 train을 2부분으로 나누어서 진행하였다. StackNet에서 Layer를 추가해야한다고 한다면 이걸 다시 나누어야 한다.<br>
우리가 충분히 많은 데이터셋을 가지고 있지 않다면 끊임없이 나누지 않고 작업을 수행해도 된다.</p>
<p>데이터를 나눌때 <code>K-Fold</code> 패러다임을 사용하는 방법이 있다. K = 4 라는 상황을 가정한다면 train 데이터를 4개로 나누어 4개의 모델에 대해서 그 중 3개로 학습하고 1개로 validation한 모델들을 만든 다음 전체 train 데이터에 predict한 결과를 생성하여 Stacking을 수행한다. 또는 평균을 취할 수도 있다.</p>
<p>StakNet에서는 하지만 Neural Network의 back propagation이 지원되지는 않는다. 왜냐면 모든 모델이 다 미분이 가능하지는 않을 수 있기 때문이다.</p>
<h4>1st level tips</h4>
<ul>
<li>
<p>Diversity based on algorithms:</p>
<ul>
<li>2-3 Gradient boosted trees (LightGBM, XGBoost, H2O, CatBoost)</li>
<li>2-3 Neural Nets (Keras, PyTouch)</li>
<li>1-2 ExtraTrees / Random Forest (sklearn)</li>
<li>1-2 Linear Models as in logistic/ridge regression, linear svm (sklearn)</li>
<li>1-2 knn models (sklearn)</li>
<li>1 Factorixation machine (libfm)</li>
<li>1 Svm with nonlinear kernel if size/memory allows (sklearn)</li>
</ul>
</li>
<li>
<p>Diversity based on input data:</p>
<ul>
<li>Categorical features: One hot, Label encoding, Target encodingm Frequency</li>
<li>Numerical features: Outliers, Binning, Derivatives, Percentiles, Scaling</li>
<li>Interactions: col1*/+-col2, groupby, unsupervised</li>
</ul>
</li>
</ul>
<h4>Subsequenct level tips</h4>
<ul>
<li>
<p>Simpler (or shallower) Algorithms:</p>
<ul>
<li>Gradient boosted trees with small depth (like 2 or 3)</li>
<li>Linear models with high regularization</li>
<li>Extra Trees</li>
<li>Shallow networks (as in 1 hidden layer)</li>
<li>Knn with BrayCutis distance</li>
<li>Brute forcing a search for best linear weights based on cv</li>
</ul>
</li>
<li>
<p>Feature engineering</p>
<ul>
<li>pairwise differences between meta features</li>
<li>row-wise statistics like averages or stds</li>
<li>Standard feature selection techniques</li>
</ul>
</li>
<li>
<p>For Every 7.5 models in previous level we add 1 in meta (empirical)</p>
</li>
<li>
<p>Be mindful of target leakage</p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://DevStarSJ.github.io/2018/10/30/kaggle.coursera.competition.04.02/" data-id="cjov1wtrg009fjw7b3b3rvme3" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DataScience/">DataScience</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kaggle/">Kaggle</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MachineLearning/">MachineLearning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-kaggle.coursera.competition.04.01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/10/30/kaggle.coursera.competition.04.01/" class="article-date">
  <time datetime="2018-10-30T06:08:00.000Z" itemprop="datePublished">2018-10-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/DataScience/">DataScience</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/10/30/kaggle.coursera.competition.04.01/">Coursera Kaggle 강의(How to win a data science competition) week 4-1 Hyperparameter Tuning 요약</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1>Coursera Kaggle 강의(How to win a data science competition) week 4-1 Hyperparameter Tuning 요약</h1>
<h2>Hyperparameter Tuning</h2>
<ul>
<li>
<p>어떤 hyperparameter가 모델에 가장 큰 영향을 미치는지 알아야 한다.</p>
</li>
<li>
<p>모든 hyperparameter를 튜닝할 시간이 없다.</p>
</li>
<li>
<p>수동 : 변경 후 결과 측정</p>
</li>
<li>
<p>자동화된 라이브러리</p>
<ul>
<li>Hyperopt</li>
<li>Scikit-optimize</li>
<li>Spearmint</li>
<li>GpyOpt</li>
<li>RobO</li>
<li>SMAC3</li>
</ul>
</li>
</ul>
<p>일반적으로 수동으로 하는것이 더 빠르다.</p>
<p>Hyperparameter 중 해당 값이 커질수록 underfitting 되는 것도 있고 (red), 해당 값이 커질수록 overfitting 되는 것도 있다. (green)</p>
<h2>1. Tree-based models</h2>
<p>XGBoost, LightGBM, CatBoost, sklearn의 RandomForest 및 Extra Trees models, Regularized Greedy Forest 등...</p>
<h3>1.1 Gradient Boosting</h3>
<p>트리를 만드는 매개변수</p>
<ul>
<li>
<p>max_depth (XGBoost, LightGBM) (green) : tree의 최대 깊이. 클수록 fit이 더 빠르게 됨. 하지만 학습 시간이 굉장히 오래 걸리게됨. 통상적으로 7로 시작하는게 좋음.</p>
</li>
<li>
<p>num_leaves (LightGBM) (green): 트리의 리프수를 제어</p>
</li>
<li>
<p>subsample (XGBoost), bagging_fraction (LightGBM) (green): 0 ~ 1</p>
</li>
<li>
<p>colsample_bytree, colsample_bylevel (XGBoost), feature_fraction (LightGBM) (green) : tree 분할시 일부만을 사용</p>
</li>
<li>
<p>min_child_weight (XGBoost), min_data_in_leaf (LightGBM) / lambda, alpha (XGBoost) , lambda_l1, lambda_l2 (LightGBM) (red): 정규화 매개변수, min_child_weight가 가장 중요. 최소값은 0 (가장 보수적 모델). 작업에 따라 최적 값은 0, 5, 15, 300 되르모 넓은 값을 사용하는 것에 주저하지 마라.</p>
</li>
</ul>
<p>학습관련 매개변수</p>
<ul>
<li>eta (XGBoost), learning_rate (LightGBM) (green): 학습 가중치. 너무 낮으면 수렴하지 않을 수 있음.</li>
<li>num_round (XGBoost), num_iterations (LightGBM) (green): 학습 회수</li>
</ul>
<p>random seed를 바꾸는 방법도 있지만, 일반적으로 큰 차이가 없다.</p>
<h3>1.2 Random Forest, Extra Trees</h3>
<p>Extra Trees는 Random Forest의 무작위 버전이며 매개변수가 동일</p>
<ul>
<li>n_estimators : 트리 수, 매루 작은 수(10)로 설정하여 시간이 얼마나 걸리는지 본 다음 300 정도의 큰 값으로 설정하는 식으로 접근. 어느 시점 이후에는 그 변화가 미비할 수 있으므로 적당값을 찾는게 좋기는 하지만, 클 수록 좋음.</li>
<li>max_depth (green) : 트리의 깊이. 7로 시작하는게 좋으나 일반적으로 Random Forest 의 최적값은 Gradient Boosting보다 높으므로 주저없이 높게 설정해라. None으로 설정하면 깊이가 무제한으로 생성된다.</li>
<li>max_features (green) : subsample(XGBoost) 과 비슷함.</li>
<li>min_samples_leaf (red) : min_child_weight (XGBoost)와 비슷</li>
</ul>
<p>Random Forest Classifier의 경우 트리 분할을 향상시키는 기준으로 Gini 와 Entropy를 사용하는데, 둘 다 시도해서 성능이 좋은 것을 선택해야 한다. 자주 Gini가 더 좋지만, Entropy가 더 좋은 경우도 있다.</p>
<ul>
<li>random_state : 랜덤 시드</li>
<li>n_jobs : 보유한 코어 수로 설정</li>
</ul>
<h2>2. Neural Nets</h2>
<p>Keras, PyTouch, Tensorflow, MxNet, ...</p>
<ul>
<li>layer 의 뉴론 수 (green)</li>
<li>layer 수 (green)</li>
<li>Optimizers
<ul>
<li>SGD + momentum (red)</li>
<li>Adam / Adamdelta / Adagrad / ... (green)</li>
</ul>
</li>
<li>Batch size (green)</li>
<li>Learning rate</li>
<li>Regularization
<ul>
<li>L1 / L2 for weights (red)</li>
<li>Dropout / Dropconnect (red)</li>
<li>Static dropconnect (red)</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://DevStarSJ.github.io/2018/10/30/kaggle.coursera.competition.04.01/" data-id="cjov1wtrc0097jw7bbh31r4r9" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DataScience/">DataScience</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kaggle/">Kaggle</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MachineLearning/">MachineLearning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-181030.data.philosophy" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/10/30/181030.data.philosophy/" class="article-date">
  <time datetime="2018-10-29T23:52:00.000Z" itemprop="datePublished">2018-10-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Book/">Book</a>►<a class="article-category-link" href="/categories/Book/Review/">Review</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/10/30/181030.data.philosophy/">데이터를 철학하다</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2>데이터를 철학하다</h2>
<ul>
<li>흐름출판</li>
<li>정석권 지음</li>
</ul>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Review/Books/image/data.philosophy.jpg" alt=""></p>
<p>제목부터가 낮설었다. 데이터라는 단어와 철학이라는 단어가 어우러 질 수 있을까 ?</p>
<p>책의 전개는 <strong>데이터</strong> -&gt; <strong>정보</strong> -&gt; <strong>지능</strong> -&gt; <strong>지혜</strong> 의 순이다.
인문학 책이면서도 통계학과 머신러닝에 관련된 기초지식이 없은 상태에서 읽었을 경우 이해하기 힘든 부분이 존재한다.
한번 읽은 상태에서 리뷰에 작가의 모든 생각을 다 이해하고 적기는 힘들듯 해서, 기억에 남는 구절들을 인용하는 것으로 리뷰를 진행하겠다.</p>
<p>아래에 나온 <code>키워드</code> 중 관심이 가는 분야가 있다면 한 번 읽어보기를 추천한다.</p>
<h3>불확실성</h3>
<p>p.108 ~</p>
<p><strong>불확실성</strong>은 우리 세계를 지배하는 가장 큰 요소 중 하나다. 정보가 이로운 것은 <strong>정보</strong>야말로 불확실성을 줄이는 유일한 수단이기 때문이다.</p>
<h3>자율 조정</h3>
<p>p.120 ~</p>
<p><strong>자율 조정</strong>은 우리 주위에 늘 존재하는 시스템의 특징 중 하나이다. 실시간 자율 조정 시스템이 요구하는 정보는 정확성과 지연 시간 면에서 매우 엄격한 요건을 충족시켜야 한다.</p>
<h3>정보 탐색</h3>
<p>p.152 ~</p>
<p>정보 탐색의 4가지 방법</p>
<ul>
<li>스캐닝 : 새로운 것을 광범위하게</li>
<li>개관 : 잘 알려진 것을 광법위하게</li>
<li>모니터링 : 새로운 것을 제한된 범위안에</li>
<li>연구 : 잘 알려진 것을 제한된 범위안에</li>
</ul>
<h3>정보 전달</h3>
<p>p.207 ~</p>
<p><strong>정보 전달</strong>의 핵심은 두 가지다. 첫째는 원하는 정보가 정확히 무엇인지를 파악하는 것, 둘때는 그 정보를 가장 소화하기 좋게 표현하는 것이다.</p>
<h3>벤포드 법칙</h3>
<p>p.259 ~</p>
<p>자연에 존재하는 수들의 첫 자리가 1,2 일 확률이 상대적으로 다른 수에 비해 크다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Review/Books/image/benford.png" alt=""></p>
<p>이를 이용하여 회계데이터에 관해서 포렌식 수사기법으로 널리 활용되기 시작했다.</p>
<h3>추론</h3>
<p>p.264 ~</p>
<p>**추론(inference)은 이미 발생한 사건이나 사고를 두고 그 원인을 논리적으로 엄정하게 밝혀내는 활동을 말한다.</p>
<h3>상호작용</h3>
<p>p.283 ~</p>
<p>서로 다른 서비스 간에 나타나는 <strong>상호 작용</strong>으로서 <strong>대체 효과</strong>와 <strong>보완 효과</strong> 외 <strong>시너지 효과</strong>가 있다. <code>P(A + B) &gt; P(A) + P(B)</code>이면 시너지 효과가 존재하는 것이다. 반면 그 부호가 반대로 나타나서 <code>P(A + B) &lt; P(A) + P(B)</code>이면 서로 다른 서비스 간에 시너지가 아니라 <strong>잠식 효과</strong>가 존재한다는 의미다. 결국 시간이 지나면서 나타나는 생태계 참여자끼리의 상호 작용은 대체 혹은 보완, 시너지 혹은 잠식의 다양한 유형으로 나타난다.</p>
<p><strong>자신 내의 상호 작용</strong>은 다양하게 존재한다. <code>P(2A) &gt; 2P(A)</code>이면 <strong>가속 현상</strong>, 즉 자기 시너지가 있다고 한다. 이외는 반대로 <code>P(2A) &lt; 2P(A)</code>이면dlaus <strong>감속 현상</strong>, 즉 자기 잠식이 있다고 한다. (시계열 데이터 분석에서 사용. 눈덩이 현상)</p>
<h3>내 주위의 알고리즘</h3>
<p>p.301 ~</p>
<p>우리가 주위를 <strong>알고리즘</strong>으로 채우면, 알고리즘으로 채워진 환경은 다시 우리를 변화시킨다.</p>
<ul>
<li>배낭 문제(knappack problem) : <a href="https://en.wikipedia.org/wiki/Knapsack_problem" target="_blank" rel="external">https://en.wikipedia.org/wiki/Knapsack_problem</a></li>
<li>외판원 문제(traveling salesman problem) : <a href="https://en.wikipedia.org/wiki/Travelling_salesman_problem" target="_blank" rel="external">https://en.wikipedia.org/wiki/Travelling_salesman_problem</a></li>
</ul>
<h3>신뢰와 주도권</h3>
<p>p.342 ~</p>
<p><strong>생태계</strong>를 지배하고자 하는 자는 자신의 가치보다는 생태계의 가치를 추구해야 한다.</p>
<ul>
<li>죄수의 딜레마(Prisoner's dilemma) : 모두 죄를 자백하지 않으면 처벌을 안 받지만, 한 사람만 자백하면 자백하지 않은 사람이 강한 처벌을 받는 상황이라, 결국 두 사람이 모두 자백하여 처벌을 받게 된다.</li>
<li>내시 균형(Nash equilibrium) : 상대방이 선택을 바꾸지 않는 항, 나도 선택을 바꿀 동기가 없는 균형 상태
<ol>
<li>게임에 참여하는 생태계 참여자 간 상호 신뢰가 없을 때, 내시 균형은 최선이 아니라 처선 또는 차악에서 이루어진다.</li>
<li>각자가 자신의 이해를 따져 최선을 다해도, 그들의 집합체인 생태계는 최선에 이르지 못한다. <code>보이지 않는 손</code>이 만능이 아니다.</li>
<li>게임 이론은 생태계 참여자 그 어느 누구의 순수한 동기(incenitive)도 존중한다.</li>
</ol>
</li>
</ul>
<h3>글로벌 생태계</h3>
<p>p.349 ~</p>
<p>독자적 <strong>글로벌 생태계</strong>를 구축하려고 노력하라. 그것이 여의치 않으면 경쟁력이 있는 생태계 파트너십을 가지고 참여하라.</p>
<p>생태계의 경쟁력 기반은 <strong>플랫폼</strong>에서 나온다. 새로운 생태계 구축을 위한 플랫폼의 개발 및 확산에 주목하라. 일단 생태계가 구축되고 나면, 생태계 내에서 동반자로서의 독자적이고 차별적인 위치를 확보하라.</p>
<h3>호모 소포스 (Homo sophos)</h3>
<p>p.371 ~</p>
<p><strong>호모 소포스 (Homo sophos)</strong> 는 빅 인텔리전스 시대에 적합하게 재정립된 인간상, 즉 <code>지혜로운 인간</code>을 지칭한다. 포스트휴먼이 차세대 인류라며 호모 소포스는 바람직한 인류의 미래상이다.</p>
<ul>
<li>호모 소포스는 적응하는 인간이다. 주관을 가지고 새로운 체제에 적응하라.</li>
<li>호모 소포스는 공생하는 인간이다. 인공 지능과 함꼐 사는 지혜를 모색하라.</li>
<li>호모 소포스는 달관하는 인간이다. 자연과 함께 살아가는 지혜를 모색하라.</li>
<li>빅 인텔리전스 세상에서 부가 가치 생산성의 극대화를 꾀하라.</li>
<li>나에 대한 시장의 믿음과 기대가 나를 키운다. 신뢰 자산을 키우려고 노력하라.</li>
<li>빅 인텔리전스 세상에서 포지셔닝을 잘 선택하라. 입지와 타이밍이 중요하다.</li>
<li>빅 인텔리전스 세상에서 여유 시간을 확보해 인간 고유의 창의성을 배양하라.</li>
<li>빅 인텔리전스 세상의 거버넌스 구조를 미리 설계하라.</li>
<li>빅 인텔리전스 세상에 대비하여 투명성 규제를 강화하라.</li>
<li>빅 인텔리전스 세상에서 <code>보이지 않는 손</code>이 작동하게 하라.</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://DevStarSJ.github.io/2018/10/30/181030.data.philosophy/" data-id="cjov1wtnv002qjw7blvki8wso" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Book/">Book</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Review/">Review</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-kaggle.coursera.competition.03.01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/10/22/kaggle.coursera.competition.03.01/" class="article-date">
  <time datetime="2018-10-22T02:04:00.000Z" itemprop="datePublished">2018-10-22</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/DataScience/">DataScience</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/10/22/kaggle.coursera.competition.03.01/">Coursera Kaggle 강의(How to win a data science competition) week 3-1 Metrics 요약</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1>Coursera Kaggle 강의(How to win a data science competition) week 3-1 Metrics 요약</h1>
<h2>Metrics</h2>
<p>어떤 metric을 사용하느냐에 따라 모델이 학습하는 방향이 다르다. 우리가 풀고자하는 문제에 최적화된 metric을 선택하는 것이 중요하다.</p>
<h3>1. Regression metrics</h3>
<h4>1.1 MSE, RMSE, R-squared</h4>
<ul>
<li><strong>MSE</strong> (Mean Square Error) : target과 predict의 차이값의 제곱의 평균
<ul>
<li><code>Best Constant</code> : target mean</li>
<li><code>sklearn.metrics.mean_squared_error</code></li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.03.01.png" alt=""></p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.03.02.png" alt=""></p>
<ul>
<li><strong>RMSE</strong> (Root Mean Square Error): MSE에 root취한 값</li>
</ul>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.03.03.png" alt=""></p>
<p>MSE의 최소값이 RMSE에서도 최소값이므로 최적화 결과가 같다. 그래서 비교적 구현이 간단한 MSE를 사용하는 경우가 많지만, <strong>learning rate</strong> 같은 몇몇의 hyperparameter 값에 따라 다르게 동작 할 수 있다.<br>
MSE와 RMSE 값이 32라고 성능이 좋은지 나쁜지 판단이 힘들다. 그래서 상대적인 값으로 평가가 필요할 수 있다.</p>
<ul>
<li><strong>R2</strong> (R Squared)
<ul>
<li><code>sklearn.metrics.r2_score</code></li>
<li>P-Value와 같이 0 ~ 1 사이의 값을 나타내는데, MSE가 0 이면 R2는 1이며, MSE가 constant 모델보다 클 때 R2는 0이다.</li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.03.04.png" alt=""></p>
<h4>1.2 MAE, RMAE</h4>
<ul>
<li><strong>MAE</strong> (Mean Absolute Error): target과 predict의 차이 절대값
<ul>
<li><code>Best Constant</code> : target median</li>
<li><code>sklearn.metrics.mean_absolute_error</code></li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.03.05.png" alt=""></p>
<ul>
<li><strong>RMAE</strong> (Root Mean Absolute Error): MAE에 root취한 값</li>
</ul>
<h4>1.3 MSE와 MAE의 차이</h4>
<ul>
<li>MSE의 경우 차이가 2배이면 error가 4배가 되는데, MAE는 차이가 2배이면 error도 2배</li>
<li>MSE와 RMSE는 최적해를 찾기위해 gradient하게 접근시 각 지점마다 기울기(미분값)이 다르지만, MAE는 왼쪽은 -1, 오른쪽은 1이다.</li>
<li>MAE는 outlier에 덜 민감하게 동작한다. (MSE는 제곱을 해서 크게 민감하다.)</li>
<li>outlier가 없다고 확신이 드는 경우에는 MSE가 더 좋은 경우가 많다.</li>
</ul>
<h4>1.4 (R)MSPE (Mean Square Percent Error), (R)MAPE(Mean Absolute Percent Error) : relative_metric</h4>
<p>MSE 와 MAE는 error를 절대적인 값으로 비교를 한다. 그래서 <code>9 -&gt; 10 (MAE, MSE=1)</code> 와 <code>999 -&gt; 1000 (MAE, MSE=1)</code>는 같은 양의 error로 계산된다.
하지만 <code>900 -&gt; 1000 (MAE=100, MSE=10000)</code>는 error의 수치가 훨씬 커진다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.03.06.png" alt=""></p>
<p>MSPE와 MAPE는 각각 MSE와 MAE에다가 전체 데이터 개수의 퍼센트로 계산한다.</p>
<p><code>Best Constant</code> 역시 MSPE는 <em>weighted target mean</em>이며, MAPE는 <em>weighted target median</em> 값이다.<br>
앞에 Root가 붙은 버전에 대한 설명은 생략한다.</p>
<h4>1.5 RMSLE (Root Mean Square Logarithmic Error)</h4>
<ul>
<li><code>sklearn.metrics.mean_squared_log_error</code></li>
</ul>
<p>로그 스케일로 계산된 RMSE</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.03.07.png" alt=""></p>
<p>Error 곡선의 좌우가 대칭적이지 않다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.03.08.png" alt=""></p>
<h3>2. Classification metrics</h3>
<h4>2.1 Accuracy</h4>
<ul>
<li><code>sklearn.metrics.accuracy_score</code></li>
</ul>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.03.09.png" alt=""></p>
<p>예측한 값과 target값이 같으면 1 아니면 0 으로 계산하여 평균을 취한 값<br>
개 그림 맞추기 문제에서 <em>개</em> 90, <em>고양이</em> 10으로 데이터셋이 있는 경우 모두 <em>개</em>라고 대답해도 Accuracy는 0.9가 나온다.</p>
<h4>2.2 Logarithmic loss (logloss)</h4>
<ul>
<li><code>sklearn.metrics.log_loss</code></li>
</ul>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.03.10.png" alt=""></p>
<p>target과 차이가 클수록 penalty가 커진다. 하나의 큰 error는 여러 개의 작은 error들보다 훨씬 더 penalty가 크다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.03.11.png" alt=""></p>
<h4>2.3 AUC (Area Under Curve)</h4>
<p>얼마나 구분을 잘하느냐, 얼마나 겹치는게 없느냐에 대한 검증
좋은 피처인지 아닌지를 구분할때 많이 사용</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.03.12.png" alt=""></p>
<p><code>True Positive</code> 와  <code>False Positive</code>를 이용하여 <code>TP</code>는 위쪽 <code>FP</code>는 오른쪽으로 움직이여 곡선을 그림을 그려서 그 아래 면적으로 평가. 면적이 넓을 수록 좋음. 최고 점수는 1</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.03.13.png" alt=""></p>
<h4>2.4 Cohen's Kappa</h4>
<p>어렵다. 무슨 내용인지 도저히 모르겠음</p>
<h3>3. General approaches for metrics optimization</h3>
<ul>
<li>Target metric : 우리가 최적화 하려는 것</li>
<li>Optimization loss : 모델이 최적화 하는 것</li>
</ul>
<p>모델은 우리가 지정한 <em>metric</em>으로 계산한 <em>loss</em>를 최소화하기 위해서 학습한다.</p>
<ul>
<li>metric 최적화 전략
<ul>
<li>처음에 그냥 model을 실행할때 : MSE, Logloss</li>
<li>train 데이터 전처리하여 다른 metric에 최적화 할때 : MSPE, MAPE, RMSLE, ...</li>
<li>다른 metric이나 predict 결과를 후처리 할때 : Accuracy, Kappa</li>
<li>기타 : loss function를 스스로 작성</li>
<li>다른 metric의 early stopping 용 : Any...</li>
</ul>
</li>
</ul>
<p>ex) 1,2차 미분값으로 loss를 계산하고자 할 때</p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">logregobj</span><span class="params">(preds, dtrain)</span>:</span></div><div class="line">    labels = dtrain.get_label()</div><div class="line">    preds = <span class="number">1.</span> / (<span class="number">1.</span> + np.exp(-preds))</div><div class="line">    grad = preds - labels </div><div class="line">    hess = preds * (<span class="number">1.</span> - preds)</div><div class="line">    <span class="keyword">return</span> grad, hess</div></pre></td></tr></table></figure></p>
<ul>
<li>Early stopping
<ul>
<li>M1 metric을 최적화하기 위해서 M2 metric의 최적값을 구하는 경우</li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.03.14.png" alt=""></p>
<h3>4. Regression metrics optimization</h3>
<h4>4.1 MSE, RMSE, R-squared</h4>
<p>대부분의 모델에서 잘 동작한다.</p>
<ul>
<li>Tree-based : XGBoost, LightGBM, sklearn.RandomForestRegressor</li>
<li>Linear models : sklearn.&lt;&gt;Regression, sklearn.SGFRegressor, Vowpal Wabbit (quantile loss)</li>
<li>Neural nets : Pytorchm Keras, TF, etc.</li>
</ul>
<p>L2 loss라고도 불림</p>
<h4>4.2 MAE</h4>
<p>MSE와 최적화 관점에서는 큰 차이가 없지만, 2차 미분이 0이기 때문에 extra boost 방식에서는 사용을 못한다.</p>
<ul>
<li>Tree-based : LightGBM, sklearn.RandomForestRegressor</li>
<li>Linear models : Vowpal Wabbit (quantile loss)</li>
<li>Neural nets : Pytorchm Keras, TF, etc.</li>
</ul>
<p>L1 loss, Median regression 이라고도 불림</p>
<h4>4.3 MSPE, MAPE</h4>
<p>이것은 앞에서 본 2가지 metric과는 용도가 다르다.<br>
각각 MSE, MAE의 가중 버전이다.<br>
다른 metric의 early stopping을 위해 사용되기도 한다.</p>
<ul>
<li>XGBoost, LightGBM 에서만 <code>sample_weights</code>용으로 사용한다.</li>
</ul>
<h4>4.4 RMSLE</h4>
<p>로그공간에서의 MSE 최적화 방식</p>
<h3>5. Classification metrics optimization</h3>
<h4>5.1 LogLoss (Logistic Loss)</h4>
<ul>
<li>모델이 잘 맞추는지를 측정</li>
<li>Regression의 MAE와 같은 존재</li>
<li>RandomForest빼고는 대부분 잘 맞음
<ul>
<li>Tree-based : XGBoost, LightGBM</li>
<li>Linear models : sklearn.&lt;&gt;Regression, sklearn.SGDRegressor, Vowpal Wabbit</li>
<li>Neural nets : Pytorchm Keras, TF, etc.</li>
</ul>
</li>
</ul>
<h4>5.2 Accuracy</h4>
<ul>
<li>metric이나 treshold를 최적화하는데 유용함</li>
</ul>
<h4>5.3 AUC</h4>
<ul>
<li>모델이 잘 맞추는것을 측정하거나 logloss를 최적화하기 위해 사용됨</li>
<li>한상의 object가 올바른 순서로 정렬될 확률</li>
<li>Tree-based : XGBoost, LightGBM</li>
<li>Neural nets : Pytorchm Keras, TF, etc.</li>
</ul>
<h4>5.4</h4>
<ul>
<li>MSE를 최적화</li>
<li>올바른 threshold를 찾음
<ul>
<li>Bad : np.round(predictions)</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://DevStarSJ.github.io/2018/10/22/kaggle.coursera.competition.03.01/" data-id="cjov1wtr9008zjw7bgxusrzxj" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DataScience/">DataScience</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kaggle/">Kaggle</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MachineLearning/">MachineLearning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-kaggle.coursera.competition.02.02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/10/21/kaggle.coursera.competition.02.02/" class="article-date">
  <time datetime="2018-10-21T08:44:00.000Z" itemprop="datePublished">2018-10-21</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/DataScience/">DataScience</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/10/21/kaggle.coursera.competition.02.02/">Coursera Kaggle 강의(How to win a data science competition) week 2-2 Validation 요약</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1>Coursera Kaggle 강의(How to win a data science competition) week 2-2 Validation 요약</h1>
<h2>Validation</h2>
<p><strong>Validation</strong>이란 target이 있는 train 데이터셋 중 일부를 validation 데이터로 나누어서 train 데이터 만으로 모델을 학습시킨 뒤 validation 데이터로 모델의 품질을 검증하는 과정을 뜻한다. 이렇게 하는 가장 큰 이유는 이후 target이 없는 test 데이터를 가지고 predict 할 때 좋은 성능이 나오는지에 대해서 검증이 가능하기 때문이다. 왜 이게 도움이 되는지를 알기 위해서는 <strong>Overfitting</strong>에 대한 이해가 필요하다.</p>
<h3>1.Overfitting</h3>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.02.13.png" alt=""></p>
<ul>
<li><strong>Underfitting</strong> : 모델이 학습이 덜 되어서 너무 단순한 모양이 띄게 된다면 정확한 예측이 힘들어진다. 위 그림에서 왼쪽 그림의 경우 모델이 단순하여 아래에 있는 3개의 파란원과 위쪽에 있는 빨간X를 제대로 예측못하게 된다.</li>
<li><strong>Overfitting</strong> : 모델이 너무 train 데이터에 정확하게 맞도록 학습이 되어 버리면, 일반적인 상황에서 제대로 예측을 못할 수도 있다. 위 그림에서 오른쪽 그림이 그러한 경우인데, 노이즈가 섞여있는 train 데이터의 모두에 대해서 예측을 하려고 학습을 한 결과 굉장히 복잡한 모델이 되었다. 이 경우 일반적인 데이터들에 대해서는 예측이 빗나갈 수도 있다.</li>
</ul>
<p>중간의 그림같이 train 데이터 중 일부에 대해서는 맞추지 못하더라도 일반적인 형태의 예측력을 가장 좋게 모델을 학습시켜야 한다.</p>
<p>그럼 어느 정도 학습해야 가장 좋은 모델인지 어떻게 할 수 있을까 ?<br>
그걸 알기 위해서는 앞에서 언급한 <strong>validation</strong> 데이터가 필요하다.
학습을 하면 할수록 train 데이터에 대해서는 점점 더 error가 줄어들 수 밖에 없다. 하지만 validation 데이터에 대해서는 특정 시점 이후에 점점 더 error가 늘어날 수도 있다. error가 늘어나기 직전의 지점이 가장 학습이 잘 된 모델의 상태라고 할 수 있다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.02.14.png" alt=""></p>
<h3>2. Validation Strategies</h3>
<p>Validation 데이터를 나누는데는 총 3가지 전력이 있다.</p>
<ol>
<li>Hold-out</li>
<li>K-Fold</li>
<li>Leave-one-out</li>
</ol>
<h4>2.1. Hold-out (ngroups=1)</h4>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.02.15.png" alt=""></p>
<ul>
<li><code>sklearn.model_selection.ShuffleSplit</code></li>
</ul>
<p>단순하게 데이터를 train, validation으로 나누는 방법이다. 통상적으로 7:3으로 많이 나눈다.</p>
<h4>2.2. K-Fold (ngroups=k)</h4>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.02.16.png" alt=""></p>
<ul>
<li><code>sklearn.model_selection.Kfold</code></li>
</ul>
<p>train 데이터를 k개로 나누어서 그중 1개를 validation 데이터로 나머지를 test 데이터로 하여 k번 반복을 한다. 이 방법의 핵심은 반복하면서 train, validation에 전체 데이터를 모두 사용했다는 점이다. 이렇게 나온 각각의 모델의 성능에 평균값으로 전체 모델의 성능을 결정한다.</p>
<h4>2.3. Leave-one-out (ngroups=len(train))</h4>
<ul>
<li><code>sklearn.model_selection.LeaveOneOut</code></li>
</ul>
<p>K-Fold의 특수한 케이스이다. K값을 train 데이터 개수만큼 한 것이다. 이러면 1개의 데이터만을 validation으로 하고 나머지를 train 데이터로 설정하여 학습한다. train 데이터의 개수가 너무 적을 경우에 주로 사용하는 방법이다.</p>
<h4>2.4. Stratification</h4>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.02.17.png" alt=""></p>
<p>train 데이터가 너무 적을 경우 train / validation으로 데이터를 나눌 때 한쪽의 데이터만 편향되게 나뉘어 질 수 있다. 예를 들어서 train 데이터는 모두 target값이 1이고, validation은 모두 0 일 수도 있다. 그래서 각각의 fold에 들어가는 데이터의 비율을 균일하게 맞추는 과정이 필요 할 수도 있다.</p>
<h3>3. Data Splitting Strategies</h3>
<p>실제 해결해야 할 문제와 가장 유사한 형태로 train / validation을 나누는 것이 좋다.</p>
<h4>3.1. Random, Rowwise</h4>
<p>각각의 row가 독립적인 경우에 유용하다. 가장 많이 사용하는 방법이다.</p>
<h4>3.2. Timewise</h4>
<p>시계열 데이터를 가지고 미래의 수요를 예측하는 문제의 경우</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.02.18.png" alt=""></p>
<p>train 데이터를 시간 순서대로 배열하여 이전 값을 train으로 이후의 값들을 validation으로 나누는 방법을 생각해 볼 수 있다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.02.19.png" alt=""></p>
<p>위 그림과 같이 <strong>Moving Window Validation</strong>을 사용할 수도 있다.</p>
<h4>3.3. By ID</h4>
<p>음악 추천 알고리즘을 개발해야 한다고 가정했을 경우, train과 validation에 같은 user가 둘 다 있어야만 의미가 있을 것이다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.02.20.png" alt=""></p>
<p>하지만 실제로 train과 test의 user가 전혀 겹치지 않을 수도 있다. 또는 id를 숨길 수도 있다. 이 경우에는 다른 feature들로 동일인 또는 동일그룹으로 id를 생성하는게 좋다.</p>
<h4>3.4 혼합하여 적용</h4>
<ul>
<li>상점별로 미래 매상을 예측 -&gt; 상점별 time-series로 나눔</li>
<li>여러 사용자로 검색쿼리를 받고 여러 엔진을 사용하는 경우 -&gt; 사용자 id, 검색엔진 id를 조합하여 나눔</li>
</ul>
<h3>4. Common Validation Problems</h3>
<p>각 Fold마다 점수 차이가 크다면 그 이유를 파악해야 한다.</p>
<p>데이터 자체가 그럴 수 밖에 없는 경우도 있다. 예를 들어서 매출 예측의 경우 1월 데이터로 train하여 2월 데이터로 validation한다면, 전체 날짜, 휴일의 날짜 등이 달라서 차이가 날 수 있다.</p>
<p>그게 아닌 경우에는 다음 사항들을 확인해 볼 필요가 있다.</p>
<ol>
<li>데이터의 개수가 너무 적을 경우</li>
<li>데이터의 값이 너무 다양하고 일관성이 없는 경우</li>
</ol>
<p>Instagram 사진으로 사람의 키를 예측하는 대회에서 train 데이터는 모두 여자만 있고, test 데이터는 모두 남자만 있다면 어떻게 해야할까 ?</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.02.21.png" alt=""></p>
<p>target 값을 분포로 구해서 평균 신장에 적용하는 방법을 생각해 볼 수 있다. 가장 간단하게는 predict 결과에다가 7 inch를 더하는 방법도 있다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.02.22.png" alt=""></p>
<p>train과 test의 성비가 다른 경우라면 어떻게 해야 할까 ? validation을 test와 같은 비율로 만들어서 학습을 시키는 방법이 유용하다.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://DevStarSJ.github.io/2018/10/21/kaggle.coursera.competition.02.02/" data-id="cjov1wtr7008vjw7bn8dy3axi" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DataScience/">DataScience</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kaggle/">Kaggle</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MachineLearning/">MachineLearning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-kaggle.coursera.competition.02" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/10/21/kaggle.coursera.competition.02/" class="article-date">
  <time datetime="2018-10-21T04:40:00.000Z" itemprop="datePublished">2018-10-21</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/DataScience/">DataScience</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/10/21/kaggle.coursera.competition.02/">Coursera Kaggle 강의(How to win a data science competition) week 2-1 EDA 요약</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1>Coursera Kaggle 강의(How to win a data science competition) week 2-1 EDA 요약</h1>
<h2>Exploratory Data Analysis</h2>
<h3>1.Exploratory Data Analysis</h3>
<h4>EDA란 무엇이며 왜 해야하나 ?</h4>
<ul>
<li>EDA란 데이터를 조사하고 이해하고 익숙해지는 과정이다.</li>
<li><code>익명처리</code>, <code>암호화</code>, <code>전처리과정</code>, <code>난독화</code> 등을 거친 데이터를 분석하기 위해서는 EDA가 필수적이다. 데이터를 시각화하면 패턴을 볼 수 있다.</li>
</ul>
<p>EDA를 왜 하는가 ?</p>
<ol>
<li>데이터를 더 잘 <strong>이해</strong>하게 된다.</li>
<li>데이터에 대한 <strong>직감</strong>이 생긴다.</li>
<li><strong>가설</strong>을 만들 수 있다.</li>
<li><strong>통찰력</strong>을 얻는다.</li>
</ol>
<p>바로 모델생성, Stacking, Mixing 과 같은 것으로 코드를 작성하기 보다는 EDA를 통해서 데이터를 이해하는 노력을 해야 장기적으로 실력을 향상 시킬 수 있다.</p>
<p>EDA의 가장 대표적인 방법은 **시각화(Visualization)**이다.</p>
<p>시각화를 통해서 아이디어를 얻고, 아이디어로부터 가설을 세워서, 그것이 맞는지 시각화하여 확인하라.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.02.01.png" alt=""></p>
<p>EDA를 함으로써</p>
<ul>
<li>데이터를 더 친숙하게 느끼게 되며,</li>
<li><strong>magic feature</strong>를 찾게 될 수 있다.</li>
</ul>
<h3>2. Building Institution about the data</h3>
<h4>2.1. 도메인 지식 얻기</h4>
<p>일반적으로 Wikipedia나 구글 검색으로 통해서 얻는다. 데이터에 대한 이해가 있으면 EDA를 통해서 얻는게 훨씬 더 많아진다.</p>
<h4>2.2. 데이터가 직관적인지 확인</h4>
<p>Age항목에서 336을 발견한다면 당연히 잘못된 데이터라고 판단이 된다.<br>
Google AdWords 데이터의 경우 광고 노출보다 클릭수가 더 클 수는 없다. 잘못된 데이터가 있는 경우 <code>is_correct</code>라는 feature를 추가하여 오류가 있는 행을 표시하는 것도 도움이 될 수 있다.</p>
<h4>2.3. 데이터 생성방법 이해</h4>
<p>train / test 데이터가 다른 방법으로 생성되었는지 확인해야 한다.
예를 들어 train 데이터는 모두 workday에 관한 데이터이고, test 데이터는 모두 holiday라던지, 특정 feature에 의한 분포도가 완전히 다른 경우라고 할 때는 비슷한 기준으로 표현되도록 데이터를 가공하던지, 아니면 해당 feature를 제거하는게 더 좋을 수 있다.</p>
<h3>3. Exploring anonymized data (익명화 데이터)</h3>
<p>일부 대회에서는 경쟁사로의 데이터 유출을 회피하고자 데이터를 비식별화하기도 한다. 그 방법으로는 문자열 값을 해쉬화 하거나 컬럼명을 무의미하게 x1, x2, ... 로 만든다.</p>
<ol>
<li>데이터 디코딩을 시도</li>
<li>숫자형, 범주형 등 데이터 유형을 확인</li>
<li>feature 간의 관계 및 그룹화 가능여부를 확인</li>
</ol>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">df.dtypes</div><div class="line">df.info()</div><div class="line">x.value_counts()</div><div class="line">x.isnull()</div></pre></td></tr></table></figure></p>
<h3>4. Visualizations (시각화)</h3>
<h4>4.1. 단일 feature 분석</h4>
<ol>
<li>Histogram</li>
</ol>
<p>데이터를 <code>bin</code>으로 나눠서 각 <code>bin</code>별 몇 개의 포인트가 있는지를 표시</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.02.02.png" alt=""></p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">plt.hist(x)</div></pre></td></tr></table></figure></p>
<p>히스토그램이 이상할 경우 <code>log</code>를 취한다던지의 가공을 하면 좀 더 명확해 지는 경우도 있다.</p>
<ol start="2">
<li>Plot (index vs value)</li>
</ol>
<p>각 index 별로 어떠한 값을 가지는지 점으로 표시.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.02.03.png" alt=""></p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">plt.plot(x,’.’)</div></pre></td></tr></table></figure></p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.02.04.png" alt=""></p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">plt.scatter(range(len(x)), x, c=y)</div></pre></td></tr></table></figure></p>
<ol start="3">
<li>Feature Statistics</li>
</ol>
<p>통계적 수치 확인</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.02.05.png" alt=""></p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">df.describe()</div><div class="line">x.mean()</div><div class="line">x.var()</div><div class="line">x.value_counts()</div><div class="line">x.isnull()</div></pre></td></tr></table></figure></p>
<h4>4.2. 2개 feature의 관계 분석</h4>
<ol>
<li>Scatter Plot</li>
</ol>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">plt.scatter(x1, x2)</div></pre></td></tr></table></figure></p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.02.06.png" alt=""></p>
<p>위 그림은 train 데이터의 target 값에 따라 빨간/파란색으로 표현했으며, test 데이터는 회색으로 표시했다. 데이터의 분포가 train/test가 서로 다르다는 것이 확인 가능하다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.02.07.png" alt=""></p>
<p><code>X2 &lt;= 1 - X1</code> 관계가 확인 가능하다.</p>
<p><strong>Pandas</strong>는 모든 feature쌍의 <strong>scatter plot</strong>을 그려주는 기능을 제공한다.</p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pd.scatter_matrix(df)</div></pre></td></tr></table></figure></p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.02.08.png" alt=""></p>
<ol start="2">
<li>Correlation Plot</li>
</ol>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">df.corr(), plt.matshow( ... )</div></pre></td></tr></table></figure></p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.02.10.png" alt=""></p>
<p>데이터를 <code>K-means</code>를 통해 군집화 한다던지, 새로 순서를 정렬하는 것이 데이터 패턴을 파악하는데 도움이 되기도 한다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.02.09.png" alt=""></p>
<h4>4.3. feature 그룹의 분석</h4>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">df.mean().sort_values().plot(style=’.’)</div></pre></td></tr></table></figure></p>
<p>각 feature 별로 평균값을 계산하여 그려 볼 수도 있다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.02.11.png" alt=""></p>
<p>이 것을 통계기반으로 정렬해서 보면 다음과 같다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.02.12.png" alt=""></p>
<h3>5. Dataset Cleaning (데이터 정제)</h3>
<h4>5.1. Constant feature 확인</h4>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">traintest.nunique(axis=<span class="number">1</span>) == <span class="number">1</span></div></pre></td></tr></table></figure></p>
<p>모든 값이 같은 feature를 확인하여 제거</p>
<h4>5.2. 중복된 feature 확인</h4>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">traintest.T.drop_duplicates()</div></pre></td></tr></table></figure></p>
<p>중복된 값을 가질 경우 1개만 남겨두고 제거하는 것이 좋다.</p>
<p>범주형 데이터에서 값은 다르지만 똑같은 기능을 하는 경우도 있을 수 있다.</p>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> f <span class="keyword">in</span> categorical_feats: </div><div class="line">    traintest[f] =raintest[f].factorize()</div><div class="line">traintest.T.drop_duplicates()</div></pre></td></tr></table></figure></p>
<p>모든 범주형 feature를 다시 encoding하여 비교하면 쉽게 찾을 수 있다.</p>
<h4>5.3. 중복된 row 제거</h4>
<p>먼저 중복된 row의 label이 같은지를 확인해야 한다. 같다고 판단이 되면 제거를 하는 것이 성능에 좋다.</p>
<p>train과 test에도 중복된 row가 있을 수 있다.</p>
<h4>5.4. 데이터가 shuffle되었는지 확인</h4>
<p>shuffle 되지 않은 데이터에서는 누락된 데이터를 유추 할 수 있는 방법들이 있을 수 있다.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://DevStarSJ.github.io/2018/10/21/kaggle.coursera.competition.02/" data-id="cjov1wtra0093jw7brqiuliev" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DataScience/">DataScience</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kaggle/">Kaggle</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MachineLearning/">MachineLearning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-kaggle.coursera.competition.01" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/10/20/kaggle.coursera.competition.01/" class="article-date">
  <time datetime="2018-10-20T08:00:00.000Z" itemprop="datePublished">2018-10-20</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/DataScience/">DataScience</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/10/20/kaggle.coursera.competition.01/">Coursera Kaggle 강의(How to win a data science competition) week 1 요약</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1>Coursera Kaggle 강의(How to win a data science competition) week 1 요약</h1>
<p>참고로 Kaggle 대회에 대한 소개, HW/SW 이야기 등은 모두 생략하였으며, Machine Learning 모델 개발에 관련된 내용들만을 정리했음</p>
<h2>02.Competition mechanics</h2>
<h3>03.Recap of main ML algorithms</h3>
<h4>1. Linear Model</h4>
<ul>
<li>공간을 나누어서 구분</li>
<li>ex) Logistic regression, SVM
<ul>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.01.png" alt=""></li>
</ul>
</li>
<li>하지만 원형으로 모여있는 경우에는 선형모델의 적용이 힘듬
<ul>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.02.png" alt=""></li>
</ul>
</li>
</ul>
<h4>2. Tree-based Model</h4>
<ul>
<li>Decision tree를 좀 더 복잡하게 구성하는 것이 기본 아이디어</li>
<li>Divide-and-conquer 접근 방법
<ul>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.03.png" alt=""></li>
<li>먼저 선하나로 devide한 다음 위쪽은 더 이상 나눌필요가 없으니 아래쪽만 다시 devide</li>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.04.png" alt=""></li>
</ul>
</li>
<li>하지만 선형으로 쉽게 해결 되는 문제에 적용할 경우 훨씬 복잡해지며, 정확성도 더 떨어질 수 있음
<ul>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.05.png" alt=""></li>
</ul>
</li>
<li>Random forest는 sklearn의 것이 가장 효과적이고, Gradient boosting은 XGBoost, LGBM이 좋음</li>
<li>대회에서 상위 랭킹자들이 많이 사용하는 알고리즘</li>
</ul>
<h4>3. k-NN (k-Nearest Neighbors)</h4>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.06.png" alt=""></p>
<ul>
<li>가장 가까운 것을 따라가는 방식</li>
<li>missing value를 채울때 유용</li>
<li>sklearn의 kNN이 좋음. (custom distance funtion 지원)</li>
</ul>
<h4>4. Neural Nets</h4>
<ul>
<li>이미지, 사운드, 텍스트 시퀀스에 적합</li>
<li>TensorFlow, Keras, MXNet, PyTorch</li>
</ul>
<h2>05.Feature preprocessing and generation with respect to models</h2>
<h3>02.Numeric features</h3>
<ul>
<li>Numeric Feature의 전처리는 tree model과 아닌 것에 따라 다르게 접근해야 한다.
<ul>
<li>Scaling : tree-model은 별로 상관이없고, non-tree의 경우 많은 영향을 미친다.
<ul>
<li>MinMaxScaler : to [0, 1]
<ul>
<li>범위가 미리 정의되어 있는 경우 유용함.</li>
<li>outlier가 없는 경우 사용</li>
<li><code>sklearn.preprocessing.MinMaxScaler</code></li>
<li><code>X = (X X.min())/(X.max() X.min())</code></li>
</ul>
</li>
<li>StandardScaler : mean 0, std 1
<ul>
<li><code>sklearn.preprocessing.StandardScaler</code></li>
<li><code>X = (X X.mean())/X.std()</code></li>
</ul>
</li>
<li>Rank : sort해서 indexing
<ul>
<li><code>scipy.stats.rankdata</code></li>
<li>ex) [1000, 1, 10] -&gt; [2, 0, 1]</li>
</ul>
</li>
<li>Log Transform
<ul>
<li><code>np.log(1+x)</code>, <code>np.sqrt(1+x)</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Feature 생성
<ul>
<li>데이터에 대한 지식이 필요.</li>
<li>Explore Data Analysis</li>
<li>ex)
<ul>
<li>소수점 이하 부분만으로 feature 생성</li>
<li>Combined = (horizontal ** 2 + vectical ** 2) ** 0.5
<ul>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.07.png" alt=""></li>
</ul>
</li>
<li>가격 / 면적 = 평당가
<ul>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.08.png" alt=""></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Outlier 처리
<ul>
<li>np.percentile 을 이용하여 1%, 99% 밖의 값을 제거하는 것이 효과적
<ul>
<li>outlier 1개때문에도 model의 이상하게 될 수 있음</li>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.09.png" alt=""></li>
</ul>
</li>
<li>Rank도 좋은 대안이 될 수 있다. 모든 값들의 간격을 동일하게 생성한다.
<ul>
<li>Outlier가 있을때 MinMaxScaler를 적용하는 것보다는 훨씬 효과적이다.</li>
<li>Linear models, KNN, Neural nets에서 전처리할 시간이 부족하다면 Rank가 효과적인 방안일 수도 있다.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3>03.Categorical and ordinal features</h3>
<p>Categorical vs Ordinal</p>
<ul>
<li>Ordinal : Categorical + 순서에 따른 의미가 존재
<ul>
<li>ex)
<ul>
<li>Driver Licence Type : A &gt; B &gt; C &gt; D</li>
<li>최종학력 : 유치원 &lt; 초등학교 &lt; 중학교 &lt; 고등학교 &lt; 학사 &lt; 석사 &lt; 박사</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Label Encoding</p>
<ul>
<li>각 Category별로 code를 부여</li>
<li>tree-model에서는 잘 동작하지만, non-tree-model에서는 혼란스러울 수 있음. 각 숫자크기별로 의미를 두어서 연산을 함
<ul>
<li>Alphabetical (sorted)
<ul>
<li>ex) [S,C,Q] -&gt; [2, 1, 3]</li>
<li>sklearn.preprocessing.LabelEncoder</li>
</ul>
</li>
<li>Order of appearance
<ul>
<li>ex) [S,C,Q] -&gt; [1, 2, 3]</li>
<li>Pandas.factorize</li>
<li>Ordinal 에서 의미상 순서대로 sorting된 경우에 사용하면 효과적이다.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Frequency Encoding</p>
<ul>
<li>
<p>각 Category별로 출현빈도(%)값을 부여</p>
<ul>
<li>ex) [S,C,Q] -&gt; [0.5, 0.3, 0.2]
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">encoding = titanic.groupby(‘Embarked’).size()</div><div class="line">encoding = encoding/len(titanic) </div><div class="line">titanic[‘enc’] = titanic.Embarked.map(encoding)</div></pre></td></tr></table></figure></li>
</ul>
</li>
<li>
<p><code>from scipy.stats import rankdata</code></p>
</li>
<li>
<p>tree-model, linear-model 모두에게 효과적</p>
</li>
<li>
<p>하지만, 여러 feature들 간에 동일한 값을 가질수 있어서 그 중요도를 구분하기 힘들다.</p>
</li>
</ul>
<p>One-hot Encoding</p>
<ul>
<li>linear-model에 효과적</li>
<li>Category내 각각의 값들을 feature로 생성하여 해당하면 1, 아니면 0값으로 채움
<ul>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.10.png" alt=""></li>
<li><code>pandas.get_dummies, sklearn.preprocessing.OneHotEncoder</code></li>
</ul>
</li>
<li>수백개의 binary feature가 생성될 수도 있음</li>
<li>tree-model에서는 속도가 많이 느려져서 비효율적</li>
<li>2가지 이상의 feature를 mix하여 사용할 경우 효과적일 수 있음 : kNN, linear
<ul>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.11.png" alt=""></li>
</ul>
</li>
</ul>
<h3>04.Datetime and Coordinates</h3>
<p>Datetime feature</p>
<ol>
<li>Periodic
<ul>
<li>year, month, day, hour, minute, second 별로 나누어서 반복성을 찾음</li>
<li>season, week 등의 기준</li>
<li>binary feature : workday/holiday, business time 등으로 나누는 방법도 있음</li>
<li>3일에 한번씩 같은 특정 패턴을 찾을때 유용하다.</li>
</ul>
</li>
<li>Time since
<ul>
<li>마지막 휴일 이후 얼마나 시간이 지났는지 / 캠페인이 끝날때까지 얼마나 남았는지 등을 고려</li>
</ul>
</li>
<li>Difference between dates
<ul>
<li>2개의 date feature 간의 차이 (diff)
<ul>
<li>ex)
<ul>
<li><code>date_diff = last_call_date - last_purchase_date</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>Coordinate</p>
<ol>
<li>중요 위치로부터의 거리
<ul>
<li>병원으로 부터의 거리, 가장 가까운 shop으로 부터의 거리</li>
<li>학습데이터 내에 그런 지점 정보가 없다면 추가로 생성하여 계산</li>
<li>지도를 분할하여 해당 지역내의 가장 비싼 지점으로부터의 거리</li>
<li>데이터를 클러스터링하여 그 중심으로 부터의 거리</li>
</ul>
</li>
<li>주변 지역의 통계적 계산값</li>
<li>Decision tree 기반의 모델의 경우 좌표값을 회전해서 사용하는게 더 효과적인 경우도 있음
<ul>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.12.png" alt=""></li>
<li>이 각도를 정확히 알기 힘들수도 있으니,  22.5 / 45 등 모든 각도로 회전한 것을 feature로 추가하는 방법도 있음</li>
</ul>
</li>
</ol>
<h3>05.Missing values</h3>
<ul>
<li>Missing value의 종류 : none, nan, 숫자가 아닌 값, 빈 문자값, -999 등...</li>
<li>Missing value 그 자체로도 의미가 있을 수 있다. 왜 이 값은 비워져있을지를 먼저 고민해 보는 것도 필요하다.</li>
</ul>
<p>Missing Value를 찾는 방법</p>
<ol>
<li>missingno 라이브러리 사용
<ul>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.13.png" alt=""></li>
<li>http://www.xavierdupre.fr/app/jupytalk/helpsphinx/notebooks/im_missingno.html</li>
</ul>
</li>
</ol>
<p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> missingno</div><div class="line"></div><div class="line">missingno.matrix(df)</div><div class="line">missingno.heatmap(df)</div><div class="line">missingno.dendrogram(df)</div><div class="line"></div><div class="line">filtered_data = missingno.nullity_filter(df, filter=<span class="string">'bottom'</span>, n=<span class="number">15</span>, p=<span class="number">0.999</span>)</div><div class="line">missingno.matrix(filtered_data)</div><div class="line"></div><div class="line">sorted_data = missingno.nullity_sort(df, sort=<span class="string">'descending'</span>)</div><div class="line">missingno.matrix(sorted_data.sample(<span class="number">250</span>))</div></pre></td></tr></table></figure></p>
<ol start="2">
<li>Histogram 이용
<ul>
<li>nan이라 표시되지 않는 missing value도 있는지 찾아봐야 한다.</li>
<li>-1, 99 등의 숫자라고 해서 무조건 missing value가 아니라고 간주할 수는 없다.</li>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.14.png" alt="">
<ul>
<li>다른 모든 값들이 0 ~ 1 사이의 정규분포를 나타내는데 몇 개 안되는 숫자가 -1인 경우는 missing value라고 볼 수 있다.</li>
</ul>
</li>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.15.png" alt="">
<ul>
<li>x축의 평균을 벗어나는 값 ? 무슨 의미인지 잘...</li>
</ul>
</li>
</ul>
</li>
<li>터무니 없는 outlier 값
<ul>
<li>ex) 기원전 또는 2025년에 작곡된 노래</li>
</ul>
</li>
</ol>
<p>Missing value 를 채우는 방법</p>
<ol>
<li>-999, -1 등 유요한 범위를 벗어나는 값
<ul>
<li>Linear network에서 성능이 저하될 수 있음</li>
</ul>
</li>
<li>mean, median 등의 값
<ul>
<li>Linear model과 Neural network에서 좋은 방법이 될 수 있다.</li>
<li>하지만  tree algorithm에서는 값이 누락된 객체를 선택하기에 어려울 수 있다.
<ul>
<li>이 경우에는 isnull feature를 추가하는 방법도 있다.</li>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.16.png" alt=""></li>
<li>하지만 컬럼 수가 2배로 늘 수도 있다는 단점이 있다.</li>
</ul>
</li>
</ul>
</li>
<li>가능한 값으로 재구성
<ul>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.17.png" alt=""></li>
<li>예를 들어 time-series 값일 경우 근사치로 값을 구할수 있음</li>
<li>하지만 대부분의 경우 각각의 row는 독립적이라 간주헤야하므로 이런 방법을 쓸 수 있는 경우는 거의 없다.</li>
</ul>
</li>
</ol>
<p>Missing value 채울 때 주의해야할 사항</p>
<ol>
<li>mean, median으로 채우면 안되는 경우
<ul>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.18.png" alt=""></li>
<li>daytime 과 온도값에 대해서 missing value가 위 그림과 같이 있는 경우, median으로 missing value를 채우면 실제 값과의 차이가 크게 날 수 있다.</li>
<li>이 케이스는 Interpolation(보간법)으로 채우는게 error를 줄일 수 있다는걸 알 수 있지만, 이렇게 판단할 시간이 충분하지 않을 경우에 missing value를 잘못된 방법으로 채웠다가는 왜 문제가 해결안되는지 찾기 힘들어 질 수도 있다.</li>
</ul>
</li>
<li>Feature generation을 하려는 경우
<ul>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.19.png" alt=""></li>
<li>category 별로 numeric의 평균값을 새로운 feature로 생성하려 할 경우, nan을 -999로 할경우 B 항목에 대해서는 값이 이상하게 된다. mean이나 median으로 채운다고 하더라도 비슷한 문제가 발생할 수 있다.
<ul>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.20.png" alt=""></li>
</ul>
</li>
<li>이 경우에는 새로운 feature를 먼저 생성한 후 missing value를 채워야 한다.</li>
</ul>
</li>
<li>Cetegorical feature 중 train에는 있지만 test에는 없는 경우
<ul>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.21.png" alt=""></li>
<li>이 경우 predict시 random하게 처리할 확률이 높다.</li>
<li>해당 feature를 encoding 하여 비슷한  category로 묶는 것도 하나의 방법이 될 수 있다.
<ul>
<li>위 예제에서는 발생 빈도를 이용하여 encoded feature를 생성하였다.</li>
<li>D와 C가 발생한 빈도가 비슷할 경우  발생 빈도가 target값에 의존성이 있다고 밝혀진 경우에는 C를 D로 간주할 수 있다.</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>Summary</p>
<ol>
<li>NaN값을 채우는 방법은 상황에 따라 다르다.</li>
<li>가장 대표적인 방법으로는 -999, mean, median으로 채우는 것이다.</li>
<li>missing value가 이미 다른 값으로 대체되었을 수도 있다. 이 경우에는 histogram으로 조사가 가능하다.</li>
<li>isnull 이라는 binary feature가 유용하다.</li>
<li>feature 생성하기 전에 missing value를 채우는 것을 피하라.</li>
<li>XGBoost는 NaN을 직접 처리 가능하며, 때로는 이것이 더 좋은 성능을 나타내기도 한다.</li>
</ol>
<h2>06.Feature extration from text and images</h2>
<h3>01.Bag of words</h3>
<ul>
<li>Text 혹은 image 데이터만 있는 경우에는 neural network를 이용하면 되지만, 다른 데이터와 같이 있을 경우에는 이 것에서 feature를 만들어야 한다.</li>
</ul>
<p>Text 데이터를 처리하는 방법은 크게 2가지가 있음</p>
<ol>
<li>Bag of words</li>
<li>Embedding (like Word2Vec)</li>
</ol>
<p>Bag of words</p>
<ul>
<li>문장의 각 단어들이 몇 번 사용되었는지를 feature로 추출
<ul>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.22.png" alt=""></li>
<li>sklearn.feature_extraction.text.CountVectorizer</li>
<li>단순 출현 회수로만 가중치를 두어서 어느 것이 중요한 단어인지를 파악하기가 힘들 수도 있다.
<ul>
<li>불용어(관사, 전치사, 대명사 등 의미가 없는 단어)들이 많이 등장</li>
</ul>
</li>
</ul>
</li>
<li>TFiDF
<ul>
<li>Term Frequency : 문단 내에 자주 등장하는 단어에 높은 가중치를 둠
<ul>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.23.png" alt=""></li>
</ul>
</li>
<li>inverse Document Frequency : 문서 내에 전체적으로 자주 등장하는 단어에는 가중치를 낮춤
<ul>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.24.png" alt=""></li>
</ul>
</li>
<li><code>sklearn.feature_extraction.text.TfidfVectorizer</code></li>
</ul>
</li>
<li>N-grams
<ul>
<li>단어들을 묶어서 feature로 생성</li>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.25.png" alt=""></li>
<li><code>sklearn.feature_extraction.text.CountVectorizer:Ngram_range, analyzer</code></li>
</ul>
</li>
</ul>
<p>Text Preprocessing</p>
<ol>
<li>Lowercase
<ul>
<li>모든 단어를 소문자로 수정</li>
<li>sklearn은 default로 lowercase로 수정하여 진행한다.</li>
</ul>
</li>
<li>Lemmatization ans Stemming
<ul>
<li>의미가 비슷한 다른 단어들을 같은 단어로 변환</li>
<li>Stemming : 단어의 뒷부분을 없에버림</li>
<li>Lemmatization : 단어의 의미를 분석하여 대표단어로 치환</li>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.26.png" alt=""></li>
</ul>
</li>
<li>Stopwords (불용어)
<ul>
<li>모델에 아무런 영향을 끼치지 않는 의미가 없거나 너무나도 일반적인 단어들</li>
<li>NLTK 등 자연어처리 라이브러리에 불용어가 잘 정의되어 있음</li>
<li>sklearn.feature_extraction.text.CountVectorizer: max_df
<ul>
<li>불용어 리스트를 인자로 전달이 가능</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>Bag of Word의 Pipeline</p>
<ol>
<li>Preprocessing : lowercase, stemming, lemmatization, stopwords</li>
<li>Bag of words (with N-grams)</li>
<li>Postprocessing : TFiDF</li>
</ol>
<h3>02.Word2Vec &amp; CNN</h3>
<p>Word2Vec</p>
<ul>
<li>Bag of words 보다 간결하게 단어들을 vector화 시키는 방법</li>
<li>Bag of words는 단어의 개수만큼 vector 차원을 사용해야 함
<ul>
<li>같은 context에서 사용되는 다른 단어들을 vector 공간에서 매우 가깝에 위치시키는 방법</li>
<li>이렇게 생성된 vector는 +, - 등의 기본 연산이 가능
<ul>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.27.png" alt=""></li>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.28.png" alt=""></li>
</ul>
</li>
</ul>
</li>
<li>종류
<ul>
<li>단어의 vector화 : Word2Vec, Glove, FastText</li>
<li>문장의 vector화 : Doc2Vec</li>
</ul>
</li>
</ul>
<p>Bag of Words vs Word2Vec</p>
<p>Bag of Words
Word2Vec</p>
<ul>
<li>vector의 크기가 큼 (단어 개수)</li>
<li>vector의 값이 해석 가능</li>
<li>상대적으로는 작은 크기의 vector</li>
<li>vector의 값은 유사한 관계라는 것을 의미</li>
<li>학습시간이 매우 오래 걸림</li>
</ul>
<p>Convolutional neural networks</p>
<ul>
<li>이미지를 처리하는데 이용</li>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.29.png" alt=""></li>
<li>처음부터 모델을 학습시키는 것보다는 이미 잘 만들어진 모델을 가져와서 필요한 것들만 다시 훈련시키는게 더 효과적인 경우가 많다.</li>
<li>Fine-tuning
<ul>
<li>다른 모델을 가져와서 우리의 목표에 맞게 수정</li>
<li>우리가 구해야할 결과가 4가지로 classification할 경우 위 model의 마지막 부분만 4개로 조정</li>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.30.png" alt=""></li>
</ul>
</li>
<li>Argumentation
<ul>
<li>훈련 이미지가 많이 없을 경우 회전, 확대, 미러링 등을 이용하여 그 개수를 늘리는 것이 도움이 된다.</li>
<li>우리가 가진 지붕 데이터가 4개밖에 없을 경우 이 기법을 이용해서 더 늘리는 것이 가능하다.</li>
<li><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Kaggle/Coursera.competition/image/coursera.competition.01.31.png" alt=""></li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://DevStarSJ.github.io/2018/10/20/kaggle.coursera.competition.01/" data-id="cjov1wtr4008njw7b0zwwp5gv" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DataScience/">DataScience</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kaggle/">Kaggle</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MachineLearning/">MachineLearning</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-jupyter.matplotlib.korean.font" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/10/13/jupyter.matplotlib.korean.font/" class="article-date">
  <time datetime="2018-10-13T04:00:00.000Z" itemprop="datePublished">2018-10-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Tips/">Tips</a>►<a class="article-category-link" href="/categories/Tips/JupyterNotebook/">JupyterNotebook</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/10/13/jupyter.matplotlib.korean.font/">Jupyter Notebook Matplotlib에서 한글폰트 사용하기 (macOS)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1>Jupyter Notebook Matplotlib에서 한글폰트 사용하기 (macOS)</h1>
<p>이 포스트를 보기 전에 먼저 <a href="https://www.facebook.com/zzonee" target="_blank" rel="external">박조은</a>님의 <a href="https://programmers.co.kr/learn/courses/21/lessons/950" target="_blank" rel="external">강의 : Matplotlib에서 한글 폰트 사용하기</a>를 먼저 보고 따라해보기를 바란다.</p>
<p>그런데, 이 글을 보고 있단것은 아마 위 강의대로 다 따라해보았는데도 제대로 안됬을 경우라 생각된다. 사실 필자도 저 강의대로 했는데 안되어서 여러 가지 시도를 해보고 알아낸 방법이다. 참고로 해당 설명은 <strong>macOS</strong> 기준인데, Linux도 비슷할 것이라 생각이되며, Windows의 경우도 어느 정도 참고는 할 수 있을것 같다.</p>
<p>아래의 과정들 중 위 강의를 진행하면서 확인된 결과 필요없다고 판단되는 경우에는 skip 가능한 단계도 있을 수 있다.</p>
<h2>1. 관련 폴더 위치 알아내기</h2>
<p>먼저 위 강의에 있는 코드대로 실행하면서 관련 폴더의 위치를 알아 놓자.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Python/JupyterNotebook/image/matplotlib.korean.01.png" alt=""></p>
<p>여기서 <code>캐시 위치</code>와 <code>설정 파일 위치</code>값을 잘 기억해 놓아야 한다.</p>
<h2>2. 시스템에 저장된 한글 폰트 위치 확인</h2>
<p>위 강의 과정에서 설치된 한글 폰트가 없다고 판단되는 경우에는 아래 단계가 필요하다.</p>
<p><strong>Launchpad</strong> 에서 <strong>서체관리자</strong> 를 찾아서 실행하라.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Python/JupyterNotebook/image/matplotlib.korean.03.png" alt=""></p>
<p>거기서 적용할 한글폰트를 하나 찾는다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Python/JupyterNotebook/image/matplotlib.korean.04.png" alt=""></p>
<p>필자의 경우 <strong>나눔바른고딕</strong>을 선택했다. 해당 폰트에서 마우스 우클릭하여 <strong>Finder에서 보기</strong>를 누른다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Python/JupyterNotebook/image/matplotlib.korean.05.png" alt=""></p>
<p><strong>Finder</strong>에서 파일 위치를 확인해보자. 필자의 경우 <code>/Library/Fonts</code>내에 있는것이 확인되었다. 이 경로를 기억해 놓자.</p>
<h2>3. 한글폰트를 Matplotlib 설정 파일 위치로 복사</h2>
<p>앞에서 확인한 <code>설정 파일 위치</code> 정보가 필요하다. 그 경로 가장 마지막의 <code>matplotlibrc</code>는 파일명이고 그 바로 앞까지가 경로이다. 해당 경로 아래에 있는 <code>/fonts/ttf/</code>로 앞에서 찾은 한글 폰트 파일을 복사한다.</p>
<p><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cp /Library/Fonts/Nanum*.ttf /anaconda3/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/</div></pre></td></tr></table></figure></p>
<h2>4. Matplotlib 캐시 파일 리셋</h2>
<p>앞에서 확인한 <code>캐시 위치</code>로 이동해서 파일들을 확인해보자. 각자 사용자명에 따라 경로가 다를 것이다.</p>
<p><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd /Users/sjyun/.matplotlib</div><div class="line">ls</div></pre></td></tr></table></figure></p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Python/JupyterNotebook/image/matplotlib.korean.02.png" alt=""></p>
<p>정확하지는 않지만, <strong>fontList.json</strong> 은 Python 2.0용 <strong>fontList-v300.json</strong>은 Python 3.0용으로 추정된다. 캐시 파일을 삭제한 뒤 새로 실행하면 캐시 파일이 새로 생성되는데, 그렇다고 파일 삭제는 위험하니 파일명 뒤에 .backup를 붙여주도록 하자.</p>
<p><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mv fontList.json fontList.json.backup</div><div class="line">mv fontList-v300.json fontList-voo.json.backup</div></pre></td></tr></table></figure></p>
<h2>5. Jupyter Notebook 및 Matplotlib 재실행</h2>
<p>이제 위 변경사항들을 새로 적용시키기 위해서는 <strong>Jupyter Notebook</strong>과 <strong>Matplotlib</strong>의 재실행이 필요하다. 다시 실행한 다음 코드상에서 <code>import matplotlib</code>를 실행하면 캐시 파일이 새로 생성 된다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Python/JupyterNotebook/image/matplotlib.korean.06.png" alt=""></p>
<p>이제 다시 예제 코드를 돌려보면 한글이 제대로 나오는 것을 확인 할 수 있다.</p>
<p><img src="https://raw.githubusercontent.com/DevStarSJ/Study/master/Blog/Python/JupyterNotebook/image/matplotlib.korean.07.png" alt=""></p>
<h2>6. 정리</h2>
<p>한글 폰트 및 각종 필요한 위치 확인 및 예제 실행은 아래 노트북 파일을 참고하면 된다.</p>
<p><a href="https://github.com/DevStarSJ/Study/blob/master/Blog/Python/JupyterNotebook/matplotlib.korea_font.ipynb" target="_blank" rel="external">https://github.com/DevStarSJ/Study/blob/master/Blog/Python/JupyterNotebook/matplotlib.korea_font.ipynb</a></p>
<p>이 예제코드도 <a href="https://www.facebook.com/zzonee" target="_blank" rel="external">박조은</a>님의 <a href="https://programmers.co.kr/learn/courses/21/lessons/950" target="_blank" rel="external">강의 : Matplotlib에서 한글 폰트 사용하기</a>를 참고한 것이다.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://DevStarSJ.github.io/2018/10/13/jupyter.matplotlib.korean.font/" data-id="cjov1wtr0008fjw7b2qq8kyfh" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/JupyterNotebook/">JupyterNotebook</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Matplotlib/">Matplotlib</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/한글폰트/">한글폰트</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="extend next" rel="next" href="/page/2/">__('next') &raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/AWS/">AWS</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/AWS/ECS/">ECS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/AWS/Lambda/">Lambda</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/AWS/SageMaker/">SageMaker</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Azure/">Azure</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Book/">Book</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Book/Review/">Review</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/C/">C#</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/C/ASP-NET/">ASP.NET</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/C/ASP-NET-Core/">ASP.NET Core</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/C/C/">C#</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/CPP/">CPP</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/CPP/MFC/">MFC</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/DataScience/">DataScience</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Database/">Database</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Database/Oracle/">Oracle</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Database/SQLP/">SQLP</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/DevOps/">DevOps</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/JavaScript/">JavaScript</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/JavaScript/Node-JS/">Node.JS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/JavaScript/TypeScript/">TypeScript</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Python/DataScience/">DataScience</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/Python/">Python</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tips/">Tips</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Tips/JupyterNotebook/">JupyterNotebook</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tips/macOS/">macOS</a></li></ul></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/APIGateway/">APIGateway</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ASP-NET/">ASP.NET</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ASP-NET-Core/">ASP.NET Core</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/AWS/">AWS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Azure/">Azure</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/AzureContainerRegistry/">AzureContainerRegistry</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/AzureContainerService/">AzureContainerService</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/AzureFileStorage/">AzureFileStorage</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/AzureFunction/">AzureFunction</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Batch/">Batch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Book/">Book</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/C/">C#</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CI-CD/">CI/CD</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CPP/">CPP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DataScience/">DataScience</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Database/">Database</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DevOps/">DevOps</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Docker/">Docker</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ECS/">ECS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HyperparameterTuning/">HyperparameterTuning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JavaScript/">JavaScript</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Jenkins/">Jenkins</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JupyterNotebook/">JupyterNotebook</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kaggle/">Kaggle</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Lambda/">Lambda</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MFC/">MFC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MachineLearning/">MachineLearning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Matplotlib/">Matplotlib</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Node-JS/">Node.JS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Node-js/">Node.js</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Oracle/">Oracle</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Review/">Review</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/S3/">S3</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SIMD/">SIMD</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SQLP/">SQLP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SageMaker/">SageMaker</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Serverless/">Serverless</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tensorflow/">Tensorflow</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ToolkitPro/">ToolkitPro</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TypeScript/">TypeScript</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/UAC/">UAC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/XGBoost/">XGBoost</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/express/">express</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/macOS/">macOS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/한글폰트/">한글폰트</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/APIGateway/" style="font-size: 15px;">APIGateway</a> <a href="/tags/ASP-NET/" style="font-size: 13.57px;">ASP.NET</a> <a href="/tags/ASP-NET-Core/" style="font-size: 12.14px;">ASP.NET Core</a> <a href="/tags/AWS/" style="font-size: 19.29px;">AWS</a> <a href="/tags/Azure/" style="font-size: 10.71px;">Azure</a> <a href="/tags/AzureContainerRegistry/" style="font-size: 10px;">AzureContainerRegistry</a> <a href="/tags/AzureContainerService/" style="font-size: 10px;">AzureContainerService</a> <a href="/tags/AzureFileStorage/" style="font-size: 10.71px;">AzureFileStorage</a> <a href="/tags/AzureFunction/" style="font-size: 10px;">AzureFunction</a> <a href="/tags/Batch/" style="font-size: 10px;">Batch</a> <a href="/tags/Book/" style="font-size: 16.43px;">Book</a> <a href="/tags/C/" style="font-size: 18.57px;">C#</a> <a href="/tags/CI-CD/" style="font-size: 11.43px;">CI/CD</a> <a href="/tags/CPP/" style="font-size: 13.57px;">CPP</a> <a href="/tags/DataScience/" style="font-size: 15.71px;">DataScience</a> <a href="/tags/Database/" style="font-size: 20px;">Database</a> <a href="/tags/DevOps/" style="font-size: 11.43px;">DevOps</a> <a href="/tags/Docker/" style="font-size: 10.71px;">Docker</a> <a href="/tags/ECS/" style="font-size: 10px;">ECS</a> <a href="/tags/HyperparameterTuning/" style="font-size: 10px;">HyperparameterTuning</a> <a href="/tags/JavaScript/" style="font-size: 11.43px;">JavaScript</a> <a href="/tags/Jenkins/" style="font-size: 10px;">Jenkins</a> <a href="/tags/JupyterNotebook/" style="font-size: 11.43px;">JupyterNotebook</a> <a href="/tags/Kaggle/" style="font-size: 14.29px;">Kaggle</a> <a href="/tags/Lambda/" style="font-size: 17.86px;">Lambda</a> <a href="/tags/MFC/" style="font-size: 13.57px;">MFC</a> <a href="/tags/MachineLearning/" style="font-size: 17.14px;">MachineLearning</a> <a href="/tags/Matplotlib/" style="font-size: 10px;">Matplotlib</a> <a href="/tags/Node-JS/" style="font-size: 12.86px;">Node.JS</a> <a href="/tags/Node-js/" style="font-size: 10px;">Node.js</a> <a href="/tags/Oracle/" style="font-size: 20px;">Oracle</a> <a href="/tags/Python/" style="font-size: 16.43px;">Python</a> <a href="/tags/Review/" style="font-size: 16.43px;">Review</a> <a href="/tags/S3/" style="font-size: 10px;">S3</a> <a href="/tags/SIMD/" style="font-size: 10px;">SIMD</a> <a href="/tags/SQLP/" style="font-size: 20px;">SQLP</a> <a href="/tags/SageMaker/" style="font-size: 10px;">SageMaker</a> <a href="/tags/Serverless/" style="font-size: 12.14px;">Serverless</a> <a href="/tags/Tensorflow/" style="font-size: 12.14px;">Tensorflow</a> <a href="/tags/ToolkitPro/" style="font-size: 10.71px;">ToolkitPro</a> <a href="/tags/TypeScript/" style="font-size: 10.71px;">TypeScript</a> <a href="/tags/UAC/" style="font-size: 10px;">UAC</a> <a href="/tags/XGBoost/" style="font-size: 10px;">XGBoost</a> <a href="/tags/express/" style="font-size: 10px;">express</a> <a href="/tags/macOS/" style="font-size: 10px;">macOS</a> <a href="/tags/한글폰트/" style="font-size: 10px;">한글폰트</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">July 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">May 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">April 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">February 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">January 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">December 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">June 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/04/">April 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">March 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">February 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">January 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">December 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">November 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/10/">October 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/06/">June 2013</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/11/24/aws-batch-tutorial/">Introduce to AWS Batch</a>
          </li>
        
          <li>
            <a href="/2018/11/04/kaggle.coursera.competition.03.02/">Coursera Kaggle 강의(How to win a data science competition) week 3,4 Advanced Feature Engineering 요약</a>
          </li>
        
          <li>
            <a href="/2018/10/30/kaggle.coursera.competition.04.02/">Coursera Kaggle 강의(How to win a data science competition) week 4-4 Ensemble 요약</a>
          </li>
        
          <li>
            <a href="/2018/10/30/kaggle.coursera.competition.04.01/">Coursera Kaggle 강의(How to win a data science competition) week 4-1 Hyperparameter Tuning 요약</a>
          </li>
        
          <li>
            <a href="/2018/10/30/181030.data.philosophy/">데이터를 철학하다</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Yun Seok-joon<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>